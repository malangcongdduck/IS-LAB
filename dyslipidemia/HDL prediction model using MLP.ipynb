{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUN, Chol 넣고 psqi 세부 항목 지우고 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sample_ID GROUP  COHORT SEX  AGE     Trait FitbitOX      Fitbit_ID  HTN  \\\n",
      "0         S0001   SMI       2   M   60  fitbit_O        O  sevrance00001  NaN   \n",
      "1         S0002   SMI       2   M   61  fitbit_O        O  sevrance00002  NaN   \n",
      "2         S0003   SMI       2   F   52  fitbit_O        O  sevrance00003  NaN   \n",
      "3         S0004   SMI       2   F   41  fitbit_O        O  sevrance00004  NaN   \n",
      "4         S0005   SMI       2   F   41  fitbit_O        O  sevrance00005  NaN   \n",
      "..          ...   ...     ...  ..  ...       ...      ...            ...  ...   \n",
      "383  MetS_S0280  MetS       1   F   24  fitbit_O        O   gnfmmets+139  NaN   \n",
      "384  MetS_S0281  MetS       1   F   44  fitbit_O        O   gnfmmets+140  NaN   \n",
      "385  MetS_S0282  MetS       1   F   37  fitbit_O        O   gnfmmets+141  1.0   \n",
      "386  MetS_S0283  MetS       1   M   51  fitbit_X        X              X  NaN   \n",
      "387  MetS_S0284  MetS       1   F   42  fitbit_X        X              X  NaN   \n",
      "\n",
      "      DM  ...  BDI_Q13_2 BDI_Q14_2  BDI_Q15_2  BDI_Q16_2 BDI_Q17_2 BDI_Q18_2  \\\n",
      "0    NaN  ...        1.0       1.0        1.0        2.0       1.0       1.0   \n",
      "1    1.0  ...        1.0       1.0        1.0        1.0       2.0       1.0   \n",
      "2    NaN  ...        1.0       1.0        1.0        1.0       1.0       1.0   \n",
      "3    NaN  ...        2.0       2.0        2.0        2.0       2.0       2.0   \n",
      "4    NaN  ...        2.0       1.0        2.0        2.0       2.0       1.0   \n",
      "..   ...  ...        ...       ...        ...        ...       ...       ...   \n",
      "383  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "384  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "385  1.0  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "386  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "387  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "\n",
      "     BDI_Q19_2  BDI_Q20_2  BDI_Q21_2  Diet_2  \n",
      "0          2.0        1.0        2.0     2.0  \n",
      "1          1.0        1.0        1.0     2.0  \n",
      "2          1.0        2.0        4.0     1.0  \n",
      "3          1.0        1.0        1.0     2.0  \n",
      "4          1.0        2.0        1.0     2.0  \n",
      "..         ...        ...        ...     ...  \n",
      "383        NaN        NaN        NaN     NaN  \n",
      "384        NaN        NaN        NaN     NaN  \n",
      "385        NaN        NaN        NaN     NaN  \n",
      "386        NaN        NaN        NaN     NaN  \n",
      "387        NaN        NaN        NaN     NaN  \n",
      "\n",
      "[388 rows x 3527 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('./최종 데이터 그래프그리기용.xlsx') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df=df[['Sample_ID','GROUP','COHORT','AGE','SEX',\n",
    "            'BMI_1','PSQI_TOTAL_1','Insulin _1','CRP_1','WBC_1','Neutrophil_1','Lym_1','GLU0_1','Creatinine_1','AST_1','ALT_1','TG_1','LDL_1','Muscle_1','Fat_1_x','FatPercentage _1','WHR_1','SBP_1',\n",
    "            'DBP_1','HR_1','Waist_1','HDL_1','BUN_1','Chol_1',\n",
    "          'BMI_2','PSQI_TOTAL_2','Insulin _2','CRP_2','WBC_2','Neutrophil_2','Lym_2','GLU0_2',\n",
    "            'Creatinine_2','AST_2','ALT_2','TG_2','LDL_2','Muscle_2','Fat_2_x','FatPercentage_2','WHR_2','SBP_2',\n",
    "            'DBP_2','HR_2','Waist_2','HDL_2','BUN_2','Chol_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>HDL_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>Chol_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.89</td>\n",
       "      <td>108.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.51</td>\n",
       "      <td>...</td>\n",
       "      <td>19.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>0.99</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>90.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.85</td>\n",
       "      <td>...</td>\n",
       "      <td>22.6</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>127.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.14</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.82</td>\n",
       "      <td>119.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.93</td>\n",
       "      <td>...</td>\n",
       "      <td>14.9</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>110.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>66.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.82</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.67</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.03</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT  AGE SEX      BMI_1  PSQI_TOTAL_1 Insulin _1  \\\n",
       "0         S0001   SMI       2   60   M  21.110190           8.0        7.7   \n",
       "1         S0002   SMI       2   61   M  27.782064           4.0        5.4   \n",
       "2         S0003   SMI       2   52   F  24.944742           3.0        5.1   \n",
       "3         S0004   SMI       2   41   F  22.620489           6.0        4.2   \n",
       "4         S0005   SMI       2   41   F  20.524157          10.0        3.2   \n",
       "..          ...   ...     ...  ...  ..        ...           ...        ...   \n",
       "383  MetS_S0280  MetS       1   24   F  34.803410           5.0       11.3   \n",
       "384  MetS_S0281  MetS       1   44   F  30.903615           3.0       10.6   \n",
       "385  MetS_S0282  MetS       1   37   F  28.676533           3.0       12.2   \n",
       "386  MetS_S0283  MetS       1   51   M  24.549738           5.0       10.4   \n",
       "387  MetS_S0284  MetS       1   42   F  24.605921           3.0       10.1   \n",
       "\n",
       "    CRP_1  WBC_1  ...  Fat_2_x  FatPercentage_2  WHR_2  SBP_2  DBP_2  HR_2  \\\n",
       "0     0.2   3.91  ...      9.7             15.9   0.89  108.0   78.0  87.0   \n",
       "1     0.2   5.51  ...     19.9             27.9   0.99  138.0   92.0  73.0   \n",
       "2     0.7   4.85  ...     22.6             36.7   0.89  127.0   80.0  66.0   \n",
       "3     0.6   6.14  ...     16.0             30.9   0.82  119.0   83.0  77.0   \n",
       "4     0.1   4.93  ...     14.9             26.8   0.80  110.0   68.0  67.0   \n",
       "..    ...    ...  ...      ...              ...    ...    ...    ...   ...   \n",
       "383   0.4   5.32  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "384   2.3   5.82  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "385     1   6.18  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "386   1.2   6.67  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "387   0.8   7.03  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "\n",
       "     Waist_2  HDL_2  BUN_2  Chol_2  \n",
       "0       83.0   77.0   13.1     NaN  \n",
       "1       90.5   59.0   19.2     NaN  \n",
       "2       86.5   40.0   17.1     NaN  \n",
       "3       77.0   54.0   12.2     NaN  \n",
       "4       66.5   72.0   16.5     NaN  \n",
       "..       ...    ...    ...     ...  \n",
       "383      NaN    NaN    NaN     NaN  \n",
       "384      NaN    NaN    NaN     NaN  \n",
       "385      NaN    NaN    NaN     NaN  \n",
       "386      NaN    NaN    NaN     NaN  \n",
       "387      NaN    NaN    NaN     NaN  \n",
       "\n",
       "[388 rows x 53 columns]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>HDL_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>Chol_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.89</td>\n",
       "      <td>108.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.51</td>\n",
       "      <td>...</td>\n",
       "      <td>19.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>0.99</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>90.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.85</td>\n",
       "      <td>...</td>\n",
       "      <td>22.6</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>127.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.14</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.82</td>\n",
       "      <td>119.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.93</td>\n",
       "      <td>...</td>\n",
       "      <td>14.9</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>110.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>66.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.82</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.67</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.03</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT  AGE SEX      BMI_1  PSQI_TOTAL_1 Insulin _1  \\\n",
       "0         S0001   SMI       2   60   M  21.110190           8.0        7.7   \n",
       "1         S0002   SMI       2   61   M  27.782064           4.0        5.4   \n",
       "2         S0003   SMI       2   52   F  24.944742           3.0        5.1   \n",
       "3         S0004   SMI       2   41   F  22.620489           6.0        4.2   \n",
       "4         S0005   SMI       2   41   F  20.524157          10.0        3.2   \n",
       "..          ...   ...     ...  ...  ..        ...           ...        ...   \n",
       "383  MetS_S0280  MetS       1   24   F  34.803410           5.0       11.3   \n",
       "384  MetS_S0281  MetS       1   44   F  30.903615           3.0       10.6   \n",
       "385  MetS_S0282  MetS       1   37   F  28.676533           3.0       12.2   \n",
       "386  MetS_S0283  MetS       1   51   M  24.549738           5.0       10.4   \n",
       "387  MetS_S0284  MetS       1   42   F  24.605921           3.0       10.1   \n",
       "\n",
       "    CRP_1  WBC_1  ...  Fat_2_x  FatPercentage_2  WHR_2  SBP_2  DBP_2  HR_2  \\\n",
       "0     0.2   3.91  ...      9.7             15.9   0.89  108.0   78.0  87.0   \n",
       "1     0.2   5.51  ...     19.9             27.9   0.99  138.0   92.0  73.0   \n",
       "2     0.7   4.85  ...     22.6             36.7   0.89  127.0   80.0  66.0   \n",
       "3     0.6   6.14  ...     16.0             30.9   0.82  119.0   83.0  77.0   \n",
       "4     0.1   4.93  ...     14.9             26.8   0.80  110.0   68.0  67.0   \n",
       "..    ...    ...  ...      ...              ...    ...    ...    ...   ...   \n",
       "383   0.4   5.32  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "384   2.3   5.82  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "385     1   6.18  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "386   1.2   6.67  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "387   0.8   7.03  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "\n",
       "     Waist_2  HDL_2  BUN_2  Chol_2  \n",
       "0       83.0   77.0   13.1     NaN  \n",
       "1       90.5   59.0   19.2     NaN  \n",
       "2       86.5   40.0   17.1     NaN  \n",
       "3       77.0   54.0   12.2     NaN  \n",
       "4       66.5   72.0   16.5     NaN  \n",
       "..       ...    ...    ...     ...  \n",
       "383      NaN    NaN    NaN     NaN  \n",
       "384      NaN    NaN    NaN     NaN  \n",
       "385      NaN    NaN    NaN     NaN  \n",
       "386      NaN    NaN    NaN     NaN  \n",
       "387      NaN    NaN    NaN     NaN  \n",
       "\n",
       "[317 rows x 53 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#보조 호르몬 요법을 받고 있는 Cohort 3 제거 Filter 적용\n",
    "psqi_df = psqi_df[(psqi_df['COHORT'] != 3)]\n",
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df=psqi_df.dropna()\n",
    "psqi_df.reset_index(drop=True, inplace=True)\n",
    "psqi_df=psqi_df.drop([\"Sample_ID\", \"GROUP\", \"COHORT\"],axis=1)\n",
    "#1분, 매일다름, 정해진간이없음 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"SEX\"] = psqi_df[\"SEX\"].apply(lambda x: 1. if x=='M' else 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"Insulin _1\"] = psqi_df[\"Insulin _1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)\n",
    "psqi_df[\"Insulin _2\"] = psqi_df[\"Insulin _2\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"CRP_1\"] = psqi_df[\"CRP_1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)\n",
    "psqi_df[\"CRP_2\"] = psqi_df[\"CRP_2\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>Neutrophil_1</th>\n",
       "      <th>Lym_1</th>\n",
       "      <th>GLU0_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>HDL_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>Chol_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.00000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.366667</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>23.799644</td>\n",
       "      <td>5.105556</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.748889</td>\n",
       "      <td>5.844867</td>\n",
       "      <td>56.086111</td>\n",
       "      <td>34.113333</td>\n",
       "      <td>98.90000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.053333</td>\n",
       "      <td>28.888333</td>\n",
       "      <td>0.862444</td>\n",
       "      <td>114.605556</td>\n",
       "      <td>72.477778</td>\n",
       "      <td>75.644444</td>\n",
       "      <td>81.328889</td>\n",
       "      <td>59.20000</td>\n",
       "      <td>12.984444</td>\n",
       "      <td>190.922222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.589776</td>\n",
       "      <td>0.461927</td>\n",
       "      <td>4.936177</td>\n",
       "      <td>2.893833</td>\n",
       "      <td>4.105985</td>\n",
       "      <td>1.344157</td>\n",
       "      <td>1.412280</td>\n",
       "      <td>8.502880</td>\n",
       "      <td>7.708889</td>\n",
       "      <td>14.43773</td>\n",
       "      <td>...</td>\n",
       "      <td>6.616151</td>\n",
       "      <td>7.098802</td>\n",
       "      <td>0.071696</td>\n",
       "      <td>13.213544</td>\n",
       "      <td>9.091991</td>\n",
       "      <td>10.306814</td>\n",
       "      <td>10.251265</td>\n",
       "      <td>14.01372</td>\n",
       "      <td>3.508550</td>\n",
       "      <td>32.017358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.231576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.820000</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>63.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>29.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.833309</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.857500</td>\n",
       "      <td>50.525000</td>\n",
       "      <td>28.975000</td>\n",
       "      <td>92.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>24.275000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>73.875000</td>\n",
       "      <td>49.00000</td>\n",
       "      <td>10.675000</td>\n",
       "      <td>167.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.422889</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>5.720000</td>\n",
       "      <td>55.950000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>95.50000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.950000</td>\n",
       "      <td>28.450000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>80.500000</td>\n",
       "      <td>57.00000</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.502662</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.505000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>6.580000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>102.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.125000</td>\n",
       "      <td>33.450000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>77.250000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>69.00000</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>10.550000</td>\n",
       "      <td>78.400000</td>\n",
       "      <td>55.400000</td>\n",
       "      <td>182.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>46.100000</td>\n",
       "      <td>48.300000</td>\n",
       "      <td>1.070000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>116.00000</td>\n",
       "      <td>36.400000</td>\n",
       "      <td>296.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              AGE         SEX       BMI_1  PSQI_TOTAL_1  Insulin _1  \\\n",
       "count  180.000000  180.000000  180.000000    180.000000  180.000000   \n",
       "mean    38.366667    0.305556   23.799644      5.105556    7.700000   \n",
       "std     11.589776    0.461927    4.936177      2.893833    4.105985   \n",
       "min     20.000000    0.000000   15.231576      0.000000    0.100000   \n",
       "25%     29.000000    0.000000   20.833309      3.000000    5.000000   \n",
       "50%     35.500000    0.000000   23.422889      5.000000    6.500000   \n",
       "75%     46.000000    1.000000   25.502662      7.000000    9.505000   \n",
       "max     63.000000    1.000000   67.500000     14.000000   24.700000   \n",
       "\n",
       "            CRP_1       WBC_1  Neutrophil_1       Lym_1     GLU0_1  ...  \\\n",
       "count  180.000000  180.000000    180.000000  180.000000  180.00000  ...   \n",
       "mean     0.748889    5.844867     56.086111   34.113333   98.90000  ...   \n",
       "std      1.344157    1.412280      8.502880    7.708889   14.43773  ...   \n",
       "min      0.000000    2.820000     34.500000   15.100000   63.00000  ...   \n",
       "25%      0.200000    4.857500     50.525000   28.975000   92.00000  ...   \n",
       "50%      0.300000    5.720000     55.950000   34.000000   95.50000  ...   \n",
       "75%      0.700000    6.580000     62.000000   39.000000  102.00000  ...   \n",
       "max     11.100000   10.550000     78.400000   55.400000  182.00000  ...   \n",
       "\n",
       "          Fat_2_x  FatPercentage_2       WHR_2       SBP_2       DBP_2  \\\n",
       "count  180.000000       180.000000  180.000000  180.000000  180.000000   \n",
       "mean    19.053333        28.888333    0.862444  114.605556   72.477778   \n",
       "std      6.616151         7.098802    0.071696   13.213544    9.091991   \n",
       "min      7.700000        11.500000    0.700000   91.000000   57.000000   \n",
       "25%     14.200000        24.275000    0.820000  104.000000   67.000000   \n",
       "50%     17.950000        28.450000    0.850000  114.000000   71.000000   \n",
       "75%     22.125000        33.450000    0.900000  123.000000   77.250000   \n",
       "max     46.100000        48.300000    1.070000  158.000000  107.000000   \n",
       "\n",
       "             HR_2     Waist_2      HDL_2       BUN_2      Chol_2  \n",
       "count  180.000000  180.000000  180.00000  180.000000  180.000000  \n",
       "mean    75.644444   81.328889   59.20000   12.984444  190.922222  \n",
       "std     10.306814   10.251265   14.01372    3.508550   32.017358  \n",
       "min     54.000000   61.000000   29.00000    6.000000  109.000000  \n",
       "25%     68.000000   73.875000   49.00000   10.675000  167.750000  \n",
       "50%     75.000000   80.500000   57.00000   12.700000  188.000000  \n",
       "75%     82.000000   89.000000   69.00000   14.600000  211.000000  \n",
       "max    112.000000  118.000000  116.00000   36.400000  296.000000  \n",
       "\n",
       "[8 rows x 50 columns]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    125\n",
       "1.0     55\n",
       "Name: SEX, dtype: int64"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df[\"SEX\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>Neutrophil_1</th>\n",
       "      <th>Lym_1</th>\n",
       "      <th>GLU0_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>HDL_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>Chol_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.097789</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.82</td>\n",
       "      <td>54.6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>20.4</td>\n",
       "      <td>26.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>131.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>88.5</td>\n",
       "      <td>53.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.472213</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.46</td>\n",
       "      <td>44.3</td>\n",
       "      <td>43.7</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>126.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.744827</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.26</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.99</td>\n",
       "      <td>51.0</td>\n",
       "      <td>37.8</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>17.8</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.89</td>\n",
       "      <td>131.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.616175</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.84</td>\n",
       "      <td>39.1</td>\n",
       "      <td>42.1</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>12.8</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.78</td>\n",
       "      <td>102.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.437500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.22</td>\n",
       "      <td>49.3</td>\n",
       "      <td>39.3</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>12.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>106.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.259585</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.78</td>\n",
       "      <td>42.3</td>\n",
       "      <td>47.3</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>27.3</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.94</td>\n",
       "      <td>134.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.630719</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.60</td>\n",
       "      <td>51.7</td>\n",
       "      <td>34.6</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>22.1</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.95</td>\n",
       "      <td>113.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>51.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.641274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.34</td>\n",
       "      <td>55.9</td>\n",
       "      <td>34.9</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>17.5</td>\n",
       "      <td>29.9</td>\n",
       "      <td>0.84</td>\n",
       "      <td>107.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>80.5</td>\n",
       "      <td>49.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.421366</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.88</td>\n",
       "      <td>40.9</td>\n",
       "      <td>48.0</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>15.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>106.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.271653</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.28</td>\n",
       "      <td>75.7</td>\n",
       "      <td>15.1</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>9.3</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>104.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGE  SEX      BMI_1  PSQI_TOTAL_1  Insulin _1  CRP_1  WBC_1  \\\n",
       "0     35  1.0  24.097789           5.0        5.57    0.0   5.82   \n",
       "1     46  1.0  23.472213           5.0        7.35    0.7   5.46   \n",
       "2     32  1.0  23.744827           2.0        9.26    0.4   3.99   \n",
       "3     33  0.0  20.616175           4.0        3.52    0.0   5.84   \n",
       "4     28  0.0  18.437500           3.0        2.86    0.0   4.22   \n",
       "..   ...  ...        ...           ...         ...    ...    ...   \n",
       "175   63  0.0  26.259585           3.0        4.20    0.2   4.78   \n",
       "176   57  1.0  28.630719           4.0        8.80    3.0   4.60   \n",
       "177   35  0.0  21.641274           1.0        6.30    0.4   6.34   \n",
       "178   61  0.0  20.421366           8.0        4.80    0.2   4.88   \n",
       "179   56  1.0  22.271653           1.0        9.00    0.2   6.28   \n",
       "\n",
       "     Neutrophil_1  Lym_1  GLU0_1  ...  Fat_2_x  FatPercentage_2  WHR_2  SBP_2  \\\n",
       "0            54.6   35.0      89  ...     20.4             26.8   1.00  131.0   \n",
       "1            44.3   43.7      90  ...     14.5             18.6   0.84  126.0   \n",
       "2            51.0   37.8      96  ...     17.8             25.6   0.89  131.0   \n",
       "3            39.1   42.1      81  ...     12.8             21.9   0.78  102.0   \n",
       "4            49.3   39.3      63  ...     12.3             25.6   0.80  106.0   \n",
       "..            ...    ...     ...  ...      ...              ...    ...    ...   \n",
       "175          42.3   47.3      96  ...     27.3             39.3   0.94  134.0   \n",
       "176          51.7   34.6      94  ...     22.1             25.7   0.95  113.0   \n",
       "177          55.9   34.9      87  ...     17.5             29.9   0.84  107.0   \n",
       "178          40.9   48.0      93  ...     15.3             29.0   0.81  106.0   \n",
       "179          75.7   15.1     125  ...      9.3             13.1   0.85  104.0   \n",
       "\n",
       "     DBP_2   HR_2  Waist_2  HDL_2  BUN_2  Chol_2  \n",
       "0     74.0   66.0     88.5   53.0   17.5   180.0  \n",
       "1     87.0  108.0     85.0   64.0   14.4   203.0  \n",
       "2     77.0   87.0     81.0   49.0   14.1   196.0  \n",
       "3     62.0   70.0     69.0   98.0   10.5   224.0  \n",
       "4     72.0   69.0     61.0   71.0   11.3   168.0  \n",
       "..     ...    ...      ...    ...    ...     ...  \n",
       "175   89.0   81.0     98.0   66.0   17.1   141.0  \n",
       "176   76.0   66.0     97.5   51.0   14.6   134.0  \n",
       "177   72.0   64.0     80.5   49.0    9.7   147.0  \n",
       "178   76.0   92.0     79.0   60.0   10.2   134.0  \n",
       "179   73.0   79.0     91.0   31.0   36.4   148.0  \n",
       "\n",
       "[180 rows x 50 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HDL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>360 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      HDL\n",
       "0    57.0\n",
       "1    68.0\n",
       "2    46.0\n",
       "3    96.0\n",
       "4    62.0\n",
       "..    ...\n",
       "175  66.0\n",
       "176  51.0\n",
       "177  49.0\n",
       "178  60.0\n",
       "179  31.0\n",
       "\n",
       "[360 rows x 1 columns]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_value_1=psqi_df[['HDL_1']]\n",
    "data_value_2=psqi_df[['HDL_2']]\n",
    "data_value_1.columns = ['HDL']\n",
    "data_value_2.columns = ['HDL']\n",
    "data_value=pd.concat([data_value_1, data_value_2],axis=0)\n",
    "data_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HDL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>59.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.287839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>58.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>69.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>116.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              HDL\n",
       "count  360.000000\n",
       "mean    59.950000\n",
       "std     14.287839\n",
       "min     28.000000\n",
       "25%     50.000000\n",
       "50%     58.000000\n",
       "75%     69.000000\n",
       "max    116.000000"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_value.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data 분포도 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDL 20-29: 2\n",
      "HDL 30-39: 12\n",
      "HDL 40-49: 75\n",
      "HDL 50-59: 109\n",
      "HDL 60-69: 77\n",
      "HDL 70-79: 53\n",
      "HDL 80-89: 21\n",
      "HDL 90-99: 8\n",
      "HDL 100-109: 1\n",
      "HDL 110-119: 2\n"
     ]
    }
   ],
   "source": [
    "data=data_value.values\n",
    "HDL_label=[[0] for _ in range(10)]\n",
    "for i in data:\n",
    "    value=float(i)\n",
    "    if 20 <= i <= 29:\n",
    "        HDL_label[0].append(i)\n",
    "    elif 30 <= i <= 39:\n",
    "        HDL_label[1].append(i)\n",
    "    elif 40 <= i <= 49:\n",
    "        HDL_label[2].append(i)\n",
    "    elif 50 <= i <= 59:\n",
    "        HDL_label[3].append(i)\n",
    "    elif 60 <= i <= 69:\n",
    "        HDL_label[4].append(i)\n",
    "    elif 70 <= i <= 79:\n",
    "        HDL_label[5].append(i)\n",
    "    elif 80 <= i <= 89:\n",
    "        HDL_label[6].append(i)\n",
    "    elif 90 <= i <= 99:\n",
    "        HDL_label[7].append(i)\n",
    "    elif 100 <= i <= 109:\n",
    "        HDL_label[8].append(i)\n",
    "    elif 110 <= i <= 119:\n",
    "        HDL_label[9].append(i)\n",
    "num1=20\n",
    "num2=29\n",
    "for i in range(len(HDL_label)):\n",
    "    HDL_label[i].pop(0)\n",
    "    print(f\"HDL {num1}-{num2}:\",len(HDL_label[i]))\n",
    "    num1+=10\n",
    "    num2+=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 피검사  안하고 넣을 수 있는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (피검사안하고 얻을 수 있는 것)\n",
    "X1=psqi_df[['SEX','AGE','PSQI_TOTAL_1','BMI_1','WHR_1',\n",
    "            'Muscle_1','Fat_1_x','FatPercentage _1','SBP_1','DBP_1','HR_1','Waist_1']].values\n",
    "X2=psqi_df[['SEX','AGE','PSQI_TOTAL_2','BMI_2','WHR_2',\n",
    "            'Muscle_2','Fat_2_x','FatPercentage_2','SBP_2','DBP_2','HR_2','Waist_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 72)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 12), (360, 1))"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "72/72 - 0s - loss: 3445.2881 - mse: 3445.2881\n",
      "Epoch 2/150\n",
      "72/72 - 0s - loss: 2814.7090 - mse: 2814.7090\n",
      "Epoch 3/150\n",
      "72/72 - 0s - loss: 1865.6669 - mse: 1865.6669\n",
      "Epoch 4/150\n",
      "72/72 - 0s - loss: 939.9670 - mse: 939.9670\n",
      "Epoch 5/150\n",
      "72/72 - 0s - loss: 383.0261 - mse: 383.0261\n",
      "Epoch 6/150\n",
      "72/72 - 0s - loss: 251.5765 - mse: 251.5765\n",
      "Epoch 7/150\n",
      "72/72 - 0s - loss: 227.6738 - mse: 227.6738\n",
      "Epoch 8/150\n",
      "72/72 - 0s - loss: 213.4165 - mse: 213.4165\n",
      "Epoch 9/150\n",
      "72/72 - 0s - loss: 203.6831 - mse: 203.6831\n",
      "Epoch 10/150\n",
      "72/72 - 0s - loss: 195.0960 - mse: 195.0960\n",
      "Epoch 11/150\n",
      "72/72 - 0s - loss: 188.3390 - mse: 188.3390\n",
      "Epoch 12/150\n",
      "72/72 - 0s - loss: 181.1553 - mse: 181.1553\n",
      "Epoch 13/150\n",
      "72/72 - 0s - loss: 176.7669 - mse: 176.7669\n",
      "Epoch 14/150\n",
      "72/72 - 0s - loss: 173.0049 - mse: 173.0049\n",
      "Epoch 15/150\n",
      "72/72 - 0s - loss: 168.4250 - mse: 168.4250\n",
      "Epoch 16/150\n",
      "72/72 - 0s - loss: 166.2608 - mse: 166.2608\n",
      "Epoch 17/150\n",
      "72/72 - 0s - loss: 162.1033 - mse: 162.1033\n",
      "Epoch 18/150\n",
      "72/72 - 0s - loss: 160.2250 - mse: 160.2250\n",
      "Epoch 19/150\n",
      "72/72 - 0s - loss: 157.0445 - mse: 157.0445\n",
      "Epoch 20/150\n",
      "72/72 - 0s - loss: 155.3762 - mse: 155.3762\n",
      "Epoch 21/150\n",
      "72/72 - 0s - loss: 153.1601 - mse: 153.1601\n",
      "Epoch 22/150\n",
      "72/72 - 0s - loss: 151.6428 - mse: 151.6428\n",
      "Epoch 23/150\n",
      "72/72 - 0s - loss: 150.5769 - mse: 150.5769\n",
      "Epoch 24/150\n",
      "72/72 - 0s - loss: 148.2738 - mse: 148.2738\n",
      "Epoch 25/150\n",
      "72/72 - 0s - loss: 146.9473 - mse: 146.9473\n",
      "Epoch 26/150\n",
      "72/72 - 0s - loss: 145.8024 - mse: 145.8024\n",
      "Epoch 27/150\n",
      "72/72 - 0s - loss: 144.1246 - mse: 144.1246\n",
      "Epoch 28/150\n",
      "72/72 - 0s - loss: 142.9005 - mse: 142.9005\n",
      "Epoch 29/150\n",
      "72/72 - 0s - loss: 143.1077 - mse: 143.1077\n",
      "Epoch 30/150\n",
      "72/72 - 0s - loss: 140.5801 - mse: 140.5801\n",
      "Epoch 31/150\n",
      "72/72 - 0s - loss: 140.0145 - mse: 140.0145\n",
      "Epoch 32/150\n",
      "72/72 - 0s - loss: 140.4516 - mse: 140.4516\n",
      "Epoch 33/150\n",
      "72/72 - 0s - loss: 139.3232 - mse: 139.3232\n",
      "Epoch 34/150\n",
      "72/72 - 0s - loss: 137.8855 - mse: 137.8855\n",
      "Epoch 35/150\n",
      "72/72 - 0s - loss: 137.4602 - mse: 137.4602\n",
      "Epoch 36/150\n",
      "72/72 - 0s - loss: 136.5380 - mse: 136.5380\n",
      "Epoch 37/150\n",
      "72/72 - 0s - loss: 136.1308 - mse: 136.1308\n",
      "Epoch 38/150\n",
      "72/72 - 0s - loss: 133.1453 - mse: 133.1453\n",
      "Epoch 39/150\n",
      "72/72 - 0s - loss: 133.9706 - mse: 133.9706\n",
      "Epoch 40/150\n",
      "72/72 - 0s - loss: 134.4862 - mse: 134.4862\n",
      "Epoch 41/150\n",
      "72/72 - 0s - loss: 133.2488 - mse: 133.2488\n",
      "Epoch 42/150\n",
      "72/72 - 0s - loss: 133.3593 - mse: 133.3593\n",
      "Epoch 43/150\n",
      "72/72 - 0s - loss: 132.4221 - mse: 132.4221\n",
      "Epoch 44/150\n",
      "72/72 - 0s - loss: 130.8073 - mse: 130.8073\n",
      "Epoch 45/150\n",
      "72/72 - 0s - loss: 132.2084 - mse: 132.2084\n",
      "Epoch 46/150\n",
      "72/72 - 0s - loss: 129.2754 - mse: 129.2754\n",
      "Epoch 47/150\n",
      "72/72 - 0s - loss: 130.5684 - mse: 130.5684\n",
      "Epoch 48/150\n",
      "72/72 - 0s - loss: 129.7179 - mse: 129.7179\n",
      "Epoch 49/150\n",
      "72/72 - 0s - loss: 128.7996 - mse: 128.7996\n",
      "Epoch 50/150\n",
      "72/72 - 0s - loss: 128.6402 - mse: 128.6402\n",
      "Epoch 51/150\n",
      "72/72 - 0s - loss: 128.1351 - mse: 128.1351\n",
      "Epoch 52/150\n",
      "72/72 - 0s - loss: 126.9303 - mse: 126.9303\n",
      "Epoch 53/150\n",
      "72/72 - 0s - loss: 128.4895 - mse: 128.4895\n",
      "Epoch 54/150\n",
      "72/72 - 0s - loss: 127.4377 - mse: 127.4377\n",
      "Epoch 55/150\n",
      "72/72 - 0s - loss: 126.2455 - mse: 126.2455\n",
      "Epoch 56/150\n",
      "72/72 - 0s - loss: 127.1667 - mse: 127.1667\n",
      "Epoch 57/150\n",
      "72/72 - 0s - loss: 126.6517 - mse: 126.6517\n",
      "Epoch 58/150\n",
      "72/72 - 0s - loss: 126.0015 - mse: 126.0015\n",
      "Epoch 59/150\n",
      "72/72 - 0s - loss: 126.2693 - mse: 126.2693\n",
      "Epoch 60/150\n",
      "72/72 - 0s - loss: 124.1650 - mse: 124.1650\n",
      "Epoch 61/150\n",
      "72/72 - 0s - loss: 125.1519 - mse: 125.1519\n",
      "Epoch 62/150\n",
      "72/72 - 0s - loss: 122.9915 - mse: 122.9915\n",
      "Epoch 63/150\n",
      "72/72 - 0s - loss: 125.1221 - mse: 125.1221\n",
      "Epoch 64/150\n",
      "72/72 - 0s - loss: 123.9485 - mse: 123.9485\n",
      "Epoch 65/150\n",
      "72/72 - 0s - loss: 124.0037 - mse: 124.0037\n",
      "Epoch 66/150\n",
      "72/72 - 0s - loss: 121.3552 - mse: 121.3552\n",
      "Epoch 67/150\n",
      "72/72 - 0s - loss: 123.5190 - mse: 123.5190\n",
      "Epoch 68/150\n",
      "72/72 - 0s - loss: 122.9750 - mse: 122.9750\n",
      "Epoch 69/150\n",
      "72/72 - 0s - loss: 122.5717 - mse: 122.5717\n",
      "Epoch 70/150\n",
      "72/72 - 0s - loss: 122.6945 - mse: 122.6945\n",
      "Epoch 71/150\n",
      "72/72 - 0s - loss: 121.0321 - mse: 121.0321\n",
      "Epoch 72/150\n",
      "72/72 - 0s - loss: 121.7887 - mse: 121.7887\n",
      "Epoch 73/150\n",
      "72/72 - 0s - loss: 121.9941 - mse: 121.9941\n",
      "Epoch 74/150\n",
      "72/72 - 0s - loss: 119.5717 - mse: 119.5717\n",
      "Epoch 75/150\n",
      "72/72 - 0s - loss: 121.5637 - mse: 121.5637\n",
      "Epoch 76/150\n",
      "72/72 - 0s - loss: 120.7842 - mse: 120.7842\n",
      "Epoch 77/150\n",
      "72/72 - 0s - loss: 120.9271 - mse: 120.9271\n",
      "Epoch 78/150\n",
      "72/72 - 0s - loss: 120.1398 - mse: 120.1398\n",
      "Epoch 79/150\n",
      "72/72 - 0s - loss: 119.9248 - mse: 119.9248\n",
      "Epoch 80/150\n",
      "72/72 - 0s - loss: 120.0805 - mse: 120.0805\n",
      "Epoch 81/150\n",
      "72/72 - 0s - loss: 119.1044 - mse: 119.1044\n",
      "Epoch 82/150\n",
      "72/72 - 0s - loss: 119.4493 - mse: 119.4493\n",
      "Epoch 83/150\n",
      "72/72 - 0s - loss: 119.5109 - mse: 119.5109\n",
      "Epoch 84/150\n",
      "72/72 - 0s - loss: 118.9525 - mse: 118.9525\n",
      "Epoch 85/150\n",
      "72/72 - 0s - loss: 118.5297 - mse: 118.5297\n",
      "Epoch 86/150\n",
      "72/72 - 0s - loss: 117.6595 - mse: 117.6595\n",
      "Epoch 87/150\n",
      "72/72 - 0s - loss: 118.7645 - mse: 118.7645\n",
      "Epoch 88/150\n",
      "72/72 - 0s - loss: 117.7502 - mse: 117.7502\n",
      "Epoch 89/150\n",
      "72/72 - 0s - loss: 118.5935 - mse: 118.5935\n",
      "Epoch 90/150\n",
      "72/72 - 0s - loss: 117.2390 - mse: 117.2390\n",
      "Epoch 91/150\n",
      "72/72 - 0s - loss: 117.2535 - mse: 117.2535\n",
      "Epoch 92/150\n",
      "72/72 - 0s - loss: 117.2663 - mse: 117.2663\n",
      "Epoch 93/150\n",
      "72/72 - 0s - loss: 116.7561 - mse: 116.7561\n",
      "Epoch 94/150\n",
      "72/72 - 0s - loss: 117.2691 - mse: 117.2691\n",
      "Epoch 95/150\n",
      "72/72 - 0s - loss: 116.4448 - mse: 116.4448\n",
      "Epoch 96/150\n",
      "72/72 - 0s - loss: 117.0155 - mse: 117.0155\n",
      "Epoch 97/150\n",
      "72/72 - 0s - loss: 116.3316 - mse: 116.3316\n",
      "Epoch 98/150\n",
      "72/72 - 0s - loss: 114.3344 - mse: 114.3344\n",
      "Epoch 99/150\n",
      "72/72 - 0s - loss: 114.7918 - mse: 114.7918\n",
      "Epoch 100/150\n",
      "72/72 - 0s - loss: 114.0825 - mse: 114.0825\n",
      "Epoch 101/150\n",
      "72/72 - 0s - loss: 113.9802 - mse: 113.9802\n",
      "Epoch 102/150\n",
      "72/72 - 0s - loss: 114.7422 - mse: 114.7422\n",
      "Epoch 103/150\n",
      "72/72 - 0s - loss: 115.2318 - mse: 115.2318\n",
      "Epoch 104/150\n",
      "72/72 - 0s - loss: 114.1577 - mse: 114.1577\n",
      "Epoch 105/150\n",
      "72/72 - 0s - loss: 114.5816 - mse: 114.5816\n",
      "Epoch 106/150\n",
      "72/72 - 0s - loss: 113.4504 - mse: 113.4504\n",
      "Epoch 107/150\n",
      "72/72 - 0s - loss: 113.4342 - mse: 113.4342\n",
      "Epoch 108/150\n",
      "72/72 - 0s - loss: 113.7239 - mse: 113.7239\n",
      "Epoch 109/150\n",
      "72/72 - 0s - loss: 112.1298 - mse: 112.1298\n",
      "Epoch 110/150\n",
      "72/72 - 0s - loss: 113.6369 - mse: 113.6369\n",
      "Epoch 111/150\n",
      "72/72 - 0s - loss: 113.3167 - mse: 113.3167\n",
      "Epoch 112/150\n",
      "72/72 - 0s - loss: 110.9268 - mse: 110.9268\n",
      "Epoch 113/150\n",
      "72/72 - 0s - loss: 113.7393 - mse: 113.7393\n",
      "Epoch 114/150\n",
      "72/72 - 0s - loss: 113.1148 - mse: 113.1148\n",
      "Epoch 115/150\n",
      "72/72 - 0s - loss: 113.1023 - mse: 113.1023\n",
      "Epoch 116/150\n",
      "72/72 - 0s - loss: 112.9456 - mse: 112.9456\n",
      "Epoch 117/150\n",
      "72/72 - 0s - loss: 112.1938 - mse: 112.1938\n",
      "Epoch 118/150\n",
      "72/72 - 0s - loss: 112.2439 - mse: 112.2439\n",
      "Epoch 119/150\n",
      "72/72 - 0s - loss: 112.5000 - mse: 112.5000\n",
      "Epoch 120/150\n",
      "72/72 - 0s - loss: 111.6482 - mse: 111.6482\n",
      "Epoch 121/150\n",
      "72/72 - 0s - loss: 111.8619 - mse: 111.8619\n",
      "Epoch 122/150\n",
      "72/72 - 0s - loss: 111.2543 - mse: 111.2543\n",
      "Epoch 123/150\n",
      "72/72 - 0s - loss: 111.3049 - mse: 111.3049\n",
      "Epoch 124/150\n",
      "72/72 - 0s - loss: 111.6128 - mse: 111.6128\n",
      "Epoch 125/150\n",
      "72/72 - 0s - loss: 110.9923 - mse: 110.9923\n",
      "Epoch 126/150\n",
      "72/72 - 0s - loss: 110.9316 - mse: 110.9316\n",
      "Epoch 127/150\n",
      "72/72 - 0s - loss: 110.8508 - mse: 110.8508\n",
      "Epoch 128/150\n",
      "72/72 - 0s - loss: 110.8288 - mse: 110.8288\n",
      "Epoch 129/150\n",
      "72/72 - 0s - loss: 111.0202 - mse: 111.0202\n",
      "Epoch 130/150\n",
      "72/72 - 0s - loss: 110.1882 - mse: 110.1882\n",
      "Epoch 131/150\n",
      "72/72 - 0s - loss: 109.9640 - mse: 109.9640\n",
      "Epoch 132/150\n",
      "72/72 - 0s - loss: 109.9504 - mse: 109.9504\n",
      "Epoch 133/150\n",
      "72/72 - 0s - loss: 109.2350 - mse: 109.2350\n",
      "Epoch 134/150\n",
      "72/72 - 0s - loss: 109.3459 - mse: 109.3459\n",
      "Epoch 135/150\n",
      "72/72 - 0s - loss: 109.1332 - mse: 109.1332\n",
      "Epoch 136/150\n",
      "72/72 - 0s - loss: 108.4839 - mse: 108.4839\n",
      "Epoch 137/150\n",
      "72/72 - 0s - loss: 109.2528 - mse: 109.2528\n",
      "Epoch 138/150\n",
      "72/72 - 0s - loss: 108.2575 - mse: 108.2575\n",
      "Epoch 139/150\n",
      "72/72 - 0s - loss: 108.8281 - mse: 108.8281\n",
      "Epoch 140/150\n",
      "72/72 - 0s - loss: 107.7537 - mse: 107.7537\n",
      "Epoch 141/150\n",
      "72/72 - 0s - loss: 108.4927 - mse: 108.4927\n",
      "Epoch 142/150\n",
      "72/72 - 0s - loss: 108.6797 - mse: 108.6797\n",
      "Epoch 143/150\n",
      "72/72 - 0s - loss: 108.1646 - mse: 108.1646\n",
      "Epoch 144/150\n",
      "72/72 - 0s - loss: 105.8718 - mse: 105.8718\n",
      "Epoch 145/150\n",
      "72/72 - 0s - loss: 109.1059 - mse: 109.1059\n",
      "Epoch 146/150\n",
      "72/72 - 0s - loss: 107.5364 - mse: 107.5364\n",
      "Epoch 147/150\n",
      "72/72 - 0s - loss: 107.2576 - mse: 107.2576\n",
      "Epoch 148/150\n",
      "72/72 - 0s - loss: 108.3876 - mse: 108.3876\n",
      "Epoch 149/150\n",
      "72/72 - 0s - loss: 107.5315 - mse: 107.5315\n",
      "Epoch 150/150\n",
      "72/72 - 0s - loss: 107.4510 - mse: 107.4510\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd936beb550> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 221.5851 - mse: 221.5851\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[221.5851287841797, 221.5851287841797]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=150, batch_size=4, verbose=2)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_45 (Dense)             (None, 32)                416       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,505\n",
      "Trainable params: 1,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for t,p in zip(y_train,y_train_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for t,p in zip(y_test,y_test_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#오차 범위 10 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy_1=(scores/len(y_train))*100\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy_2=(scores/len(y_test))*100\n",
    "result_list.append([12, accuracy_1, accuracy_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<오차범위 10>\n",
      "- train set prediction accuracy(+-10): 70.14 %\n",
      "- test set prediction accuracy(+-10): 65.28 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#오차 범위 10 설정\n",
    "print('<오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 혈액 검사 결과 제외 특징 중 중요한 특징 선별"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (피검사 안할 수 있는 것 중에 선별한 것)\n",
    "X1=psqi_df[['SEX','AGE','PSQI_TOTAL_1','BMI_1','Muscle_1','Fat_1_x','SBP_1','DBP_1','HR_1','Waist_1']].values\n",
    "X2=psqi_df[['SEX','AGE','PSQI_TOTAL_2','BMI_2','Muscle_2','Fat_2_x','SBP_2','DBP_2','HR_2','Waist_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 72)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 10), (360, 1))"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "72/72 - 0s - loss: 3464.9653 - mse: 3464.9653\n",
      "Epoch 2/150\n",
      "72/72 - 0s - loss: 2885.6084 - mse: 2885.6084\n",
      "Epoch 3/150\n",
      "72/72 - 0s - loss: 1984.2852 - mse: 1984.2852\n",
      "Epoch 4/150\n",
      "72/72 - 0s - loss: 991.8587 - mse: 991.8587\n",
      "Epoch 5/150\n",
      "72/72 - 0s - loss: 403.0878 - mse: 403.0878\n",
      "Epoch 6/150\n",
      "72/72 - 0s - loss: 284.8588 - mse: 284.8588\n",
      "Epoch 7/150\n",
      "72/72 - 0s - loss: 247.5618 - mse: 247.5618\n",
      "Epoch 8/150\n",
      "72/72 - 0s - loss: 223.3112 - mse: 223.3112\n",
      "Epoch 9/150\n",
      "72/72 - 0s - loss: 203.0857 - mse: 203.0857\n",
      "Epoch 10/150\n",
      "72/72 - 0s - loss: 189.9907 - mse: 189.9907\n",
      "Epoch 11/150\n",
      "72/72 - 0s - loss: 181.4632 - mse: 181.4632\n",
      "Epoch 12/150\n",
      "72/72 - 0s - loss: 173.0619 - mse: 173.0619\n",
      "Epoch 13/150\n",
      "72/72 - 0s - loss: 164.4738 - mse: 164.4738\n",
      "Epoch 14/150\n",
      "72/72 - 0s - loss: 163.8799 - mse: 163.8799\n",
      "Epoch 15/150\n",
      "72/72 - 0s - loss: 159.4356 - mse: 159.4356\n",
      "Epoch 16/150\n",
      "72/72 - 0s - loss: 155.2837 - mse: 155.2837\n",
      "Epoch 17/150\n",
      "72/72 - 0s - loss: 152.6922 - mse: 152.6922\n",
      "Epoch 18/150\n",
      "72/72 - 0s - loss: 149.4388 - mse: 149.4388\n",
      "Epoch 19/150\n",
      "72/72 - 0s - loss: 148.2705 - mse: 148.2705\n",
      "Epoch 20/150\n",
      "72/72 - 0s - loss: 146.6673 - mse: 146.6673\n",
      "Epoch 21/150\n",
      "72/72 - 0s - loss: 144.0780 - mse: 144.0780\n",
      "Epoch 22/150\n",
      "72/72 - 0s - loss: 142.8901 - mse: 142.8901\n",
      "Epoch 23/150\n",
      "72/72 - 0s - loss: 141.4651 - mse: 141.4651\n",
      "Epoch 24/150\n",
      "72/72 - 0s - loss: 140.1434 - mse: 140.1434\n",
      "Epoch 25/150\n",
      "72/72 - 0s - loss: 138.2189 - mse: 138.2189\n",
      "Epoch 26/150\n",
      "72/72 - 0s - loss: 137.4999 - mse: 137.4999\n",
      "Epoch 27/150\n",
      "72/72 - 0s - loss: 135.8081 - mse: 135.8081\n",
      "Epoch 28/150\n",
      "72/72 - 0s - loss: 135.5946 - mse: 135.5946\n",
      "Epoch 29/150\n",
      "72/72 - 0s - loss: 133.9065 - mse: 133.9065\n",
      "Epoch 30/150\n",
      "72/72 - 0s - loss: 133.4479 - mse: 133.4479\n",
      "Epoch 31/150\n",
      "72/72 - 0s - loss: 132.7025 - mse: 132.7025\n",
      "Epoch 32/150\n",
      "72/72 - 0s - loss: 132.6707 - mse: 132.6707\n",
      "Epoch 33/150\n",
      "72/72 - 0s - loss: 130.0738 - mse: 130.0738\n",
      "Epoch 34/150\n",
      "72/72 - 0s - loss: 130.6532 - mse: 130.6532\n",
      "Epoch 35/150\n",
      "72/72 - 0s - loss: 127.4683 - mse: 127.4683\n",
      "Epoch 36/150\n",
      "72/72 - 0s - loss: 129.9310 - mse: 129.9310\n",
      "Epoch 37/150\n",
      "72/72 - 0s - loss: 126.9789 - mse: 126.9789\n",
      "Epoch 38/150\n",
      "72/72 - 0s - loss: 128.2740 - mse: 128.2740\n",
      "Epoch 39/150\n",
      "72/72 - 0s - loss: 127.1177 - mse: 127.1177\n",
      "Epoch 40/150\n",
      "72/72 - 0s - loss: 126.5572 - mse: 126.5572\n",
      "Epoch 41/150\n",
      "72/72 - 0s - loss: 126.1994 - mse: 126.1994\n",
      "Epoch 42/150\n",
      "72/72 - 0s - loss: 126.1300 - mse: 126.1300\n",
      "Epoch 43/150\n",
      "72/72 - 0s - loss: 125.8186 - mse: 125.8186\n",
      "Epoch 44/150\n",
      "72/72 - 0s - loss: 124.8985 - mse: 124.8985\n",
      "Epoch 45/150\n",
      "72/72 - 0s - loss: 125.1672 - mse: 125.1672\n",
      "Epoch 46/150\n",
      "72/72 - 0s - loss: 124.4163 - mse: 124.4163\n",
      "Epoch 47/150\n",
      "72/72 - 0s - loss: 124.0063 - mse: 124.0063\n",
      "Epoch 48/150\n",
      "72/72 - 0s - loss: 123.1260 - mse: 123.1260\n",
      "Epoch 49/150\n",
      "72/72 - 0s - loss: 123.9706 - mse: 123.9706\n",
      "Epoch 50/150\n",
      "72/72 - 0s - loss: 123.2581 - mse: 123.2581\n",
      "Epoch 51/150\n",
      "72/72 - 0s - loss: 122.8299 - mse: 122.8299\n",
      "Epoch 52/150\n",
      "72/72 - 0s - loss: 122.6594 - mse: 122.6594\n",
      "Epoch 53/150\n",
      "72/72 - 0s - loss: 121.8937 - mse: 121.8937\n",
      "Epoch 54/150\n",
      "72/72 - 0s - loss: 122.2225 - mse: 122.2225\n",
      "Epoch 55/150\n",
      "72/72 - 0s - loss: 121.6905 - mse: 121.6905\n",
      "Epoch 56/150\n",
      "72/72 - 0s - loss: 121.2049 - mse: 121.2049\n",
      "Epoch 57/150\n",
      "72/72 - 0s - loss: 121.5100 - mse: 121.5100\n",
      "Epoch 58/150\n",
      "72/72 - 0s - loss: 120.9426 - mse: 120.9426\n",
      "Epoch 59/150\n",
      "72/72 - 0s - loss: 120.6238 - mse: 120.6238\n",
      "Epoch 60/150\n",
      "72/72 - 0s - loss: 119.3188 - mse: 119.3188\n",
      "Epoch 61/150\n",
      "72/72 - 0s - loss: 119.5796 - mse: 119.5796\n",
      "Epoch 62/150\n",
      "72/72 - 0s - loss: 120.9169 - mse: 120.9169\n",
      "Epoch 63/150\n",
      "72/72 - 0s - loss: 119.1717 - mse: 119.1717\n",
      "Epoch 64/150\n",
      "72/72 - 0s - loss: 119.4096 - mse: 119.4096\n",
      "Epoch 65/150\n",
      "72/72 - 0s - loss: 120.0203 - mse: 120.0203\n",
      "Epoch 66/150\n",
      "72/72 - 0s - loss: 118.3055 - mse: 118.3055\n",
      "Epoch 67/150\n",
      "72/72 - 0s - loss: 119.5726 - mse: 119.5726\n",
      "Epoch 68/150\n",
      "72/72 - 0s - loss: 119.3603 - mse: 119.3603\n",
      "Epoch 69/150\n",
      "72/72 - 0s - loss: 118.1513 - mse: 118.1513\n",
      "Epoch 70/150\n",
      "72/72 - 0s - loss: 117.1827 - mse: 117.1827\n",
      "Epoch 71/150\n",
      "72/72 - 0s - loss: 116.9037 - mse: 116.9037\n",
      "Epoch 72/150\n",
      "72/72 - 0s - loss: 118.2296 - mse: 118.2296\n",
      "Epoch 73/150\n",
      "72/72 - 0s - loss: 118.6158 - mse: 118.6158\n",
      "Epoch 74/150\n",
      "72/72 - 0s - loss: 118.0575 - mse: 118.0575\n",
      "Epoch 75/150\n",
      "72/72 - 0s - loss: 116.7917 - mse: 116.7917\n",
      "Epoch 76/150\n",
      "72/72 - 0s - loss: 117.2403 - mse: 117.2403\n",
      "Epoch 77/150\n",
      "72/72 - 0s - loss: 116.6879 - mse: 116.6879\n",
      "Epoch 78/150\n",
      "72/72 - 0s - loss: 116.4222 - mse: 116.4222\n",
      "Epoch 79/150\n",
      "72/72 - 0s - loss: 117.5018 - mse: 117.5018\n",
      "Epoch 80/150\n",
      "72/72 - 0s - loss: 115.4876 - mse: 115.4876\n",
      "Epoch 81/150\n",
      "72/72 - 0s - loss: 116.2664 - mse: 116.2664\n",
      "Epoch 82/150\n",
      "72/72 - 0s - loss: 115.4689 - mse: 115.4689\n",
      "Epoch 83/150\n",
      "72/72 - 0s - loss: 113.8398 - mse: 113.8398\n",
      "Epoch 84/150\n",
      "72/72 - 0s - loss: 116.2539 - mse: 116.2539\n",
      "Epoch 85/150\n",
      "72/72 - 0s - loss: 115.1035 - mse: 115.1035\n",
      "Epoch 86/150\n",
      "72/72 - 0s - loss: 115.4148 - mse: 115.4148\n",
      "Epoch 87/150\n",
      "72/72 - 0s - loss: 114.9621 - mse: 114.9621\n",
      "Epoch 88/150\n",
      "72/72 - 0s - loss: 114.9153 - mse: 114.9153\n",
      "Epoch 89/150\n",
      "72/72 - 0s - loss: 114.9163 - mse: 114.9163\n",
      "Epoch 90/150\n",
      "72/72 - 0s - loss: 114.4551 - mse: 114.4551\n",
      "Epoch 91/150\n",
      "72/72 - 0s - loss: 114.3352 - mse: 114.3352\n",
      "Epoch 92/150\n",
      "72/72 - 0s - loss: 113.9351 - mse: 113.9351\n",
      "Epoch 93/150\n",
      "72/72 - 0s - loss: 113.4356 - mse: 113.4356\n",
      "Epoch 94/150\n",
      "72/72 - 0s - loss: 113.9130 - mse: 113.9130\n",
      "Epoch 95/150\n",
      "72/72 - 0s - loss: 113.3266 - mse: 113.3266\n",
      "Epoch 96/150\n",
      "72/72 - 0s - loss: 114.1965 - mse: 114.1965\n",
      "Epoch 97/150\n",
      "72/72 - 0s - loss: 112.8434 - mse: 112.8434\n",
      "Epoch 98/150\n",
      "72/72 - 0s - loss: 112.1545 - mse: 112.1545\n",
      "Epoch 99/150\n",
      "72/72 - 0s - loss: 112.5882 - mse: 112.5882\n",
      "Epoch 100/150\n",
      "72/72 - 0s - loss: 113.3133 - mse: 113.3133\n",
      "Epoch 101/150\n",
      "72/72 - 0s - loss: 110.7994 - mse: 110.7994\n",
      "Epoch 102/150\n",
      "72/72 - 0s - loss: 113.2173 - mse: 113.2173\n",
      "Epoch 103/150\n",
      "72/72 - 0s - loss: 113.0020 - mse: 113.0020\n",
      "Epoch 104/150\n",
      "72/72 - 0s - loss: 111.7956 - mse: 111.7956\n",
      "Epoch 105/150\n",
      "72/72 - 0s - loss: 111.7746 - mse: 111.7746\n",
      "Epoch 106/150\n",
      "72/72 - 0s - loss: 111.7160 - mse: 111.7160\n",
      "Epoch 107/150\n",
      "72/72 - 0s - loss: 111.4765 - mse: 111.4765\n",
      "Epoch 108/150\n",
      "72/72 - 0s - loss: 111.3252 - mse: 111.3252\n",
      "Epoch 109/150\n",
      "72/72 - 0s - loss: 111.1572 - mse: 111.1572\n",
      "Epoch 110/150\n",
      "72/72 - 0s - loss: 111.3558 - mse: 111.3558\n",
      "Epoch 111/150\n",
      "72/72 - 0s - loss: 110.7376 - mse: 110.7376\n",
      "Epoch 112/150\n",
      "72/72 - 0s - loss: 110.4288 - mse: 110.4288\n",
      "Epoch 113/150\n",
      "72/72 - 0s - loss: 110.0859 - mse: 110.0859\n",
      "Epoch 114/150\n",
      "72/72 - 0s - loss: 110.5494 - mse: 110.5494\n",
      "Epoch 115/150\n",
      "72/72 - 0s - loss: 109.6459 - mse: 109.6459\n",
      "Epoch 116/150\n",
      "72/72 - 0s - loss: 109.5047 - mse: 109.5047\n",
      "Epoch 117/150\n",
      "72/72 - 0s - loss: 109.5976 - mse: 109.5976\n",
      "Epoch 118/150\n",
      "72/72 - 0s - loss: 109.7342 - mse: 109.7342\n",
      "Epoch 119/150\n",
      "72/72 - 0s - loss: 109.5996 - mse: 109.5996\n",
      "Epoch 120/150\n",
      "72/72 - 0s - loss: 107.8151 - mse: 107.8151\n",
      "Epoch 121/150\n",
      "72/72 - 0s - loss: 109.2435 - mse: 109.2435\n",
      "Epoch 122/150\n",
      "72/72 - 0s - loss: 108.5507 - mse: 108.5507\n",
      "Epoch 123/150\n",
      "72/72 - 0s - loss: 108.9577 - mse: 108.9577\n",
      "Epoch 124/150\n",
      "72/72 - 0s - loss: 108.8068 - mse: 108.8068\n",
      "Epoch 125/150\n",
      "72/72 - 0s - loss: 107.3797 - mse: 107.3797\n",
      "Epoch 126/150\n",
      "72/72 - 0s - loss: 107.5669 - mse: 107.5669\n",
      "Epoch 127/150\n",
      "72/72 - 0s - loss: 108.1137 - mse: 108.1137\n",
      "Epoch 128/150\n",
      "72/72 - 0s - loss: 106.9893 - mse: 106.9893\n",
      "Epoch 129/150\n",
      "72/72 - 0s - loss: 106.9431 - mse: 106.9431\n",
      "Epoch 130/150\n",
      "72/72 - 0s - loss: 107.4405 - mse: 107.4405\n",
      "Epoch 131/150\n",
      "72/72 - 0s - loss: 108.2198 - mse: 108.2198\n",
      "Epoch 132/150\n",
      "72/72 - 0s - loss: 106.3492 - mse: 106.3492\n",
      "Epoch 133/150\n",
      "72/72 - 0s - loss: 106.0015 - mse: 106.0015\n",
      "Epoch 134/150\n",
      "72/72 - 0s - loss: 106.2719 - mse: 106.2719\n",
      "Epoch 135/150\n",
      "72/72 - 0s - loss: 105.6484 - mse: 105.6484\n",
      "Epoch 136/150\n",
      "72/72 - 0s - loss: 106.7339 - mse: 106.7339\n",
      "Epoch 137/150\n",
      "72/72 - 0s - loss: 106.0425 - mse: 106.0425\n",
      "Epoch 138/150\n",
      "72/72 - 0s - loss: 105.3686 - mse: 105.3686\n",
      "Epoch 139/150\n",
      "72/72 - 0s - loss: 105.7650 - mse: 105.7650\n",
      "Epoch 140/150\n",
      "72/72 - 0s - loss: 104.5513 - mse: 104.5513\n",
      "Epoch 141/150\n",
      "72/72 - 0s - loss: 104.7870 - mse: 104.7870\n",
      "Epoch 142/150\n",
      "72/72 - 0s - loss: 103.1854 - mse: 103.1854\n",
      "Epoch 143/150\n",
      "72/72 - 0s - loss: 104.5857 - mse: 104.5857\n",
      "Epoch 144/150\n",
      "72/72 - 0s - loss: 104.0167 - mse: 104.0167\n",
      "Epoch 145/150\n",
      "72/72 - 0s - loss: 103.3149 - mse: 103.3149\n",
      "Epoch 146/150\n",
      "72/72 - 0s - loss: 103.3803 - mse: 103.3803\n",
      "Epoch 147/150\n",
      "72/72 - 0s - loss: 103.6465 - mse: 103.6465\n",
      "Epoch 148/150\n",
      "72/72 - 0s - loss: 103.8679 - mse: 103.8679\n",
      "Epoch 149/150\n",
      "72/72 - 0s - loss: 103.3602 - mse: 103.3602\n",
      "Epoch 150/150\n",
      "72/72 - 0s - loss: 102.6109 - mse: 102.6109\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd91ee3e1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 109.9917 - mse: 109.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[109.99166870117188, 109.99166870117188]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=150, batch_size=4, verbose=2)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_48 (Dense)             (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,441\n",
      "Trainable params: 1,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for t,p in zip(y_train,y_train_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for t,p in zip(y_test,y_test_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "#오차 범위 10 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy_1=(scores/len(y_train))*100\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy_2=(scores/len(y_test))*100\n",
    "result_list.append([10, accuracy_1, accuracy_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<오차범위 10>\n",
      "- train set prediction accuracy(+-10): 72.22 %\n",
      "- test set prediction accuracy(+-10): 70.83 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#오차 범위 10 설정\n",
    "print('<오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8가지 특징 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X, Y 배열 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (피검사 안할 수 있는 것 중에 선별한 것)\n",
    "X1=psqi_df[['SEX','AGE','BMI_1','Muscle_1','Fat_1_x','SBP_1','DBP_1','Waist_1']].values\n",
    "X2=psqi_df[['SEX','AGE','BMI_2','Muscle_2','Fat_2_x','SBP_2','DBP_2','Waist_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 360)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 8), (360, 1))"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 72)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 8), (360, 1))"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "72/72 - 0s - loss: 3531.4600 - mse: 3531.4600\n",
      "Epoch 2/150\n",
      "72/72 - 0s - loss: 2993.4321 - mse: 2993.4321\n",
      "Epoch 3/150\n",
      "72/72 - 0s - loss: 2073.8701 - mse: 2073.8701\n",
      "Epoch 4/150\n",
      "72/72 - 0s - loss: 1022.8505 - mse: 1022.8505\n",
      "Epoch 5/150\n",
      "72/72 - 0s - loss: 440.8520 - mse: 440.8520\n",
      "Epoch 6/150\n",
      "72/72 - 0s - loss: 329.5905 - mse: 329.5905\n",
      "Epoch 7/150\n",
      "72/72 - 0s - loss: 280.6910 - mse: 280.6910\n",
      "Epoch 8/150\n",
      "72/72 - 0s - loss: 243.9059 - mse: 243.9059\n",
      "Epoch 9/150\n",
      "72/72 - 0s - loss: 218.1366 - mse: 218.1366\n",
      "Epoch 10/150\n",
      "72/72 - 0s - loss: 200.9890 - mse: 200.9890\n",
      "Epoch 11/150\n",
      "72/72 - 0s - loss: 187.5383 - mse: 187.5383\n",
      "Epoch 12/150\n",
      "72/72 - 0s - loss: 176.5115 - mse: 176.5115\n",
      "Epoch 13/150\n",
      "72/72 - 0s - loss: 169.5193 - mse: 169.5193\n",
      "Epoch 14/150\n",
      "72/72 - 0s - loss: 163.6751 - mse: 163.6751\n",
      "Epoch 15/150\n",
      "72/72 - 0s - loss: 159.1357 - mse: 159.1357\n",
      "Epoch 16/150\n",
      "72/72 - 0s - loss: 155.3073 - mse: 155.3073\n",
      "Epoch 17/150\n",
      "72/72 - 0s - loss: 151.5064 - mse: 151.5064\n",
      "Epoch 18/150\n",
      "72/72 - 0s - loss: 148.4011 - mse: 148.4011\n",
      "Epoch 19/150\n",
      "72/72 - 0s - loss: 146.7083 - mse: 146.7083\n",
      "Epoch 20/150\n",
      "72/72 - 0s - loss: 145.3340 - mse: 145.3340\n",
      "Epoch 21/150\n",
      "72/72 - 0s - loss: 143.6018 - mse: 143.6018\n",
      "Epoch 22/150\n",
      "72/72 - 0s - loss: 141.8523 - mse: 141.8523\n",
      "Epoch 23/150\n",
      "72/72 - 0s - loss: 139.8393 - mse: 139.8393\n",
      "Epoch 24/150\n",
      "72/72 - 0s - loss: 138.2198 - mse: 138.2198\n",
      "Epoch 25/150\n",
      "72/72 - 0s - loss: 138.2261 - mse: 138.2261\n",
      "Epoch 26/150\n",
      "72/72 - 0s - loss: 136.3128 - mse: 136.3128\n",
      "Epoch 27/150\n",
      "72/72 - 0s - loss: 136.5823 - mse: 136.5823\n",
      "Epoch 28/150\n",
      "72/72 - 0s - loss: 135.9507 - mse: 135.9507\n",
      "Epoch 29/150\n",
      "72/72 - 0s - loss: 134.7602 - mse: 134.7602\n",
      "Epoch 30/150\n",
      "72/72 - 0s - loss: 135.4364 - mse: 135.4364\n",
      "Epoch 31/150\n",
      "72/72 - 0s - loss: 134.2245 - mse: 134.2245\n",
      "Epoch 32/150\n",
      "72/72 - 0s - loss: 132.5481 - mse: 132.5481\n",
      "Epoch 33/150\n",
      "72/72 - 0s - loss: 133.0912 - mse: 133.0912\n",
      "Epoch 34/150\n",
      "72/72 - 0s - loss: 132.4710 - mse: 132.4710\n",
      "Epoch 35/150\n",
      "72/72 - 0s - loss: 131.6751 - mse: 131.6751\n",
      "Epoch 36/150\n",
      "72/72 - 0s - loss: 130.4636 - mse: 130.4636\n",
      "Epoch 37/150\n",
      "72/72 - 0s - loss: 131.3419 - mse: 131.3419\n",
      "Epoch 38/150\n",
      "72/72 - 0s - loss: 130.3582 - mse: 130.3582\n",
      "Epoch 39/150\n",
      "72/72 - 0s - loss: 130.6430 - mse: 130.6430\n",
      "Epoch 40/150\n",
      "72/72 - 0s - loss: 131.0200 - mse: 131.0200\n",
      "Epoch 41/150\n",
      "72/72 - 0s - loss: 128.9189 - mse: 128.9189\n",
      "Epoch 42/150\n",
      "72/72 - 0s - loss: 129.2079 - mse: 129.2079\n",
      "Epoch 43/150\n",
      "72/72 - 0s - loss: 129.2933 - mse: 129.2933\n",
      "Epoch 44/150\n",
      "72/72 - 0s - loss: 129.3484 - mse: 129.3484\n",
      "Epoch 45/150\n",
      "72/72 - 0s - loss: 128.2035 - mse: 128.2035\n",
      "Epoch 46/150\n",
      "72/72 - 0s - loss: 127.2634 - mse: 127.2634\n",
      "Epoch 47/150\n",
      "72/72 - 0s - loss: 128.8147 - mse: 128.8147\n",
      "Epoch 48/150\n",
      "72/72 - 0s - loss: 127.8903 - mse: 127.8903\n",
      "Epoch 49/150\n",
      "72/72 - 0s - loss: 128.1779 - mse: 128.1779\n",
      "Epoch 50/150\n",
      "72/72 - 0s - loss: 127.8473 - mse: 127.8473\n",
      "Epoch 51/150\n",
      "72/72 - 0s - loss: 127.4034 - mse: 127.4034\n",
      "Epoch 52/150\n",
      "72/72 - 0s - loss: 126.9689 - mse: 126.9689\n",
      "Epoch 53/150\n",
      "72/72 - 0s - loss: 126.2576 - mse: 126.2576\n",
      "Epoch 54/150\n",
      "72/72 - 0s - loss: 126.1889 - mse: 126.1889\n",
      "Epoch 55/150\n",
      "72/72 - 0s - loss: 126.1681 - mse: 126.1681\n",
      "Epoch 56/150\n",
      "72/72 - 0s - loss: 125.7718 - mse: 125.7718\n",
      "Epoch 57/150\n",
      "72/72 - 0s - loss: 125.8189 - mse: 125.8189\n",
      "Epoch 58/150\n",
      "72/72 - 0s - loss: 125.6733 - mse: 125.6733\n",
      "Epoch 59/150\n",
      "72/72 - 0s - loss: 126.3860 - mse: 126.3860\n",
      "Epoch 60/150\n",
      "72/72 - 0s - loss: 123.9885 - mse: 123.9885\n",
      "Epoch 61/150\n",
      "72/72 - 0s - loss: 125.7148 - mse: 125.7148\n",
      "Epoch 62/150\n",
      "72/72 - 0s - loss: 124.7507 - mse: 124.7507\n",
      "Epoch 63/150\n",
      "72/72 - 0s - loss: 125.0527 - mse: 125.0527\n",
      "Epoch 64/150\n",
      "72/72 - 0s - loss: 124.5598 - mse: 124.5598\n",
      "Epoch 65/150\n",
      "72/72 - 0s - loss: 125.0103 - mse: 125.0103\n",
      "Epoch 66/150\n",
      "72/72 - 0s - loss: 124.0266 - mse: 124.0266\n",
      "Epoch 67/150\n",
      "72/72 - 0s - loss: 124.6988 - mse: 124.6988\n",
      "Epoch 68/150\n",
      "72/72 - 0s - loss: 123.9067 - mse: 123.9067\n",
      "Epoch 69/150\n",
      "72/72 - 0s - loss: 123.4897 - mse: 123.4897\n",
      "Epoch 70/150\n",
      "72/72 - 0s - loss: 124.1155 - mse: 124.1155\n",
      "Epoch 71/150\n",
      "72/72 - 0s - loss: 123.5410 - mse: 123.5410\n",
      "Epoch 72/150\n",
      "72/72 - 0s - loss: 124.0835 - mse: 124.0835\n",
      "Epoch 73/150\n",
      "72/72 - 0s - loss: 122.8694 - mse: 122.8694\n",
      "Epoch 74/150\n",
      "72/72 - 0s - loss: 123.1479 - mse: 123.1479\n",
      "Epoch 75/150\n",
      "72/72 - 0s - loss: 123.7132 - mse: 123.7132\n",
      "Epoch 76/150\n",
      "72/72 - 0s - loss: 122.8386 - mse: 122.8386\n",
      "Epoch 77/150\n",
      "72/72 - 0s - loss: 122.8247 - mse: 122.8247\n",
      "Epoch 78/150\n",
      "72/72 - 0s - loss: 122.8114 - mse: 122.8114\n",
      "Epoch 79/150\n",
      "72/72 - 0s - loss: 122.9659 - mse: 122.9659\n",
      "Epoch 80/150\n",
      "72/72 - 0s - loss: 123.2381 - mse: 123.2381\n",
      "Epoch 81/150\n",
      "72/72 - 0s - loss: 122.7796 - mse: 122.7796\n",
      "Epoch 82/150\n",
      "72/72 - 0s - loss: 121.8413 - mse: 121.8413\n",
      "Epoch 83/150\n",
      "72/72 - 0s - loss: 122.9336 - mse: 122.9336\n",
      "Epoch 84/150\n",
      "72/72 - 0s - loss: 122.3481 - mse: 122.3481\n",
      "Epoch 85/150\n",
      "72/72 - 0s - loss: 122.2073 - mse: 122.2073\n",
      "Epoch 86/150\n",
      "72/72 - 0s - loss: 122.0508 - mse: 122.0508\n",
      "Epoch 87/150\n",
      "72/72 - 0s - loss: 121.9730 - mse: 121.9730\n",
      "Epoch 88/150\n",
      "72/72 - 0s - loss: 121.6748 - mse: 121.6748\n",
      "Epoch 89/150\n",
      "72/72 - 0s - loss: 122.4997 - mse: 122.4997\n",
      "Epoch 90/150\n",
      "72/72 - 0s - loss: 121.7890 - mse: 121.7890\n",
      "Epoch 91/150\n",
      "72/72 - 0s - loss: 121.6683 - mse: 121.6683\n",
      "Epoch 92/150\n",
      "72/72 - 0s - loss: 121.7615 - mse: 121.7615\n",
      "Epoch 93/150\n",
      "72/72 - 0s - loss: 121.1036 - mse: 121.1036\n",
      "Epoch 94/150\n",
      "72/72 - 0s - loss: 121.0210 - mse: 121.0210\n",
      "Epoch 95/150\n",
      "72/72 - 0s - loss: 121.3983 - mse: 121.3983\n",
      "Epoch 96/150\n",
      "72/72 - 0s - loss: 121.5369 - mse: 121.5369\n",
      "Epoch 97/150\n",
      "72/72 - 0s - loss: 121.1207 - mse: 121.1207\n",
      "Epoch 98/150\n",
      "72/72 - 0s - loss: 121.2126 - mse: 121.2126\n",
      "Epoch 99/150\n",
      "72/72 - 0s - loss: 120.3968 - mse: 120.3968\n",
      "Epoch 100/150\n",
      "72/72 - 0s - loss: 120.5967 - mse: 120.5967\n",
      "Epoch 101/150\n",
      "72/72 - 0s - loss: 121.1606 - mse: 121.1606\n",
      "Epoch 102/150\n",
      "72/72 - 0s - loss: 120.9010 - mse: 120.9010\n",
      "Epoch 103/150\n",
      "72/72 - 0s - loss: 120.7538 - mse: 120.7538\n",
      "Epoch 104/150\n",
      "72/72 - 0s - loss: 120.7335 - mse: 120.7335\n",
      "Epoch 105/150\n",
      "72/72 - 0s - loss: 120.2435 - mse: 120.2435\n",
      "Epoch 106/150\n",
      "72/72 - 0s - loss: 120.3054 - mse: 120.3054\n",
      "Epoch 107/150\n",
      "72/72 - 0s - loss: 119.6716 - mse: 119.6716\n",
      "Epoch 108/150\n",
      "72/72 - 0s - loss: 120.7587 - mse: 120.7587\n",
      "Epoch 109/150\n",
      "72/72 - 0s - loss: 119.3220 - mse: 119.3220\n",
      "Epoch 110/150\n",
      "72/72 - 0s - loss: 120.6423 - mse: 120.6423\n",
      "Epoch 111/150\n",
      "72/72 - 0s - loss: 119.2035 - mse: 119.2035\n",
      "Epoch 112/150\n",
      "72/72 - 0s - loss: 120.1516 - mse: 120.1516\n",
      "Epoch 113/150\n",
      "72/72 - 0s - loss: 119.5591 - mse: 119.5591\n",
      "Epoch 114/150\n",
      "72/72 - 0s - loss: 119.0049 - mse: 119.0049\n",
      "Epoch 115/150\n",
      "72/72 - 0s - loss: 120.5747 - mse: 120.5747\n",
      "Epoch 116/150\n",
      "72/72 - 0s - loss: 118.8405 - mse: 118.8405\n",
      "Epoch 117/150\n",
      "72/72 - 0s - loss: 118.8905 - mse: 118.8905\n",
      "Epoch 118/150\n",
      "72/72 - 0s - loss: 119.3524 - mse: 119.3524\n",
      "Epoch 119/150\n",
      "72/72 - 0s - loss: 119.0380 - mse: 119.0380\n",
      "Epoch 120/150\n",
      "72/72 - 0s - loss: 118.5467 - mse: 118.5467\n",
      "Epoch 121/150\n",
      "72/72 - 0s - loss: 118.5201 - mse: 118.5201\n",
      "Epoch 122/150\n",
      "72/72 - 0s - loss: 119.1143 - mse: 119.1143\n",
      "Epoch 123/150\n",
      "72/72 - 0s - loss: 118.9233 - mse: 118.9233\n",
      "Epoch 124/150\n",
      "72/72 - 0s - loss: 118.0137 - mse: 118.0137\n",
      "Epoch 125/150\n",
      "72/72 - 0s - loss: 117.1249 - mse: 117.1249\n",
      "Epoch 126/150\n",
      "72/72 - 0s - loss: 117.9465 - mse: 117.9465\n",
      "Epoch 127/150\n",
      "72/72 - 0s - loss: 117.4109 - mse: 117.4109\n",
      "Epoch 128/150\n",
      "72/72 - 0s - loss: 117.6992 - mse: 117.6992\n",
      "Epoch 129/150\n",
      "72/72 - 0s - loss: 118.7565 - mse: 118.7565\n",
      "Epoch 130/150\n",
      "72/72 - 0s - loss: 117.6027 - mse: 117.6027\n",
      "Epoch 131/150\n",
      "72/72 - 0s - loss: 117.4684 - mse: 117.4684\n",
      "Epoch 132/150\n",
      "72/72 - 0s - loss: 117.4030 - mse: 117.4030\n",
      "Epoch 133/150\n",
      "72/72 - 0s - loss: 116.8232 - mse: 116.8232\n",
      "Epoch 134/150\n",
      "72/72 - 0s - loss: 117.0474 - mse: 117.0474\n",
      "Epoch 135/150\n",
      "72/72 - 0s - loss: 117.3753 - mse: 117.3753\n",
      "Epoch 136/150\n",
      "72/72 - 0s - loss: 117.6985 - mse: 117.6985\n",
      "Epoch 137/150\n",
      "72/72 - 0s - loss: 117.1798 - mse: 117.1798\n",
      "Epoch 138/150\n",
      "72/72 - 0s - loss: 116.1438 - mse: 116.1438\n",
      "Epoch 139/150\n",
      "72/72 - 0s - loss: 117.4607 - mse: 117.4607\n",
      "Epoch 140/150\n",
      "72/72 - 0s - loss: 116.8844 - mse: 116.8844\n",
      "Epoch 141/150\n",
      "72/72 - 0s - loss: 116.6110 - mse: 116.6110\n",
      "Epoch 142/150\n",
      "72/72 - 0s - loss: 117.0274 - mse: 117.0274\n",
      "Epoch 143/150\n",
      "72/72 - 0s - loss: 116.7077 - mse: 116.7077\n",
      "Epoch 144/150\n",
      "72/72 - 0s - loss: 116.7734 - mse: 116.7734\n",
      "Epoch 145/150\n",
      "72/72 - 0s - loss: 115.0425 - mse: 115.0425\n",
      "Epoch 146/150\n",
      "72/72 - 0s - loss: 115.8245 - mse: 115.8245\n",
      "Epoch 147/150\n",
      "72/72 - 0s - loss: 115.5696 - mse: 115.5696\n",
      "Epoch 148/150\n",
      "72/72 - 0s - loss: 115.2029 - mse: 115.2029\n",
      "Epoch 149/150\n",
      "72/72 - 0s - loss: 116.8855 - mse: 116.8855\n",
      "Epoch 150/150\n",
      "72/72 - 0s - loss: 115.4939 - mse: 115.4939\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd919651430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 119.0460 - mse: 119.0460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[119.04595184326172, 119.04595184326172]"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=150, batch_size=4, verbose=2)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_51 (Dense)             (None, 32)                288       \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,377\n",
      "Trainable params: 1,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for t,p in zip(y_train,y_train_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for t,p in zip(y_test,y_test_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#오차 범위 10 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy_1=(scores/len(y_train))*100\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy_2=(scores/len(y_test))*100\n",
    "result_list.append([8, accuracy_1, accuracy_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<오차범위 10>\n",
      "- train set prediction accuracy(+-10): 70.14 %\n",
      "- test set prediction accuracy(+-10): 63.89 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#오차 범위 10 설정\n",
    "print('<오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 임상적 기준 발생 위험 요인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (임상적 기준 HDL 위험 요인)\n",
    "X1=psqi_df[['SEX','AGE','PSQI_TOTAL_1','BMI_1']].values\n",
    "X2=psqi_df[['SEX','AGE','PSQI_TOTAL_2','BMI_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 72)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 4), (360, 1))"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "72/72 - 0s - loss: 3528.6016 - mse: 3528.6016\n",
      "Epoch 2/150\n",
      "72/72 - 0s - loss: 3119.8962 - mse: 3119.8962\n",
      "Epoch 3/150\n",
      "72/72 - 0s - loss: 2439.6978 - mse: 2439.6978\n",
      "Epoch 4/150\n",
      "72/72 - 0s - loss: 1526.5825 - mse: 1526.5825\n",
      "Epoch 5/150\n",
      "72/72 - 0s - loss: 674.9138 - mse: 674.9138\n",
      "Epoch 6/150\n",
      "72/72 - 0s - loss: 241.2494 - mse: 241.2494\n",
      "Epoch 7/150\n",
      "72/72 - 0s - loss: 185.1534 - mse: 185.1534\n",
      "Epoch 8/150\n",
      "72/72 - 0s - loss: 180.3941 - mse: 180.3941\n",
      "Epoch 9/150\n",
      "72/72 - 0s - loss: 174.6745 - mse: 174.6745\n",
      "Epoch 10/150\n",
      "72/72 - 0s - loss: 170.8385 - mse: 170.8385\n",
      "Epoch 11/150\n",
      "72/72 - 0s - loss: 167.3963 - mse: 167.3963\n",
      "Epoch 12/150\n",
      "72/72 - 0s - loss: 163.6557 - mse: 163.6557\n",
      "Epoch 13/150\n",
      "72/72 - 0s - loss: 160.4321 - mse: 160.4321\n",
      "Epoch 14/150\n",
      "72/72 - 0s - loss: 158.4318 - mse: 158.4318\n",
      "Epoch 15/150\n",
      "72/72 - 0s - loss: 155.4015 - mse: 155.4015\n",
      "Epoch 16/150\n",
      "72/72 - 0s - loss: 153.5448 - mse: 153.5448\n",
      "Epoch 17/150\n",
      "72/72 - 0s - loss: 151.4666 - mse: 151.4666\n",
      "Epoch 18/150\n",
      "72/72 - 0s - loss: 149.9824 - mse: 149.9824\n",
      "Epoch 19/150\n",
      "72/72 - 0s - loss: 149.2337 - mse: 149.2337\n",
      "Epoch 20/150\n",
      "72/72 - 0s - loss: 147.3609 - mse: 147.3609\n",
      "Epoch 21/150\n",
      "72/72 - 0s - loss: 146.9489 - mse: 146.9489\n",
      "Epoch 22/150\n",
      "72/72 - 0s - loss: 144.6267 - mse: 144.6267\n",
      "Epoch 23/150\n",
      "72/72 - 0s - loss: 143.6666 - mse: 143.6666\n",
      "Epoch 24/150\n",
      "72/72 - 0s - loss: 142.1218 - mse: 142.1218\n",
      "Epoch 25/150\n",
      "72/72 - 0s - loss: 142.3344 - mse: 142.3344\n",
      "Epoch 26/150\n",
      "72/72 - 0s - loss: 140.8060 - mse: 140.8060\n",
      "Epoch 27/150\n",
      "72/72 - 0s - loss: 141.3223 - mse: 141.3223\n",
      "Epoch 28/150\n",
      "72/72 - 0s - loss: 140.1993 - mse: 140.1993\n",
      "Epoch 29/150\n",
      "72/72 - 0s - loss: 138.9026 - mse: 138.9026\n",
      "Epoch 30/150\n",
      "72/72 - 0s - loss: 139.2712 - mse: 139.2712\n",
      "Epoch 31/150\n",
      "72/72 - 0s - loss: 137.9635 - mse: 137.9635\n",
      "Epoch 32/150\n",
      "72/72 - 0s - loss: 137.9635 - mse: 137.9635\n",
      "Epoch 33/150\n",
      "72/72 - 0s - loss: 137.0379 - mse: 137.0379\n",
      "Epoch 34/150\n",
      "72/72 - 0s - loss: 136.9447 - mse: 136.9447\n",
      "Epoch 35/150\n",
      "72/72 - 0s - loss: 135.9899 - mse: 135.9899\n",
      "Epoch 36/150\n",
      "72/72 - 0s - loss: 135.7762 - mse: 135.7762\n",
      "Epoch 37/150\n",
      "72/72 - 0s - loss: 136.5306 - mse: 136.5306\n",
      "Epoch 38/150\n",
      "72/72 - 0s - loss: 135.2681 - mse: 135.2681\n",
      "Epoch 39/150\n",
      "72/72 - 0s - loss: 135.9403 - mse: 135.9403\n",
      "Epoch 40/150\n",
      "72/72 - 0s - loss: 135.3658 - mse: 135.3658\n",
      "Epoch 41/150\n",
      "72/72 - 0s - loss: 134.4520 - mse: 134.4520\n",
      "Epoch 42/150\n",
      "72/72 - 0s - loss: 133.2532 - mse: 133.2532\n",
      "Epoch 43/150\n",
      "72/72 - 0s - loss: 135.0311 - mse: 135.0311\n",
      "Epoch 44/150\n",
      "72/72 - 0s - loss: 134.1210 - mse: 134.1210\n",
      "Epoch 45/150\n",
      "72/72 - 0s - loss: 133.9601 - mse: 133.9601\n",
      "Epoch 46/150\n",
      "72/72 - 0s - loss: 133.7350 - mse: 133.7350\n",
      "Epoch 47/150\n",
      "72/72 - 0s - loss: 133.2704 - mse: 133.2704\n",
      "Epoch 48/150\n",
      "72/72 - 0s - loss: 132.8793 - mse: 132.8793\n",
      "Epoch 49/150\n",
      "72/72 - 0s - loss: 133.0423 - mse: 133.0423\n",
      "Epoch 50/150\n",
      "72/72 - 0s - loss: 133.1410 - mse: 133.1410\n",
      "Epoch 51/150\n",
      "72/72 - 0s - loss: 132.1725 - mse: 132.1725\n",
      "Epoch 52/150\n",
      "72/72 - 0s - loss: 132.4073 - mse: 132.4073\n",
      "Epoch 53/150\n",
      "72/72 - 0s - loss: 132.6609 - mse: 132.6609\n",
      "Epoch 54/150\n",
      "72/72 - 0s - loss: 131.8246 - mse: 131.8246\n",
      "Epoch 55/150\n",
      "72/72 - 0s - loss: 132.7393 - mse: 132.7393\n",
      "Epoch 56/150\n",
      "72/72 - 0s - loss: 132.7184 - mse: 132.7184\n",
      "Epoch 57/150\n",
      "72/72 - 0s - loss: 132.1142 - mse: 132.1142\n",
      "Epoch 58/150\n",
      "72/72 - 0s - loss: 132.1904 - mse: 132.1904\n",
      "Epoch 59/150\n",
      "72/72 - 0s - loss: 131.5706 - mse: 131.5706\n",
      "Epoch 60/150\n",
      "72/72 - 0s - loss: 131.7595 - mse: 131.7595\n",
      "Epoch 61/150\n",
      "72/72 - 0s - loss: 131.3188 - mse: 131.3188\n",
      "Epoch 62/150\n",
      "72/72 - 0s - loss: 131.6763 - mse: 131.6763\n",
      "Epoch 63/150\n",
      "72/72 - 0s - loss: 131.5691 - mse: 131.5691\n",
      "Epoch 64/150\n",
      "72/72 - 0s - loss: 130.9650 - mse: 130.9650\n",
      "Epoch 65/150\n",
      "72/72 - 0s - loss: 131.0628 - mse: 131.0628\n",
      "Epoch 66/150\n",
      "72/72 - 0s - loss: 131.7620 - mse: 131.7620\n",
      "Epoch 67/150\n",
      "72/72 - 0s - loss: 130.6202 - mse: 130.6202\n",
      "Epoch 68/150\n",
      "72/72 - 0s - loss: 130.4379 - mse: 130.4379\n",
      "Epoch 69/150\n",
      "72/72 - 0s - loss: 130.6064 - mse: 130.6064\n",
      "Epoch 70/150\n",
      "72/72 - 0s - loss: 130.3879 - mse: 130.3879\n",
      "Epoch 71/150\n",
      "72/72 - 0s - loss: 130.9482 - mse: 130.9482\n",
      "Epoch 72/150\n",
      "72/72 - 0s - loss: 130.6970 - mse: 130.6970\n",
      "Epoch 73/150\n",
      "72/72 - 0s - loss: 130.2253 - mse: 130.2253\n",
      "Epoch 74/150\n",
      "72/72 - 0s - loss: 130.3012 - mse: 130.3012\n",
      "Epoch 75/150\n",
      "72/72 - 0s - loss: 130.5378 - mse: 130.5378\n",
      "Epoch 76/150\n",
      "72/72 - 0s - loss: 129.8458 - mse: 129.8458\n",
      "Epoch 77/150\n",
      "72/72 - 0s - loss: 129.8328 - mse: 129.8328\n",
      "Epoch 78/150\n",
      "72/72 - 0s - loss: 129.7642 - mse: 129.7642\n",
      "Epoch 79/150\n",
      "72/72 - 0s - loss: 128.6080 - mse: 128.6080\n",
      "Epoch 80/150\n",
      "72/72 - 0s - loss: 129.5882 - mse: 129.5882\n",
      "Epoch 81/150\n",
      "72/72 - 0s - loss: 129.3899 - mse: 129.3899\n",
      "Epoch 82/150\n",
      "72/72 - 0s - loss: 129.9207 - mse: 129.9207\n",
      "Epoch 83/150\n",
      "72/72 - 0s - loss: 129.4286 - mse: 129.4286\n",
      "Epoch 84/150\n",
      "72/72 - 0s - loss: 129.6566 - mse: 129.6566\n",
      "Epoch 85/150\n",
      "72/72 - 0s - loss: 128.8010 - mse: 128.8010\n",
      "Epoch 86/150\n",
      "72/72 - 0s - loss: 129.3543 - mse: 129.3543\n",
      "Epoch 87/150\n",
      "72/72 - 0s - loss: 127.8430 - mse: 127.8430\n",
      "Epoch 88/150\n",
      "72/72 - 0s - loss: 129.0567 - mse: 129.0567\n",
      "Epoch 89/150\n",
      "72/72 - 0s - loss: 128.5317 - mse: 128.5317\n",
      "Epoch 90/150\n",
      "72/72 - 0s - loss: 129.3397 - mse: 129.3397\n",
      "Epoch 91/150\n",
      "72/72 - 0s - loss: 128.5423 - mse: 128.5423\n",
      "Epoch 92/150\n",
      "72/72 - 0s - loss: 128.6111 - mse: 128.6111\n",
      "Epoch 93/150\n",
      "72/72 - 0s - loss: 127.9427 - mse: 127.9427\n",
      "Epoch 94/150\n",
      "72/72 - 0s - loss: 127.7507 - mse: 127.7507\n",
      "Epoch 95/150\n",
      "72/72 - 0s - loss: 128.5943 - mse: 128.5943\n",
      "Epoch 96/150\n",
      "72/72 - 0s - loss: 128.5981 - mse: 128.5981\n",
      "Epoch 97/150\n",
      "72/72 - 0s - loss: 128.3880 - mse: 128.3880\n",
      "Epoch 98/150\n",
      "72/72 - 0s - loss: 128.3937 - mse: 128.3937\n",
      "Epoch 99/150\n",
      "72/72 - 0s - loss: 128.0961 - mse: 128.0961\n",
      "Epoch 100/150\n",
      "72/72 - 0s - loss: 128.0634 - mse: 128.0634\n",
      "Epoch 101/150\n",
      "72/72 - 0s - loss: 127.9548 - mse: 127.9548\n",
      "Epoch 102/150\n",
      "72/72 - 0s - loss: 127.8959 - mse: 127.8959\n",
      "Epoch 103/150\n",
      "72/72 - 0s - loss: 127.9012 - mse: 127.9012\n",
      "Epoch 104/150\n",
      "72/72 - 0s - loss: 127.3430 - mse: 127.3430\n",
      "Epoch 105/150\n",
      "72/72 - 0s - loss: 127.6717 - mse: 127.6717\n",
      "Epoch 106/150\n",
      "72/72 - 0s - loss: 127.1869 - mse: 127.1869\n",
      "Epoch 107/150\n",
      "72/72 - 0s - loss: 127.9200 - mse: 127.9200\n",
      "Epoch 108/150\n",
      "72/72 - 0s - loss: 127.3802 - mse: 127.3802\n",
      "Epoch 109/150\n",
      "72/72 - 0s - loss: 127.3020 - mse: 127.3020\n",
      "Epoch 110/150\n",
      "72/72 - 0s - loss: 127.2331 - mse: 127.2331\n",
      "Epoch 111/150\n",
      "72/72 - 0s - loss: 127.3105 - mse: 127.3105\n",
      "Epoch 112/150\n",
      "72/72 - 0s - loss: 126.8194 - mse: 126.8194\n",
      "Epoch 113/150\n",
      "72/72 - 0s - loss: 127.5795 - mse: 127.5795\n",
      "Epoch 114/150\n",
      "72/72 - 0s - loss: 125.8439 - mse: 125.8439\n",
      "Epoch 115/150\n",
      "72/72 - 0s - loss: 126.8858 - mse: 126.8858\n",
      "Epoch 116/150\n",
      "72/72 - 0s - loss: 127.0962 - mse: 127.0962\n",
      "Epoch 117/150\n",
      "72/72 - 0s - loss: 126.6600 - mse: 126.6600\n",
      "Epoch 118/150\n",
      "72/72 - 0s - loss: 126.5058 - mse: 126.5058\n",
      "Epoch 119/150\n",
      "72/72 - 0s - loss: 126.7747 - mse: 126.7747\n",
      "Epoch 120/150\n",
      "72/72 - 0s - loss: 126.6081 - mse: 126.6081\n",
      "Epoch 121/150\n",
      "72/72 - 0s - loss: 127.4102 - mse: 127.4102\n",
      "Epoch 122/150\n",
      "72/72 - 0s - loss: 126.5577 - mse: 126.5577\n",
      "Epoch 123/150\n",
      "72/72 - 0s - loss: 126.0715 - mse: 126.0715\n",
      "Epoch 124/150\n",
      "72/72 - 0s - loss: 125.8928 - mse: 125.8928\n",
      "Epoch 125/150\n",
      "72/72 - 0s - loss: 125.9422 - mse: 125.9422\n",
      "Epoch 126/150\n",
      "72/72 - 0s - loss: 126.4749 - mse: 126.4749\n",
      "Epoch 127/150\n",
      "72/72 - 0s - loss: 126.4259 - mse: 126.4259\n",
      "Epoch 128/150\n",
      "72/72 - 0s - loss: 126.3476 - mse: 126.3476\n",
      "Epoch 129/150\n",
      "72/72 - 0s - loss: 124.6009 - mse: 124.6009\n",
      "Epoch 130/150\n",
      "72/72 - 0s - loss: 125.1202 - mse: 125.1202\n",
      "Epoch 131/150\n",
      "72/72 - 0s - loss: 125.9333 - mse: 125.9333\n",
      "Epoch 132/150\n",
      "72/72 - 0s - loss: 125.4448 - mse: 125.4448\n",
      "Epoch 133/150\n",
      "72/72 - 0s - loss: 125.3880 - mse: 125.3880\n",
      "Epoch 134/150\n",
      "72/72 - 0s - loss: 126.1107 - mse: 126.1107\n",
      "Epoch 135/150\n",
      "72/72 - 0s - loss: 125.2566 - mse: 125.2566\n",
      "Epoch 136/150\n",
      "72/72 - 0s - loss: 123.3405 - mse: 123.3405\n",
      "Epoch 137/150\n",
      "72/72 - 0s - loss: 126.1952 - mse: 126.1952\n",
      "Epoch 138/150\n",
      "72/72 - 0s - loss: 125.7854 - mse: 125.7854\n",
      "Epoch 139/150\n",
      "72/72 - 0s - loss: 125.0654 - mse: 125.0654\n",
      "Epoch 140/150\n",
      "72/72 - 0s - loss: 125.7821 - mse: 125.7821\n",
      "Epoch 141/150\n",
      "72/72 - 0s - loss: 125.0885 - mse: 125.0885\n",
      "Epoch 142/150\n",
      "72/72 - 0s - loss: 125.3294 - mse: 125.3294\n",
      "Epoch 143/150\n",
      "72/72 - 0s - loss: 125.6117 - mse: 125.6117\n",
      "Epoch 144/150\n",
      "72/72 - 0s - loss: 124.7455 - mse: 124.7455\n",
      "Epoch 145/150\n",
      "72/72 - 0s - loss: 124.7786 - mse: 124.7786\n",
      "Epoch 146/150\n",
      "72/72 - 0s - loss: 125.5101 - mse: 125.5101\n",
      "Epoch 147/150\n",
      "72/72 - 0s - loss: 124.5042 - mse: 124.5042\n",
      "Epoch 148/150\n",
      "72/72 - 0s - loss: 124.2167 - mse: 124.2167\n",
      "Epoch 149/150\n",
      "72/72 - 0s - loss: 124.5683 - mse: 124.5683\n",
      "Epoch 150/150\n",
      "72/72 - 0s - loss: 124.9923 - mse: 124.9923\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fd9199f9af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 118.2839 - mse: 118.2839\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[118.28389739990234, 118.28389739990234]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=150, batch_size=4, verbose=2)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_54 (Dense)             (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,249\n",
      "Trainable params: 1,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for t,p in zip(y_train,y_train_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for t,p in zip(y_test,y_test_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "#오차 범위 10 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy_1=(scores/len(y_train))*100\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy_2=(scores/len(y_test))*100\n",
    "result_list.append([4, accuracy_1, accuracy_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<오차범위 10>\n",
      "- train set prediction accuracy(+-10): 69.10 %\n",
      "- test set prediction accuracy(+-10): 69.44 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#오차 범위 10 설정\n",
    "print('<오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12개의 특징 사용 train: 70.13888888888889 |  test: 65.27777777777779\n",
      "10개의 특징 사용 train: 72.22222222222221 |  test: 70.83333333333334\n",
      "8개의 특징 사용 train: 70.13888888888889 |  test: 63.888888888888886\n",
      "4개의 특징 사용 train: 69.09722222222221 |  test: 69.44444444444444\n"
     ]
    }
   ],
   "source": [
    "for i in result_list:\n",
    "    print(f'{i[0]}개의 특징 사용 train: {i[1]} |  test: {i[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

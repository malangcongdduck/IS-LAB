{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sample_ID GROUP  COHORT SEX  AGE     Trait FitbitOX      Fitbit_ID  HTN  \\\n",
      "0         S0001   SMI       2   M   60  fitbit_O        O  sevrance00001  NaN   \n",
      "1         S0002   SMI       2   M   61  fitbit_O        O  sevrance00002  NaN   \n",
      "2         S0003   SMI       2   F   52  fitbit_O        O  sevrance00003  NaN   \n",
      "3         S0004   SMI       2   F   41  fitbit_O        O  sevrance00004  NaN   \n",
      "4         S0005   SMI       2   F   41  fitbit_O        O  sevrance00005  NaN   \n",
      "..          ...   ...     ...  ..  ...       ...      ...            ...  ...   \n",
      "383  MetS_S0280  MetS       1   F   24  fitbit_O        O   gnfmmets+139  NaN   \n",
      "384  MetS_S0281  MetS       1   F   44  fitbit_O        O   gnfmmets+140  NaN   \n",
      "385  MetS_S0282  MetS       1   F   37  fitbit_O        O   gnfmmets+141  1.0   \n",
      "386  MetS_S0283  MetS       1   M   51  fitbit_X        X              X  NaN   \n",
      "387  MetS_S0284  MetS       1   F   42  fitbit_X        X              X  NaN   \n",
      "\n",
      "      DM  ...  BDI_Q13_2 BDI_Q14_2  BDI_Q15_2  BDI_Q16_2 BDI_Q17_2 BDI_Q18_2  \\\n",
      "0    NaN  ...        1.0       1.0        1.0        2.0       1.0       1.0   \n",
      "1    1.0  ...        1.0       1.0        1.0        1.0       2.0       1.0   \n",
      "2    NaN  ...        1.0       1.0        1.0        1.0       1.0       1.0   \n",
      "3    NaN  ...        2.0       2.0        2.0        2.0       2.0       2.0   \n",
      "4    NaN  ...        2.0       1.0        2.0        2.0       2.0       1.0   \n",
      "..   ...  ...        ...       ...        ...        ...       ...       ...   \n",
      "383  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "384  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "385  1.0  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "386  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "387  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "\n",
      "     BDI_Q19_2  BDI_Q20_2  BDI_Q21_2  Diet_2  \n",
      "0          2.0        1.0        2.0     2.0  \n",
      "1          1.0        1.0        1.0     2.0  \n",
      "2          1.0        2.0        4.0     1.0  \n",
      "3          1.0        1.0        1.0     2.0  \n",
      "4          1.0        2.0        1.0     2.0  \n",
      "..         ...        ...        ...     ...  \n",
      "383        NaN        NaN        NaN     NaN  \n",
      "384        NaN        NaN        NaN     NaN  \n",
      "385        NaN        NaN        NaN     NaN  \n",
      "386        NaN        NaN        NaN     NaN  \n",
      "387        NaN        NaN        NaN     NaN  \n",
      "\n",
      "[388 rows x 3527 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('./최종 데이터 그래프그리기용.xlsx') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#빈데이터 많은 Chol, BUN 삭제\n",
    "psqi_df=df[['Sample_ID','GROUP','COHORT','AGE','SEX','BMI_1','PSQI_TOTAL_1','Insulin _1','CRP_1','WBC_1','Neutrophil_1','Lym_1','GLU0_1','Creatinine_1','AST_1','ALT_1','TG_1','LDL_1','Muscle_1','Fat_1_x','FatPercentage _1','WHR_1','SBP_1',\n",
    "            'DBP_1','HR_1','Waist_1','HDL_1',\n",
    "          'BMI_2','PSQI_TOTAL_2','Insulin _2','CRP_2','WBC_2','Neutrophil_2','Lym_2','GLU0_2',\n",
    "            'Creatinine_2','AST_2','ALT_2','TG_2','LDL_2','Muscle_2','Fat_2_x','FatPercentage_2','WHR_2','SBP_2',\n",
    "            'DBP_2','HR_2','Waist_2','HDL_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#빈데이터 많은 Chol, BUN 추가\n",
    "psqi_df=df[['Sample_ID','GROUP','COHORT','AGE','SEX',\n",
    "            'BMI_1','PSQI_TOTAL_1','Insulin _1','CRP_1','WBC_1','Neutrophil_1','Lym_1','GLU0_1',\n",
    "            'Creatinine_1','AST_1','ALT_1','TG_1','LDL_1','Muscle_1','Fat_1_x','FatPercentage _1','WHR_1','SBP_1',\n",
    "            'DBP_1','HR_1','Waist_1','HDL_1','BUN_1','Chol_1',\n",
    "          'BMI_2','PSQI_TOTAL_2','Insulin _2','CRP_2','WBC_2','Neutrophil_2','Lym_2','GLU0_2',\n",
    "            'Creatinine_2','AST_2','ALT_2','TG_2','LDL_2','Muscle_2','Fat_2_x','FatPercentage_2','WHR_2','SBP_2',\n",
    "            'DBP_2','HR_2','Waist_2','HDL_2','BUN_2','Chol_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>HDL_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>Chol_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.89</td>\n",
       "      <td>108.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.51</td>\n",
       "      <td>...</td>\n",
       "      <td>19.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>0.99</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>90.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.85</td>\n",
       "      <td>...</td>\n",
       "      <td>22.6</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>127.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.14</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.82</td>\n",
       "      <td>119.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.93</td>\n",
       "      <td>...</td>\n",
       "      <td>14.9</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>110.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>66.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.82</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.67</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.03</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT  AGE SEX      BMI_1  PSQI_TOTAL_1 Insulin _1  \\\n",
       "0         S0001   SMI       2   60   M  21.110190           8.0        7.7   \n",
       "1         S0002   SMI       2   61   M  27.782064           4.0        5.4   \n",
       "2         S0003   SMI       2   52   F  24.944742           3.0        5.1   \n",
       "3         S0004   SMI       2   41   F  22.620489           6.0        4.2   \n",
       "4         S0005   SMI       2   41   F  20.524157          10.0        3.2   \n",
       "..          ...   ...     ...  ...  ..        ...           ...        ...   \n",
       "383  MetS_S0280  MetS       1   24   F  34.803410           5.0       11.3   \n",
       "384  MetS_S0281  MetS       1   44   F  30.903615           3.0       10.6   \n",
       "385  MetS_S0282  MetS       1   37   F  28.676533           3.0       12.2   \n",
       "386  MetS_S0283  MetS       1   51   M  24.549738           5.0       10.4   \n",
       "387  MetS_S0284  MetS       1   42   F  24.605921           3.0       10.1   \n",
       "\n",
       "    CRP_1  WBC_1  ...  Fat_2_x  FatPercentage_2  WHR_2  SBP_2  DBP_2  HR_2  \\\n",
       "0     0.2   3.91  ...      9.7             15.9   0.89  108.0   78.0  87.0   \n",
       "1     0.2   5.51  ...     19.9             27.9   0.99  138.0   92.0  73.0   \n",
       "2     0.7   4.85  ...     22.6             36.7   0.89  127.0   80.0  66.0   \n",
       "3     0.6   6.14  ...     16.0             30.9   0.82  119.0   83.0  77.0   \n",
       "4     0.1   4.93  ...     14.9             26.8   0.80  110.0   68.0  67.0   \n",
       "..    ...    ...  ...      ...              ...    ...    ...    ...   ...   \n",
       "383   0.4   5.32  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "384   2.3   5.82  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "385     1   6.18  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "386   1.2   6.67  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "387   0.8   7.03  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "\n",
       "     Waist_2  HDL_2  BUN_2  Chol_2  \n",
       "0       83.0   77.0   13.1     NaN  \n",
       "1       90.5   59.0   19.2     NaN  \n",
       "2       86.5   40.0   17.1     NaN  \n",
       "3       77.0   54.0   12.2     NaN  \n",
       "4       66.5   72.0   16.5     NaN  \n",
       "..       ...    ...    ...     ...  \n",
       "383      NaN    NaN    NaN     NaN  \n",
       "384      NaN    NaN    NaN     NaN  \n",
       "385      NaN    NaN    NaN     NaN  \n",
       "386      NaN    NaN    NaN     NaN  \n",
       "387      NaN    NaN    NaN     NaN  \n",
       "\n",
       "[388 rows x 53 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>HDL_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>Chol_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.89</td>\n",
       "      <td>108.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.51</td>\n",
       "      <td>...</td>\n",
       "      <td>19.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>0.99</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>90.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.85</td>\n",
       "      <td>...</td>\n",
       "      <td>22.6</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>127.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.14</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.82</td>\n",
       "      <td>119.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.93</td>\n",
       "      <td>...</td>\n",
       "      <td>14.9</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>110.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>66.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.82</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.67</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.03</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT  AGE SEX      BMI_1  PSQI_TOTAL_1 Insulin _1  \\\n",
       "0         S0001   SMI       2   60   M  21.110190           8.0        7.7   \n",
       "1         S0002   SMI       2   61   M  27.782064           4.0        5.4   \n",
       "2         S0003   SMI       2   52   F  24.944742           3.0        5.1   \n",
       "3         S0004   SMI       2   41   F  22.620489           6.0        4.2   \n",
       "4         S0005   SMI       2   41   F  20.524157          10.0        3.2   \n",
       "..          ...   ...     ...  ...  ..        ...           ...        ...   \n",
       "383  MetS_S0280  MetS       1   24   F  34.803410           5.0       11.3   \n",
       "384  MetS_S0281  MetS       1   44   F  30.903615           3.0       10.6   \n",
       "385  MetS_S0282  MetS       1   37   F  28.676533           3.0       12.2   \n",
       "386  MetS_S0283  MetS       1   51   M  24.549738           5.0       10.4   \n",
       "387  MetS_S0284  MetS       1   42   F  24.605921           3.0       10.1   \n",
       "\n",
       "    CRP_1  WBC_1  ...  Fat_2_x  FatPercentage_2  WHR_2  SBP_2  DBP_2  HR_2  \\\n",
       "0     0.2   3.91  ...      9.7             15.9   0.89  108.0   78.0  87.0   \n",
       "1     0.2   5.51  ...     19.9             27.9   0.99  138.0   92.0  73.0   \n",
       "2     0.7   4.85  ...     22.6             36.7   0.89  127.0   80.0  66.0   \n",
       "3     0.6   6.14  ...     16.0             30.9   0.82  119.0   83.0  77.0   \n",
       "4     0.1   4.93  ...     14.9             26.8   0.80  110.0   68.0  67.0   \n",
       "..    ...    ...  ...      ...              ...    ...    ...    ...   ...   \n",
       "383   0.4   5.32  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "384   2.3   5.82  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "385     1   6.18  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "386   1.2   6.67  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "387   0.8   7.03  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "\n",
       "     Waist_2  HDL_2  BUN_2  Chol_2  \n",
       "0       83.0   77.0   13.1     NaN  \n",
       "1       90.5   59.0   19.2     NaN  \n",
       "2       86.5   40.0   17.1     NaN  \n",
       "3       77.0   54.0   12.2     NaN  \n",
       "4       66.5   72.0   16.5     NaN  \n",
       "..       ...    ...    ...     ...  \n",
       "383      NaN    NaN    NaN     NaN  \n",
       "384      NaN    NaN    NaN     NaN  \n",
       "385      NaN    NaN    NaN     NaN  \n",
       "386      NaN    NaN    NaN     NaN  \n",
       "387      NaN    NaN    NaN     NaN  \n",
       "\n",
       "[317 rows x 53 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#보조 호르몬 요법을 받고 있는 Cohort 3 제거 Filter 적용\n",
    "psqi_df = psqi_df[(psqi_df['COHORT'] != 3)]\n",
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df=psqi_df.dropna()\n",
    "psqi_df.reset_index(drop=True, inplace=True)\n",
    "psqi_df=psqi_df.drop([\"Sample_ID\", \"GROUP\", \"COHORT\"],axis=1)\n",
    "#1분, 매일다름, 정해진간이없음 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"SEX\"] = psqi_df[\"SEX\"].apply(lambda x: 1. if x=='M' else 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"Insulin _1\"] = psqi_df[\"Insulin _1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)\n",
    "psqi_df[\"Insulin _2\"] = psqi_df[\"Insulin _2\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"CRP_1\"] = psqi_df[\"CRP_1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)\n",
    "psqi_df[\"CRP_2\"] = psqi_df[\"CRP_2\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>Neutrophil_1</th>\n",
       "      <th>Lym_1</th>\n",
       "      <th>GLU0_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>HDL_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>Chol_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.00000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.366667</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>23.799644</td>\n",
       "      <td>5.105556</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.748889</td>\n",
       "      <td>5.844867</td>\n",
       "      <td>56.086111</td>\n",
       "      <td>34.113333</td>\n",
       "      <td>98.90000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.053333</td>\n",
       "      <td>28.888333</td>\n",
       "      <td>0.862444</td>\n",
       "      <td>114.605556</td>\n",
       "      <td>72.477778</td>\n",
       "      <td>75.644444</td>\n",
       "      <td>81.328889</td>\n",
       "      <td>59.20000</td>\n",
       "      <td>12.984444</td>\n",
       "      <td>190.922222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.589776</td>\n",
       "      <td>0.461927</td>\n",
       "      <td>4.936177</td>\n",
       "      <td>2.893833</td>\n",
       "      <td>4.105985</td>\n",
       "      <td>1.344157</td>\n",
       "      <td>1.412280</td>\n",
       "      <td>8.502880</td>\n",
       "      <td>7.708889</td>\n",
       "      <td>14.43773</td>\n",
       "      <td>...</td>\n",
       "      <td>6.616151</td>\n",
       "      <td>7.098802</td>\n",
       "      <td>0.071696</td>\n",
       "      <td>13.213544</td>\n",
       "      <td>9.091991</td>\n",
       "      <td>10.306814</td>\n",
       "      <td>10.251265</td>\n",
       "      <td>14.01372</td>\n",
       "      <td>3.508550</td>\n",
       "      <td>32.017358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.231576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.820000</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>63.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>29.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.833309</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.857500</td>\n",
       "      <td>50.525000</td>\n",
       "      <td>28.975000</td>\n",
       "      <td>92.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>24.275000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>73.875000</td>\n",
       "      <td>49.00000</td>\n",
       "      <td>10.675000</td>\n",
       "      <td>167.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.422889</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>5.720000</td>\n",
       "      <td>55.950000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>95.50000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.950000</td>\n",
       "      <td>28.450000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>80.500000</td>\n",
       "      <td>57.00000</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.502662</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.505000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>6.580000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>102.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.125000</td>\n",
       "      <td>33.450000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>77.250000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>69.00000</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>10.550000</td>\n",
       "      <td>78.400000</td>\n",
       "      <td>55.400000</td>\n",
       "      <td>182.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>46.100000</td>\n",
       "      <td>48.300000</td>\n",
       "      <td>1.070000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>116.00000</td>\n",
       "      <td>36.400000</td>\n",
       "      <td>296.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              AGE         SEX       BMI_1  PSQI_TOTAL_1  Insulin _1  \\\n",
       "count  180.000000  180.000000  180.000000    180.000000  180.000000   \n",
       "mean    38.366667    0.305556   23.799644      5.105556    7.700000   \n",
       "std     11.589776    0.461927    4.936177      2.893833    4.105985   \n",
       "min     20.000000    0.000000   15.231576      0.000000    0.100000   \n",
       "25%     29.000000    0.000000   20.833309      3.000000    5.000000   \n",
       "50%     35.500000    0.000000   23.422889      5.000000    6.500000   \n",
       "75%     46.000000    1.000000   25.502662      7.000000    9.505000   \n",
       "max     63.000000    1.000000   67.500000     14.000000   24.700000   \n",
       "\n",
       "            CRP_1       WBC_1  Neutrophil_1       Lym_1     GLU0_1  ...  \\\n",
       "count  180.000000  180.000000    180.000000  180.000000  180.00000  ...   \n",
       "mean     0.748889    5.844867     56.086111   34.113333   98.90000  ...   \n",
       "std      1.344157    1.412280      8.502880    7.708889   14.43773  ...   \n",
       "min      0.000000    2.820000     34.500000   15.100000   63.00000  ...   \n",
       "25%      0.200000    4.857500     50.525000   28.975000   92.00000  ...   \n",
       "50%      0.300000    5.720000     55.950000   34.000000   95.50000  ...   \n",
       "75%      0.700000    6.580000     62.000000   39.000000  102.00000  ...   \n",
       "max     11.100000   10.550000     78.400000   55.400000  182.00000  ...   \n",
       "\n",
       "          Fat_2_x  FatPercentage_2       WHR_2       SBP_2       DBP_2  \\\n",
       "count  180.000000       180.000000  180.000000  180.000000  180.000000   \n",
       "mean    19.053333        28.888333    0.862444  114.605556   72.477778   \n",
       "std      6.616151         7.098802    0.071696   13.213544    9.091991   \n",
       "min      7.700000        11.500000    0.700000   91.000000   57.000000   \n",
       "25%     14.200000        24.275000    0.820000  104.000000   67.000000   \n",
       "50%     17.950000        28.450000    0.850000  114.000000   71.000000   \n",
       "75%     22.125000        33.450000    0.900000  123.000000   77.250000   \n",
       "max     46.100000        48.300000    1.070000  158.000000  107.000000   \n",
       "\n",
       "             HR_2     Waist_2      HDL_2       BUN_2      Chol_2  \n",
       "count  180.000000  180.000000  180.00000  180.000000  180.000000  \n",
       "mean    75.644444   81.328889   59.20000   12.984444  190.922222  \n",
       "std     10.306814   10.251265   14.01372    3.508550   32.017358  \n",
       "min     54.000000   61.000000   29.00000    6.000000  109.000000  \n",
       "25%     68.000000   73.875000   49.00000   10.675000  167.750000  \n",
       "50%     75.000000   80.500000   57.00000   12.700000  188.000000  \n",
       "75%     82.000000   89.000000   69.00000   14.600000  211.000000  \n",
       "max    112.000000  118.000000  116.00000   36.400000  296.000000  \n",
       "\n",
       "[8 rows x 50 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    125\n",
       "1.0     55\n",
       "Name: SEX, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df[\"SEX\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>Neutrophil_1</th>\n",
       "      <th>Lym_1</th>\n",
       "      <th>GLU0_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>HDL_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>Chol_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.097789</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.82</td>\n",
       "      <td>54.6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>20.4</td>\n",
       "      <td>26.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>131.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>88.5</td>\n",
       "      <td>53.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.472213</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.46</td>\n",
       "      <td>44.3</td>\n",
       "      <td>43.7</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>126.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.744827</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.26</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.99</td>\n",
       "      <td>51.0</td>\n",
       "      <td>37.8</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>17.8</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.89</td>\n",
       "      <td>131.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.616175</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.84</td>\n",
       "      <td>39.1</td>\n",
       "      <td>42.1</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>12.8</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.78</td>\n",
       "      <td>102.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.437500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.22</td>\n",
       "      <td>49.3</td>\n",
       "      <td>39.3</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>12.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>106.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.259585</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.78</td>\n",
       "      <td>42.3</td>\n",
       "      <td>47.3</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>27.3</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.94</td>\n",
       "      <td>134.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.630719</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.60</td>\n",
       "      <td>51.7</td>\n",
       "      <td>34.6</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>22.1</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.95</td>\n",
       "      <td>113.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>51.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.641274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.34</td>\n",
       "      <td>55.9</td>\n",
       "      <td>34.9</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>17.5</td>\n",
       "      <td>29.9</td>\n",
       "      <td>0.84</td>\n",
       "      <td>107.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>80.5</td>\n",
       "      <td>49.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.421366</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.88</td>\n",
       "      <td>40.9</td>\n",
       "      <td>48.0</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>15.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>106.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.271653</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.28</td>\n",
       "      <td>75.7</td>\n",
       "      <td>15.1</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>9.3</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>104.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGE  SEX      BMI_1  PSQI_TOTAL_1  Insulin _1  CRP_1  WBC_1  \\\n",
       "0     35  1.0  24.097789           5.0        5.57    0.0   5.82   \n",
       "1     46  1.0  23.472213           5.0        7.35    0.7   5.46   \n",
       "2     32  1.0  23.744827           2.0        9.26    0.4   3.99   \n",
       "3     33  0.0  20.616175           4.0        3.52    0.0   5.84   \n",
       "4     28  0.0  18.437500           3.0        2.86    0.0   4.22   \n",
       "..   ...  ...        ...           ...         ...    ...    ...   \n",
       "175   63  0.0  26.259585           3.0        4.20    0.2   4.78   \n",
       "176   57  1.0  28.630719           4.0        8.80    3.0   4.60   \n",
       "177   35  0.0  21.641274           1.0        6.30    0.4   6.34   \n",
       "178   61  0.0  20.421366           8.0        4.80    0.2   4.88   \n",
       "179   56  1.0  22.271653           1.0        9.00    0.2   6.28   \n",
       "\n",
       "     Neutrophil_1  Lym_1  GLU0_1  ...  Fat_2_x  FatPercentage_2  WHR_2  SBP_2  \\\n",
       "0            54.6   35.0      89  ...     20.4             26.8   1.00  131.0   \n",
       "1            44.3   43.7      90  ...     14.5             18.6   0.84  126.0   \n",
       "2            51.0   37.8      96  ...     17.8             25.6   0.89  131.0   \n",
       "3            39.1   42.1      81  ...     12.8             21.9   0.78  102.0   \n",
       "4            49.3   39.3      63  ...     12.3             25.6   0.80  106.0   \n",
       "..            ...    ...     ...  ...      ...              ...    ...    ...   \n",
       "175          42.3   47.3      96  ...     27.3             39.3   0.94  134.0   \n",
       "176          51.7   34.6      94  ...     22.1             25.7   0.95  113.0   \n",
       "177          55.9   34.9      87  ...     17.5             29.9   0.84  107.0   \n",
       "178          40.9   48.0      93  ...     15.3             29.0   0.81  106.0   \n",
       "179          75.7   15.1     125  ...      9.3             13.1   0.85  104.0   \n",
       "\n",
       "     DBP_2   HR_2  Waist_2  HDL_2  BUN_2  Chol_2  \n",
       "0     74.0   66.0     88.5   53.0   17.5   180.0  \n",
       "1     87.0  108.0     85.0   64.0   14.4   203.0  \n",
       "2     77.0   87.0     81.0   49.0   14.1   196.0  \n",
       "3     62.0   70.0     69.0   98.0   10.5   224.0  \n",
       "4     72.0   69.0     61.0   71.0   11.3   168.0  \n",
       "..     ...    ...      ...    ...    ...     ...  \n",
       "175   89.0   81.0     98.0   66.0   17.1   141.0  \n",
       "176   76.0   66.0     97.5   51.0   14.6   134.0  \n",
       "177   72.0   64.0     80.5   49.0    9.7   147.0  \n",
       "178   76.0   92.0     79.0   60.0   10.2   134.0  \n",
       "179   73.0   79.0     91.0   31.0   36.4   148.0  \n",
       "\n",
       "[180 rows x 50 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (x=쓸 수 있는 모든 특징)\n",
    "X1=psqi_df[['AGE','SEX','BMI_1','PSQI_TOTAL_1','Insulin _1','CRP_1','WBC_1','Neutrophil_1','Lym_1','GLU0_1',\n",
    "            'Creatinine_1','AST_1','ALT_1','HDL_1','LDL_1','Muscle_1','Fat_1_x','FatPercentage _1','WHR_1','SBP_1',\n",
    "            'DBP_1','HR_1','Waist_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','SEX','BMI_2','PSQI_TOTAL_2','Insulin _2','CRP_2','WBC_2','Neutrophil_2','Lym_2','GLU0_2',\n",
    "            'Creatinine_2','AST_2','ALT_2','HDL_2','LDL_2','Muscle_2','Fat_2_x','FatPercentage_2','WHR_2','SBP_2',\n",
    "            'DBP_2','HR_2','Waist_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['TG_1']].values\n",
    "Y2= psqi_df[['TG_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 360)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 23), (360, 1))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 72)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 23), (360, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "72/72 - 0s - loss: 14293.3623 - mse: 14293.3623\n",
      "Epoch 2/1000\n",
      "72/72 - 0s - loss: 12881.1602 - mse: 12881.1602\n",
      "Epoch 3/1000\n",
      "72/72 - 0s - loss: 10660.8135 - mse: 10660.8135\n",
      "Epoch 4/1000\n",
      "72/72 - 0s - loss: 7790.7354 - mse: 7790.7354\n",
      "Epoch 5/1000\n",
      "72/72 - 0s - loss: 5606.8301 - mse: 5606.8301\n",
      "Epoch 6/1000\n",
      "72/72 - 0s - loss: 4276.1201 - mse: 4276.1201\n",
      "Epoch 7/1000\n",
      "72/72 - 0s - loss: 3772.7666 - mse: 3772.7666\n",
      "Epoch 8/1000\n",
      "72/72 - 0s - loss: 3531.0852 - mse: 3531.0852\n",
      "Epoch 9/1000\n",
      "72/72 - 0s - loss: 3386.1519 - mse: 3386.1519\n",
      "Epoch 10/1000\n",
      "72/72 - 0s - loss: 3280.6172 - mse: 3280.6172\n",
      "Epoch 11/1000\n",
      "72/72 - 0s - loss: 3178.4126 - mse: 3178.4126\n",
      "Epoch 12/1000\n",
      "72/72 - 0s - loss: 3117.5708 - mse: 3117.5708\n",
      "Epoch 13/1000\n",
      "72/72 - 0s - loss: 3049.9268 - mse: 3049.9268\n",
      "Epoch 14/1000\n",
      "72/72 - 0s - loss: 2981.9907 - mse: 2981.9907\n",
      "Epoch 15/1000\n",
      "72/72 - 0s - loss: 2957.5278 - mse: 2957.5278\n",
      "Epoch 16/1000\n",
      "72/72 - 0s - loss: 2891.6963 - mse: 2891.6963\n",
      "Epoch 17/1000\n",
      "72/72 - 0s - loss: 2885.9370 - mse: 2885.9370\n",
      "Epoch 18/1000\n",
      "72/72 - 0s - loss: 2855.2190 - mse: 2855.2190\n",
      "Epoch 19/1000\n",
      "72/72 - 0s - loss: 2824.2178 - mse: 2824.2178\n",
      "Epoch 20/1000\n",
      "72/72 - 0s - loss: 2788.4800 - mse: 2788.4800\n",
      "Epoch 21/1000\n",
      "72/72 - 0s - loss: 2769.9653 - mse: 2769.9653\n",
      "Epoch 22/1000\n",
      "72/72 - 0s - loss: 2764.4670 - mse: 2764.4670\n",
      "Epoch 23/1000\n",
      "72/72 - 0s - loss: 2742.1089 - mse: 2742.1089\n",
      "Epoch 24/1000\n",
      "72/72 - 0s - loss: 2728.8643 - mse: 2728.8643\n",
      "Epoch 25/1000\n",
      "72/72 - 0s - loss: 2705.5398 - mse: 2705.5398\n",
      "Epoch 26/1000\n",
      "72/72 - 0s - loss: 2683.5420 - mse: 2683.5420\n",
      "Epoch 27/1000\n",
      "72/72 - 0s - loss: 2677.1213 - mse: 2677.1213\n",
      "Epoch 28/1000\n",
      "72/72 - 0s - loss: 2651.8015 - mse: 2651.8015\n",
      "Epoch 29/1000\n",
      "72/72 - 0s - loss: 2644.2051 - mse: 2644.2051\n",
      "Epoch 30/1000\n",
      "72/72 - 0s - loss: 2636.3396 - mse: 2636.3396\n",
      "Epoch 31/1000\n",
      "72/72 - 0s - loss: 2598.7393 - mse: 2598.7393\n",
      "Epoch 32/1000\n",
      "72/72 - 0s - loss: 2601.7004 - mse: 2601.7004\n",
      "Epoch 33/1000\n",
      "72/72 - 0s - loss: 2604.0845 - mse: 2604.0845\n",
      "Epoch 34/1000\n",
      "72/72 - 0s - loss: 2599.2161 - mse: 2599.2161\n",
      "Epoch 35/1000\n",
      "72/72 - 0s - loss: 2572.3293 - mse: 2572.3293\n",
      "Epoch 36/1000\n",
      "72/72 - 0s - loss: 2562.1396 - mse: 2562.1396\n",
      "Epoch 37/1000\n",
      "72/72 - 0s - loss: 2563.4351 - mse: 2563.4351\n",
      "Epoch 38/1000\n",
      "72/72 - 0s - loss: 2547.3665 - mse: 2547.3665\n",
      "Epoch 39/1000\n",
      "72/72 - 0s - loss: 2532.2463 - mse: 2532.2463\n",
      "Epoch 40/1000\n",
      "72/72 - 0s - loss: 2533.6919 - mse: 2533.6919\n",
      "Epoch 41/1000\n",
      "72/72 - 0s - loss: 2508.7734 - mse: 2508.7734\n",
      "Epoch 42/1000\n",
      "72/72 - 0s - loss: 2516.5435 - mse: 2516.5435\n",
      "Epoch 43/1000\n",
      "72/72 - 0s - loss: 2493.5330 - mse: 2493.5330\n",
      "Epoch 44/1000\n",
      "72/72 - 0s - loss: 2483.3230 - mse: 2483.3230\n",
      "Epoch 45/1000\n",
      "72/72 - 0s - loss: 2480.2881 - mse: 2480.2881\n",
      "Epoch 46/1000\n",
      "72/72 - 0s - loss: 2471.9795 - mse: 2471.9795\n",
      "Epoch 47/1000\n",
      "72/72 - 0s - loss: 2464.5264 - mse: 2464.5264\n",
      "Epoch 48/1000\n",
      "72/72 - 0s - loss: 2467.8477 - mse: 2467.8477\n",
      "Epoch 49/1000\n",
      "72/72 - 0s - loss: 2444.5139 - mse: 2444.5139\n",
      "Epoch 50/1000\n",
      "72/72 - 0s - loss: 2442.4316 - mse: 2442.4316\n",
      "Epoch 51/1000\n",
      "72/72 - 0s - loss: 2445.0706 - mse: 2445.0706\n",
      "Epoch 52/1000\n",
      "72/72 - 0s - loss: 2433.5793 - mse: 2433.5793\n",
      "Epoch 53/1000\n",
      "72/72 - 0s - loss: 2430.0154 - mse: 2430.0154\n",
      "Epoch 54/1000\n",
      "72/72 - 0s - loss: 2426.6787 - mse: 2426.6787\n",
      "Epoch 55/1000\n",
      "72/72 - 0s - loss: 2405.5986 - mse: 2405.5986\n",
      "Epoch 56/1000\n",
      "72/72 - 0s - loss: 2427.1667 - mse: 2427.1667\n",
      "Epoch 57/1000\n",
      "72/72 - 0s - loss: 2387.0701 - mse: 2387.0701\n",
      "Epoch 58/1000\n",
      "72/72 - 0s - loss: 2386.6687 - mse: 2386.6687\n",
      "Epoch 59/1000\n",
      "72/72 - 0s - loss: 2378.7319 - mse: 2378.7319\n",
      "Epoch 60/1000\n",
      "72/72 - 0s - loss: 2353.9399 - mse: 2353.9399\n",
      "Epoch 61/1000\n",
      "72/72 - 0s - loss: 2374.0503 - mse: 2374.0503\n",
      "Epoch 62/1000\n",
      "72/72 - 0s - loss: 2356.0012 - mse: 2356.0012\n",
      "Epoch 63/1000\n",
      "72/72 - 0s - loss: 2354.1667 - mse: 2354.1667\n",
      "Epoch 64/1000\n",
      "72/72 - 0s - loss: 2361.0537 - mse: 2361.0537\n",
      "Epoch 65/1000\n",
      "72/72 - 0s - loss: 2361.7476 - mse: 2361.7476\n",
      "Epoch 66/1000\n",
      "72/72 - 0s - loss: 2347.6533 - mse: 2347.6533\n",
      "Epoch 67/1000\n",
      "72/72 - 0s - loss: 2322.8013 - mse: 2322.8013\n",
      "Epoch 68/1000\n",
      "72/72 - 0s - loss: 2346.2356 - mse: 2346.2356\n",
      "Epoch 69/1000\n",
      "72/72 - 0s - loss: 2324.7676 - mse: 2324.7676\n",
      "Epoch 70/1000\n",
      "72/72 - 0s - loss: 2328.9658 - mse: 2328.9658\n",
      "Epoch 71/1000\n",
      "72/72 - 0s - loss: 2322.7566 - mse: 2322.7566\n",
      "Epoch 72/1000\n",
      "72/72 - 0s - loss: 2328.1331 - mse: 2328.1331\n",
      "Epoch 73/1000\n",
      "72/72 - 0s - loss: 2295.4353 - mse: 2295.4353\n",
      "Epoch 74/1000\n",
      "72/72 - 0s - loss: 2304.9995 - mse: 2304.9995\n",
      "Epoch 75/1000\n",
      "72/72 - 0s - loss: 2306.0459 - mse: 2306.0459\n",
      "Epoch 76/1000\n",
      "72/72 - 0s - loss: 2285.6670 - mse: 2285.6670\n",
      "Epoch 77/1000\n",
      "72/72 - 0s - loss: 2305.7256 - mse: 2305.7256\n",
      "Epoch 78/1000\n",
      "72/72 - 0s - loss: 2295.7051 - mse: 2295.7051\n",
      "Epoch 79/1000\n",
      "72/72 - 0s - loss: 2279.6465 - mse: 2279.6465\n",
      "Epoch 80/1000\n",
      "72/72 - 0s - loss: 2275.2822 - mse: 2275.2822\n",
      "Epoch 81/1000\n",
      "72/72 - 0s - loss: 2289.9231 - mse: 2289.9231\n",
      "Epoch 82/1000\n",
      "72/72 - 0s - loss: 2268.7520 - mse: 2268.7520\n",
      "Epoch 83/1000\n",
      "72/72 - 0s - loss: 2269.2966 - mse: 2269.2966\n",
      "Epoch 84/1000\n",
      "72/72 - 0s - loss: 2274.4958 - mse: 2274.4958\n",
      "Epoch 85/1000\n",
      "72/72 - 0s - loss: 2261.0142 - mse: 2261.0142\n",
      "Epoch 86/1000\n",
      "72/72 - 0s - loss: 2242.7786 - mse: 2242.7786\n",
      "Epoch 87/1000\n",
      "72/72 - 0s - loss: 2254.3945 - mse: 2254.3945\n",
      "Epoch 88/1000\n",
      "72/72 - 0s - loss: 2261.5952 - mse: 2261.5952\n",
      "Epoch 89/1000\n",
      "72/72 - 0s - loss: 2238.3501 - mse: 2238.3501\n",
      "Epoch 90/1000\n",
      "72/72 - 0s - loss: 2252.1877 - mse: 2252.1877\n",
      "Epoch 91/1000\n",
      "72/72 - 0s - loss: 2226.1123 - mse: 2226.1123\n",
      "Epoch 92/1000\n",
      "72/72 - 0s - loss: 2224.6924 - mse: 2224.6924\n",
      "Epoch 93/1000\n",
      "72/72 - 0s - loss: 2225.0669 - mse: 2225.0669\n",
      "Epoch 94/1000\n",
      "72/72 - 0s - loss: 2216.3806 - mse: 2216.3806\n",
      "Epoch 95/1000\n",
      "72/72 - 0s - loss: 2199.0693 - mse: 2199.0693\n",
      "Epoch 96/1000\n",
      "72/72 - 0s - loss: 2203.7256 - mse: 2203.7256\n",
      "Epoch 97/1000\n",
      "72/72 - 0s - loss: 2199.5215 - mse: 2199.5215\n",
      "Epoch 98/1000\n",
      "72/72 - 0s - loss: 2204.9565 - mse: 2204.9565\n",
      "Epoch 99/1000\n",
      "72/72 - 0s - loss: 2202.9043 - mse: 2202.9043\n",
      "Epoch 100/1000\n",
      "72/72 - 0s - loss: 2184.6384 - mse: 2184.6384\n",
      "Epoch 101/1000\n",
      "72/72 - 0s - loss: 2180.5400 - mse: 2180.5400\n",
      "Epoch 102/1000\n",
      "72/72 - 0s - loss: 2169.7715 - mse: 2169.7715\n",
      "Epoch 103/1000\n",
      "72/72 - 0s - loss: 2176.3018 - mse: 2176.3018\n",
      "Epoch 104/1000\n",
      "72/72 - 0s - loss: 2157.8650 - mse: 2157.8650\n",
      "Epoch 105/1000\n",
      "72/72 - 0s - loss: 2153.8804 - mse: 2153.8804\n",
      "Epoch 106/1000\n",
      "72/72 - 0s - loss: 2161.2756 - mse: 2161.2756\n",
      "Epoch 107/1000\n",
      "72/72 - 0s - loss: 2157.3501 - mse: 2157.3501\n",
      "Epoch 108/1000\n",
      "72/72 - 0s - loss: 2135.6211 - mse: 2135.6211\n",
      "Epoch 109/1000\n",
      "72/72 - 0s - loss: 2141.7068 - mse: 2141.7068\n",
      "Epoch 110/1000\n",
      "72/72 - 0s - loss: 2133.0400 - mse: 2133.0400\n",
      "Epoch 111/1000\n",
      "72/72 - 0s - loss: 2134.5986 - mse: 2134.5986\n",
      "Epoch 112/1000\n",
      "72/72 - 0s - loss: 2113.6252 - mse: 2113.6252\n",
      "Epoch 113/1000\n",
      "72/72 - 0s - loss: 2120.7483 - mse: 2120.7483\n",
      "Epoch 114/1000\n",
      "72/72 - 0s - loss: 2126.5811 - mse: 2126.5811\n",
      "Epoch 115/1000\n",
      "72/72 - 0s - loss: 2115.3296 - mse: 2115.3296\n",
      "Epoch 116/1000\n",
      "72/72 - 0s - loss: 2102.5498 - mse: 2102.5498\n",
      "Epoch 117/1000\n",
      "72/72 - 0s - loss: 2100.0933 - mse: 2100.0933\n",
      "Epoch 118/1000\n",
      "72/72 - 0s - loss: 2109.6013 - mse: 2109.6013\n",
      "Epoch 119/1000\n",
      "72/72 - 0s - loss: 2083.7773 - mse: 2083.7773\n",
      "Epoch 120/1000\n",
      "72/72 - 0s - loss: 2100.7959 - mse: 2100.7959\n",
      "Epoch 121/1000\n",
      "72/72 - 0s - loss: 2054.6450 - mse: 2054.6450\n",
      "Epoch 122/1000\n",
      "72/72 - 0s - loss: 2064.1279 - mse: 2064.1279\n",
      "Epoch 123/1000\n",
      "72/72 - 0s - loss: 2078.8931 - mse: 2078.8931\n",
      "Epoch 124/1000\n",
      "72/72 - 0s - loss: 2056.4900 - mse: 2056.4900\n",
      "Epoch 125/1000\n",
      "72/72 - 0s - loss: 2067.2166 - mse: 2067.2166\n",
      "Epoch 126/1000\n",
      "72/72 - 0s - loss: 2064.7400 - mse: 2064.7400\n",
      "Epoch 127/1000\n",
      "72/72 - 0s - loss: 2042.4551 - mse: 2042.4551\n",
      "Epoch 128/1000\n",
      "72/72 - 0s - loss: 2055.9507 - mse: 2055.9507\n",
      "Epoch 129/1000\n",
      "72/72 - 0s - loss: 2019.3892 - mse: 2019.3892\n",
      "Epoch 130/1000\n",
      "72/72 - 0s - loss: 2039.1002 - mse: 2039.1002\n",
      "Epoch 131/1000\n",
      "72/72 - 0s - loss: 2040.4358 - mse: 2040.4358\n",
      "Epoch 132/1000\n",
      "72/72 - 0s - loss: 2035.5173 - mse: 2035.5173\n",
      "Epoch 133/1000\n",
      "72/72 - 0s - loss: 2025.6890 - mse: 2025.6890\n",
      "Epoch 134/1000\n",
      "72/72 - 0s - loss: 2014.7137 - mse: 2014.7137\n",
      "Epoch 135/1000\n",
      "72/72 - 0s - loss: 2009.7570 - mse: 2009.7570\n",
      "Epoch 136/1000\n",
      "72/72 - 0s - loss: 2008.4749 - mse: 2008.4749\n",
      "Epoch 137/1000\n",
      "72/72 - 0s - loss: 2013.3628 - mse: 2013.3628\n",
      "Epoch 138/1000\n",
      "72/72 - 0s - loss: 1983.5717 - mse: 1983.5717\n",
      "Epoch 139/1000\n",
      "72/72 - 0s - loss: 1993.0959 - mse: 1993.0959\n",
      "Epoch 140/1000\n",
      "72/72 - 0s - loss: 1969.6278 - mse: 1969.6278\n",
      "Epoch 141/1000\n",
      "72/72 - 0s - loss: 1979.2561 - mse: 1979.2561\n",
      "Epoch 142/1000\n",
      "72/72 - 0s - loss: 1974.9409 - mse: 1974.9409\n",
      "Epoch 143/1000\n",
      "72/72 - 0s - loss: 1963.4897 - mse: 1963.4897\n",
      "Epoch 144/1000\n",
      "72/72 - 0s - loss: 1967.8813 - mse: 1967.8813\n",
      "Epoch 145/1000\n",
      "72/72 - 0s - loss: 1950.6810 - mse: 1950.6810\n",
      "Epoch 146/1000\n",
      "72/72 - 0s - loss: 1960.2173 - mse: 1960.2173\n",
      "Epoch 147/1000\n",
      "72/72 - 0s - loss: 1941.6122 - mse: 1941.6122\n",
      "Epoch 148/1000\n",
      "72/72 - 0s - loss: 1932.5918 - mse: 1932.5918\n",
      "Epoch 149/1000\n",
      "72/72 - 0s - loss: 1946.3959 - mse: 1946.3959\n",
      "Epoch 150/1000\n",
      "72/72 - 0s - loss: 1949.6331 - mse: 1949.6331\n",
      "Epoch 151/1000\n",
      "72/72 - 0s - loss: 1929.4056 - mse: 1929.4056\n",
      "Epoch 152/1000\n",
      "72/72 - 0s - loss: 1927.4763 - mse: 1927.4763\n",
      "Epoch 153/1000\n",
      "72/72 - 0s - loss: 1904.5616 - mse: 1904.5616\n",
      "Epoch 154/1000\n",
      "72/72 - 0s - loss: 1916.0909 - mse: 1916.0909\n",
      "Epoch 155/1000\n",
      "72/72 - 0s - loss: 1918.3164 - mse: 1918.3164\n",
      "Epoch 156/1000\n",
      "72/72 - 0s - loss: 1901.7198 - mse: 1901.7198\n",
      "Epoch 157/1000\n",
      "72/72 - 0s - loss: 1906.2854 - mse: 1906.2854\n",
      "Epoch 158/1000\n",
      "72/72 - 0s - loss: 1880.6705 - mse: 1880.6705\n",
      "Epoch 159/1000\n",
      "72/72 - 0s - loss: 1879.6730 - mse: 1879.6730\n",
      "Epoch 160/1000\n",
      "72/72 - 0s - loss: 1872.2612 - mse: 1872.2612\n",
      "Epoch 161/1000\n",
      "72/72 - 0s - loss: 1853.0078 - mse: 1853.0078\n",
      "Epoch 162/1000\n",
      "72/72 - 0s - loss: 1876.7257 - mse: 1876.7257\n",
      "Epoch 163/1000\n",
      "72/72 - 0s - loss: 1874.5636 - mse: 1874.5636\n",
      "Epoch 164/1000\n",
      "72/72 - 0s - loss: 1832.9451 - mse: 1832.9451\n",
      "Epoch 165/1000\n",
      "72/72 - 0s - loss: 1846.5260 - mse: 1846.5260\n",
      "Epoch 166/1000\n",
      "72/72 - 0s - loss: 1844.9518 - mse: 1844.9518\n",
      "Epoch 167/1000\n",
      "72/72 - 0s - loss: 1825.9438 - mse: 1825.9438\n",
      "Epoch 168/1000\n",
      "72/72 - 0s - loss: 1835.3719 - mse: 1835.3719\n",
      "Epoch 169/1000\n",
      "72/72 - 0s - loss: 1809.3955 - mse: 1809.3955\n",
      "Epoch 170/1000\n",
      "72/72 - 0s - loss: 1817.2490 - mse: 1817.2490\n",
      "Epoch 171/1000\n",
      "72/72 - 0s - loss: 1814.9935 - mse: 1814.9935\n",
      "Epoch 172/1000\n",
      "72/72 - 0s - loss: 1794.7546 - mse: 1794.7546\n",
      "Epoch 173/1000\n",
      "72/72 - 0s - loss: 1804.4678 - mse: 1804.4678\n",
      "Epoch 174/1000\n",
      "72/72 - 0s - loss: 1786.4849 - mse: 1786.4849\n",
      "Epoch 175/1000\n",
      "72/72 - 0s - loss: 1773.6196 - mse: 1773.6196\n",
      "Epoch 176/1000\n",
      "72/72 - 0s - loss: 1777.1727 - mse: 1777.1727\n",
      "Epoch 177/1000\n",
      "72/72 - 0s - loss: 1779.4373 - mse: 1779.4373\n",
      "Epoch 178/1000\n",
      "72/72 - 0s - loss: 1764.1698 - mse: 1764.1698\n",
      "Epoch 179/1000\n",
      "72/72 - 0s - loss: 1756.3434 - mse: 1756.3434\n",
      "Epoch 180/1000\n",
      "72/72 - 0s - loss: 1743.0836 - mse: 1743.0836\n",
      "Epoch 181/1000\n",
      "72/72 - 0s - loss: 1731.9437 - mse: 1731.9437\n",
      "Epoch 182/1000\n",
      "72/72 - 0s - loss: 1737.6764 - mse: 1737.6764\n",
      "Epoch 183/1000\n",
      "72/72 - 0s - loss: 1749.8345 - mse: 1749.8345\n",
      "Epoch 184/1000\n",
      "72/72 - 0s - loss: 1735.3287 - mse: 1735.3287\n",
      "Epoch 185/1000\n",
      "72/72 - 0s - loss: 1708.2754 - mse: 1708.2754\n",
      "Epoch 186/1000\n",
      "72/72 - 0s - loss: 1717.7386 - mse: 1717.7386\n",
      "Epoch 187/1000\n",
      "72/72 - 0s - loss: 1717.9537 - mse: 1717.9537\n",
      "Epoch 188/1000\n",
      "72/72 - 0s - loss: 1701.7848 - mse: 1701.7848\n",
      "Epoch 189/1000\n",
      "72/72 - 0s - loss: 1689.2473 - mse: 1689.2473\n",
      "Epoch 190/1000\n",
      "72/72 - 0s - loss: 1681.3717 - mse: 1681.3717\n",
      "Epoch 191/1000\n",
      "72/72 - 0s - loss: 1676.9266 - mse: 1676.9266\n",
      "Epoch 192/1000\n",
      "72/72 - 0s - loss: 1698.7314 - mse: 1698.7314\n",
      "Epoch 193/1000\n",
      "72/72 - 0s - loss: 1687.2129 - mse: 1687.2129\n",
      "Epoch 194/1000\n",
      "72/72 - 0s - loss: 1663.7495 - mse: 1663.7495\n",
      "Epoch 195/1000\n",
      "72/72 - 0s - loss: 1667.1401 - mse: 1667.1401\n",
      "Epoch 196/1000\n",
      "72/72 - 0s - loss: 1631.1320 - mse: 1631.1320\n",
      "Epoch 197/1000\n",
      "72/72 - 0s - loss: 1656.5288 - mse: 1656.5288\n",
      "Epoch 198/1000\n",
      "72/72 - 0s - loss: 1646.9183 - mse: 1646.9183\n",
      "Epoch 199/1000\n",
      "72/72 - 0s - loss: 1632.5253 - mse: 1632.5253\n",
      "Epoch 200/1000\n",
      "72/72 - 0s - loss: 1613.5112 - mse: 1613.5112\n",
      "Epoch 201/1000\n",
      "72/72 - 0s - loss: 1613.3440 - mse: 1613.3440\n",
      "Epoch 202/1000\n",
      "72/72 - 0s - loss: 1605.8997 - mse: 1605.8997\n",
      "Epoch 203/1000\n",
      "72/72 - 0s - loss: 1582.8728 - mse: 1582.8728\n",
      "Epoch 204/1000\n",
      "72/72 - 0s - loss: 1596.5259 - mse: 1596.5259\n",
      "Epoch 205/1000\n",
      "72/72 - 0s - loss: 1578.1149 - mse: 1578.1149\n",
      "Epoch 206/1000\n",
      "72/72 - 0s - loss: 1583.6116 - mse: 1583.6116\n",
      "Epoch 207/1000\n",
      "72/72 - 0s - loss: 1576.2363 - mse: 1576.2363\n",
      "Epoch 208/1000\n",
      "72/72 - 0s - loss: 1565.8950 - mse: 1565.8950\n",
      "Epoch 209/1000\n",
      "72/72 - 0s - loss: 1565.0850 - mse: 1565.0850\n",
      "Epoch 210/1000\n",
      "72/72 - 0s - loss: 1543.1368 - mse: 1543.1368\n",
      "Epoch 211/1000\n",
      "72/72 - 0s - loss: 1556.0682 - mse: 1556.0682\n",
      "Epoch 212/1000\n",
      "72/72 - 0s - loss: 1548.4048 - mse: 1548.4048\n",
      "Epoch 213/1000\n",
      "72/72 - 0s - loss: 1521.7676 - mse: 1521.7676\n",
      "Epoch 214/1000\n",
      "72/72 - 0s - loss: 1537.1667 - mse: 1537.1667\n",
      "Epoch 215/1000\n",
      "72/72 - 0s - loss: 1520.8292 - mse: 1520.8292\n",
      "Epoch 216/1000\n",
      "72/72 - 0s - loss: 1508.8291 - mse: 1508.8291\n",
      "Epoch 217/1000\n",
      "72/72 - 0s - loss: 1501.9075 - mse: 1501.9075\n",
      "Epoch 218/1000\n",
      "72/72 - 0s - loss: 1489.4099 - mse: 1489.4099\n",
      "Epoch 219/1000\n",
      "72/72 - 0s - loss: 1496.1267 - mse: 1496.1267\n",
      "Epoch 220/1000\n",
      "72/72 - 0s - loss: 1478.3608 - mse: 1478.3608\n",
      "Epoch 221/1000\n",
      "72/72 - 0s - loss: 1487.2478 - mse: 1487.2478\n",
      "Epoch 222/1000\n",
      "72/72 - 0s - loss: 1460.6877 - mse: 1460.6877\n",
      "Epoch 223/1000\n",
      "72/72 - 0s - loss: 1454.6260 - mse: 1454.6260\n",
      "Epoch 224/1000\n",
      "72/72 - 0s - loss: 1463.0801 - mse: 1463.0801\n",
      "Epoch 225/1000\n",
      "72/72 - 0s - loss: 1438.1118 - mse: 1438.1118\n",
      "Epoch 226/1000\n",
      "72/72 - 0s - loss: 1457.6696 - mse: 1457.6696\n",
      "Epoch 227/1000\n",
      "72/72 - 0s - loss: 1441.1401 - mse: 1441.1401\n",
      "Epoch 228/1000\n",
      "72/72 - 0s - loss: 1430.8979 - mse: 1430.8979\n",
      "Epoch 229/1000\n",
      "72/72 - 0s - loss: 1408.8781 - mse: 1408.8781\n",
      "Epoch 230/1000\n",
      "72/72 - 0s - loss: 1407.0995 - mse: 1407.0995\n",
      "Epoch 231/1000\n",
      "72/72 - 0s - loss: 1416.0404 - mse: 1416.0404\n",
      "Epoch 232/1000\n",
      "72/72 - 0s - loss: 1406.9082 - mse: 1406.9082\n",
      "Epoch 233/1000\n",
      "72/72 - 0s - loss: 1374.6757 - mse: 1374.6757\n",
      "Epoch 234/1000\n",
      "72/72 - 0s - loss: 1391.8901 - mse: 1391.8901\n",
      "Epoch 235/1000\n",
      "72/72 - 0s - loss: 1374.8983 - mse: 1374.8983\n",
      "Epoch 236/1000\n",
      "72/72 - 0s - loss: 1365.1522 - mse: 1365.1522\n",
      "Epoch 237/1000\n",
      "72/72 - 0s - loss: 1375.4624 - mse: 1375.4624\n",
      "Epoch 238/1000\n",
      "72/72 - 0s - loss: 1367.4911 - mse: 1367.4911\n",
      "Epoch 239/1000\n",
      "72/72 - 0s - loss: 1331.1520 - mse: 1331.1520\n",
      "Epoch 240/1000\n",
      "72/72 - 0s - loss: 1350.2812 - mse: 1350.2812\n",
      "Epoch 241/1000\n",
      "72/72 - 0s - loss: 1335.0380 - mse: 1335.0380\n",
      "Epoch 242/1000\n",
      "72/72 - 0s - loss: 1318.4218 - mse: 1318.4218\n",
      "Epoch 243/1000\n",
      "72/72 - 0s - loss: 1318.9235 - mse: 1318.9235\n",
      "Epoch 244/1000\n",
      "72/72 - 0s - loss: 1308.1256 - mse: 1308.1256\n",
      "Epoch 245/1000\n",
      "72/72 - 0s - loss: 1299.7842 - mse: 1299.7842\n",
      "Epoch 246/1000\n",
      "72/72 - 0s - loss: 1285.5778 - mse: 1285.5778\n",
      "Epoch 247/1000\n",
      "72/72 - 0s - loss: 1295.1958 - mse: 1295.1958\n",
      "Epoch 248/1000\n",
      "72/72 - 0s - loss: 1273.0321 - mse: 1273.0321\n",
      "Epoch 249/1000\n",
      "72/72 - 0s - loss: 1265.2645 - mse: 1265.2645\n",
      "Epoch 250/1000\n",
      "72/72 - 0s - loss: 1266.3401 - mse: 1266.3401\n",
      "Epoch 251/1000\n",
      "72/72 - 0s - loss: 1242.0372 - mse: 1242.0372\n",
      "Epoch 252/1000\n",
      "72/72 - 0s - loss: 1228.5900 - mse: 1228.5900\n",
      "Epoch 253/1000\n",
      "72/72 - 0s - loss: 1236.4082 - mse: 1236.4082\n",
      "Epoch 254/1000\n",
      "72/72 - 0s - loss: 1230.9237 - mse: 1230.9237\n",
      "Epoch 255/1000\n",
      "72/72 - 0s - loss: 1218.9685 - mse: 1218.9685\n",
      "Epoch 256/1000\n",
      "72/72 - 0s - loss: 1218.3055 - mse: 1218.3055\n",
      "Epoch 257/1000\n",
      "72/72 - 0s - loss: 1190.0912 - mse: 1190.0912\n",
      "Epoch 258/1000\n",
      "72/72 - 0s - loss: 1212.6903 - mse: 1212.6903\n",
      "Epoch 259/1000\n",
      "72/72 - 0s - loss: 1170.8981 - mse: 1170.8981\n",
      "Epoch 260/1000\n",
      "72/72 - 0s - loss: 1191.6736 - mse: 1191.6736\n",
      "Epoch 261/1000\n",
      "72/72 - 0s - loss: 1181.0051 - mse: 1181.0051\n",
      "Epoch 262/1000\n",
      "72/72 - 0s - loss: 1163.6456 - mse: 1163.6456\n",
      "Epoch 263/1000\n",
      "72/72 - 0s - loss: 1162.7808 - mse: 1162.7808\n",
      "Epoch 264/1000\n",
      "72/72 - 0s - loss: 1161.0739 - mse: 1161.0739\n",
      "Epoch 265/1000\n",
      "72/72 - 0s - loss: 1145.9265 - mse: 1145.9265\n",
      "Epoch 266/1000\n",
      "72/72 - 0s - loss: 1137.9917 - mse: 1137.9917\n",
      "Epoch 267/1000\n",
      "72/72 - 0s - loss: 1126.9167 - mse: 1126.9167\n",
      "Epoch 268/1000\n",
      "72/72 - 0s - loss: 1131.1039 - mse: 1131.1039\n",
      "Epoch 269/1000\n",
      "72/72 - 0s - loss: 1099.4783 - mse: 1099.4783\n",
      "Epoch 270/1000\n",
      "72/72 - 0s - loss: 1123.6266 - mse: 1123.6266\n",
      "Epoch 271/1000\n",
      "72/72 - 0s - loss: 1119.2777 - mse: 1119.2777\n",
      "Epoch 272/1000\n",
      "72/72 - 0s - loss: 1093.2120 - mse: 1093.2120\n",
      "Epoch 273/1000\n",
      "72/72 - 0s - loss: 1095.5544 - mse: 1095.5544\n",
      "Epoch 274/1000\n",
      "72/72 - 0s - loss: 1094.1670 - mse: 1094.1670\n",
      "Epoch 275/1000\n",
      "72/72 - 0s - loss: 1054.2637 - mse: 1054.2637\n",
      "Epoch 276/1000\n",
      "72/72 - 0s - loss: 1077.9010 - mse: 1077.9010\n",
      "Epoch 277/1000\n",
      "72/72 - 0s - loss: 1036.5619 - mse: 1036.5619\n",
      "Epoch 278/1000\n",
      "72/72 - 0s - loss: 1061.1643 - mse: 1061.1643\n",
      "Epoch 279/1000\n",
      "72/72 - 0s - loss: 1026.9355 - mse: 1026.9355\n",
      "Epoch 280/1000\n",
      "72/72 - 0s - loss: 1054.5558 - mse: 1054.5558\n",
      "Epoch 281/1000\n",
      "72/72 - 0s - loss: 1056.8906 - mse: 1056.8906\n",
      "Epoch 282/1000\n",
      "72/72 - 0s - loss: 1021.1948 - mse: 1021.1948\n",
      "Epoch 283/1000\n",
      "72/72 - 0s - loss: 1010.7472 - mse: 1010.7472\n",
      "Epoch 284/1000\n",
      "72/72 - 0s - loss: 1013.3888 - mse: 1013.3888\n",
      "Epoch 285/1000\n",
      "72/72 - 0s - loss: 996.8704 - mse: 996.8704\n",
      "Epoch 286/1000\n",
      "72/72 - 0s - loss: 1005.6693 - mse: 1005.6693\n",
      "Epoch 287/1000\n",
      "72/72 - 0s - loss: 996.4206 - mse: 996.4206\n",
      "Epoch 288/1000\n",
      "72/72 - 0s - loss: 988.0932 - mse: 988.0932\n",
      "Epoch 289/1000\n",
      "72/72 - 0s - loss: 979.1228 - mse: 979.1228\n",
      "Epoch 290/1000\n",
      "72/72 - 0s - loss: 971.7483 - mse: 971.7483\n",
      "Epoch 291/1000\n",
      "72/72 - 0s - loss: 946.0494 - mse: 946.0494\n",
      "Epoch 292/1000\n",
      "72/72 - 0s - loss: 969.6849 - mse: 969.6849\n",
      "Epoch 293/1000\n",
      "72/72 - 0s - loss: 955.2932 - mse: 955.2932\n",
      "Epoch 294/1000\n",
      "72/72 - 0s - loss: 960.3962 - mse: 960.3962\n",
      "Epoch 295/1000\n",
      "72/72 - 0s - loss: 949.5703 - mse: 949.5703\n",
      "Epoch 296/1000\n",
      "72/72 - 0s - loss: 929.7914 - mse: 929.7914\n",
      "Epoch 297/1000\n",
      "72/72 - 0s - loss: 930.4473 - mse: 930.4473\n",
      "Epoch 298/1000\n",
      "72/72 - 0s - loss: 935.9028 - mse: 935.9028\n",
      "Epoch 299/1000\n",
      "72/72 - 0s - loss: 915.5724 - mse: 915.5724\n",
      "Epoch 300/1000\n",
      "72/72 - 0s - loss: 911.0523 - mse: 911.0523\n",
      "Epoch 301/1000\n",
      "72/72 - 0s - loss: 902.6469 - mse: 902.6469\n",
      "Epoch 302/1000\n",
      "72/72 - 0s - loss: 896.4904 - mse: 896.4904\n",
      "Epoch 303/1000\n",
      "72/72 - 0s - loss: 891.6877 - mse: 891.6877\n",
      "Epoch 304/1000\n",
      "72/72 - 0s - loss: 898.8567 - mse: 898.8567\n",
      "Epoch 305/1000\n",
      "72/72 - 0s - loss: 882.8616 - mse: 882.8616\n",
      "Epoch 306/1000\n",
      "72/72 - 0s - loss: 880.2452 - mse: 880.2452\n",
      "Epoch 307/1000\n",
      "72/72 - 0s - loss: 851.5593 - mse: 851.5593\n",
      "Epoch 308/1000\n",
      "72/72 - 0s - loss: 836.8864 - mse: 836.8864\n",
      "Epoch 309/1000\n",
      "72/72 - 0s - loss: 873.3598 - mse: 873.3598\n",
      "Epoch 310/1000\n",
      "72/72 - 0s - loss: 833.6328 - mse: 833.6328\n",
      "Epoch 311/1000\n",
      "72/72 - 0s - loss: 868.3305 - mse: 868.3305\n",
      "Epoch 312/1000\n",
      "72/72 - 0s - loss: 827.6256 - mse: 827.6256\n",
      "Epoch 313/1000\n",
      "72/72 - 0s - loss: 848.0103 - mse: 848.0103\n",
      "Epoch 314/1000\n",
      "72/72 - 0s - loss: 846.0379 - mse: 846.0379\n",
      "Epoch 315/1000\n",
      "72/72 - 0s - loss: 814.1649 - mse: 814.1649\n",
      "Epoch 316/1000\n",
      "72/72 - 0s - loss: 805.6016 - mse: 805.6016\n",
      "Epoch 317/1000\n",
      "72/72 - 0s - loss: 820.3307 - mse: 820.3307\n",
      "Epoch 318/1000\n",
      "72/72 - 0s - loss: 813.5854 - mse: 813.5854\n",
      "Epoch 319/1000\n",
      "72/72 - 0s - loss: 802.1472 - mse: 802.1472\n",
      "Epoch 320/1000\n",
      "72/72 - 0s - loss: 790.3189 - mse: 790.3189\n",
      "Epoch 321/1000\n",
      "72/72 - 0s - loss: 796.9753 - mse: 796.9753\n",
      "Epoch 322/1000\n",
      "72/72 - 0s - loss: 776.2415 - mse: 776.2415\n",
      "Epoch 323/1000\n",
      "72/72 - 0s - loss: 783.5356 - mse: 783.5356\n",
      "Epoch 324/1000\n",
      "72/72 - 0s - loss: 783.9377 - mse: 783.9377\n",
      "Epoch 325/1000\n",
      "72/72 - 0s - loss: 764.4637 - mse: 764.4637\n",
      "Epoch 326/1000\n",
      "72/72 - 0s - loss: 752.2800 - mse: 752.2800\n",
      "Epoch 327/1000\n",
      "72/72 - 0s - loss: 749.6341 - mse: 749.6341\n",
      "Epoch 328/1000\n",
      "72/72 - 0s - loss: 751.8882 - mse: 751.8882\n",
      "Epoch 329/1000\n",
      "72/72 - 0s - loss: 760.4835 - mse: 760.4835\n",
      "Epoch 330/1000\n",
      "72/72 - 0s - loss: 732.1628 - mse: 732.1628\n",
      "Epoch 331/1000\n",
      "72/72 - 0s - loss: 717.7233 - mse: 717.7233\n",
      "Epoch 332/1000\n",
      "72/72 - 0s - loss: 721.9753 - mse: 721.9753\n",
      "Epoch 333/1000\n",
      "72/72 - 0s - loss: 749.5944 - mse: 749.5944\n",
      "Epoch 334/1000\n",
      "72/72 - 0s - loss: 720.2832 - mse: 720.2832\n",
      "Epoch 335/1000\n",
      "72/72 - 0s - loss: 714.6655 - mse: 714.6655\n",
      "Epoch 336/1000\n",
      "72/72 - 0s - loss: 714.6071 - mse: 714.6071\n",
      "Epoch 337/1000\n",
      "72/72 - 0s - loss: 714.8847 - mse: 714.8847\n",
      "Epoch 338/1000\n",
      "72/72 - 0s - loss: 706.2454 - mse: 706.2454\n",
      "Epoch 339/1000\n",
      "72/72 - 0s - loss: 687.1345 - mse: 687.1345\n",
      "Epoch 340/1000\n",
      "72/72 - 0s - loss: 695.2419 - mse: 695.2419\n",
      "Epoch 341/1000\n",
      "72/72 - 0s - loss: 672.0158 - mse: 672.0158\n",
      "Epoch 342/1000\n",
      "72/72 - 0s - loss: 676.2515 - mse: 676.2515\n",
      "Epoch 343/1000\n",
      "72/72 - 0s - loss: 677.9874 - mse: 677.9874\n",
      "Epoch 344/1000\n",
      "72/72 - 0s - loss: 688.0709 - mse: 688.0709\n",
      "Epoch 345/1000\n",
      "72/72 - 0s - loss: 657.6322 - mse: 657.6322\n",
      "Epoch 346/1000\n",
      "72/72 - 0s - loss: 675.2040 - mse: 675.2040\n",
      "Epoch 347/1000\n",
      "72/72 - 0s - loss: 634.3190 - mse: 634.3190\n",
      "Epoch 348/1000\n",
      "72/72 - 0s - loss: 660.1237 - mse: 660.1237\n",
      "Epoch 349/1000\n",
      "72/72 - 0s - loss: 640.1533 - mse: 640.1533\n",
      "Epoch 350/1000\n",
      "72/72 - 0s - loss: 634.2203 - mse: 634.2203\n",
      "Epoch 351/1000\n",
      "72/72 - 0s - loss: 642.8710 - mse: 642.8710\n",
      "Epoch 352/1000\n",
      "72/72 - 0s - loss: 625.5602 - mse: 625.5602\n",
      "Epoch 353/1000\n",
      "72/72 - 0s - loss: 630.6628 - mse: 630.6628\n",
      "Epoch 354/1000\n",
      "72/72 - 0s - loss: 621.2350 - mse: 621.2350\n",
      "Epoch 355/1000\n",
      "72/72 - 0s - loss: 626.8854 - mse: 626.8854\n",
      "Epoch 356/1000\n",
      "72/72 - 0s - loss: 594.8399 - mse: 594.8399\n",
      "Epoch 357/1000\n",
      "72/72 - 0s - loss: 608.0555 - mse: 608.0555\n",
      "Epoch 358/1000\n",
      "72/72 - 0s - loss: 594.7263 - mse: 594.7263\n",
      "Epoch 359/1000\n",
      "72/72 - 0s - loss: 582.4368 - mse: 582.4368\n",
      "Epoch 360/1000\n",
      "72/72 - 0s - loss: 591.6274 - mse: 591.6274\n",
      "Epoch 361/1000\n",
      "72/72 - 0s - loss: 588.2697 - mse: 588.2697\n",
      "Epoch 362/1000\n",
      "72/72 - 0s - loss: 590.8186 - mse: 590.8186\n",
      "Epoch 363/1000\n",
      "72/72 - 0s - loss: 573.1338 - mse: 573.1338\n",
      "Epoch 364/1000\n",
      "72/72 - 0s - loss: 564.2433 - mse: 564.2433\n",
      "Epoch 365/1000\n",
      "72/72 - 0s - loss: 583.0430 - mse: 583.0430\n",
      "Epoch 366/1000\n",
      "72/72 - 0s - loss: 555.4058 - mse: 555.4058\n",
      "Epoch 367/1000\n",
      "72/72 - 0s - loss: 552.1780 - mse: 552.1780\n",
      "Epoch 368/1000\n",
      "72/72 - 0s - loss: 548.5647 - mse: 548.5647\n",
      "Epoch 369/1000\n",
      "72/72 - 0s - loss: 544.2324 - mse: 544.2324\n",
      "Epoch 370/1000\n",
      "72/72 - 0s - loss: 537.8453 - mse: 537.8453\n",
      "Epoch 371/1000\n",
      "72/72 - 0s - loss: 537.6205 - mse: 537.6205\n",
      "Epoch 372/1000\n",
      "72/72 - 0s - loss: 535.9617 - mse: 535.9617\n",
      "Epoch 373/1000\n",
      "72/72 - 0s - loss: 507.1446 - mse: 507.1446\n",
      "Epoch 374/1000\n",
      "72/72 - 0s - loss: 517.7426 - mse: 517.7426\n",
      "Epoch 375/1000\n",
      "72/72 - 0s - loss: 510.0480 - mse: 510.0480\n",
      "Epoch 376/1000\n",
      "72/72 - 0s - loss: 501.3287 - mse: 501.3287\n",
      "Epoch 377/1000\n",
      "72/72 - 0s - loss: 505.2385 - mse: 505.2385\n",
      "Epoch 378/1000\n",
      "72/72 - 0s - loss: 501.8905 - mse: 501.8905\n",
      "Epoch 379/1000\n",
      "72/72 - 0s - loss: 486.1559 - mse: 486.1559\n",
      "Epoch 380/1000\n",
      "72/72 - 0s - loss: 489.9037 - mse: 489.9037\n",
      "Epoch 381/1000\n",
      "72/72 - 0s - loss: 483.7762 - mse: 483.7762\n",
      "Epoch 382/1000\n",
      "72/72 - 0s - loss: 477.6433 - mse: 477.6433\n",
      "Epoch 383/1000\n",
      "72/72 - 0s - loss: 478.6892 - mse: 478.6892\n",
      "Epoch 384/1000\n",
      "72/72 - 0s - loss: 483.7172 - mse: 483.7172\n",
      "Epoch 385/1000\n",
      "72/72 - 0s - loss: 472.6469 - mse: 472.6469\n",
      "Epoch 386/1000\n",
      "72/72 - 0s - loss: 461.8551 - mse: 461.8551\n",
      "Epoch 387/1000\n",
      "72/72 - 0s - loss: 468.4407 - mse: 468.4407\n",
      "Epoch 388/1000\n",
      "72/72 - 0s - loss: 457.9950 - mse: 457.9950\n",
      "Epoch 389/1000\n",
      "72/72 - 0s - loss: 449.7914 - mse: 449.7914\n",
      "Epoch 390/1000\n",
      "72/72 - 0s - loss: 451.2658 - mse: 451.2658\n",
      "Epoch 391/1000\n",
      "72/72 - 0s - loss: 450.9622 - mse: 450.9622\n",
      "Epoch 392/1000\n",
      "72/72 - 0s - loss: 441.3444 - mse: 441.3444\n",
      "Epoch 393/1000\n",
      "72/72 - 0s - loss: 429.9033 - mse: 429.9033\n",
      "Epoch 394/1000\n",
      "72/72 - 0s - loss: 416.2023 - mse: 416.2023\n",
      "Epoch 395/1000\n",
      "72/72 - 0s - loss: 431.6963 - mse: 431.6963\n",
      "Epoch 396/1000\n",
      "72/72 - 0s - loss: 408.7734 - mse: 408.7734\n",
      "Epoch 397/1000\n",
      "72/72 - 0s - loss: 422.5094 - mse: 422.5094\n",
      "Epoch 398/1000\n",
      "72/72 - 0s - loss: 418.3197 - mse: 418.3197\n",
      "Epoch 399/1000\n",
      "72/72 - 0s - loss: 406.9952 - mse: 406.9952\n",
      "Epoch 400/1000\n",
      "72/72 - 0s - loss: 415.5192 - mse: 415.5192\n",
      "Epoch 401/1000\n",
      "72/72 - 0s - loss: 397.5472 - mse: 397.5472\n",
      "Epoch 402/1000\n",
      "72/72 - 0s - loss: 400.3753 - mse: 400.3753\n",
      "Epoch 403/1000\n",
      "72/72 - 0s - loss: 393.9118 - mse: 393.9118\n",
      "Epoch 404/1000\n",
      "72/72 - 0s - loss: 383.8530 - mse: 383.8530\n",
      "Epoch 405/1000\n",
      "72/72 - 0s - loss: 395.2987 - mse: 395.2987\n",
      "Epoch 406/1000\n",
      "72/72 - 0s - loss: 381.8756 - mse: 381.8756\n",
      "Epoch 407/1000\n",
      "72/72 - 0s - loss: 385.6593 - mse: 385.6593\n",
      "Epoch 408/1000\n",
      "72/72 - 0s - loss: 370.0833 - mse: 370.0833\n",
      "Epoch 409/1000\n",
      "72/72 - 0s - loss: 363.6681 - mse: 363.6681\n",
      "Epoch 410/1000\n",
      "72/72 - 0s - loss: 356.9039 - mse: 356.9039\n",
      "Epoch 411/1000\n",
      "72/72 - 0s - loss: 372.9317 - mse: 372.9317\n",
      "Epoch 412/1000\n",
      "72/72 - 0s - loss: 351.0997 - mse: 351.0997\n",
      "Epoch 413/1000\n",
      "72/72 - 0s - loss: 362.1644 - mse: 362.1644\n",
      "Epoch 414/1000\n",
      "72/72 - 0s - loss: 357.7689 - mse: 357.7689\n",
      "Epoch 415/1000\n",
      "72/72 - 0s - loss: 349.4522 - mse: 349.4522\n",
      "Epoch 416/1000\n",
      "72/72 - 0s - loss: 347.8040 - mse: 347.8040\n",
      "Epoch 417/1000\n",
      "72/72 - 0s - loss: 340.2471 - mse: 340.2471\n",
      "Epoch 418/1000\n",
      "72/72 - 0s - loss: 344.6954 - mse: 344.6954\n",
      "Epoch 419/1000\n",
      "72/72 - 0s - loss: 338.0726 - mse: 338.0726\n",
      "Epoch 420/1000\n",
      "72/72 - 0s - loss: 334.3875 - mse: 334.3875\n",
      "Epoch 421/1000\n",
      "72/72 - 0s - loss: 336.0020 - mse: 336.0020\n",
      "Epoch 422/1000\n",
      "72/72 - 0s - loss: 335.4036 - mse: 335.4036\n",
      "Epoch 423/1000\n",
      "72/72 - 0s - loss: 312.2022 - mse: 312.2022\n",
      "Epoch 424/1000\n",
      "72/72 - 0s - loss: 324.4122 - mse: 324.4122\n",
      "Epoch 425/1000\n",
      "72/72 - 0s - loss: 314.4079 - mse: 314.4079\n",
      "Epoch 426/1000\n",
      "72/72 - 0s - loss: 309.9124 - mse: 309.9124\n",
      "Epoch 427/1000\n",
      "72/72 - 0s - loss: 319.6299 - mse: 319.6299\n",
      "Epoch 428/1000\n",
      "72/72 - 0s - loss: 299.9835 - mse: 299.9835\n",
      "Epoch 429/1000\n",
      "72/72 - 0s - loss: 290.8187 - mse: 290.8187\n",
      "Epoch 430/1000\n",
      "72/72 - 0s - loss: 299.9338 - mse: 299.9338\n",
      "Epoch 431/1000\n",
      "72/72 - 0s - loss: 303.2265 - mse: 303.2265\n",
      "Epoch 432/1000\n",
      "72/72 - 0s - loss: 288.7055 - mse: 288.7055\n",
      "Epoch 433/1000\n",
      "72/72 - 0s - loss: 276.2523 - mse: 276.2523\n",
      "Epoch 434/1000\n",
      "72/72 - 0s - loss: 291.5661 - mse: 291.5661\n",
      "Epoch 435/1000\n",
      "72/72 - 0s - loss: 276.4959 - mse: 276.4959\n",
      "Epoch 436/1000\n",
      "72/72 - 0s - loss: 270.4429 - mse: 270.4429\n",
      "Epoch 437/1000\n",
      "72/72 - 0s - loss: 280.7103 - mse: 280.7103\n",
      "Epoch 438/1000\n",
      "72/72 - 0s - loss: 270.0642 - mse: 270.0642\n",
      "Epoch 439/1000\n",
      "72/72 - 0s - loss: 263.2517 - mse: 263.2517\n",
      "Epoch 440/1000\n",
      "72/72 - 0s - loss: 269.9917 - mse: 269.9917\n",
      "Epoch 441/1000\n",
      "72/72 - 0s - loss: 259.5689 - mse: 259.5689\n",
      "Epoch 442/1000\n",
      "72/72 - 0s - loss: 255.1155 - mse: 255.1155\n",
      "Epoch 443/1000\n",
      "72/72 - 0s - loss: 250.6105 - mse: 250.6105\n",
      "Epoch 444/1000\n",
      "72/72 - 0s - loss: 253.1559 - mse: 253.1559\n",
      "Epoch 445/1000\n",
      "72/72 - 0s - loss: 244.1960 - mse: 244.1960\n",
      "Epoch 446/1000\n",
      "72/72 - 0s - loss: 239.3076 - mse: 239.3076\n",
      "Epoch 447/1000\n",
      "72/72 - 0s - loss: 238.6995 - mse: 238.6995\n",
      "Epoch 448/1000\n",
      "72/72 - 0s - loss: 243.0802 - mse: 243.0802\n",
      "Epoch 449/1000\n",
      "72/72 - 0s - loss: 244.3320 - mse: 244.3320\n",
      "Epoch 450/1000\n",
      "72/72 - 0s - loss: 240.0084 - mse: 240.0084\n",
      "Epoch 451/1000\n",
      "72/72 - 0s - loss: 241.0370 - mse: 241.0370\n",
      "Epoch 452/1000\n",
      "72/72 - 0s - loss: 232.2188 - mse: 232.2188\n",
      "Epoch 453/1000\n",
      "72/72 - 0s - loss: 229.2532 - mse: 229.2532\n",
      "Epoch 454/1000\n",
      "72/72 - 0s - loss: 223.4070 - mse: 223.4070\n",
      "Epoch 455/1000\n",
      "72/72 - 0s - loss: 218.4235 - mse: 218.4235\n",
      "Epoch 456/1000\n",
      "72/72 - 0s - loss: 210.5226 - mse: 210.5226\n",
      "Epoch 457/1000\n",
      "72/72 - 0s - loss: 220.1125 - mse: 220.1125\n",
      "Epoch 458/1000\n",
      "72/72 - 0s - loss: 216.2111 - mse: 216.2111\n",
      "Epoch 459/1000\n",
      "72/72 - 0s - loss: 210.4148 - mse: 210.4148\n",
      "Epoch 460/1000\n",
      "72/72 - 0s - loss: 198.4298 - mse: 198.4298\n",
      "Epoch 461/1000\n",
      "72/72 - 0s - loss: 215.4218 - mse: 215.4218\n",
      "Epoch 462/1000\n",
      "72/72 - 0s - loss: 198.5565 - mse: 198.5565\n",
      "Epoch 463/1000\n",
      "72/72 - 0s - loss: 201.0879 - mse: 201.0879\n",
      "Epoch 464/1000\n",
      "72/72 - 0s - loss: 193.4765 - mse: 193.4765\n",
      "Epoch 465/1000\n",
      "72/72 - 0s - loss: 199.2327 - mse: 199.2327\n",
      "Epoch 466/1000\n",
      "72/72 - 0s - loss: 190.1643 - mse: 190.1643\n",
      "Epoch 467/1000\n",
      "72/72 - 0s - loss: 183.3833 - mse: 183.3833\n",
      "Epoch 468/1000\n",
      "72/72 - 0s - loss: 190.3137 - mse: 190.3137\n",
      "Epoch 469/1000\n",
      "72/72 - 0s - loss: 181.4978 - mse: 181.4978\n",
      "Epoch 470/1000\n",
      "72/72 - 0s - loss: 179.9578 - mse: 179.9578\n",
      "Epoch 471/1000\n",
      "72/72 - 0s - loss: 181.5560 - mse: 181.5560\n",
      "Epoch 472/1000\n",
      "72/72 - 0s - loss: 176.1417 - mse: 176.1417\n",
      "Epoch 473/1000\n",
      "72/72 - 0s - loss: 169.3721 - mse: 169.3721\n",
      "Epoch 474/1000\n",
      "72/72 - 0s - loss: 173.4677 - mse: 173.4677\n",
      "Epoch 475/1000\n",
      "72/72 - 0s - loss: 173.2001 - mse: 173.2001\n",
      "Epoch 476/1000\n",
      "72/72 - 0s - loss: 164.8147 - mse: 164.8147\n",
      "Epoch 477/1000\n",
      "72/72 - 0s - loss: 163.4639 - mse: 163.4639\n",
      "Epoch 478/1000\n",
      "72/72 - 0s - loss: 156.7197 - mse: 156.7197\n",
      "Epoch 479/1000\n",
      "72/72 - 0s - loss: 167.8655 - mse: 167.8655\n",
      "Epoch 480/1000\n",
      "72/72 - 0s - loss: 154.3193 - mse: 154.3193\n",
      "Epoch 481/1000\n",
      "72/72 - 0s - loss: 158.1035 - mse: 158.1035\n",
      "Epoch 482/1000\n",
      "72/72 - 0s - loss: 158.2414 - mse: 158.2414\n",
      "Epoch 483/1000\n",
      "72/72 - 0s - loss: 154.9250 - mse: 154.9250\n",
      "Epoch 484/1000\n",
      "72/72 - 0s - loss: 152.4537 - mse: 152.4537\n",
      "Epoch 485/1000\n",
      "72/72 - 0s - loss: 147.1280 - mse: 147.1280\n",
      "Epoch 486/1000\n",
      "72/72 - 0s - loss: 147.6460 - mse: 147.6460\n",
      "Epoch 487/1000\n",
      "72/72 - 0s - loss: 143.2504 - mse: 143.2504\n",
      "Epoch 488/1000\n",
      "72/72 - 0s - loss: 140.6913 - mse: 140.6913\n",
      "Epoch 489/1000\n",
      "72/72 - 0s - loss: 136.7446 - mse: 136.7446\n",
      "Epoch 490/1000\n",
      "72/72 - 0s - loss: 140.9233 - mse: 140.9233\n",
      "Epoch 491/1000\n",
      "72/72 - 0s - loss: 129.1040 - mse: 129.1040\n",
      "Epoch 492/1000\n",
      "72/72 - 0s - loss: 136.3823 - mse: 136.3823\n",
      "Epoch 493/1000\n",
      "72/72 - 0s - loss: 134.3462 - mse: 134.3462\n",
      "Epoch 494/1000\n",
      "72/72 - 0s - loss: 127.7859 - mse: 127.7859\n",
      "Epoch 495/1000\n",
      "72/72 - 0s - loss: 130.0907 - mse: 130.0907\n",
      "Epoch 496/1000\n",
      "72/72 - 0s - loss: 127.1390 - mse: 127.1390\n",
      "Epoch 497/1000\n",
      "72/72 - 0s - loss: 123.2893 - mse: 123.2893\n",
      "Epoch 498/1000\n",
      "72/72 - 0s - loss: 124.3528 - mse: 124.3528\n",
      "Epoch 499/1000\n",
      "72/72 - 0s - loss: 121.1528 - mse: 121.1528\n",
      "Epoch 500/1000\n",
      "72/72 - 0s - loss: 116.7879 - mse: 116.7879\n",
      "Epoch 501/1000\n",
      "72/72 - 0s - loss: 110.9903 - mse: 110.9903\n",
      "Epoch 502/1000\n",
      "72/72 - 0s - loss: 121.1209 - mse: 121.1209\n",
      "Epoch 503/1000\n",
      "72/72 - 0s - loss: 110.5441 - mse: 110.5441\n",
      "Epoch 504/1000\n",
      "72/72 - 0s - loss: 119.0791 - mse: 119.0791\n",
      "Epoch 505/1000\n",
      "72/72 - 0s - loss: 110.3261 - mse: 110.3261\n",
      "Epoch 506/1000\n",
      "72/72 - 0s - loss: 107.0840 - mse: 107.0840\n",
      "Epoch 507/1000\n",
      "72/72 - 0s - loss: 111.9228 - mse: 111.9228\n",
      "Epoch 508/1000\n",
      "72/72 - 0s - loss: 108.5648 - mse: 108.5648\n",
      "Epoch 509/1000\n",
      "72/72 - 0s - loss: 104.3107 - mse: 104.3107\n",
      "Epoch 510/1000\n",
      "72/72 - 0s - loss: 99.5944 - mse: 99.5944\n",
      "Epoch 511/1000\n",
      "72/72 - 0s - loss: 110.3327 - mse: 110.3327\n",
      "Epoch 512/1000\n",
      "72/72 - 0s - loss: 105.5034 - mse: 105.5034\n",
      "Epoch 513/1000\n",
      "72/72 - 0s - loss: 99.1100 - mse: 99.1100\n",
      "Epoch 514/1000\n",
      "72/72 - 0s - loss: 99.6580 - mse: 99.6580\n",
      "Epoch 515/1000\n",
      "72/72 - 0s - loss: 95.2932 - mse: 95.2932\n",
      "Epoch 516/1000\n",
      "72/72 - 0s - loss: 90.4468 - mse: 90.4468\n",
      "Epoch 517/1000\n",
      "72/72 - 0s - loss: 92.4925 - mse: 92.4925\n",
      "Epoch 518/1000\n",
      "72/72 - 0s - loss: 95.4302 - mse: 95.4302\n",
      "Epoch 519/1000\n",
      "72/72 - 0s - loss: 94.7078 - mse: 94.7078\n",
      "Epoch 520/1000\n",
      "72/72 - 0s - loss: 85.8035 - mse: 85.8035\n",
      "Epoch 521/1000\n",
      "72/72 - 0s - loss: 90.9568 - mse: 90.9568\n",
      "Epoch 522/1000\n",
      "72/72 - 0s - loss: 84.3507 - mse: 84.3507\n",
      "Epoch 523/1000\n",
      "72/72 - 0s - loss: 85.5603 - mse: 85.5603\n",
      "Epoch 524/1000\n",
      "72/72 - 0s - loss: 79.2575 - mse: 79.2575\n",
      "Epoch 525/1000\n",
      "72/72 - 0s - loss: 84.0808 - mse: 84.0808\n",
      "Epoch 526/1000\n",
      "72/72 - 0s - loss: 80.5397 - mse: 80.5397\n",
      "Epoch 527/1000\n",
      "72/72 - 0s - loss: 72.9942 - mse: 72.9942\n",
      "Epoch 528/1000\n",
      "72/72 - 0s - loss: 78.6907 - mse: 78.6907\n",
      "Epoch 529/1000\n",
      "72/72 - 0s - loss: 75.2789 - mse: 75.2789\n",
      "Epoch 530/1000\n",
      "72/72 - 0s - loss: 75.3561 - mse: 75.3561\n",
      "Epoch 531/1000\n",
      "72/72 - 0s - loss: 75.4539 - mse: 75.4539\n",
      "Epoch 532/1000\n",
      "72/72 - 0s - loss: 73.8796 - mse: 73.8796\n",
      "Epoch 533/1000\n",
      "72/72 - 0s - loss: 67.3974 - mse: 67.3974\n",
      "Epoch 534/1000\n",
      "72/72 - 0s - loss: 68.4181 - mse: 68.4181\n",
      "Epoch 535/1000\n",
      "72/72 - 0s - loss: 74.7372 - mse: 74.7372\n",
      "Epoch 536/1000\n",
      "72/72 - 0s - loss: 69.5186 - mse: 69.5186\n",
      "Epoch 537/1000\n",
      "72/72 - 0s - loss: 71.6391 - mse: 71.6391\n",
      "Epoch 538/1000\n",
      "72/72 - 0s - loss: 63.6709 - mse: 63.6709\n",
      "Epoch 539/1000\n",
      "72/72 - 0s - loss: 60.9518 - mse: 60.9518\n",
      "Epoch 540/1000\n",
      "72/72 - 0s - loss: 62.0372 - mse: 62.0372\n",
      "Epoch 541/1000\n",
      "72/72 - 0s - loss: 64.7768 - mse: 64.7768\n",
      "Epoch 542/1000\n",
      "72/72 - 0s - loss: 57.3723 - mse: 57.3723\n",
      "Epoch 543/1000\n",
      "72/72 - 0s - loss: 59.7941 - mse: 59.7941\n",
      "Epoch 544/1000\n",
      "72/72 - 0s - loss: 60.3360 - mse: 60.3360\n",
      "Epoch 545/1000\n",
      "72/72 - 0s - loss: 59.7799 - mse: 59.7799\n",
      "Epoch 546/1000\n",
      "72/72 - 0s - loss: 61.0773 - mse: 61.0773\n",
      "Epoch 547/1000\n",
      "72/72 - 0s - loss: 55.7329 - mse: 55.7329\n",
      "Epoch 548/1000\n",
      "72/72 - 0s - loss: 56.3885 - mse: 56.3885\n",
      "Epoch 549/1000\n",
      "72/72 - 0s - loss: 50.5978 - mse: 50.5978\n",
      "Epoch 550/1000\n",
      "72/72 - 0s - loss: 55.3506 - mse: 55.3506\n",
      "Epoch 551/1000\n",
      "72/72 - 0s - loss: 54.6836 - mse: 54.6836\n",
      "Epoch 552/1000\n",
      "72/72 - 0s - loss: 51.2216 - mse: 51.2216\n",
      "Epoch 553/1000\n",
      "72/72 - 0s - loss: 50.1758 - mse: 50.1758\n",
      "Epoch 554/1000\n",
      "72/72 - 0s - loss: 52.9071 - mse: 52.9071\n",
      "Epoch 555/1000\n",
      "72/72 - 0s - loss: 51.9621 - mse: 51.9621\n",
      "Epoch 556/1000\n",
      "72/72 - 0s - loss: 50.4890 - mse: 50.4890\n",
      "Epoch 557/1000\n",
      "72/72 - 0s - loss: 46.2950 - mse: 46.2950\n",
      "Epoch 558/1000\n",
      "72/72 - 0s - loss: 45.0191 - mse: 45.0191\n",
      "Epoch 559/1000\n",
      "72/72 - 0s - loss: 46.7163 - mse: 46.7163\n",
      "Epoch 560/1000\n",
      "72/72 - 0s - loss: 42.6246 - mse: 42.6246\n",
      "Epoch 561/1000\n",
      "72/72 - 0s - loss: 42.4849 - mse: 42.4849\n",
      "Epoch 562/1000\n",
      "72/72 - 0s - loss: 40.1391 - mse: 40.1391\n",
      "Epoch 563/1000\n",
      "72/72 - 0s - loss: 39.0797 - mse: 39.0797\n",
      "Epoch 564/1000\n",
      "72/72 - 0s - loss: 40.4360 - mse: 40.4360\n",
      "Epoch 565/1000\n",
      "72/72 - 0s - loss: 45.1316 - mse: 45.1316\n",
      "Epoch 566/1000\n",
      "72/72 - 0s - loss: 39.8524 - mse: 39.8524\n",
      "Epoch 567/1000\n",
      "72/72 - 0s - loss: 36.1578 - mse: 36.1578\n",
      "Epoch 568/1000\n",
      "72/72 - 0s - loss: 38.7516 - mse: 38.7516\n",
      "Epoch 569/1000\n",
      "72/72 - 0s - loss: 37.4961 - mse: 37.4961\n",
      "Epoch 570/1000\n",
      "72/72 - 0s - loss: 38.1648 - mse: 38.1648\n",
      "Epoch 571/1000\n",
      "72/72 - 0s - loss: 39.3379 - mse: 39.3379\n",
      "Epoch 572/1000\n",
      "72/72 - 0s - loss: 34.8833 - mse: 34.8833\n",
      "Epoch 573/1000\n",
      "72/72 - 0s - loss: 38.0535 - mse: 38.0535\n",
      "Epoch 574/1000\n",
      "72/72 - 0s - loss: 32.3518 - mse: 32.3518\n",
      "Epoch 575/1000\n",
      "72/72 - 0s - loss: 35.4523 - mse: 35.4523\n",
      "Epoch 576/1000\n",
      "72/72 - 0s - loss: 35.6455 - mse: 35.6455\n",
      "Epoch 577/1000\n",
      "72/72 - 0s - loss: 31.2658 - mse: 31.2658\n",
      "Epoch 578/1000\n",
      "72/72 - 0s - loss: 34.8974 - mse: 34.8974\n",
      "Epoch 579/1000\n",
      "72/72 - 0s - loss: 33.0969 - mse: 33.0969\n",
      "Epoch 580/1000\n",
      "72/72 - 0s - loss: 30.9043 - mse: 30.9043\n",
      "Epoch 581/1000\n",
      "72/72 - 0s - loss: 31.5745 - mse: 31.5745\n",
      "Epoch 582/1000\n",
      "72/72 - 0s - loss: 33.0524 - mse: 33.0524\n",
      "Epoch 583/1000\n",
      "72/72 - 0s - loss: 30.5747 - mse: 30.5747\n",
      "Epoch 584/1000\n",
      "72/72 - 0s - loss: 27.8654 - mse: 27.8654\n",
      "Epoch 585/1000\n",
      "72/72 - 0s - loss: 29.8200 - mse: 29.8200\n",
      "Epoch 586/1000\n",
      "72/72 - 0s - loss: 27.6273 - mse: 27.6273\n",
      "Epoch 587/1000\n",
      "72/72 - 0s - loss: 28.9078 - mse: 28.9078\n",
      "Epoch 588/1000\n",
      "72/72 - 0s - loss: 26.6477 - mse: 26.6477\n",
      "Epoch 589/1000\n",
      "72/72 - 0s - loss: 28.3305 - mse: 28.3305\n",
      "Epoch 590/1000\n",
      "72/72 - 0s - loss: 28.3844 - mse: 28.3844\n",
      "Epoch 591/1000\n",
      "72/72 - 0s - loss: 23.9217 - mse: 23.9217\n",
      "Epoch 592/1000\n",
      "72/72 - 0s - loss: 25.2176 - mse: 25.2176\n",
      "Epoch 593/1000\n",
      "72/72 - 0s - loss: 24.4462 - mse: 24.4462\n",
      "Epoch 594/1000\n",
      "72/72 - 0s - loss: 25.4838 - mse: 25.4838\n",
      "Epoch 595/1000\n",
      "72/72 - 0s - loss: 25.8642 - mse: 25.8642\n",
      "Epoch 596/1000\n",
      "72/72 - 0s - loss: 24.5315 - mse: 24.5315\n",
      "Epoch 597/1000\n",
      "72/72 - 0s - loss: 24.8234 - mse: 24.8234\n",
      "Epoch 598/1000\n",
      "72/72 - 0s - loss: 23.6151 - mse: 23.6151\n",
      "Epoch 599/1000\n",
      "72/72 - 0s - loss: 23.2285 - mse: 23.2285\n",
      "Epoch 600/1000\n",
      "72/72 - 0s - loss: 21.3043 - mse: 21.3043\n",
      "Epoch 601/1000\n",
      "72/72 - 0s - loss: 20.5552 - mse: 20.5552\n",
      "Epoch 602/1000\n",
      "72/72 - 0s - loss: 25.3315 - mse: 25.3315\n",
      "Epoch 603/1000\n",
      "72/72 - 0s - loss: 22.3583 - mse: 22.3583\n",
      "Epoch 604/1000\n",
      "72/72 - 0s - loss: 25.3260 - mse: 25.3260\n",
      "Epoch 605/1000\n",
      "72/72 - 0s - loss: 20.4929 - mse: 20.4929\n",
      "Epoch 606/1000\n",
      "72/72 - 0s - loss: 21.1415 - mse: 21.1415\n",
      "Epoch 607/1000\n",
      "72/72 - 0s - loss: 18.9307 - mse: 18.9307\n",
      "Epoch 608/1000\n",
      "72/72 - 0s - loss: 22.7025 - mse: 22.7025\n",
      "Epoch 609/1000\n",
      "72/72 - 0s - loss: 18.9341 - mse: 18.9341\n",
      "Epoch 610/1000\n",
      "72/72 - 0s - loss: 21.3278 - mse: 21.3278\n",
      "Epoch 611/1000\n",
      "72/72 - 0s - loss: 19.1749 - mse: 19.1749\n",
      "Epoch 612/1000\n",
      "72/72 - 0s - loss: 19.0554 - mse: 19.0554\n",
      "Epoch 613/1000\n",
      "72/72 - 0s - loss: 17.6626 - mse: 17.6626\n",
      "Epoch 614/1000\n",
      "72/72 - 0s - loss: 17.7716 - mse: 17.7716\n",
      "Epoch 615/1000\n",
      "72/72 - 0s - loss: 18.0033 - mse: 18.0033\n",
      "Epoch 616/1000\n",
      "72/72 - 0s - loss: 17.2723 - mse: 17.2723\n",
      "Epoch 617/1000\n",
      "72/72 - 0s - loss: 18.3013 - mse: 18.3013\n",
      "Epoch 618/1000\n",
      "72/72 - 0s - loss: 17.1296 - mse: 17.1296\n",
      "Epoch 619/1000\n",
      "72/72 - 0s - loss: 16.9957 - mse: 16.9957\n",
      "Epoch 620/1000\n",
      "72/72 - 0s - loss: 17.3900 - mse: 17.3900\n",
      "Epoch 621/1000\n",
      "72/72 - 0s - loss: 14.9697 - mse: 14.9697\n",
      "Epoch 622/1000\n",
      "72/72 - 0s - loss: 18.8835 - mse: 18.8835\n",
      "Epoch 623/1000\n",
      "72/72 - 0s - loss: 14.7650 - mse: 14.7650\n",
      "Epoch 624/1000\n",
      "72/72 - 0s - loss: 17.2111 - mse: 17.2111\n",
      "Epoch 625/1000\n",
      "72/72 - 0s - loss: 20.0217 - mse: 20.0217\n",
      "Epoch 626/1000\n",
      "72/72 - 0s - loss: 15.9107 - mse: 15.9107\n",
      "Epoch 627/1000\n",
      "72/72 - 0s - loss: 16.7465 - mse: 16.7465\n",
      "Epoch 628/1000\n",
      "72/72 - 0s - loss: 15.1649 - mse: 15.1649\n",
      "Epoch 629/1000\n",
      "72/72 - 0s - loss: 18.8633 - mse: 18.8633\n",
      "Epoch 630/1000\n",
      "72/72 - 0s - loss: 17.2743 - mse: 17.2743\n",
      "Epoch 631/1000\n",
      "72/72 - 0s - loss: 14.0682 - mse: 14.0682\n",
      "Epoch 632/1000\n",
      "72/72 - 0s - loss: 16.3624 - mse: 16.3624\n",
      "Epoch 633/1000\n",
      "72/72 - 0s - loss: 13.6407 - mse: 13.6407\n",
      "Epoch 634/1000\n",
      "72/72 - 0s - loss: 16.1274 - mse: 16.1274\n",
      "Epoch 635/1000\n",
      "72/72 - 0s - loss: 14.5302 - mse: 14.5302\n",
      "Epoch 636/1000\n",
      "72/72 - 0s - loss: 15.5190 - mse: 15.5190\n",
      "Epoch 637/1000\n",
      "72/72 - 0s - loss: 14.7226 - mse: 14.7226\n",
      "Epoch 638/1000\n",
      "72/72 - 0s - loss: 15.2113 - mse: 15.2113\n",
      "Epoch 639/1000\n",
      "72/72 - 0s - loss: 14.2323 - mse: 14.2323\n",
      "Epoch 640/1000\n",
      "72/72 - 0s - loss: 17.0760 - mse: 17.0760\n",
      "Epoch 641/1000\n",
      "72/72 - 0s - loss: 12.1423 - mse: 12.1423\n",
      "Epoch 642/1000\n",
      "72/72 - 0s - loss: 13.4720 - mse: 13.4720\n",
      "Epoch 643/1000\n",
      "72/72 - 0s - loss: 13.5426 - mse: 13.5426\n",
      "Epoch 644/1000\n",
      "72/72 - 0s - loss: 12.4518 - mse: 12.4518\n",
      "Epoch 645/1000\n",
      "72/72 - 0s - loss: 13.5615 - mse: 13.5615\n",
      "Epoch 646/1000\n",
      "72/72 - 0s - loss: 12.5533 - mse: 12.5533\n",
      "Epoch 647/1000\n",
      "72/72 - 0s - loss: 13.0498 - mse: 13.0498\n",
      "Epoch 648/1000\n",
      "72/72 - 0s - loss: 12.1079 - mse: 12.1079\n",
      "Epoch 649/1000\n",
      "72/72 - 0s - loss: 17.8875 - mse: 17.8875\n",
      "Epoch 650/1000\n",
      "72/72 - 0s - loss: 15.3375 - mse: 15.3375\n",
      "Epoch 651/1000\n",
      "72/72 - 0s - loss: 11.3123 - mse: 11.3123\n",
      "Epoch 652/1000\n",
      "72/72 - 0s - loss: 13.0270 - mse: 13.0270\n",
      "Epoch 653/1000\n",
      "72/72 - 0s - loss: 11.4517 - mse: 11.4517\n",
      "Epoch 654/1000\n",
      "72/72 - 0s - loss: 10.6988 - mse: 10.6988\n",
      "Epoch 655/1000\n",
      "72/72 - 0s - loss: 15.1856 - mse: 15.1856\n",
      "Epoch 656/1000\n",
      "72/72 - 0s - loss: 12.8728 - mse: 12.8728\n",
      "Epoch 657/1000\n",
      "72/72 - 0s - loss: 11.1332 - mse: 11.1332\n",
      "Epoch 658/1000\n",
      "72/72 - 0s - loss: 12.2482 - mse: 12.2482\n",
      "Epoch 659/1000\n",
      "72/72 - 0s - loss: 12.7794 - mse: 12.7794\n",
      "Epoch 660/1000\n",
      "72/72 - 0s - loss: 16.8872 - mse: 16.8872\n",
      "Epoch 661/1000\n",
      "72/72 - 0s - loss: 14.6253 - mse: 14.6253\n",
      "Epoch 662/1000\n",
      "72/72 - 0s - loss: 10.2686 - mse: 10.2686\n",
      "Epoch 663/1000\n",
      "72/72 - 0s - loss: 12.2133 - mse: 12.2133\n",
      "Epoch 664/1000\n",
      "72/72 - 0s - loss: 14.7784 - mse: 14.7784\n",
      "Epoch 665/1000\n",
      "72/72 - 0s - loss: 10.3826 - mse: 10.3826\n",
      "Epoch 666/1000\n",
      "72/72 - 0s - loss: 12.1758 - mse: 12.1758\n",
      "Epoch 667/1000\n",
      "72/72 - 0s - loss: 13.0175 - mse: 13.0175\n",
      "Epoch 668/1000\n",
      "72/72 - 0s - loss: 10.7854 - mse: 10.7854\n",
      "Epoch 669/1000\n",
      "72/72 - 0s - loss: 12.5010 - mse: 12.5010\n",
      "Epoch 670/1000\n",
      "72/72 - 0s - loss: 12.3792 - mse: 12.3792\n",
      "Epoch 671/1000\n",
      "72/72 - 0s - loss: 11.8669 - mse: 11.8669\n",
      "Epoch 672/1000\n",
      "72/72 - 0s - loss: 9.1778 - mse: 9.1778\n",
      "Epoch 673/1000\n",
      "72/72 - 0s - loss: 12.6667 - mse: 12.6667\n",
      "Epoch 674/1000\n",
      "72/72 - 0s - loss: 10.1986 - mse: 10.1986\n",
      "Epoch 675/1000\n",
      "72/72 - 0s - loss: 12.3820 - mse: 12.3820\n",
      "Epoch 676/1000\n",
      "72/72 - 0s - loss: 12.3761 - mse: 12.3761\n",
      "Epoch 677/1000\n",
      "72/72 - 0s - loss: 12.8877 - mse: 12.8877\n",
      "Epoch 678/1000\n",
      "72/72 - 0s - loss: 9.0744 - mse: 9.0744\n",
      "Epoch 679/1000\n",
      "72/72 - 0s - loss: 12.4242 - mse: 12.4242\n",
      "Epoch 680/1000\n",
      "72/72 - 0s - loss: 11.7770 - mse: 11.7770\n",
      "Epoch 681/1000\n",
      "72/72 - 0s - loss: 12.3606 - mse: 12.3606\n",
      "Epoch 682/1000\n",
      "72/72 - 0s - loss: 9.6442 - mse: 9.6442\n",
      "Epoch 683/1000\n",
      "72/72 - 0s - loss: 11.7341 - mse: 11.7341\n",
      "Epoch 684/1000\n",
      "72/72 - 0s - loss: 9.9223 - mse: 9.9223\n",
      "Epoch 685/1000\n",
      "72/72 - 0s - loss: 11.7152 - mse: 11.7152\n",
      "Epoch 686/1000\n",
      "72/72 - 0s - loss: 11.0291 - mse: 11.0291\n",
      "Epoch 687/1000\n",
      "72/72 - 0s - loss: 14.4669 - mse: 14.4669\n",
      "Epoch 688/1000\n",
      "72/72 - 0s - loss: 9.8777 - mse: 9.8777\n",
      "Epoch 689/1000\n",
      "72/72 - 0s - loss: 9.4609 - mse: 9.4609\n",
      "Epoch 690/1000\n",
      "72/72 - 0s - loss: 9.8131 - mse: 9.8131\n",
      "Epoch 691/1000\n",
      "72/72 - 0s - loss: 11.0653 - mse: 11.0653\n",
      "Epoch 692/1000\n",
      "72/72 - 0s - loss: 11.9985 - mse: 11.9985\n",
      "Epoch 693/1000\n",
      "72/72 - 0s - loss: 13.5643 - mse: 13.5643\n",
      "Epoch 694/1000\n",
      "72/72 - 0s - loss: 11.8293 - mse: 11.8293\n",
      "Epoch 695/1000\n",
      "72/72 - 0s - loss: 10.3037 - mse: 10.3037\n",
      "Epoch 696/1000\n",
      "72/72 - 0s - loss: 11.5511 - mse: 11.5511\n",
      "Epoch 697/1000\n",
      "72/72 - 0s - loss: 10.6606 - mse: 10.6606\n",
      "Epoch 698/1000\n",
      "72/72 - 0s - loss: 11.9422 - mse: 11.9422\n",
      "Epoch 699/1000\n",
      "72/72 - 0s - loss: 9.2453 - mse: 9.2453\n",
      "Epoch 700/1000\n",
      "72/72 - 0s - loss: 11.5351 - mse: 11.5351\n",
      "Epoch 701/1000\n",
      "72/72 - 0s - loss: 9.0424 - mse: 9.0424\n",
      "Epoch 702/1000\n",
      "72/72 - 0s - loss: 10.1436 - mse: 10.1436\n",
      "Epoch 703/1000\n",
      "72/72 - 0s - loss: 10.5756 - mse: 10.5756\n",
      "Epoch 704/1000\n",
      "72/72 - 0s - loss: 9.2438 - mse: 9.2438\n",
      "Epoch 705/1000\n",
      "72/72 - 0s - loss: 8.6508 - mse: 8.6508\n",
      "Epoch 706/1000\n",
      "72/72 - 0s - loss: 10.2512 - mse: 10.2512\n",
      "Epoch 707/1000\n",
      "72/72 - 0s - loss: 10.9314 - mse: 10.9314\n",
      "Epoch 708/1000\n",
      "72/72 - 0s - loss: 11.2532 - mse: 11.2532\n",
      "Epoch 709/1000\n",
      "72/72 - 0s - loss: 12.5390 - mse: 12.5390\n",
      "Epoch 710/1000\n",
      "72/72 - 0s - loss: 7.8663 - mse: 7.8663\n",
      "Epoch 711/1000\n",
      "72/72 - 0s - loss: 10.7913 - mse: 10.7913\n",
      "Epoch 712/1000\n",
      "72/72 - 0s - loss: 11.8991 - mse: 11.8991\n",
      "Epoch 713/1000\n",
      "72/72 - 0s - loss: 11.2534 - mse: 11.2534\n",
      "Epoch 714/1000\n",
      "72/72 - 0s - loss: 8.1132 - mse: 8.1132\n",
      "Epoch 715/1000\n",
      "72/72 - 0s - loss: 9.9042 - mse: 9.9042\n",
      "Epoch 716/1000\n",
      "72/72 - 0s - loss: 10.5598 - mse: 10.5598\n",
      "Epoch 717/1000\n",
      "72/72 - 0s - loss: 12.5243 - mse: 12.5243\n",
      "Epoch 718/1000\n",
      "72/72 - 0s - loss: 9.6079 - mse: 9.6079\n",
      "Epoch 719/1000\n",
      "72/72 - 0s - loss: 9.1670 - mse: 9.1670\n",
      "Epoch 720/1000\n",
      "72/72 - 0s - loss: 11.7117 - mse: 11.7117\n",
      "Epoch 721/1000\n",
      "72/72 - 0s - loss: 9.5086 - mse: 9.5086\n",
      "Epoch 722/1000\n",
      "72/72 - 0s - loss: 8.8816 - mse: 8.8816\n",
      "Epoch 723/1000\n",
      "72/72 - 0s - loss: 8.9649 - mse: 8.9649\n",
      "Epoch 724/1000\n",
      "72/72 - 0s - loss: 10.3017 - mse: 10.3017\n",
      "Epoch 725/1000\n",
      "72/72 - 0s - loss: 8.9289 - mse: 8.9289\n",
      "Epoch 726/1000\n",
      "72/72 - 0s - loss: 12.0908 - mse: 12.0908\n",
      "Epoch 727/1000\n",
      "72/72 - 0s - loss: 14.0220 - mse: 14.0220\n",
      "Epoch 728/1000\n",
      "72/72 - 0s - loss: 10.4103 - mse: 10.4103\n",
      "Epoch 729/1000\n",
      "72/72 - 0s - loss: 9.7111 - mse: 9.7111\n",
      "Epoch 730/1000\n",
      "72/72 - 0s - loss: 9.9432 - mse: 9.9432\n",
      "Epoch 731/1000\n",
      "72/72 - 0s - loss: 9.1839 - mse: 9.1839\n",
      "Epoch 732/1000\n",
      "72/72 - 0s - loss: 15.9920 - mse: 15.9920\n",
      "Epoch 733/1000\n",
      "72/72 - 0s - loss: 7.8664 - mse: 7.8664\n",
      "Epoch 734/1000\n",
      "72/72 - 0s - loss: 11.8002 - mse: 11.8002\n",
      "Epoch 735/1000\n",
      "72/72 - 0s - loss: 10.4374 - mse: 10.4374\n",
      "Epoch 736/1000\n",
      "72/72 - 0s - loss: 7.9176 - mse: 7.9176\n",
      "Epoch 737/1000\n",
      "72/72 - 0s - loss: 10.5894 - mse: 10.5894\n",
      "Epoch 738/1000\n",
      "72/72 - 0s - loss: 11.7206 - mse: 11.7206\n",
      "Epoch 739/1000\n",
      "72/72 - 0s - loss: 9.8660 - mse: 9.8660\n",
      "Epoch 740/1000\n",
      "72/72 - 0s - loss: 8.2345 - mse: 8.2345\n",
      "Epoch 741/1000\n",
      "72/72 - 0s - loss: 9.2971 - mse: 9.2971\n",
      "Epoch 742/1000\n",
      "72/72 - 0s - loss: 13.1001 - mse: 13.1001\n",
      "Epoch 743/1000\n",
      "72/72 - 0s - loss: 8.5143 - mse: 8.5143\n",
      "Epoch 744/1000\n",
      "72/72 - 0s - loss: 8.5696 - mse: 8.5696\n",
      "Epoch 745/1000\n",
      "72/72 - 0s - loss: 12.4079 - mse: 12.4079\n",
      "Epoch 746/1000\n",
      "72/72 - 0s - loss: 11.4024 - mse: 11.4024\n",
      "Epoch 747/1000\n",
      "72/72 - 0s - loss: 8.3579 - mse: 8.3579\n",
      "Epoch 748/1000\n",
      "72/72 - 0s - loss: 9.1540 - mse: 9.1540\n",
      "Epoch 749/1000\n",
      "72/72 - 0s - loss: 10.7082 - mse: 10.7082\n",
      "Epoch 750/1000\n",
      "72/72 - 0s - loss: 12.7213 - mse: 12.7213\n",
      "Epoch 751/1000\n",
      "72/72 - 0s - loss: 7.5282 - mse: 7.5282\n",
      "Epoch 752/1000\n",
      "72/72 - 0s - loss: 8.5165 - mse: 8.5165\n",
      "Epoch 753/1000\n",
      "72/72 - 0s - loss: 10.9025 - mse: 10.9025\n",
      "Epoch 754/1000\n",
      "72/72 - 0s - loss: 10.3482 - mse: 10.3482\n",
      "Epoch 755/1000\n",
      "72/72 - 0s - loss: 9.3984 - mse: 9.3984\n",
      "Epoch 756/1000\n",
      "72/72 - 0s - loss: 9.1237 - mse: 9.1237\n",
      "Epoch 757/1000\n",
      "72/72 - 0s - loss: 12.0268 - mse: 12.0268\n",
      "Epoch 758/1000\n",
      "72/72 - 0s - loss: 8.6565 - mse: 8.6565\n",
      "Epoch 759/1000\n",
      "72/72 - 0s - loss: 8.8698 - mse: 8.8698\n",
      "Epoch 760/1000\n",
      "72/72 - 0s - loss: 9.2804 - mse: 9.2804\n",
      "Epoch 761/1000\n",
      "72/72 - 0s - loss: 11.0579 - mse: 11.0579\n",
      "Epoch 762/1000\n",
      "72/72 - 0s - loss: 10.3308 - mse: 10.3308\n",
      "Epoch 763/1000\n",
      "72/72 - 0s - loss: 9.1771 - mse: 9.1771\n",
      "Epoch 764/1000\n",
      "72/72 - 0s - loss: 13.4161 - mse: 13.4161\n",
      "Epoch 765/1000\n",
      "72/72 - 0s - loss: 8.5549 - mse: 8.5549\n",
      "Epoch 766/1000\n",
      "72/72 - 0s - loss: 11.2619 - mse: 11.2619\n",
      "Epoch 767/1000\n",
      "72/72 - 0s - loss: 10.0144 - mse: 10.0144\n",
      "Epoch 768/1000\n",
      "72/72 - 0s - loss: 7.8426 - mse: 7.8426\n",
      "Epoch 769/1000\n",
      "72/72 - 0s - loss: 11.4241 - mse: 11.4241\n",
      "Epoch 770/1000\n",
      "72/72 - 0s - loss: 10.7552 - mse: 10.7552\n",
      "Epoch 771/1000\n",
      "72/72 - 0s - loss: 7.6570 - mse: 7.6570\n",
      "Epoch 772/1000\n",
      "72/72 - 0s - loss: 9.1056 - mse: 9.1056\n",
      "Epoch 773/1000\n",
      "72/72 - 0s - loss: 13.5569 - mse: 13.5569\n",
      "Epoch 774/1000\n",
      "72/72 - 0s - loss: 8.3083 - mse: 8.3083\n",
      "Epoch 775/1000\n",
      "72/72 - 0s - loss: 9.1801 - mse: 9.1801\n",
      "Epoch 776/1000\n",
      "72/72 - 0s - loss: 9.3616 - mse: 9.3616\n",
      "Epoch 777/1000\n",
      "72/72 - 0s - loss: 8.9598 - mse: 8.9598\n",
      "Epoch 778/1000\n",
      "72/72 - 0s - loss: 11.0456 - mse: 11.0456\n",
      "Epoch 779/1000\n",
      "72/72 - 0s - loss: 7.4459 - mse: 7.4459\n",
      "Epoch 780/1000\n",
      "72/72 - 0s - loss: 11.1871 - mse: 11.1871\n",
      "Epoch 781/1000\n",
      "72/72 - 0s - loss: 9.2442 - mse: 9.2442\n",
      "Epoch 782/1000\n",
      "72/72 - 0s - loss: 7.2163 - mse: 7.2163\n",
      "Epoch 783/1000\n",
      "72/72 - 0s - loss: 10.4667 - mse: 10.4667\n",
      "Epoch 784/1000\n",
      "72/72 - 0s - loss: 12.2510 - mse: 12.2510\n",
      "Epoch 785/1000\n",
      "72/72 - 0s - loss: 11.0635 - mse: 11.0635\n",
      "Epoch 786/1000\n",
      "72/72 - 0s - loss: 10.2249 - mse: 10.2249\n",
      "Epoch 787/1000\n",
      "72/72 - 0s - loss: 8.2532 - mse: 8.2532\n",
      "Epoch 788/1000\n",
      "72/72 - 0s - loss: 9.1033 - mse: 9.1033\n",
      "Epoch 789/1000\n",
      "72/72 - 0s - loss: 11.9376 - mse: 11.9376\n",
      "Epoch 790/1000\n",
      "72/72 - 0s - loss: 9.4293 - mse: 9.4293\n",
      "Epoch 791/1000\n",
      "72/72 - 0s - loss: 8.6450 - mse: 8.6450\n",
      "Epoch 792/1000\n",
      "72/72 - 0s - loss: 8.6110 - mse: 8.6110\n",
      "Epoch 793/1000\n",
      "72/72 - 0s - loss: 9.5900 - mse: 9.5900\n",
      "Epoch 794/1000\n",
      "72/72 - 0s - loss: 9.7718 - mse: 9.7718\n",
      "Epoch 795/1000\n",
      "72/72 - 0s - loss: 8.9470 - mse: 8.9470\n",
      "Epoch 796/1000\n",
      "72/72 - 0s - loss: 9.3275 - mse: 9.3275\n",
      "Epoch 797/1000\n",
      "72/72 - 0s - loss: 9.1385 - mse: 9.1385\n",
      "Epoch 798/1000\n",
      "72/72 - 0s - loss: 10.3793 - mse: 10.3793\n",
      "Epoch 799/1000\n",
      "72/72 - 0s - loss: 10.9316 - mse: 10.9316\n",
      "Epoch 800/1000\n",
      "72/72 - 0s - loss: 9.1408 - mse: 9.1408\n",
      "Epoch 801/1000\n",
      "72/72 - 0s - loss: 8.5698 - mse: 8.5698\n",
      "Epoch 802/1000\n",
      "72/72 - 0s - loss: 7.2573 - mse: 7.2573\n",
      "Epoch 803/1000\n",
      "72/72 - 0s - loss: 14.3635 - mse: 14.3635\n",
      "Epoch 804/1000\n",
      "72/72 - 0s - loss: 7.4784 - mse: 7.4784\n",
      "Epoch 805/1000\n",
      "72/72 - 0s - loss: 8.1703 - mse: 8.1703\n",
      "Epoch 806/1000\n",
      "72/72 - 0s - loss: 10.3979 - mse: 10.3979\n",
      "Epoch 807/1000\n",
      "72/72 - 0s - loss: 9.5698 - mse: 9.5698\n",
      "Epoch 808/1000\n",
      "72/72 - 0s - loss: 11.7387 - mse: 11.7387\n",
      "Epoch 809/1000\n",
      "72/72 - 0s - loss: 9.3199 - mse: 9.3199\n",
      "Epoch 810/1000\n",
      "72/72 - 0s - loss: 9.7709 - mse: 9.7709\n",
      "Epoch 811/1000\n",
      "72/72 - 0s - loss: 9.3401 - mse: 9.3401\n",
      "Epoch 812/1000\n",
      "72/72 - 0s - loss: 9.1812 - mse: 9.1812\n",
      "Epoch 813/1000\n",
      "72/72 - 0s - loss: 9.9524 - mse: 9.9524\n",
      "Epoch 814/1000\n",
      "72/72 - 0s - loss: 9.4761 - mse: 9.4761\n",
      "Epoch 815/1000\n",
      "72/72 - 0s - loss: 7.8771 - mse: 7.8771\n",
      "Epoch 816/1000\n",
      "72/72 - 0s - loss: 10.5112 - mse: 10.5112\n",
      "Epoch 817/1000\n",
      "72/72 - 0s - loss: 8.9915 - mse: 8.9915\n",
      "Epoch 818/1000\n",
      "72/72 - 0s - loss: 10.2259 - mse: 10.2259\n",
      "Epoch 819/1000\n",
      "72/72 - 0s - loss: 8.9910 - mse: 8.9910\n",
      "Epoch 820/1000\n",
      "72/72 - 0s - loss: 9.4086 - mse: 9.4086\n",
      "Epoch 821/1000\n",
      "72/72 - 0s - loss: 8.0359 - mse: 8.0359\n",
      "Epoch 822/1000\n",
      "72/72 - 0s - loss: 10.0479 - mse: 10.0479\n",
      "Epoch 823/1000\n",
      "72/72 - 0s - loss: 11.0839 - mse: 11.0839\n",
      "Epoch 824/1000\n",
      "72/72 - 0s - loss: 9.6511 - mse: 9.6511\n",
      "Epoch 825/1000\n",
      "72/72 - 0s - loss: 9.0035 - mse: 9.0035\n",
      "Epoch 826/1000\n",
      "72/72 - 0s - loss: 9.3768 - mse: 9.3768\n",
      "Epoch 827/1000\n",
      "72/72 - 0s - loss: 9.9236 - mse: 9.9236\n",
      "Epoch 828/1000\n",
      "72/72 - 0s - loss: 10.5799 - mse: 10.5799\n",
      "Epoch 829/1000\n",
      "72/72 - 0s - loss: 11.4411 - mse: 11.4411\n",
      "Epoch 830/1000\n",
      "72/72 - 0s - loss: 7.0568 - mse: 7.0568\n",
      "Epoch 831/1000\n",
      "72/72 - 0s - loss: 8.2101 - mse: 8.2101\n",
      "Epoch 832/1000\n",
      "72/72 - 0s - loss: 10.8541 - mse: 10.8541\n",
      "Epoch 833/1000\n",
      "72/72 - 0s - loss: 7.5007 - mse: 7.5007\n",
      "Epoch 834/1000\n",
      "72/72 - 0s - loss: 10.4063 - mse: 10.4063\n",
      "Epoch 835/1000\n",
      "72/72 - 0s - loss: 7.6429 - mse: 7.6429\n",
      "Epoch 836/1000\n",
      "72/72 - 0s - loss: 10.0908 - mse: 10.0908\n",
      "Epoch 837/1000\n",
      "72/72 - 0s - loss: 10.6967 - mse: 10.6967\n",
      "Epoch 838/1000\n",
      "72/72 - 0s - loss: 9.1284 - mse: 9.1284\n",
      "Epoch 839/1000\n",
      "72/72 - 0s - loss: 8.4599 - mse: 8.4599\n",
      "Epoch 840/1000\n",
      "72/72 - 0s - loss: 8.7897 - mse: 8.7897\n",
      "Epoch 841/1000\n",
      "72/72 - 0s - loss: 11.9635 - mse: 11.9635\n",
      "Epoch 842/1000\n",
      "72/72 - 0s - loss: 8.8204 - mse: 8.8204\n",
      "Epoch 843/1000\n",
      "72/72 - 0s - loss: 9.8613 - mse: 9.8613\n",
      "Epoch 844/1000\n",
      "72/72 - 0s - loss: 9.4727 - mse: 9.4727\n",
      "Epoch 845/1000\n",
      "72/72 - 0s - loss: 11.4570 - mse: 11.4570\n",
      "Epoch 846/1000\n",
      "72/72 - 0s - loss: 9.9213 - mse: 9.9213\n",
      "Epoch 847/1000\n",
      "72/72 - 0s - loss: 10.2297 - mse: 10.2297\n",
      "Epoch 848/1000\n",
      "72/72 - 0s - loss: 8.5245 - mse: 8.5245\n",
      "Epoch 849/1000\n",
      "72/72 - 0s - loss: 9.6452 - mse: 9.6452\n",
      "Epoch 850/1000\n",
      "72/72 - 0s - loss: 7.6433 - mse: 7.6433\n",
      "Epoch 851/1000\n",
      "72/72 - 0s - loss: 8.4503 - mse: 8.4503\n",
      "Epoch 852/1000\n",
      "72/72 - 0s - loss: 14.8790 - mse: 14.8790\n",
      "Epoch 853/1000\n",
      "72/72 - 0s - loss: 10.4278 - mse: 10.4278\n",
      "Epoch 854/1000\n",
      "72/72 - 0s - loss: 7.4114 - mse: 7.4114\n",
      "Epoch 855/1000\n",
      "72/72 - 0s - loss: 10.1365 - mse: 10.1365\n",
      "Epoch 856/1000\n",
      "72/72 - 0s - loss: 8.8475 - mse: 8.8475\n",
      "Epoch 857/1000\n",
      "72/72 - 0s - loss: 10.3377 - mse: 10.3377\n",
      "Epoch 858/1000\n",
      "72/72 - 0s - loss: 8.6783 - mse: 8.6783\n",
      "Epoch 859/1000\n",
      "72/72 - 0s - loss: 9.7705 - mse: 9.7705\n",
      "Epoch 860/1000\n",
      "72/72 - 0s - loss: 10.7098 - mse: 10.7098\n",
      "Epoch 861/1000\n",
      "72/72 - 0s - loss: 9.8006 - mse: 9.8006\n",
      "Epoch 862/1000\n",
      "72/72 - 0s - loss: 8.7742 - mse: 8.7742\n",
      "Epoch 863/1000\n",
      "72/72 - 0s - loss: 9.4179 - mse: 9.4179\n",
      "Epoch 864/1000\n",
      "72/72 - 0s - loss: 8.6001 - mse: 8.6001\n",
      "Epoch 865/1000\n",
      "72/72 - 0s - loss: 8.6945 - mse: 8.6945\n",
      "Epoch 866/1000\n",
      "72/72 - 0s - loss: 9.0863 - mse: 9.0863\n",
      "Epoch 867/1000\n",
      "72/72 - 0s - loss: 11.9254 - mse: 11.9254\n",
      "Epoch 868/1000\n",
      "72/72 - 0s - loss: 13.2999 - mse: 13.2999\n",
      "Epoch 869/1000\n",
      "72/72 - 0s - loss: 8.5508 - mse: 8.5508\n",
      "Epoch 870/1000\n",
      "72/72 - 0s - loss: 7.9507 - mse: 7.9507\n",
      "Epoch 871/1000\n",
      "72/72 - 0s - loss: 8.9582 - mse: 8.9582\n",
      "Epoch 872/1000\n",
      "72/72 - 0s - loss: 10.5194 - mse: 10.5194\n",
      "Epoch 873/1000\n",
      "72/72 - 0s - loss: 8.8066 - mse: 8.8066\n",
      "Epoch 874/1000\n",
      "72/72 - 0s - loss: 9.8866 - mse: 9.8866\n",
      "Epoch 875/1000\n",
      "72/72 - 0s - loss: 7.6807 - mse: 7.6807\n",
      "Epoch 876/1000\n",
      "72/72 - 0s - loss: 10.2742 - mse: 10.2742\n",
      "Epoch 877/1000\n",
      "72/72 - 0s - loss: 8.8725 - mse: 8.8725\n",
      "Epoch 878/1000\n",
      "72/72 - 0s - loss: 9.1598 - mse: 9.1598\n",
      "Epoch 879/1000\n",
      "72/72 - 0s - loss: 7.6975 - mse: 7.6975\n",
      "Epoch 880/1000\n",
      "72/72 - 0s - loss: 11.5327 - mse: 11.5327\n",
      "Epoch 881/1000\n",
      "72/72 - 0s - loss: 7.8756 - mse: 7.8756\n",
      "Epoch 882/1000\n",
      "72/72 - 0s - loss: 9.0980 - mse: 9.0980\n",
      "Epoch 883/1000\n",
      "72/72 - 0s - loss: 9.6383 - mse: 9.6383\n",
      "Epoch 884/1000\n",
      "72/72 - 0s - loss: 10.2886 - mse: 10.2886\n",
      "Epoch 885/1000\n",
      "72/72 - 0s - loss: 8.5401 - mse: 8.5401\n",
      "Epoch 886/1000\n",
      "72/72 - 0s - loss: 10.0219 - mse: 10.0219\n",
      "Epoch 887/1000\n",
      "72/72 - 0s - loss: 7.8775 - mse: 7.8775\n",
      "Epoch 888/1000\n",
      "72/72 - 0s - loss: 9.6632 - mse: 9.6632\n",
      "Epoch 889/1000\n",
      "72/72 - 0s - loss: 9.0686 - mse: 9.0686\n",
      "Epoch 890/1000\n",
      "72/72 - 0s - loss: 9.7265 - mse: 9.7265\n",
      "Epoch 891/1000\n",
      "72/72 - 0s - loss: 10.8788 - mse: 10.8788\n",
      "Epoch 892/1000\n",
      "72/72 - 0s - loss: 10.1665 - mse: 10.1665\n",
      "Epoch 893/1000\n",
      "72/72 - 0s - loss: 9.9943 - mse: 9.9943\n",
      "Epoch 894/1000\n",
      "72/72 - 0s - loss: 8.9993 - mse: 8.9993\n",
      "Epoch 895/1000\n",
      "72/72 - 0s - loss: 9.7310 - mse: 9.7310\n",
      "Epoch 896/1000\n",
      "72/72 - 0s - loss: 6.9890 - mse: 6.9890\n",
      "Epoch 897/1000\n",
      "72/72 - 0s - loss: 9.3936 - mse: 9.3936\n",
      "Epoch 898/1000\n",
      "72/72 - 0s - loss: 8.6865 - mse: 8.6865\n",
      "Epoch 899/1000\n",
      "72/72 - 0s - loss: 9.2904 - mse: 9.2904\n",
      "Epoch 900/1000\n",
      "72/72 - 0s - loss: 8.2286 - mse: 8.2286\n",
      "Epoch 901/1000\n",
      "72/72 - 0s - loss: 9.1873 - mse: 9.1873\n",
      "Epoch 902/1000\n",
      "72/72 - 0s - loss: 8.2337 - mse: 8.2337\n",
      "Epoch 903/1000\n",
      "72/72 - 0s - loss: 10.3750 - mse: 10.3750\n",
      "Epoch 904/1000\n",
      "72/72 - 0s - loss: 9.3768 - mse: 9.3768\n",
      "Epoch 905/1000\n",
      "72/72 - 0s - loss: 7.7962 - mse: 7.7962\n",
      "Epoch 906/1000\n",
      "72/72 - 0s - loss: 11.5367 - mse: 11.5367\n",
      "Epoch 907/1000\n",
      "72/72 - 0s - loss: 10.6374 - mse: 10.6374\n",
      "Epoch 908/1000\n",
      "72/72 - 0s - loss: 7.7692 - mse: 7.7692\n",
      "Epoch 909/1000\n",
      "72/72 - 0s - loss: 9.0339 - mse: 9.0339\n",
      "Epoch 910/1000\n",
      "72/72 - 0s - loss: 7.6346 - mse: 7.6346\n",
      "Epoch 911/1000\n",
      "72/72 - 0s - loss: 9.2797 - mse: 9.2797\n",
      "Epoch 912/1000\n",
      "72/72 - 0s - loss: 6.1164 - mse: 6.1164\n",
      "Epoch 913/1000\n",
      "72/72 - 0s - loss: 11.7394 - mse: 11.7394\n",
      "Epoch 914/1000\n",
      "72/72 - 0s - loss: 8.4036 - mse: 8.4036\n",
      "Epoch 915/1000\n",
      "72/72 - 0s - loss: 8.7983 - mse: 8.7983\n",
      "Epoch 916/1000\n",
      "72/72 - 0s - loss: 9.9641 - mse: 9.9641\n",
      "Epoch 917/1000\n",
      "72/72 - 0s - loss: 9.8273 - mse: 9.8273\n",
      "Epoch 918/1000\n",
      "72/72 - 0s - loss: 11.2053 - mse: 11.2053\n",
      "Epoch 919/1000\n",
      "72/72 - 0s - loss: 6.9622 - mse: 6.9622\n",
      "Epoch 920/1000\n",
      "72/72 - 0s - loss: 11.2043 - mse: 11.2043\n",
      "Epoch 921/1000\n",
      "72/72 - 0s - loss: 7.4428 - mse: 7.4428\n",
      "Epoch 922/1000\n",
      "72/72 - 0s - loss: 8.9742 - mse: 8.9742\n",
      "Epoch 923/1000\n",
      "72/72 - 0s - loss: 12.3168 - mse: 12.3168\n",
      "Epoch 924/1000\n",
      "72/72 - 0s - loss: 9.7154 - mse: 9.7154\n",
      "Epoch 925/1000\n",
      "72/72 - 0s - loss: 9.0051 - mse: 9.0051\n",
      "Epoch 926/1000\n",
      "72/72 - 0s - loss: 7.9550 - mse: 7.9550\n",
      "Epoch 927/1000\n",
      "72/72 - 0s - loss: 8.3958 - mse: 8.3958\n",
      "Epoch 928/1000\n",
      "72/72 - 0s - loss: 9.1359 - mse: 9.1359\n",
      "Epoch 929/1000\n",
      "72/72 - 0s - loss: 9.3568 - mse: 9.3568\n",
      "Epoch 930/1000\n",
      "72/72 - 0s - loss: 9.2010 - mse: 9.2010\n",
      "Epoch 931/1000\n",
      "72/72 - 0s - loss: 9.5234 - mse: 9.5234\n",
      "Epoch 932/1000\n",
      "72/72 - 0s - loss: 9.0920 - mse: 9.0920\n",
      "Epoch 933/1000\n",
      "72/72 - 0s - loss: 8.7660 - mse: 8.7660\n",
      "Epoch 934/1000\n",
      "72/72 - 0s - loss: 8.9023 - mse: 8.9023\n",
      "Epoch 935/1000\n",
      "72/72 - 0s - loss: 10.4127 - mse: 10.4127\n",
      "Epoch 936/1000\n",
      "72/72 - 0s - loss: 11.3064 - mse: 11.3064\n",
      "Epoch 937/1000\n",
      "72/72 - 0s - loss: 6.9479 - mse: 6.9479\n",
      "Epoch 938/1000\n",
      "72/72 - 0s - loss: 8.5724 - mse: 8.5724\n",
      "Epoch 939/1000\n",
      "72/72 - 0s - loss: 9.0959 - mse: 9.0959\n",
      "Epoch 940/1000\n",
      "72/72 - 0s - loss: 12.6909 - mse: 12.6909\n",
      "Epoch 941/1000\n",
      "72/72 - 0s - loss: 10.5505 - mse: 10.5505\n",
      "Epoch 942/1000\n",
      "72/72 - 0s - loss: 8.3275 - mse: 8.3275\n",
      "Epoch 943/1000\n",
      "72/72 - 0s - loss: 8.8822 - mse: 8.8822\n",
      "Epoch 944/1000\n",
      "72/72 - 0s - loss: 8.9388 - mse: 8.9388\n",
      "Epoch 945/1000\n",
      "72/72 - 0s - loss: 13.4053 - mse: 13.4053\n",
      "Epoch 946/1000\n",
      "72/72 - 0s - loss: 9.7772 - mse: 9.7772\n",
      "Epoch 947/1000\n",
      "72/72 - 0s - loss: 8.7907 - mse: 8.7907\n",
      "Epoch 948/1000\n",
      "72/72 - 0s - loss: 9.1841 - mse: 9.1841\n",
      "Epoch 949/1000\n",
      "72/72 - 0s - loss: 8.6357 - mse: 8.6357\n",
      "Epoch 950/1000\n",
      "72/72 - 0s - loss: 8.9007 - mse: 8.9007\n",
      "Epoch 951/1000\n",
      "72/72 - 0s - loss: 11.8736 - mse: 11.8736\n",
      "Epoch 952/1000\n",
      "72/72 - 0s - loss: 8.2947 - mse: 8.2947\n",
      "Epoch 953/1000\n",
      "72/72 - 0s - loss: 10.7797 - mse: 10.7797\n",
      "Epoch 954/1000\n",
      "72/72 - 0s - loss: 7.9079 - mse: 7.9079\n",
      "Epoch 955/1000\n",
      "72/72 - 0s - loss: 8.2993 - mse: 8.2993\n",
      "Epoch 956/1000\n",
      "72/72 - 0s - loss: 9.4845 - mse: 9.4845\n",
      "Epoch 957/1000\n",
      "72/72 - 0s - loss: 8.9930 - mse: 8.9930\n",
      "Epoch 958/1000\n",
      "72/72 - 0s - loss: 8.6483 - mse: 8.6483\n",
      "Epoch 959/1000\n",
      "72/72 - 0s - loss: 9.8529 - mse: 9.8529\n",
      "Epoch 960/1000\n",
      "72/72 - 0s - loss: 8.6629 - mse: 8.6629\n",
      "Epoch 961/1000\n",
      "72/72 - 0s - loss: 10.4781 - mse: 10.4781\n",
      "Epoch 962/1000\n",
      "72/72 - 0s - loss: 8.3835 - mse: 8.3835\n",
      "Epoch 963/1000\n",
      "72/72 - 0s - loss: 10.1532 - mse: 10.1532\n",
      "Epoch 964/1000\n",
      "72/72 - 0s - loss: 8.9636 - mse: 8.9636\n",
      "Epoch 965/1000\n",
      "72/72 - 0s - loss: 13.1880 - mse: 13.1880\n",
      "Epoch 966/1000\n",
      "72/72 - 0s - loss: 11.4290 - mse: 11.4290\n",
      "Epoch 967/1000\n",
      "72/72 - 0s - loss: 11.0328 - mse: 11.0328\n",
      "Epoch 968/1000\n",
      "72/72 - 0s - loss: 8.4982 - mse: 8.4982\n",
      "Epoch 969/1000\n",
      "72/72 - 0s - loss: 8.0636 - mse: 8.0636\n",
      "Epoch 970/1000\n",
      "72/72 - 0s - loss: 7.5017 - mse: 7.5017\n",
      "Epoch 971/1000\n",
      "72/72 - 0s - loss: 11.3314 - mse: 11.3314\n",
      "Epoch 972/1000\n",
      "72/72 - 0s - loss: 8.0170 - mse: 8.0170\n",
      "Epoch 973/1000\n",
      "72/72 - 0s - loss: 9.9614 - mse: 9.9614\n",
      "Epoch 974/1000\n",
      "72/72 - 0s - loss: 8.4533 - mse: 8.4533\n",
      "Epoch 975/1000\n",
      "72/72 - 0s - loss: 8.6093 - mse: 8.6093\n",
      "Epoch 976/1000\n",
      "72/72 - 0s - loss: 8.6288 - mse: 8.6288\n",
      "Epoch 977/1000\n",
      "72/72 - 0s - loss: 10.3338 - mse: 10.3338\n",
      "Epoch 978/1000\n",
      "72/72 - 0s - loss: 8.7214 - mse: 8.7214\n",
      "Epoch 979/1000\n",
      "72/72 - 0s - loss: 9.5718 - mse: 9.5718\n",
      "Epoch 980/1000\n",
      "72/72 - 0s - loss: 9.2216 - mse: 9.2216\n",
      "Epoch 981/1000\n",
      "72/72 - 0s - loss: 11.0336 - mse: 11.0336\n",
      "Epoch 982/1000\n",
      "72/72 - 0s - loss: 6.7071 - mse: 6.7071\n",
      "Epoch 983/1000\n",
      "72/72 - 0s - loss: 8.6812 - mse: 8.6812\n",
      "Epoch 984/1000\n",
      "72/72 - 0s - loss: 8.3374 - mse: 8.3374\n",
      "Epoch 985/1000\n",
      "72/72 - 0s - loss: 10.0797 - mse: 10.0797\n",
      "Epoch 986/1000\n",
      "72/72 - 0s - loss: 7.9989 - mse: 7.9989\n",
      "Epoch 987/1000\n",
      "72/72 - 0s - loss: 9.7658 - mse: 9.7658\n",
      "Epoch 988/1000\n",
      "72/72 - 0s - loss: 6.2842 - mse: 6.2842\n",
      "Epoch 989/1000\n",
      "72/72 - 0s - loss: 12.0410 - mse: 12.0410\n",
      "Epoch 990/1000\n",
      "72/72 - 0s - loss: 8.6170 - mse: 8.6170\n",
      "Epoch 991/1000\n",
      "72/72 - 0s - loss: 11.2500 - mse: 11.2500\n",
      "Epoch 992/1000\n",
      "72/72 - 0s - loss: 8.7935 - mse: 8.7935\n",
      "Epoch 993/1000\n",
      "72/72 - 0s - loss: 7.7573 - mse: 7.7573\n",
      "Epoch 994/1000\n",
      "72/72 - 0s - loss: 14.7058 - mse: 14.7058\n",
      "Epoch 995/1000\n",
      "72/72 - 0s - loss: 9.5764 - mse: 9.5764\n",
      "Epoch 996/1000\n",
      "72/72 - 0s - loss: 9.0489 - mse: 9.0489\n",
      "Epoch 997/1000\n",
      "72/72 - 0s - loss: 8.0284 - mse: 8.0284\n",
      "Epoch 998/1000\n",
      "72/72 - 0s - loss: 6.7030 - mse: 6.7030\n",
      "Epoch 999/1000\n",
      "72/72 - 0s - loss: 8.7259 - mse: 8.7259\n",
      "Epoch 1000/1000\n",
      "72/72 - 0s - loss: 12.6944 - mse: 12.6944\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 107429.0312 - mse: 107429.0312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[107429.03125, 107429.03125]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=1000, batch_size=4, verbose=2)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                768       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,857\n",
      "Trainable params: 1,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set prediction accuracy: 11.46 %\n",
      "test set prediction accuracy: 8.33 %\n"
     ]
    }
   ],
   "source": [
    "#평균 성능 테스트\n",
    "scores = 0\n",
    "mean=np.mean(Y, axis=0)\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= mean <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"train set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= mean <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"test set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### <오차범위 3>\n",
      "- train set prediction accuracy(+-3): 89.93 % <br>\n",
      "- test set prediction accuracy(+-3): 4.17 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 5>\n",
      "- train set prediction accuracy(+-5): 96.18 % <br>\n",
      "- test set prediction accuracy(+-5): 9.72 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 10>\n",
      "- train set prediction accuracy(+-10): 99.65 % <br>\n",
      "- test set prediction accuracy(+-10): 15.28 % <br>\n",
      "<br>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######입력용#######\n",
    "\n",
    "#오차 범위 3 설정\n",
    "print('### <오차범위 3>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "print('### <오차범위 5>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "print('### <오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (시본으로 선별한 특징)\n",
    "X1=psqi_df[['SEX','AGE','PSQI_TOTAL_1','BMI_1','WBC_1','Insulin _1','Neutrophil_1','HDL_1','GLU0_1',\n",
    "            'Muscle_1','FatPercentage _1','SBP_1','DBP_1','HR_1','Waist_1']].values\n",
    "\n",
    "X2=psqi_df[['SEX','AGE','PSQI_TOTAL_2','BMI_2','WBC_2','Insulin _2','Neutrophil_2','HDL_2','GLU0_2',\n",
    "            'Muscle_2','FatPercentage_2','SBP_2','DBP_2','HR_2','Waist_2']].values\n",
    "\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=TG)\n",
    "Y1= psqi_df[['TG_1']].values\n",
    "Y2= psqi_df[['TG_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 72)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 15), (360, 1))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "72/72 - 1s - loss: 14851.0625 - mse: 14851.0625\n",
      "Epoch 2/150\n",
      "72/72 - 0s - loss: 14373.9219 - mse: 14373.9219\n",
      "Epoch 3/150\n",
      "72/72 - 0s - loss: 13366.1816 - mse: 13366.1816\n",
      "Epoch 4/150\n",
      "72/72 - 0s - loss: 11835.8730 - mse: 11835.8730\n",
      "Epoch 5/150\n",
      "72/72 - 0s - loss: 9569.8633 - mse: 9569.8633\n",
      "Epoch 6/150\n",
      "72/72 - 0s - loss: 7183.9243 - mse: 7183.9243\n",
      "Epoch 7/150\n",
      "72/72 - 0s - loss: 5075.7915 - mse: 5075.7915\n",
      "Epoch 8/150\n",
      "72/72 - 0s - loss: 4061.9722 - mse: 4061.9722\n",
      "Epoch 9/150\n",
      "72/72 - 0s - loss: 3631.3821 - mse: 3631.3821\n",
      "Epoch 10/150\n",
      "72/72 - 0s - loss: 3468.8340 - mse: 3468.8340\n",
      "Epoch 11/150\n",
      "72/72 - 0s - loss: 3373.6628 - mse: 3373.6628\n",
      "Epoch 12/150\n",
      "72/72 - 0s - loss: 3276.3738 - mse: 3276.3738\n",
      "Epoch 13/150\n",
      "72/72 - 0s - loss: 3229.0830 - mse: 3229.0830\n",
      "Epoch 14/150\n",
      "72/72 - 0s - loss: 3168.7351 - mse: 3168.7351\n",
      "Epoch 15/150\n",
      "72/72 - 0s - loss: 3119.7937 - mse: 3119.7937\n",
      "Epoch 16/150\n",
      "72/72 - 0s - loss: 3086.7119 - mse: 3086.7119\n",
      "Epoch 17/150\n",
      "72/72 - 0s - loss: 3021.8777 - mse: 3021.8777\n",
      "Epoch 18/150\n",
      "72/72 - 0s - loss: 3012.0596 - mse: 3012.0596\n",
      "Epoch 19/150\n",
      "72/72 - 0s - loss: 2982.4873 - mse: 2982.4873\n",
      "Epoch 20/150\n",
      "72/72 - 0s - loss: 2960.3003 - mse: 2960.3003\n",
      "Epoch 21/150\n",
      "72/72 - 0s - loss: 2939.7141 - mse: 2939.7141\n",
      "Epoch 22/150\n",
      "72/72 - 0s - loss: 2905.7520 - mse: 2905.7520\n",
      "Epoch 23/150\n",
      "72/72 - 0s - loss: 2901.4937 - mse: 2901.4937\n",
      "Epoch 24/150\n",
      "72/72 - 0s - loss: 2882.9385 - mse: 2882.9385\n",
      "Epoch 25/150\n",
      "72/72 - 0s - loss: 2861.0823 - mse: 2861.0823\n",
      "Epoch 26/150\n",
      "72/72 - 0s - loss: 2854.7156 - mse: 2854.7156\n",
      "Epoch 27/150\n",
      "72/72 - 0s - loss: 2830.1096 - mse: 2830.1096\n",
      "Epoch 28/150\n",
      "72/72 - 0s - loss: 2820.1934 - mse: 2820.1934\n",
      "Epoch 29/150\n",
      "72/72 - 0s - loss: 2814.7563 - mse: 2814.7563\n",
      "Epoch 30/150\n",
      "72/72 - 0s - loss: 2796.9385 - mse: 2796.9385\n",
      "Epoch 31/150\n",
      "72/72 - 0s - loss: 2781.5901 - mse: 2781.5901\n",
      "Epoch 32/150\n",
      "72/72 - 0s - loss: 2779.3428 - mse: 2779.3428\n",
      "Epoch 33/150\n",
      "72/72 - 0s - loss: 2767.5168 - mse: 2767.5168\n",
      "Epoch 34/150\n",
      "72/72 - 0s - loss: 2753.3406 - mse: 2753.3406\n",
      "Epoch 35/150\n",
      "72/72 - 0s - loss: 2759.6433 - mse: 2759.6433\n",
      "Epoch 36/150\n",
      "72/72 - 0s - loss: 2736.4326 - mse: 2736.4326\n",
      "Epoch 37/150\n",
      "72/72 - 0s - loss: 2738.3977 - mse: 2738.3977\n",
      "Epoch 38/150\n",
      "72/72 - 0s - loss: 2721.5496 - mse: 2721.5496\n",
      "Epoch 39/150\n",
      "72/72 - 0s - loss: 2729.7290 - mse: 2729.7290\n",
      "Epoch 40/150\n",
      "72/72 - 0s - loss: 2732.2434 - mse: 2732.2434\n",
      "Epoch 41/150\n",
      "72/72 - 0s - loss: 2714.2153 - mse: 2714.2153\n",
      "Epoch 42/150\n",
      "72/72 - 0s - loss: 2703.6260 - mse: 2703.6260\n",
      "Epoch 43/150\n",
      "72/72 - 0s - loss: 2701.7502 - mse: 2701.7502\n",
      "Epoch 44/150\n",
      "72/72 - 0s - loss: 2687.6602 - mse: 2687.6602\n",
      "Epoch 45/150\n",
      "72/72 - 0s - loss: 2690.5830 - mse: 2690.5830\n",
      "Epoch 46/150\n",
      "72/72 - 0s - loss: 2678.2524 - mse: 2678.2524\n",
      "Epoch 47/150\n",
      "72/72 - 0s - loss: 2671.9695 - mse: 2671.9695\n",
      "Epoch 48/150\n",
      "72/72 - 0s - loss: 2674.3975 - mse: 2674.3975\n",
      "Epoch 49/150\n",
      "72/72 - 0s - loss: 2669.4795 - mse: 2669.4795\n",
      "Epoch 50/150\n",
      "72/72 - 0s - loss: 2662.8760 - mse: 2662.8760\n",
      "Epoch 51/150\n",
      "72/72 - 0s - loss: 2655.9480 - mse: 2655.9480\n",
      "Epoch 52/150\n",
      "72/72 - 0s - loss: 2658.9851 - mse: 2658.9851\n",
      "Epoch 53/150\n",
      "72/72 - 0s - loss: 2646.4182 - mse: 2646.4182\n",
      "Epoch 54/150\n",
      "72/72 - 0s - loss: 2652.1960 - mse: 2652.1960\n",
      "Epoch 55/150\n",
      "72/72 - 0s - loss: 2632.1841 - mse: 2632.1841\n",
      "Epoch 56/150\n",
      "72/72 - 0s - loss: 2657.4731 - mse: 2657.4731\n",
      "Epoch 57/150\n",
      "72/72 - 0s - loss: 2626.5562 - mse: 2626.5562\n",
      "Epoch 58/150\n",
      "72/72 - 0s - loss: 2621.1755 - mse: 2621.1755\n",
      "Epoch 59/150\n",
      "72/72 - 0s - loss: 2625.2549 - mse: 2625.2549\n",
      "Epoch 60/150\n",
      "72/72 - 0s - loss: 2617.7717 - mse: 2617.7717\n",
      "Epoch 61/150\n",
      "72/72 - 0s - loss: 2612.3584 - mse: 2612.3584\n",
      "Epoch 62/150\n",
      "72/72 - 0s - loss: 2595.5066 - mse: 2595.5066\n",
      "Epoch 63/150\n",
      "72/72 - 0s - loss: 2561.0752 - mse: 2561.0752\n",
      "Epoch 64/150\n",
      "72/72 - 0s - loss: 2606.1167 - mse: 2606.1167\n",
      "Epoch 65/150\n",
      "72/72 - 0s - loss: 2591.0483 - mse: 2591.0483\n",
      "Epoch 66/150\n",
      "72/72 - 0s - loss: 2585.7163 - mse: 2585.7163\n",
      "Epoch 67/150\n",
      "72/72 - 0s - loss: 2580.0911 - mse: 2580.0911\n",
      "Epoch 68/150\n",
      "72/72 - 0s - loss: 2574.1123 - mse: 2574.1123\n",
      "Epoch 69/150\n",
      "72/72 - 0s - loss: 2582.3857 - mse: 2582.3857\n",
      "Epoch 70/150\n",
      "72/72 - 0s - loss: 2566.8879 - mse: 2566.8879\n",
      "Epoch 71/150\n",
      "72/72 - 0s - loss: 2553.3455 - mse: 2553.3455\n",
      "Epoch 72/150\n",
      "72/72 - 0s - loss: 2577.1021 - mse: 2577.1021\n",
      "Epoch 73/150\n",
      "72/72 - 0s - loss: 2546.3147 - mse: 2546.3147\n",
      "Epoch 74/150\n",
      "72/72 - 0s - loss: 2562.4231 - mse: 2562.4231\n",
      "Epoch 75/150\n",
      "72/72 - 0s - loss: 2554.4150 - mse: 2554.4150\n",
      "Epoch 76/150\n",
      "72/72 - 0s - loss: 2550.2002 - mse: 2550.2002\n",
      "Epoch 77/150\n",
      "72/72 - 0s - loss: 2545.3599 - mse: 2545.3599\n",
      "Epoch 78/150\n",
      "72/72 - 0s - loss: 2550.9380 - mse: 2550.9380\n",
      "Epoch 79/150\n",
      "72/72 - 0s - loss: 2545.4006 - mse: 2545.4006\n",
      "Epoch 80/150\n",
      "72/72 - 0s - loss: 2541.0410 - mse: 2541.0410\n",
      "Epoch 81/150\n",
      "72/72 - 0s - loss: 2535.6208 - mse: 2535.6208\n",
      "Epoch 82/150\n",
      "72/72 - 0s - loss: 2535.0920 - mse: 2535.0920\n",
      "Epoch 83/150\n",
      "72/72 - 0s - loss: 2531.0649 - mse: 2531.0649\n",
      "Epoch 84/150\n",
      "72/72 - 0s - loss: 2533.3035 - mse: 2533.3035\n",
      "Epoch 85/150\n",
      "72/72 - 0s - loss: 2512.7185 - mse: 2512.7185\n",
      "Epoch 86/150\n",
      "72/72 - 0s - loss: 2508.4382 - mse: 2508.4382\n",
      "Epoch 87/150\n",
      "72/72 - 0s - loss: 2507.0156 - mse: 2507.0156\n",
      "Epoch 88/150\n",
      "72/72 - 0s - loss: 2511.4417 - mse: 2511.4417\n",
      "Epoch 89/150\n",
      "72/72 - 0s - loss: 2497.2583 - mse: 2497.2583\n",
      "Epoch 90/150\n",
      "72/72 - 0s - loss: 2512.2383 - mse: 2512.2383\n",
      "Epoch 91/150\n",
      "72/72 - 0s - loss: 2507.0066 - mse: 2507.0066\n",
      "Epoch 92/150\n",
      "72/72 - 0s - loss: 2519.0315 - mse: 2519.0315\n",
      "Epoch 93/150\n",
      "72/72 - 0s - loss: 2492.1067 - mse: 2492.1067\n",
      "Epoch 94/150\n",
      "72/72 - 0s - loss: 2498.5244 - mse: 2498.5244\n",
      "Epoch 95/150\n",
      "72/72 - 0s - loss: 2484.1614 - mse: 2484.1614\n",
      "Epoch 96/150\n",
      "72/72 - 0s - loss: 2478.6672 - mse: 2478.6672\n",
      "Epoch 97/150\n",
      "72/72 - 0s - loss: 2484.2041 - mse: 2484.2041\n",
      "Epoch 98/150\n",
      "72/72 - 0s - loss: 2474.7288 - mse: 2474.7288\n",
      "Epoch 99/150\n",
      "72/72 - 0s - loss: 2487.2600 - mse: 2487.2600\n",
      "Epoch 100/150\n",
      "72/72 - 0s - loss: 2472.2729 - mse: 2472.2729\n",
      "Epoch 101/150\n",
      "72/72 - 0s - loss: 2480.7998 - mse: 2480.7998\n",
      "Epoch 102/150\n",
      "72/72 - 0s - loss: 2462.3401 - mse: 2462.3401\n",
      "Epoch 103/150\n",
      "72/72 - 0s - loss: 2474.0994 - mse: 2474.0994\n",
      "Epoch 104/150\n",
      "72/72 - 0s - loss: 2467.9377 - mse: 2467.9377\n",
      "Epoch 105/150\n",
      "72/72 - 0s - loss: 2443.2693 - mse: 2443.2693\n",
      "Epoch 106/150\n",
      "72/72 - 0s - loss: 2467.1750 - mse: 2467.1750\n",
      "Epoch 107/150\n",
      "72/72 - 0s - loss: 2434.0894 - mse: 2434.0894\n",
      "Epoch 108/150\n",
      "72/72 - 0s - loss: 2457.1746 - mse: 2457.1746\n",
      "Epoch 109/150\n",
      "72/72 - 0s - loss: 2452.7236 - mse: 2452.7236\n",
      "Epoch 110/150\n",
      "72/72 - 0s - loss: 2462.5791 - mse: 2462.5791\n",
      "Epoch 111/150\n",
      "72/72 - 0s - loss: 2451.2502 - mse: 2451.2502\n",
      "Epoch 112/150\n",
      "72/72 - 0s - loss: 2450.5291 - mse: 2450.5291\n",
      "Epoch 113/150\n",
      "72/72 - 0s - loss: 2439.0693 - mse: 2439.0693\n",
      "Epoch 114/150\n",
      "72/72 - 0s - loss: 2454.5652 - mse: 2454.5652\n",
      "Epoch 115/150\n",
      "72/72 - 0s - loss: 2447.4028 - mse: 2447.4028\n",
      "Epoch 116/150\n",
      "72/72 - 0s - loss: 2446.2634 - mse: 2446.2634\n",
      "Epoch 117/150\n",
      "72/72 - 0s - loss: 2431.1174 - mse: 2431.1174\n",
      "Epoch 118/150\n",
      "72/72 - 0s - loss: 2442.4568 - mse: 2442.4568\n",
      "Epoch 119/150\n",
      "72/72 - 0s - loss: 2418.0930 - mse: 2418.0930\n",
      "Epoch 120/150\n",
      "72/72 - 0s - loss: 2412.1689 - mse: 2412.1689\n",
      "Epoch 121/150\n",
      "72/72 - 0s - loss: 2425.3792 - mse: 2425.3792\n",
      "Epoch 122/150\n",
      "72/72 - 0s - loss: 2422.3926 - mse: 2422.3926\n",
      "Epoch 123/150\n",
      "72/72 - 0s - loss: 2412.2852 - mse: 2412.2852\n",
      "Epoch 124/150\n",
      "72/72 - 0s - loss: 2399.7524 - mse: 2399.7524\n",
      "Epoch 125/150\n",
      "72/72 - 0s - loss: 2401.4277 - mse: 2401.4277\n",
      "Epoch 126/150\n",
      "72/72 - 0s - loss: 2400.3491 - mse: 2400.3491\n",
      "Epoch 127/150\n",
      "72/72 - 0s - loss: 2398.4590 - mse: 2398.4590\n",
      "Epoch 128/150\n",
      "72/72 - 0s - loss: 2410.0718 - mse: 2410.0718\n",
      "Epoch 129/150\n",
      "72/72 - 0s - loss: 2390.0435 - mse: 2390.0435\n",
      "Epoch 130/150\n",
      "72/72 - 0s - loss: 2392.1733 - mse: 2392.1733\n",
      "Epoch 131/150\n",
      "72/72 - 0s - loss: 2385.8723 - mse: 2385.8723\n",
      "Epoch 132/150\n",
      "72/72 - 0s - loss: 2378.7249 - mse: 2378.7249\n",
      "Epoch 133/150\n",
      "72/72 - 0s - loss: 2370.8330 - mse: 2370.8330\n",
      "Epoch 134/150\n",
      "72/72 - 0s - loss: 2364.6943 - mse: 2364.6943\n",
      "Epoch 135/150\n",
      "72/72 - 0s - loss: 2371.6865 - mse: 2371.6865\n",
      "Epoch 136/150\n",
      "72/72 - 0s - loss: 2369.5825 - mse: 2369.5825\n",
      "Epoch 137/150\n",
      "72/72 - 0s - loss: 2358.6243 - mse: 2358.6243\n",
      "Epoch 138/150\n",
      "72/72 - 0s - loss: 2363.5657 - mse: 2363.5657\n",
      "Epoch 139/150\n",
      "72/72 - 0s - loss: 2364.3821 - mse: 2364.3821\n",
      "Epoch 140/150\n",
      "72/72 - 0s - loss: 2352.0740 - mse: 2352.0740\n",
      "Epoch 141/150\n",
      "72/72 - 0s - loss: 2347.4343 - mse: 2347.4343\n",
      "Epoch 142/150\n",
      "72/72 - 0s - loss: 2338.9497 - mse: 2338.9497\n",
      "Epoch 143/150\n",
      "72/72 - 0s - loss: 2346.1265 - mse: 2346.1265\n",
      "Epoch 144/150\n",
      "72/72 - 0s - loss: 2327.8401 - mse: 2327.8401\n",
      "Epoch 145/150\n",
      "72/72 - 0s - loss: 2333.3845 - mse: 2333.3845\n",
      "Epoch 146/150\n",
      "72/72 - 0s - loss: 2327.3149 - mse: 2327.3149\n",
      "Epoch 147/150\n",
      "72/72 - 0s - loss: 2318.7678 - mse: 2318.7678\n",
      "Epoch 148/150\n",
      "72/72 - 0s - loss: 2319.7947 - mse: 2319.7947\n",
      "Epoch 149/150\n",
      "72/72 - 0s - loss: 2313.7593 - mse: 2313.7593\n",
      "Epoch 150/150\n",
      "72/72 - 0s - loss: 2306.0115 - mse: 2306.0115\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 9658.2314 - mse: 9658.2314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9658.2314453125, 9658.2314453125]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=150, batch_size=4, verbose=2)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                512       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,601\n",
      "Trainable params: 1,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set prediction accuracy: 11.46 %\n",
      "test set prediction accuracy: 8.33 %\n"
     ]
    }
   ],
   "source": [
    "#평균 성능 테스트\n",
    "scores = 0\n",
    "mean=np.mean(Y, axis=0)\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= mean <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"train set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= mean <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"test set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### <오차범위 3>\n",
      "- train set prediction accuracy(+-3): 7.64 % <br>\n",
      "- test set prediction accuracy(+-3): 6.94 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 5>\n",
      "- train set prediction accuracy(+-5): 13.19 % <br>\n",
      "- test set prediction accuracy(+-5): 9.72 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 10>\n",
      "- train set prediction accuracy(+-10): 25.35 % <br>\n",
      "- test set prediction accuracy(+-10): 25.00 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 20>\n",
      "- train set prediction accuracy(+-20): 48.96 % <br>\n",
      "- test set prediction accuracy(+-20): 54.17 % <br>\n"
     ]
    }
   ],
   "source": [
    "######입력용#######\n",
    "\n",
    "#오차 범위 3 설정\n",
    "print('### <오차범위 3>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "print('### <오차범위 5>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "print('### <오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "print('### <오차범위 20>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (피검사 안하고 할 수 있는 수치)\n",
    "X1=psqi_df[['SEX','AGE','PSQI_TOTAL_1','BMI_1',\n",
    "            'Muscle_1','FatPercentage _1','SBP_1','DBP_1','HR_1','Waist_1']].values\n",
    "\n",
    "X2=psqi_df[['SEX','AGE','PSQI_TOTAL_2','BMI_2',\n",
    "            'Muscle_2','FatPercentage_2','SBP_2','DBP_2','HR_2','Waist_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "\n",
    "#y 배열 생성 (y=TG)\n",
    "Y1= psqi_df[['TG_1']].values\n",
    "Y2= psqi_df[['TG_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 72)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 10), (360, 1))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "72/72 - 1s - loss: 14555.7432 - mse: 14555.7432\n",
      "Epoch 2/150\n",
      "72/72 - 0s - loss: 13647.1133 - mse: 13647.1133\n",
      "Epoch 3/150\n",
      "72/72 - 0s - loss: 12046.6699 - mse: 12046.6699\n",
      "Epoch 4/150\n",
      "72/72 - 0s - loss: 9738.7324 - mse: 9738.7324\n",
      "Epoch 5/150\n",
      "72/72 - 0s - loss: 7297.1816 - mse: 7297.1816\n",
      "Epoch 6/150\n",
      "72/72 - 0s - loss: 5274.3525 - mse: 5274.3525\n",
      "Epoch 7/150\n",
      "72/72 - 0s - loss: 4257.6792 - mse: 4257.6792\n",
      "Epoch 8/150\n",
      "72/72 - 0s - loss: 3866.3499 - mse: 3866.3499\n",
      "Epoch 9/150\n",
      "72/72 - 0s - loss: 3755.8481 - mse: 3755.8481\n",
      "Epoch 10/150\n",
      "72/72 - 0s - loss: 3695.7512 - mse: 3695.7512\n",
      "Epoch 11/150\n",
      "72/72 - 0s - loss: 3646.7622 - mse: 3646.7622\n",
      "Epoch 12/150\n",
      "72/72 - 0s - loss: 3616.5178 - mse: 3616.5178\n",
      "Epoch 13/150\n",
      "72/72 - 0s - loss: 3589.9465 - mse: 3589.9465\n",
      "Epoch 14/150\n",
      "72/72 - 0s - loss: 3549.6084 - mse: 3549.6084\n",
      "Epoch 15/150\n",
      "72/72 - 0s - loss: 3539.3721 - mse: 3539.3721\n",
      "Epoch 16/150\n",
      "72/72 - 0s - loss: 3513.3745 - mse: 3513.3745\n",
      "Epoch 17/150\n",
      "72/72 - 0s - loss: 3497.9146 - mse: 3497.9146\n",
      "Epoch 18/150\n",
      "72/72 - 0s - loss: 3489.1946 - mse: 3489.1946\n",
      "Epoch 19/150\n",
      "72/72 - 0s - loss: 3450.2749 - mse: 3450.2749\n",
      "Epoch 20/150\n",
      "72/72 - 0s - loss: 3446.6616 - mse: 3446.6616\n",
      "Epoch 21/150\n",
      "72/72 - 0s - loss: 3428.5576 - mse: 3428.5576\n",
      "Epoch 22/150\n",
      "72/72 - 0s - loss: 3413.8977 - mse: 3413.8977\n",
      "Epoch 23/150\n",
      "72/72 - 0s - loss: 3398.7251 - mse: 3398.7251\n",
      "Epoch 24/150\n",
      "72/72 - 0s - loss: 3392.7373 - mse: 3392.7373\n",
      "Epoch 25/150\n",
      "72/72 - 0s - loss: 3379.9136 - mse: 3379.9136\n",
      "Epoch 26/150\n",
      "72/72 - 0s - loss: 3370.0271 - mse: 3370.0271\n",
      "Epoch 27/150\n",
      "72/72 - 0s - loss: 3361.1685 - mse: 3361.1685\n",
      "Epoch 28/150\n",
      "72/72 - 0s - loss: 3345.4473 - mse: 3345.4473\n",
      "Epoch 29/150\n",
      "72/72 - 0s - loss: 3342.0308 - mse: 3342.0308\n",
      "Epoch 30/150\n",
      "72/72 - 0s - loss: 3328.7683 - mse: 3328.7683\n",
      "Epoch 31/150\n",
      "72/72 - 0s - loss: 3316.3464 - mse: 3316.3464\n",
      "Epoch 32/150\n",
      "72/72 - 0s - loss: 3309.2200 - mse: 3309.2200\n",
      "Epoch 33/150\n",
      "72/72 - 0s - loss: 3302.1697 - mse: 3302.1697\n",
      "Epoch 34/150\n",
      "72/72 - 0s - loss: 3303.9045 - mse: 3303.9045\n",
      "Epoch 35/150\n",
      "72/72 - 0s - loss: 3290.7461 - mse: 3290.7461\n",
      "Epoch 36/150\n",
      "72/72 - 0s - loss: 3292.2705 - mse: 3292.2705\n",
      "Epoch 37/150\n",
      "72/72 - 0s - loss: 3277.5591 - mse: 3277.5591\n",
      "Epoch 38/150\n",
      "72/72 - 0s - loss: 3279.5986 - mse: 3279.5986\n",
      "Epoch 39/150\n",
      "72/72 - 0s - loss: 3268.2617 - mse: 3268.2617\n",
      "Epoch 40/150\n",
      "72/72 - 0s - loss: 3268.2776 - mse: 3268.2776\n",
      "Epoch 41/150\n",
      "72/72 - 0s - loss: 3256.9575 - mse: 3256.9575\n",
      "Epoch 42/150\n",
      "72/72 - 0s - loss: 3245.5479 - mse: 3245.5479\n",
      "Epoch 43/150\n",
      "72/72 - 0s - loss: 3244.0447 - mse: 3244.0447\n",
      "Epoch 44/150\n",
      "72/72 - 0s - loss: 3244.9041 - mse: 3244.9041\n",
      "Epoch 45/150\n",
      "72/72 - 0s - loss: 3244.3689 - mse: 3244.3689\n",
      "Epoch 46/150\n",
      "72/72 - 0s - loss: 3234.7295 - mse: 3234.7295\n",
      "Epoch 47/150\n",
      "72/72 - 0s - loss: 3225.2856 - mse: 3225.2856\n",
      "Epoch 48/150\n",
      "72/72 - 0s - loss: 3216.2297 - mse: 3216.2297\n",
      "Epoch 49/150\n",
      "72/72 - 0s - loss: 3214.5547 - mse: 3214.5547\n",
      "Epoch 50/150\n",
      "72/72 - 0s - loss: 3212.8569 - mse: 3212.8569\n",
      "Epoch 51/150\n",
      "72/72 - 0s - loss: 3211.5752 - mse: 3211.5752\n",
      "Epoch 52/150\n",
      "72/72 - 0s - loss: 3190.6392 - mse: 3190.6392\n",
      "Epoch 53/150\n",
      "72/72 - 0s - loss: 3196.5771 - mse: 3196.5771\n",
      "Epoch 54/150\n",
      "72/72 - 0s - loss: 3187.6782 - mse: 3187.6782\n",
      "Epoch 55/150\n",
      "72/72 - 0s - loss: 3180.0276 - mse: 3180.0276\n",
      "Epoch 56/150\n",
      "72/72 - 0s - loss: 3188.6997 - mse: 3188.6997\n",
      "Epoch 57/150\n",
      "72/72 - 0s - loss: 3189.7070 - mse: 3189.7070\n",
      "Epoch 58/150\n",
      "72/72 - 0s - loss: 3171.2817 - mse: 3171.2817\n",
      "Epoch 59/150\n",
      "72/72 - 0s - loss: 3175.8838 - mse: 3175.8838\n",
      "Epoch 60/150\n",
      "72/72 - 0s - loss: 3162.9077 - mse: 3162.9077\n",
      "Epoch 61/150\n",
      "72/72 - 0s - loss: 3166.5037 - mse: 3166.5037\n",
      "Epoch 62/150\n",
      "72/72 - 0s - loss: 3162.4062 - mse: 3162.4062\n",
      "Epoch 63/150\n",
      "72/72 - 0s - loss: 3162.6240 - mse: 3162.6240\n",
      "Epoch 64/150\n",
      "72/72 - 0s - loss: 3156.6719 - mse: 3156.6719\n",
      "Epoch 65/150\n",
      "72/72 - 0s - loss: 3153.1516 - mse: 3153.1516\n",
      "Epoch 66/150\n",
      "72/72 - 0s - loss: 3141.7354 - mse: 3141.7354\n",
      "Epoch 67/150\n",
      "72/72 - 0s - loss: 3159.9841 - mse: 3159.9841\n",
      "Epoch 68/150\n",
      "72/72 - 0s - loss: 3139.2693 - mse: 3139.2693\n",
      "Epoch 69/150\n",
      "72/72 - 0s - loss: 3139.0469 - mse: 3139.0469\n",
      "Epoch 70/150\n",
      "72/72 - 0s - loss: 3136.2041 - mse: 3136.2041\n",
      "Epoch 71/150\n",
      "72/72 - 0s - loss: 3138.9656 - mse: 3138.9656\n",
      "Epoch 72/150\n",
      "72/72 - 0s - loss: 3124.2295 - mse: 3124.2295\n",
      "Epoch 73/150\n",
      "72/72 - 0s - loss: 3125.1333 - mse: 3125.1333\n",
      "Epoch 74/150\n",
      "72/72 - 0s - loss: 3124.3801 - mse: 3124.3801\n",
      "Epoch 75/150\n",
      "72/72 - 0s - loss: 3127.7859 - mse: 3127.7859\n",
      "Epoch 76/150\n",
      "72/72 - 0s - loss: 3125.6689 - mse: 3125.6689\n",
      "Epoch 77/150\n",
      "72/72 - 0s - loss: 3113.9500 - mse: 3113.9500\n",
      "Epoch 78/150\n",
      "72/72 - 0s - loss: 3113.6040 - mse: 3113.6040\n",
      "Epoch 79/150\n",
      "72/72 - 0s - loss: 3112.2581 - mse: 3112.2581\n",
      "Epoch 80/150\n",
      "72/72 - 0s - loss: 3107.4424 - mse: 3107.4424\n",
      "Epoch 81/150\n",
      "72/72 - 0s - loss: 3107.6790 - mse: 3107.6790\n",
      "Epoch 82/150\n",
      "72/72 - 0s - loss: 3104.0872 - mse: 3104.0872\n",
      "Epoch 83/150\n",
      "72/72 - 0s - loss: 3099.1816 - mse: 3099.1816\n",
      "Epoch 84/150\n",
      "72/72 - 0s - loss: 3095.8599 - mse: 3095.8599\n",
      "Epoch 85/150\n",
      "72/72 - 0s - loss: 3076.6294 - mse: 3076.6294\n",
      "Epoch 86/150\n",
      "72/72 - 0s - loss: 3081.2471 - mse: 3081.2471\n",
      "Epoch 87/150\n",
      "72/72 - 0s - loss: 3092.4866 - mse: 3092.4866\n",
      "Epoch 88/150\n",
      "72/72 - 0s - loss: 3077.2959 - mse: 3077.2959\n",
      "Epoch 89/150\n",
      "72/72 - 0s - loss: 3082.4187 - mse: 3082.4187\n",
      "Epoch 90/150\n",
      "72/72 - 0s - loss: 3083.7898 - mse: 3083.7898\n",
      "Epoch 91/150\n",
      "72/72 - 0s - loss: 3067.4893 - mse: 3067.4893\n",
      "Epoch 92/150\n",
      "72/72 - 0s - loss: 3081.7373 - mse: 3081.7373\n",
      "Epoch 93/150\n",
      "72/72 - 0s - loss: 3068.2803 - mse: 3068.2803\n",
      "Epoch 94/150\n",
      "72/72 - 0s - loss: 3056.5352 - mse: 3056.5352\n",
      "Epoch 95/150\n",
      "72/72 - 0s - loss: 3069.8193 - mse: 3069.8193\n",
      "Epoch 96/150\n",
      "72/72 - 0s - loss: 3066.4153 - mse: 3066.4153\n",
      "Epoch 97/150\n",
      "72/72 - 0s - loss: 3064.9014 - mse: 3064.9014\n",
      "Epoch 98/150\n",
      "72/72 - 0s - loss: 3049.6245 - mse: 3049.6245\n",
      "Epoch 99/150\n",
      "72/72 - 0s - loss: 3050.4370 - mse: 3050.4370\n",
      "Epoch 100/150\n",
      "72/72 - 0s - loss: 3044.3430 - mse: 3044.3430\n",
      "Epoch 101/150\n",
      "72/72 - 0s - loss: 3047.2217 - mse: 3047.2217\n",
      "Epoch 102/150\n",
      "72/72 - 0s - loss: 3024.4688 - mse: 3024.4688\n",
      "Epoch 103/150\n",
      "72/72 - 0s - loss: 3035.9492 - mse: 3035.9492\n",
      "Epoch 104/150\n",
      "72/72 - 0s - loss: 3028.5728 - mse: 3028.5728\n",
      "Epoch 105/150\n",
      "72/72 - 0s - loss: 3038.4817 - mse: 3038.4817\n",
      "Epoch 106/150\n",
      "72/72 - 0s - loss: 3031.2317 - mse: 3031.2317\n",
      "Epoch 107/150\n",
      "72/72 - 0s - loss: 3036.5342 - mse: 3036.5342\n",
      "Epoch 108/150\n",
      "72/72 - 0s - loss: 3026.3369 - mse: 3026.3369\n",
      "Epoch 109/150\n",
      "72/72 - 0s - loss: 3016.5842 - mse: 3016.5842\n",
      "Epoch 110/150\n",
      "72/72 - 0s - loss: 3016.5413 - mse: 3016.5413\n",
      "Epoch 111/150\n",
      "72/72 - 0s - loss: 3011.0100 - mse: 3011.0100\n",
      "Epoch 112/150\n",
      "72/72 - 0s - loss: 3011.6143 - mse: 3011.6143\n",
      "Epoch 113/150\n",
      "72/72 - 0s - loss: 3010.4702 - mse: 3010.4702\n",
      "Epoch 114/150\n",
      "72/72 - 0s - loss: 2999.8599 - mse: 2999.8599\n",
      "Epoch 115/150\n",
      "72/72 - 0s - loss: 3004.2280 - mse: 3004.2280\n",
      "Epoch 116/150\n",
      "72/72 - 0s - loss: 2993.3660 - mse: 2993.3660\n",
      "Epoch 117/150\n",
      "72/72 - 0s - loss: 2995.0522 - mse: 2995.0522\n",
      "Epoch 118/150\n",
      "72/72 - 0s - loss: 2989.5864 - mse: 2989.5864\n",
      "Epoch 119/150\n",
      "72/72 - 0s - loss: 2998.1665 - mse: 2998.1665\n",
      "Epoch 120/150\n",
      "72/72 - 0s - loss: 2993.9443 - mse: 2993.9443\n",
      "Epoch 121/150\n",
      "72/72 - 0s - loss: 2987.5759 - mse: 2987.5759\n",
      "Epoch 122/150\n",
      "72/72 - 0s - loss: 2977.9253 - mse: 2977.9253\n",
      "Epoch 123/150\n",
      "72/72 - 0s - loss: 2989.2163 - mse: 2989.2163\n",
      "Epoch 124/150\n",
      "72/72 - 0s - loss: 2970.9500 - mse: 2970.9500\n",
      "Epoch 125/150\n",
      "72/72 - 0s - loss: 2961.9541 - mse: 2961.9541\n",
      "Epoch 126/150\n",
      "72/72 - 0s - loss: 2965.8279 - mse: 2965.8279\n",
      "Epoch 127/150\n",
      "72/72 - 0s - loss: 2963.4604 - mse: 2963.4604\n",
      "Epoch 128/150\n",
      "72/72 - 0s - loss: 2962.1592 - mse: 2962.1592\n",
      "Epoch 129/150\n",
      "72/72 - 0s - loss: 2964.0718 - mse: 2964.0718\n",
      "Epoch 130/150\n",
      "72/72 - 0s - loss: 2949.2429 - mse: 2949.2429\n",
      "Epoch 131/150\n",
      "72/72 - 0s - loss: 2954.4517 - mse: 2954.4517\n",
      "Epoch 132/150\n",
      "72/72 - 0s - loss: 2949.9138 - mse: 2949.9138\n",
      "Epoch 133/150\n",
      "72/72 - 0s - loss: 2942.1101 - mse: 2942.1101\n",
      "Epoch 134/150\n",
      "72/72 - 0s - loss: 2930.0415 - mse: 2930.0415\n",
      "Epoch 135/150\n",
      "72/72 - 0s - loss: 2943.1514 - mse: 2943.1514\n",
      "Epoch 136/150\n",
      "72/72 - 0s - loss: 2934.1729 - mse: 2934.1729\n",
      "Epoch 137/150\n",
      "72/72 - 0s - loss: 2928.3931 - mse: 2928.3931\n",
      "Epoch 138/150\n",
      "72/72 - 0s - loss: 2916.6135 - mse: 2916.6135\n",
      "Epoch 139/150\n",
      "72/72 - 0s - loss: 2922.2576 - mse: 2922.2576\n",
      "Epoch 140/150\n",
      "72/72 - 0s - loss: 2921.1914 - mse: 2921.1914\n",
      "Epoch 141/150\n",
      "72/72 - 0s - loss: 2916.9236 - mse: 2916.9236\n",
      "Epoch 142/150\n",
      "72/72 - 0s - loss: 2922.1587 - mse: 2922.1587\n",
      "Epoch 143/150\n",
      "72/72 - 0s - loss: 2900.3586 - mse: 2900.3586\n",
      "Epoch 144/150\n",
      "72/72 - 0s - loss: 2901.9307 - mse: 2901.9307\n",
      "Epoch 145/150\n",
      "72/72 - 0s - loss: 2896.4539 - mse: 2896.4539\n",
      "Epoch 146/150\n",
      "72/72 - 0s - loss: 2897.3372 - mse: 2897.3372\n",
      "Epoch 147/150\n",
      "72/72 - 0s - loss: 2892.3906 - mse: 2892.3906\n",
      "Epoch 148/150\n",
      "72/72 - 0s - loss: 2868.2024 - mse: 2868.2024\n",
      "Epoch 149/150\n",
      "72/72 - 0s - loss: 2887.3352 - mse: 2887.3352\n",
      "Epoch 150/150\n",
      "72/72 - 0s - loss: 2885.8484 - mse: 2885.8484\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 10358.7793 - mse: 10358.7793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10358.779296875, 10358.779296875]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=150, batch_size=4, verbose=2)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,441\n",
      "Trainable params: 1,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set prediction accuracy: 11.46 %\n",
      "test set prediction accuracy: 8.33 %\n"
     ]
    }
   ],
   "source": [
    "#평균 성능 테스트\n",
    "scores = 0\n",
    "mean=np.mean(Y, axis=0)\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= mean <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"train set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= mean <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"test set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### <오차범위 3>\n",
      "- train set prediction accuracy(+-3): 6.25 % <br>\n",
      "- test set prediction accuracy(+-3): 8.33 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 5>\n",
      "- train set prediction accuracy(+-5): 11.81 % <br>\n",
      "- test set prediction accuracy(+-5): 15.28 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 10>\n",
      "- train set prediction accuracy(+-10): 23.96 % <br>\n",
      "- test set prediction accuracy(+-10): 29.17 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 20>\n",
      "- train set prediction accuracy(+-20): 45.49 % <br>\n",
      "- test set prediction accuracy(+-20): 45.83 % <br>\n"
     ]
    }
   ],
   "source": [
    "######입력용#######\n",
    "\n",
    "#오차 범위 3 설정\n",
    "print('### <오차범위 3>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "print('### <오차범위 5>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "print('### <오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "print('### <오차범위 20>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다쓴거\n",
    "### <오차범위 3>\n",
    "- train_all set prediction accuracy(+-3): 88.89 % <br>\n",
    "- test_all set prediction accuracy(+-3): 31.94 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 5>\n",
    "- train_all set prediction accuracy(+-5): 96.53 % <br>\n",
    "- test_all set prediction accuracy(+-5): 55.56 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 10>\n",
    "- train_all set prediction accuracy(+-10): 100.00 % <br>\n",
    "- test_all set prediction accuracy(+-10): 83.33 % <br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다안쓴거\n",
    "### <오차범위 3>\n",
    "- train_some set prediction accuracy(+-3): 32.99 % <br>\n",
    "- test_some set prediction accuracy(+-3): 27.78 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 5>\n",
    "- train_some set prediction accuracy(+-5): 54.86 % <br>\n",
    "- test_some set prediction accuracy(+-5): 40.28 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 10>\n",
    "- train_some set prediction accuracy(+-10): 82.29 % <br>\n",
    "- test_some set prediction accuracy(+-10): 59.72 % <br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FONT 깨질때 폰트깨질때\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname = \"C:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font',family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sample_ID GROUP  COHORT SEX  AGE     Trait FitbitOX      Fitbit_ID  HTN  \\\n",
      "0         S0001   SMI       2   M   60  fitbit_O        O  sevrance00001  NaN   \n",
      "1         S0002   SMI       2   M   61  fitbit_O        O  sevrance00002  NaN   \n",
      "2         S0003   SMI       2   F   52  fitbit_O        O  sevrance00003  NaN   \n",
      "3         S0004   SMI       2   F   41  fitbit_O        O  sevrance00004  NaN   \n",
      "4         S0005   SMI       2   F   41  fitbit_O        O  sevrance00005  NaN   \n",
      "..          ...   ...     ...  ..  ...       ...      ...            ...  ...   \n",
      "383  MetS_S0280  MetS       1   F   24  fitbit_O        O   gnfmmets+139  NaN   \n",
      "384  MetS_S0281  MetS       1   F   44  fitbit_O        O   gnfmmets+140  NaN   \n",
      "385  MetS_S0282  MetS       1   F   37  fitbit_O        O   gnfmmets+141  1.0   \n",
      "386  MetS_S0283  MetS       1   M   51  fitbit_X        X              X  NaN   \n",
      "387  MetS_S0284  MetS       1   F   42  fitbit_X        X              X  NaN   \n",
      "\n",
      "      DM  ...  BDI_Q13_2 BDI_Q14_2  BDI_Q15_2  BDI_Q16_2 BDI_Q17_2 BDI_Q18_2  \\\n",
      "0    NaN  ...        1.0       1.0        1.0        2.0       1.0       1.0   \n",
      "1    1.0  ...        1.0       1.0        1.0        1.0       2.0       1.0   \n",
      "2    NaN  ...        1.0       1.0        1.0        1.0       1.0       1.0   \n",
      "3    NaN  ...        2.0       2.0        2.0        2.0       2.0       2.0   \n",
      "4    NaN  ...        2.0       1.0        2.0        2.0       2.0       1.0   \n",
      "..   ...  ...        ...       ...        ...        ...       ...       ...   \n",
      "383  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "384  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "385  1.0  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "386  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "387  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "\n",
      "     BDI_Q19_2  BDI_Q20_2  BDI_Q21_2  Diet_2  \n",
      "0          2.0        1.0        2.0     2.0  \n",
      "1          1.0        1.0        1.0     2.0  \n",
      "2          1.0        2.0        4.0     1.0  \n",
      "3          1.0        1.0        1.0     2.0  \n",
      "4          1.0        2.0        1.0     2.0  \n",
      "..         ...        ...        ...     ...  \n",
      "383        NaN        NaN        NaN     NaN  \n",
      "384        NaN        NaN        NaN     NaN  \n",
      "385        NaN        NaN        NaN     NaN  \n",
      "386        NaN        NaN        NaN     NaN  \n",
      "387        NaN        NaN        NaN     NaN  \n",
      "\n",
      "[388 rows x 3527 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('./최종 데이터 그래프그리기용.xlsx') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df=df[['Sample_ID','GROUP','COHORT','SEX','AGE','Insulin _1','FatPercentage _1','TG_1','BMI_1','AST_1','BUN_1','HDL_1','DBP_1','Waist_1','SBP_1','Fat_1_x','LDL_1',\n",
    "            'PSQI_TOTAL_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1',\n",
    "              'Insulin _2','FatPercentage_2','TG_2','BMI_2','AST_2','BUN_2','HDL_2','DBP_2','Waist_2','SBP_2','Fat_2_x','LDL_2',\n",
    "            'PSQI_TOTAL_2','PSQI_C1_2','PSQI_C2_2','PSQI_C3_2','PSQI_C4_2','PSQI_C5_2','PSQI_C6_2','PSQI_C7_2','PSQI_Q1_2','PSQI_Q2_2','PSQI_Q3_2','PSQI_Q4_2',\n",
    "            'PSQI_Q5a_2','PSQI_Q5b_2','PSQI_Q5c_2','PSQI_Q5d_2','PSQI_Q5e_2','PSQI_Q5f_2','PSQI_Q5g_2','PSQI_Q5h_2','PSQI_Q5i_2','PSQI_Q5j_2','PSQI_Q6_2','PSQI_Q7_2','PSQI_Q8_2','PSQI_Q9_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>FatPercentage _1</th>\n",
       "      <th>TG_1</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>AST_1</th>\n",
       "      <th>...</th>\n",
       "      <th>PSQI_Q5e_2</th>\n",
       "      <th>PSQI_Q5f_2</th>\n",
       "      <th>PSQI_Q5g_2</th>\n",
       "      <th>PSQI_Q5h_2</th>\n",
       "      <th>PSQI_Q5i_2</th>\n",
       "      <th>PSQI_Q5j_2</th>\n",
       "      <th>PSQI_Q6_2</th>\n",
       "      <th>PSQI_Q7_2</th>\n",
       "      <th>PSQI_Q8_2</th>\n",
       "      <th>PSQI_Q9_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>60</td>\n",
       "      <td>7.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>81</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>61</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.5</td>\n",
       "      <td>106</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>5.1</td>\n",
       "      <td>39.1</td>\n",
       "      <td>231</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>4.2</td>\n",
       "      <td>29.1</td>\n",
       "      <td>94</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>3.2</td>\n",
       "      <td>24.6</td>\n",
       "      <td>70</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>24</td>\n",
       "      <td>11.3</td>\n",
       "      <td>34.4</td>\n",
       "      <td>51</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>44</td>\n",
       "      <td>10.6</td>\n",
       "      <td>43.8</td>\n",
       "      <td>104</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>12.2</td>\n",
       "      <td>35.8</td>\n",
       "      <td>128</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>10.4</td>\n",
       "      <td>26.8</td>\n",
       "      <td>163</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>42</td>\n",
       "      <td>10.1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>90</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT SEX  AGE Insulin _1  FatPercentage _1  TG_1  \\\n",
       "0         S0001   SMI       2   M   60        7.7              15.0    81   \n",
       "1         S0002   SMI       2   M   61        5.4              29.5   106   \n",
       "2         S0003   SMI       2   F   52        5.1              39.1   231   \n",
       "3         S0004   SMI       2   F   41        4.2              29.1    94   \n",
       "4         S0005   SMI       2   F   41        3.2              24.6    70   \n",
       "..          ...   ...     ...  ..  ...        ...               ...   ...   \n",
       "383  MetS_S0280  MetS       1   F   24       11.3              34.4    51   \n",
       "384  MetS_S0281  MetS       1   F   44       10.6              43.8   104   \n",
       "385  MetS_S0282  MetS       1   F   37       12.2              35.8   128   \n",
       "386  MetS_S0283  MetS       1   M   51       10.4              26.8   163   \n",
       "387  MetS_S0284  MetS       1   F   42       10.1              32.6    90   \n",
       "\n",
       "         BMI_1  AST_1  ...  PSQI_Q5e_2  PSQI_Q5f_2  PSQI_Q5g_2  PSQI_Q5h_2  \\\n",
       "0    21.110190   21.0  ...         0.0         0.0         0.0         1.0   \n",
       "1    27.782064   29.0  ...         3.0         0.0         2.0         0.0   \n",
       "2    24.944742   16.0  ...         3.0         0.0         3.0         0.0   \n",
       "3    22.620489   16.0  ...         1.0         0.0         0.0         0.0   \n",
       "4    20.524157   26.0  ...         0.0         0.0         0.0         1.0   \n",
       "..         ...    ...  ...         ...         ...         ...         ...   \n",
       "383  34.803410   14.0  ...         NaN         NaN         NaN         NaN   \n",
       "384  30.903615   27.0  ...         NaN         NaN         NaN         NaN   \n",
       "385  28.676533   61.0  ...         NaN         NaN         NaN         NaN   \n",
       "386  24.549738   81.0  ...         NaN         NaN         NaN         NaN   \n",
       "387  24.605921   32.0  ...         NaN         NaN         NaN         NaN   \n",
       "\n",
       "     PSQI_Q5i_2  PSQI_Q5j_2  PSQI_Q6_2  PSQI_Q7_2  PSQI_Q8_2  PSQI_Q9_2  \n",
       "0           0.0         0.0        1.0        0.0        1.0        0.0  \n",
       "1           0.0         0.0        1.0        0.0        2.0        1.0  \n",
       "2           0.0         0.0        1.0        0.0        2.0        0.0  \n",
       "3           0.0         0.0        1.0        0.0        2.0        1.0  \n",
       "4           1.0         1.0        3.0        0.0        2.0        1.0  \n",
       "..          ...         ...        ...        ...        ...        ...  \n",
       "383         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "384         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "385         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "386         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "387         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "\n",
       "[388 rows x 81 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>FatPercentage _1</th>\n",
       "      <th>TG_1</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>AST_1</th>\n",
       "      <th>...</th>\n",
       "      <th>PSQI_Q5e_2</th>\n",
       "      <th>PSQI_Q5f_2</th>\n",
       "      <th>PSQI_Q5g_2</th>\n",
       "      <th>PSQI_Q5h_2</th>\n",
       "      <th>PSQI_Q5i_2</th>\n",
       "      <th>PSQI_Q5j_2</th>\n",
       "      <th>PSQI_Q6_2</th>\n",
       "      <th>PSQI_Q7_2</th>\n",
       "      <th>PSQI_Q8_2</th>\n",
       "      <th>PSQI_Q9_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>60</td>\n",
       "      <td>7.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>81</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>61</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.5</td>\n",
       "      <td>106</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>5.1</td>\n",
       "      <td>39.1</td>\n",
       "      <td>231</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>4.2</td>\n",
       "      <td>29.1</td>\n",
       "      <td>94</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>3.2</td>\n",
       "      <td>24.6</td>\n",
       "      <td>70</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>24</td>\n",
       "      <td>11.3</td>\n",
       "      <td>34.4</td>\n",
       "      <td>51</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>44</td>\n",
       "      <td>10.6</td>\n",
       "      <td>43.8</td>\n",
       "      <td>104</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>12.2</td>\n",
       "      <td>35.8</td>\n",
       "      <td>128</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>10.4</td>\n",
       "      <td>26.8</td>\n",
       "      <td>163</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>42</td>\n",
       "      <td>10.1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>90</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT SEX  AGE Insulin _1  FatPercentage _1  TG_1  \\\n",
       "0         S0001   SMI       2   M   60        7.7              15.0    81   \n",
       "1         S0002   SMI       2   M   61        5.4              29.5   106   \n",
       "2         S0003   SMI       2   F   52        5.1              39.1   231   \n",
       "3         S0004   SMI       2   F   41        4.2              29.1    94   \n",
       "4         S0005   SMI       2   F   41        3.2              24.6    70   \n",
       "..          ...   ...     ...  ..  ...        ...               ...   ...   \n",
       "383  MetS_S0280  MetS       1   F   24       11.3              34.4    51   \n",
       "384  MetS_S0281  MetS       1   F   44       10.6              43.8   104   \n",
       "385  MetS_S0282  MetS       1   F   37       12.2              35.8   128   \n",
       "386  MetS_S0283  MetS       1   M   51       10.4              26.8   163   \n",
       "387  MetS_S0284  MetS       1   F   42       10.1              32.6    90   \n",
       "\n",
       "         BMI_1  AST_1  ...  PSQI_Q5e_2  PSQI_Q5f_2  PSQI_Q5g_2  PSQI_Q5h_2  \\\n",
       "0    21.110190   21.0  ...         0.0         0.0         0.0         1.0   \n",
       "1    27.782064   29.0  ...         3.0         0.0         2.0         0.0   \n",
       "2    24.944742   16.0  ...         3.0         0.0         3.0         0.0   \n",
       "3    22.620489   16.0  ...         1.0         0.0         0.0         0.0   \n",
       "4    20.524157   26.0  ...         0.0         0.0         0.0         1.0   \n",
       "..         ...    ...  ...         ...         ...         ...         ...   \n",
       "383  34.803410   14.0  ...         NaN         NaN         NaN         NaN   \n",
       "384  30.903615   27.0  ...         NaN         NaN         NaN         NaN   \n",
       "385  28.676533   61.0  ...         NaN         NaN         NaN         NaN   \n",
       "386  24.549738   81.0  ...         NaN         NaN         NaN         NaN   \n",
       "387  24.605921   32.0  ...         NaN         NaN         NaN         NaN   \n",
       "\n",
       "     PSQI_Q5i_2  PSQI_Q5j_2  PSQI_Q6_2  PSQI_Q7_2  PSQI_Q8_2  PSQI_Q9_2  \n",
       "0           0.0         0.0        1.0        0.0        1.0        0.0  \n",
       "1           0.0         0.0        1.0        0.0        2.0        1.0  \n",
       "2           0.0         0.0        1.0        0.0        2.0        0.0  \n",
       "3           0.0         0.0        1.0        0.0        2.0        1.0  \n",
       "4           1.0         1.0        3.0        0.0        2.0        1.0  \n",
       "..          ...         ...        ...        ...        ...        ...  \n",
       "383         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "384         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "385         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "386         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "387         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "\n",
       "[317 rows x 81 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#보조 호르몬 요법을 받고 있는 Cohort 3 제거 Filter 적용\n",
    "psqi_df = psqi_df[(psqi_df['COHORT'] != 3)]\n",
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df=psqi_df.dropna()\n",
    "psqi_df.reset_index(drop=True, inplace=True)\n",
    "psqi_df.isnull().sum()\n",
    "psqi_df=psqi_df.drop([\"Sample_ID\", \"GROUP\", \"COHORT\"],axis=1)\n",
    "#1분, 매일다름, 정해진간이없음 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"SEX\"] = psqi_df[\"SEX\"].apply(lambda x: 1. if x=='M' else 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"Insulin _1\"] = psqi_df[\"Insulin _1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)\n",
    "psqi_df[\"Insulin _2\"] = psqi_df[\"Insulin _1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>FatPercentage _1</th>\n",
       "      <th>TG_1</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>AST_1</th>\n",
       "      <th>BUN_1</th>\n",
       "      <th>HDL_1</th>\n",
       "      <th>DBP_1</th>\n",
       "      <th>...</th>\n",
       "      <th>PSQI_Q5e_2</th>\n",
       "      <th>PSQI_Q5f_2</th>\n",
       "      <th>PSQI_Q5g_2</th>\n",
       "      <th>PSQI_Q5h_2</th>\n",
       "      <th>PSQI_Q5i_2</th>\n",
       "      <th>PSQI_Q5j_2</th>\n",
       "      <th>PSQI_Q6_2</th>\n",
       "      <th>PSQI_Q7_2</th>\n",
       "      <th>PSQI_Q8_2</th>\n",
       "      <th>PSQI_Q9_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.306818</td>\n",
       "      <td>38.107955</td>\n",
       "      <td>7.715909</td>\n",
       "      <td>29.548523</td>\n",
       "      <td>105.295455</td>\n",
       "      <td>23.787859</td>\n",
       "      <td>22.783295</td>\n",
       "      <td>13.456818</td>\n",
       "      <td>60.755682</td>\n",
       "      <td>75.210227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488636</td>\n",
       "      <td>0.119318</td>\n",
       "      <td>0.164773</td>\n",
       "      <td>0.278409</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.261364</td>\n",
       "      <td>1.056818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.443182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.462489</td>\n",
       "      <td>11.451001</td>\n",
       "      <td>4.133429</td>\n",
       "      <td>6.793497</td>\n",
       "      <td>90.584787</td>\n",
       "      <td>4.980203</td>\n",
       "      <td>9.643329</td>\n",
       "      <td>3.504358</td>\n",
       "      <td>14.626101</td>\n",
       "      <td>10.480246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925750</td>\n",
       "      <td>0.456661</td>\n",
       "      <td>0.535706</td>\n",
       "      <td>0.592129</td>\n",
       "      <td>0.842307</td>\n",
       "      <td>0.676027</td>\n",
       "      <td>0.542122</td>\n",
       "      <td>0.444300</td>\n",
       "      <td>0.819883</td>\n",
       "      <td>0.602053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>15.231576</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>4.975000</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>20.833309</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>11.275000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>67.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>29.300000</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>23.351473</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>9.505000</td>\n",
       "      <td>33.925000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>25.502662</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>15.025000</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>49.800000</td>\n",
       "      <td>936.000000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>38.900000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              SEX         AGE  Insulin _1  FatPercentage _1        TG_1  \\\n",
       "count  176.000000  176.000000  176.000000        176.000000  176.000000   \n",
       "mean     0.306818   38.107955    7.715909         29.548523  105.295455   \n",
       "std      0.462489   11.451001    4.133429          6.793497   90.584787   \n",
       "min      0.000000   20.000000    0.100000         13.100000   38.000000   \n",
       "25%      0.000000   29.000000    4.975000         24.400000   61.000000   \n",
       "50%      0.000000   35.000000    6.600000         29.300000   84.500000   \n",
       "75%      1.000000   46.000000    9.505000         33.925000  123.000000   \n",
       "max      1.000000   63.000000   24.700000         49.800000  936.000000   \n",
       "\n",
       "            BMI_1       AST_1       BUN_1       HDL_1       DBP_1  ...  \\\n",
       "count  176.000000  176.000000  176.000000  176.000000  176.000000  ...   \n",
       "mean    23.787859   22.783295   13.456818   60.755682   75.210227  ...   \n",
       "std      4.980203    9.643329    3.504358   14.626101   10.480246  ...   \n",
       "min     15.231576    0.860000    7.700000   28.000000   50.000000  ...   \n",
       "25%     20.833309   18.000000   11.275000   50.000000   67.750000  ...   \n",
       "50%     23.351473   21.000000   12.900000   58.000000   74.000000  ...   \n",
       "75%     25.502662   25.000000   15.025000   69.500000   82.000000  ...   \n",
       "max     67.500000   91.000000   38.900000  114.000000  123.000000  ...   \n",
       "\n",
       "       PSQI_Q5e_2  PSQI_Q5f_2  PSQI_Q5g_2  PSQI_Q5h_2  PSQI_Q5i_2  PSQI_Q5j_2  \\\n",
       "count  176.000000  176.000000  176.000000  176.000000  176.000000  176.000000   \n",
       "mean     0.488636    0.119318    0.164773    0.278409    0.397727    0.261364   \n",
       "std      0.925750    0.456661    0.535706    0.592129    0.842307    0.676027   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.250000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      3.000000    3.000000    3.000000    3.000000    3.000000    3.000000   \n",
       "\n",
       "        PSQI_Q6_2   PSQI_Q7_2   PSQI_Q8_2   PSQI_Q9_2  \n",
       "count  176.000000  176.000000  176.000000  176.000000  \n",
       "mean     1.056818    0.090909    0.454545    0.443182  \n",
       "std      0.542122    0.444300    0.819883    0.602053  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      1.000000    0.000000    0.000000    0.000000  \n",
       "50%      1.000000    0.000000    0.000000    0.000000  \n",
       "75%      1.000000    0.000000    1.000000    1.000000  \n",
       "max      3.000000    3.000000    3.000000    3.000000  \n",
       "\n",
       "[8 rows x 77 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    122\n",
       "1.0     54\n",
       "Name: SEX, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df[\"SEX\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#x 배열 생성 (x=임의+선별)\n",
    "#선별: 'AGE','HDL_1','DBP_1','Waist_1','SBP_1','Fat_1_x','Insulin _1','FatPercentage _1','LDL_1','AST_1','BUN_1'\n",
    "X1=psqi_df[['AGE','LDL_1','DBP_1','Waist_1','SBP_1','Fat_1_x','Insulin _1','FatPercentage _1','AST_1','BUN_1','BMI_1','TG_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','LDL_2','DBP_2','Waist_2','SBP_2','Fat_2_x','Insulin _2','FatPercentage_2','AST_2','BUN_2','BMI_2','TG_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (x=임의+선별+PSQI)\n",
    "X1=psqi_df[['AGE','LDL_1','DBP_1','Waist_1','Insulin _1','SBP_1','Fat_1_x','TG_1','FatPercentage _1','AST_1','BUN_1','BMI_1',\n",
    "            'PSQI_TOTAL_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','LDL_2','DBP_2','Waist_2','Insulin _2','SBP_2','Fat_2_x','TG_2','FatPercentage_2','AST_2','BUN_2','BMI_2',\n",
    "            'PSQI_TOTAL_2','PSQI_C1_2','PSQI_C2_2','PSQI_C3_2','PSQI_C4_2','PSQI_C5_2','PSQI_C6_2','PSQI_C7_2','PSQI_Q1_2','PSQI_Q2_2','PSQI_Q3_2','PSQI_Q4_2',\n",
    "            'PSQI_Q5a_2','PSQI_Q5b_2','PSQI_Q5c_2','PSQI_Q5d_2','PSQI_Q5e_2','PSQI_Q5f_2','PSQI_Q5g_2','PSQI_Q5h_2','PSQI_Q5i_2','PSQI_Q5j_2','PSQI_Q6_2','PSQI_Q7_2','PSQI_Q8_2','PSQI_Q9_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#x 배열 생성 (x=AGE, SEX, PSQI, BMI, Waist, Fat, FatPercentage)\n",
    "X1=psqi_df[['AGE','SEX','BMI_1','Waist_1','Fat_1_x','FatPercentage _1',\n",
    "           'PSQI_TOTAL_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','SEX','BMI_2','Waist_2','Fat_2_x','FatPercentage_2',\n",
    "           'PSQI_TOTAL_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (x=AGE, SEX, PSQI, BMI)\n",
    "X1=psqi_df[['AGE','SEX','BMI_1',\n",
    "           'PSQI_TOTAL_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','SEX','BMI_2',\n",
    "           'PSQI_TOTAL_2','PSQI_C1_2','PSQI_C2_2','PSQI_C3_2','PSQI_C4_2','PSQI_C5_2','PSQI_C6_2','PSQI_C7_2','PSQI_Q1_2','PSQI_Q2_2','PSQI_Q3_2','PSQI_Q4_2',\n",
    "            'PSQI_Q5a_2','PSQI_Q5b_2','PSQI_Q5c_2','PSQI_Q5d_2','PSQI_Q5e_2','PSQI_Q5f_2','PSQI_Q5g_2','PSQI_Q5h_2','PSQI_Q5i_2','PSQI_Q5j_2','PSQI_Q6_2','PSQI_Q7_2','PSQI_Q8_2','PSQI_Q9_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 352)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((352, 38), (352, 1))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((352, 38), (352, 1))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "71/71 [==============================] - 0s 629us/step - loss: 3667.3258 - mse: 3667.3258\n",
      "Epoch 2/150\n",
      "71/71 [==============================] - 0s 583us/step - loss: 2966.3647 - mse: 2966.3647\n",
      "Epoch 3/150\n",
      "71/71 [==============================] - 0s 602us/step - loss: 2176.0961 - mse: 2176.0961\n",
      "Epoch 4/150\n",
      "71/71 [==============================] - 0s 639us/step - loss: 933.4257 - mse: 933.4257\n",
      "Epoch 5/150\n",
      "71/71 [==============================] - 0s 691us/step - loss: 470.7218 - mse: 470.7218\n",
      "Epoch 6/150\n",
      "71/71 [==============================] - 0s 510us/step - loss: 330.7388 - mse: 330.7388\n",
      "Epoch 7/150\n",
      "71/71 [==============================] - 0s 640us/step - loss: 231.4170 - mse: 231.4170\n",
      "Epoch 8/150\n",
      "71/71 [==============================] - 0s 680us/step - loss: 246.3684 - mse: 246.3684\n",
      "Epoch 9/150\n",
      "71/71 [==============================] - 0s 726us/step - loss: 183.7924 - mse: 183.7924\n",
      "Epoch 10/150\n",
      "71/71 [==============================] - 0s 679us/step - loss: 152.1517 - mse: 152.1517\n",
      "Epoch 11/150\n",
      "71/71 [==============================] - 0s 739us/step - loss: 159.8067 - mse: 159.8067\n",
      "Epoch 12/150\n",
      "71/71 [==============================] - 0s 673us/step - loss: 137.6711 - mse: 137.6711\n",
      "Epoch 13/150\n",
      "71/71 [==============================] - 0s 648us/step - loss: 140.4423 - mse: 140.4423\n",
      "Epoch 14/150\n",
      "71/71 [==============================] - 0s 665us/step - loss: 135.2349 - mse: 135.2349\n",
      "Epoch 15/150\n",
      "71/71 [==============================] - 0s 684us/step - loss: 106.2489 - mse: 106.2489\n",
      "Epoch 16/150\n",
      "71/71 [==============================] - 0s 804us/step - loss: 109.6990 - mse: 109.6990\n",
      "Epoch 17/150\n",
      "71/71 [==============================] - 0s 740us/step - loss: 111.1900 - mse: 111.1900\n",
      "Epoch 18/150\n",
      "71/71 [==============================] - 0s 739us/step - loss: 103.8617 - mse: 103.8617\n",
      "Epoch 19/150\n",
      "71/71 [==============================] - 0s 702us/step - loss: 106.0949 - mse: 106.0949\n",
      "Epoch 20/150\n",
      "71/71 [==============================] - 0s 735us/step - loss: 109.7518 - mse: 109.7518\n",
      "Epoch 21/150\n",
      "71/71 [==============================] - 0s 702us/step - loss: 85.9423 - mse: 85.9423\n",
      "Epoch 22/150\n",
      "71/71 [==============================] - 0s 697us/step - loss: 84.6990 - mse: 84.6990\n",
      "Epoch 23/150\n",
      "71/71 [==============================] - 0s 697us/step - loss: 89.8291 - mse: 89.8291\n",
      "Epoch 24/150\n",
      "71/71 [==============================] - 0s 683us/step - loss: 85.7267 - mse: 85.7267\n",
      "Epoch 25/150\n",
      "71/71 [==============================] - 0s 592us/step - loss: 87.4364 - mse: 87.4364\n",
      "Epoch 26/150\n",
      "71/71 [==============================] - 0s 658us/step - loss: 64.8416 - mse: 64.8416\n",
      "Epoch 27/150\n",
      "71/71 [==============================] - 0s 675us/step - loss: 69.6077 - mse: 69.6077\n",
      "Epoch 28/150\n",
      "71/71 [==============================] - 0s 671us/step - loss: 65.8084 - mse: 65.8084\n",
      "Epoch 29/150\n",
      "71/71 [==============================] - 0s 798us/step - loss: 80.8385 - mse: 80.8385\n",
      "Epoch 30/150\n",
      "71/71 [==============================] - 0s 592us/step - loss: 77.6426 - mse: 77.6426\n",
      "Epoch 31/150\n",
      "71/71 [==============================] - 0s 711us/step - loss: 68.8203 - mse: 68.8203\n",
      "Epoch 32/150\n",
      "71/71 [==============================] - 0s 632us/step - loss: 76.1804 - mse: 76.1804\n",
      "Epoch 33/150\n",
      "71/71 [==============================] - 0s 651us/step - loss: 78.3295 - mse: 78.3295\n",
      "Epoch 34/150\n",
      "71/71 [==============================] - 0s 688us/step - loss: 59.4443 - mse: 59.4443\n",
      "Epoch 35/150\n",
      "71/71 [==============================] - 0s 680us/step - loss: 64.7958 - mse: 64.7958\n",
      "Epoch 36/150\n",
      "71/71 [==============================] - 0s 661us/step - loss: 54.6170 - mse: 54.6170\n",
      "Epoch 37/150\n",
      "71/71 [==============================] - 0s 686us/step - loss: 61.1168 - mse: 61.1168\n",
      "Epoch 38/150\n",
      "71/71 [==============================] - 0s 749us/step - loss: 65.0202 - mse: 65.0202\n",
      "Epoch 39/150\n",
      "71/71 [==============================] - 0s 687us/step - loss: 52.2767 - mse: 52.2767\n",
      "Epoch 40/150\n",
      "71/71 [==============================] - 0s 700us/step - loss: 61.7973 - mse: 61.7973\n",
      "Epoch 41/150\n",
      "71/71 [==============================] - 0s 710us/step - loss: 43.3077 - mse: 43.3077\n",
      "Epoch 42/150\n",
      "71/71 [==============================] - 0s 711us/step - loss: 54.9396 - mse: 54.9396\n",
      "Epoch 43/150\n",
      "71/71 [==============================] - 0s 672us/step - loss: 54.4628 - mse: 54.4628\n",
      "Epoch 44/150\n",
      "71/71 [==============================] - 0s 669us/step - loss: 51.3653 - mse: 51.3653\n",
      "Epoch 45/150\n",
      "71/71 [==============================] - 0s 682us/step - loss: 57.9263 - mse: 57.9263\n",
      "Epoch 46/150\n",
      "71/71 [==============================] - 0s 678us/step - loss: 49.3541 - mse: 49.3541\n",
      "Epoch 47/150\n",
      "71/71 [==============================] - 0s 676us/step - loss: 56.3731 - mse: 56.3731\n",
      "Epoch 48/150\n",
      "71/71 [==============================] - 0s 694us/step - loss: 48.1279 - mse: 48.1279\n",
      "Epoch 49/150\n",
      "71/71 [==============================] - 0s 649us/step - loss: 49.5565 - mse: 49.5565\n",
      "Epoch 50/150\n",
      "71/71 [==============================] - 0s 683us/step - loss: 50.5465 - mse: 50.5465\n",
      "Epoch 51/150\n",
      "71/71 [==============================] - 0s 679us/step - loss: 44.5970 - mse: 44.5970\n",
      "Epoch 52/150\n",
      "71/71 [==============================] - 0s 708us/step - loss: 41.0688 - mse: 41.0688\n",
      "Epoch 53/150\n",
      "71/71 [==============================] - 0s 779us/step - loss: 49.9997 - mse: 49.9997\n",
      "Epoch 54/150\n",
      "71/71 [==============================] - 0s 621us/step - loss: 48.0398 - mse: 48.0398\n",
      "Epoch 55/150\n",
      "71/71 [==============================] - 0s 650us/step - loss: 51.8277 - mse: 51.8277\n",
      "Epoch 56/150\n",
      "71/71 [==============================] - 0s 668us/step - loss: 40.9045 - mse: 40.9045\n",
      "Epoch 57/150\n",
      "71/71 [==============================] - 0s 731us/step - loss: 38.8705 - mse: 38.8705\n",
      "Epoch 58/150\n",
      "71/71 [==============================] - 0s 703us/step - loss: 39.7492 - mse: 39.7492\n",
      "Epoch 59/150\n",
      "71/71 [==============================] - 0s 691us/step - loss: 34.4219 - mse: 34.4219\n",
      "Epoch 60/150\n",
      "71/71 [==============================] - 0s 661us/step - loss: 33.6888 - mse: 33.6888\n",
      "Epoch 61/150\n",
      "71/71 [==============================] - 0s 664us/step - loss: 35.7576 - mse: 35.7576\n",
      "Epoch 62/150\n",
      "71/71 [==============================] - 0s 683us/step - loss: 35.1555 - mse: 35.1555\n",
      "Epoch 63/150\n",
      "71/71 [==============================] - 0s 704us/step - loss: 36.7799 - mse: 36.7799\n",
      "Epoch 64/150\n",
      "71/71 [==============================] - 0s 681us/step - loss: 34.1954 - mse: 34.1954\n",
      "Epoch 65/150\n",
      "71/71 [==============================] - 0s 689us/step - loss: 32.2384 - mse: 32.2384\n",
      "Epoch 66/150\n",
      "71/71 [==============================] - 0s 661us/step - loss: 41.0495 - mse: 41.0495\n",
      "Epoch 67/150\n",
      "71/71 [==============================] - 0s 667us/step - loss: 43.6469 - mse: 43.6469\n",
      "Epoch 68/150\n",
      "71/71 [==============================] - 0s 550us/step - loss: 35.1606 - mse: 35.1606\n",
      "Epoch 69/150\n",
      "71/71 [==============================] - 0s 603us/step - loss: 27.0814 - mse: 27.0814\n",
      "Epoch 70/150\n",
      "71/71 [==============================] - 0s 659us/step - loss: 31.6710 - mse: 31.6710\n",
      "Epoch 71/150\n",
      "71/71 [==============================] - 0s 627us/step - loss: 31.8984 - mse: 31.8984\n",
      "Epoch 72/150\n",
      "71/71 [==============================] - 0s 666us/step - loss: 28.8793 - mse: 28.8793\n",
      "Epoch 73/150\n",
      "71/71 [==============================] - 0s 681us/step - loss: 28.4852 - mse: 28.4852\n",
      "Epoch 74/150\n",
      "71/71 [==============================] - 0s 680us/step - loss: 26.1849 - mse: 26.1849\n",
      "Epoch 75/150\n",
      "71/71 [==============================] - 0s 585us/step - loss: 24.6280 - mse: 24.6280\n",
      "Epoch 76/150\n",
      "71/71 [==============================] - 0s 692us/step - loss: 28.5259 - mse: 28.5259\n",
      "Epoch 77/150\n",
      "71/71 [==============================] - 0s 650us/step - loss: 25.2215 - mse: 25.2215\n",
      "Epoch 78/150\n",
      "71/71 [==============================] - 0s 640us/step - loss: 24.8569 - mse: 24.8569\n",
      "Epoch 79/150\n",
      "71/71 [==============================] - 0s 634us/step - loss: 27.0510 - mse: 27.0510\n",
      "Epoch 80/150\n",
      "71/71 [==============================] - 0s 670us/step - loss: 22.7650 - mse: 22.7650\n",
      "Epoch 81/150\n",
      "71/71 [==============================] - 0s 685us/step - loss: 22.7824 - mse: 22.7824\n",
      "Epoch 82/150\n",
      "71/71 [==============================] - 0s 683us/step - loss: 27.3935 - mse: 27.3935\n",
      "Epoch 83/150\n",
      "71/71 [==============================] - 0s 650us/step - loss: 18.3144 - mse: 18.3144\n",
      "Epoch 84/150\n",
      "71/71 [==============================] - 0s 648us/step - loss: 26.1540 - mse: 26.1540\n",
      "Epoch 85/150\n",
      "71/71 [==============================] - 0s 606us/step - loss: 21.4754 - mse: 21.4754\n",
      "Epoch 86/150\n",
      "71/71 [==============================] - 0s 644us/step - loss: 25.7886 - mse: 25.7886\n",
      "Epoch 87/150\n",
      "71/71 [==============================] - 0s 626us/step - loss: 20.5014 - mse: 20.5014\n",
      "Epoch 88/150\n",
      "71/71 [==============================] - 0s 667us/step - loss: 18.9732 - mse: 18.9732\n",
      "Epoch 89/150\n",
      "71/71 [==============================] - 0s 650us/step - loss: 20.5829 - mse: 20.5829\n",
      "Epoch 90/150\n",
      "71/71 [==============================] - 0s 795us/step - loss: 21.4540 - mse: 21.4540\n",
      "Epoch 91/150\n",
      "71/71 [==============================] - 0s 784us/step - loss: 22.7615 - mse: 22.7615\n",
      "Epoch 92/150\n",
      "71/71 [==============================] - 0s 696us/step - loss: 17.6091 - mse: 17.6091\n",
      "Epoch 93/150\n",
      "71/71 [==============================] - 0s 703us/step - loss: 19.8083 - mse: 19.8083\n",
      "Epoch 94/150\n",
      "71/71 [==============================] - 0s 696us/step - loss: 15.4641 - mse: 15.4641\n",
      "Epoch 95/150\n",
      "71/71 [==============================] - 0s 766us/step - loss: 16.5041 - mse: 16.5041\n",
      "Epoch 96/150\n",
      "71/71 [==============================] - 0s 668us/step - loss: 18.1860 - mse: 18.1860\n",
      "Epoch 97/150\n",
      "71/71 [==============================] - 0s 676us/step - loss: 14.8800 - mse: 14.8800\n",
      "Epoch 98/150\n",
      "71/71 [==============================] - 0s 794us/step - loss: 14.5195 - mse: 14.5195\n",
      "Epoch 99/150\n",
      "71/71 [==============================] - 0s 707us/step - loss: 13.7150 - mse: 13.7150\n",
      "Epoch 100/150\n",
      "71/71 [==============================] - 0s 729us/step - loss: 16.8335 - mse: 16.8335\n",
      "Epoch 101/150\n",
      "71/71 [==============================] - 0s 633us/step - loss: 12.1298 - mse: 12.1298\n",
      "Epoch 102/150\n",
      "71/71 [==============================] - 0s 714us/step - loss: 10.6610 - mse: 10.6610\n",
      "Epoch 103/150\n",
      "71/71 [==============================] - 0s 834us/step - loss: 17.9556 - mse: 17.9556\n",
      "Epoch 104/150\n",
      "71/71 [==============================] - 0s 725us/step - loss: 13.0584 - mse: 13.0584\n",
      "Epoch 105/150\n",
      "71/71 [==============================] - 0s 708us/step - loss: 12.7513 - mse: 12.7513\n",
      "Epoch 106/150\n",
      "71/71 [==============================] - 0s 633us/step - loss: 14.8989 - mse: 14.8989\n",
      "Epoch 107/150\n",
      "71/71 [==============================] - 0s 665us/step - loss: 17.1353 - mse: 17.1353\n",
      "Epoch 108/150\n",
      "71/71 [==============================] - 0s 666us/step - loss: 11.9850 - mse: 11.9850\n",
      "Epoch 109/150\n",
      "71/71 [==============================] - 0s 692us/step - loss: 8.8044 - mse: 8.8044\n",
      "Epoch 110/150\n",
      "71/71 [==============================] - 0s 711us/step - loss: 10.3632 - mse: 10.3632\n",
      "Epoch 111/150\n",
      "71/71 [==============================] - 0s 675us/step - loss: 9.8113 - mse: 9.8113\n",
      "Epoch 112/150\n",
      "71/71 [==============================] - 0s 704us/step - loss: 10.9616 - mse: 10.9616\n",
      "Epoch 113/150\n",
      "71/71 [==============================] - 0s 647us/step - loss: 10.3262 - mse: 10.3262\n",
      "Epoch 114/150\n",
      "71/71 [==============================] - 0s 630us/step - loss: 12.6506 - mse: 12.6506\n",
      "Epoch 115/150\n",
      "71/71 [==============================] - 0s 544us/step - loss: 12.4372 - mse: 12.4372\n",
      "Epoch 116/150\n",
      "71/71 [==============================] - 0s 670us/step - loss: 9.5837 - mse: 9.5837\n",
      "Epoch 117/150\n",
      "71/71 [==============================] - 0s 639us/step - loss: 9.4861 - mse: 9.4861\n",
      "Epoch 118/150\n",
      "71/71 [==============================] - 0s 624us/step - loss: 10.0213 - mse: 10.0213\n",
      "Epoch 119/150\n",
      "71/71 [==============================] - 0s 581us/step - loss: 7.6302 - mse: 7.6302\n",
      "Epoch 120/150\n",
      "71/71 [==============================] - 0s 621us/step - loss: 8.3120 - mse: 8.3120\n",
      "Epoch 121/150\n",
      "71/71 [==============================] - 0s 759us/step - loss: 6.4488 - mse: 6.4488\n",
      "Epoch 122/150\n",
      "71/71 [==============================] - 0s 644us/step - loss: 8.4492 - mse: 8.4492\n",
      "Epoch 123/150\n",
      "71/71 [==============================] - 0s 622us/step - loss: 8.0873 - mse: 8.0873\n",
      "Epoch 124/150\n",
      "71/71 [==============================] - 0s 649us/step - loss: 6.4881 - mse: 6.4881\n",
      "Epoch 125/150\n",
      "71/71 [==============================] - 0s 726us/step - loss: 6.3871 - mse: 6.3871\n",
      "Epoch 126/150\n",
      "71/71 [==============================] - 0s 801us/step - loss: 5.0559 - mse: 5.0559\n",
      "Epoch 127/150\n",
      "71/71 [==============================] - 0s 756us/step - loss: 5.7423 - mse: 5.7423\n",
      "Epoch 128/150\n",
      "71/71 [==============================] - 0s 803us/step - loss: 5.1574 - mse: 5.1574\n",
      "Epoch 129/150\n",
      "71/71 [==============================] - 0s 761us/step - loss: 6.6559 - mse: 6.6559\n",
      "Epoch 130/150\n",
      "71/71 [==============================] - 0s 685us/step - loss: 6.1934 - mse: 6.1934\n",
      "Epoch 131/150\n",
      "71/71 [==============================] - 0s 670us/step - loss: 5.5308 - mse: 5.5308\n",
      "Epoch 132/150\n",
      "71/71 [==============================] - 0s 734us/step - loss: 5.3583 - mse: 5.3583\n",
      "Epoch 133/150\n",
      "71/71 [==============================] - 0s 678us/step - loss: 5.6407 - mse: 5.6407\n",
      "Epoch 134/150\n",
      "71/71 [==============================] - 0s 698us/step - loss: 4.5033 - mse: 4.5033\n",
      "Epoch 135/150\n",
      "71/71 [==============================] - 0s 744us/step - loss: 4.1372 - mse: 4.1372\n",
      "Epoch 136/150\n",
      "71/71 [==============================] - 0s 746us/step - loss: 4.3718 - mse: 4.3718\n",
      "Epoch 137/150\n",
      "71/71 [==============================] - 0s 768us/step - loss: 5.4548 - mse: 5.4548\n",
      "Epoch 138/150\n",
      "71/71 [==============================] - 0s 778us/step - loss: 4.3375 - mse: 4.3375\n",
      "Epoch 139/150\n",
      "71/71 [==============================] - 0s 785us/step - loss: 4.1283 - mse: 4.1283\n",
      "Epoch 140/150\n",
      "71/71 [==============================] - 0s 777us/step - loss: 4.0038 - mse: 4.0038\n",
      "Epoch 141/150\n",
      "71/71 [==============================] - 0s 694us/step - loss: 4.2793 - mse: 4.2793\n",
      "Epoch 142/150\n",
      "71/71 [==============================] - 0s 668us/step - loss: 4.2448 - mse: 4.2448\n",
      "Epoch 143/150\n",
      "71/71 [==============================] - 0s 674us/step - loss: 3.7018 - mse: 3.7018\n",
      "Epoch 144/150\n",
      "71/71 [==============================] - 0s 667us/step - loss: 2.9514 - mse: 2.9514\n",
      "Epoch 145/150\n",
      "71/71 [==============================] - 0s 662us/step - loss: 3.3124 - mse: 3.3124\n",
      "Epoch 146/150\n",
      "71/71 [==============================] - 0s 727us/step - loss: 2.6950 - mse: 2.6950\n",
      "Epoch 147/150\n",
      "71/71 [==============================] - 0s 757us/step - loss: 3.1538 - mse: 3.1538\n",
      "Epoch 148/150\n",
      "71/71 [==============================] - 0s 780us/step - loss: 3.6878 - mse: 3.6878\n",
      "Epoch 149/150\n",
      "71/71 [==============================] - 0s 778us/step - loss: 3.2935 - mse: 3.2935\n",
      "Epoch 150/150\n",
      "71/71 [==============================] - 0s 768us/step - loss: 2.5455 - mse: 2.5455\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 208.6303 - mse: 208.6303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[208.63034057617188, 208.63034057617188]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=150, batch_size=4)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                1248      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,337\n",
      "Trainable params: 2,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77.] [78.56688]\n",
      "[80.] [78.14603]\n",
      "[58.] [58.229595]\n",
      "[46.] [44.570652]\n",
      "[47.] [47.902126]\n",
      "[49.] [50.183075]\n",
      "[49.] [50.622204]\n",
      "[72.] [73.208694]\n",
      "[66.] [66.43617]\n",
      "[56.] [56.50264]\n",
      "[65.] [61.98627]\n",
      "[70.] [70.55114]\n",
      "[99.] [93.55167]\n",
      "[83.] [79.38255]\n",
      "[49.] [48.329628]\n",
      "[116.] [114.42819]\n",
      "[53.] [52.418423]\n",
      "[60.] [60.356556]\n",
      "[53.] [51.929844]\n",
      "[68.] [67.1873]\n",
      "[50.] [49.211075]\n",
      "[50.] [49.924484]\n",
      "[48.] [48.300552]\n",
      "[46.] [44.472546]\n",
      "[47.] [47.51921]\n",
      "[78.] [76.49332]\n",
      "[54.] [55.039375]\n",
      "[91.] [88.36985]\n",
      "[49.] [50.079517]\n",
      "[50.] [51.442863]\n",
      "[50.] [49.370083]\n",
      "[46.] [46.907352]\n",
      "[49.] [47.38512]\n",
      "[50.] [49.918854]\n",
      "[61.] [61.742176]\n",
      "[80.] [77.10206]\n",
      "[45.] [44.58429]\n",
      "[42.] [42.41776]\n",
      "[69.] [67.92593]\n",
      "[82.] [79.561356]\n",
      "[44.] [43.157654]\n",
      "[80.] [78.29039]\n",
      "[49.] [48.495686]\n",
      "[79.] [77.742035]\n",
      "[48.] [47.730797]\n",
      "[66.] [65.40649]\n",
      "[65.] [63.119053]\n",
      "[53.] [53.027847]\n",
      "[54.] [53.195213]\n",
      "[57.] [57.46104]\n",
      "[50.] [48.997723]\n",
      "[50.] [51.32533]\n",
      "[48.] [48.414955]\n",
      "[68.] [68.26135]\n",
      "[58.] [57.980183]\n",
      "[69.] [66.57271]\n",
      "[50.] [48.7971]\n",
      "[64.] [64.66159]\n",
      "[75.] [70.2653]\n",
      "[72.] [70.37]\n",
      "[45.] [45.96278]\n",
      "[74.] [74.94396]\n",
      "[74.] [71.77838]\n",
      "[66.] [66.64021]\n",
      "[51.] [52.65247]\n",
      "[57.] [56.272602]\n",
      "[42.] [42.183846]\n",
      "[51.] [51.142735]\n",
      "[57.] [57.51391]\n",
      "[99.] [97.26392]\n",
      "[72.] [71.10019]\n",
      "[75.] [67.79348]\n",
      "[62.] [62.452747]\n",
      "[29.] [29.24489]\n",
      "[52.] [51.887566]\n",
      "[60.] [58.639072]\n",
      "[63.] [66.62221]\n",
      "[71.] [71.65549]\n",
      "[55.] [55.00476]\n",
      "[47.] [46.053844]\n",
      "[88.] [85.72182]\n",
      "[88.] [84.04906]\n",
      "[55.] [54.26788]\n",
      "[57.] [57.143726]\n",
      "[72.] [71.226234]\n",
      "[52.] [50.938633]\n",
      "[52.] [53.11276]\n",
      "[86.] [84.80469]\n",
      "[37.] [36.789303]\n",
      "[47.] [45.31218]\n",
      "[62.] [61.774723]\n",
      "[98.] [95.77051]\n",
      "[45.] [45.619766]\n",
      "[66.] [65.45628]\n",
      "[56.] [55.59799]\n",
      "[50.] [50.27712]\n",
      "[81.] [80.28857]\n",
      "[58.] [58.563297]\n",
      "[42.] [41.03474]\n",
      "[52.] [49.84511]\n",
      "[58.] [58.919937]\n",
      "[58.] [58.462627]\n",
      "[58.] [57.34644]\n",
      "[60.] [60.689808]\n",
      "[68.] [66.777596]\n",
      "[66.] [67.331215]\n",
      "[61.] [60.54955]\n",
      "[83.] [80.946045]\n",
      "[57.] [57.861134]\n",
      "[52.] [51.13422]\n",
      "[52.] [51.198746]\n",
      "[64.] [64.3347]\n",
      "[39.] [38.052456]\n",
      "[56.] [57.09389]\n",
      "[62.] [61.9536]\n",
      "[86.] [85.48035]\n",
      "[38.] [39.2861]\n",
      "[51.] [48.337948]\n",
      "[33.] [33.479042]\n",
      "[75.] [72.32765]\n",
      "[43.] [44.892124]\n",
      "[50.] [49.12878]\n",
      "[67.] [66.534805]\n",
      "[58.] [56.880444]\n",
      "[40.] [39.584488]\n",
      "[46.] [46.512096]\n",
      "[79.] [76.96748]\n",
      "[57.] [57.595734]\n",
      "[85.] [84.69005]\n",
      "[51.] [50.946465]\n",
      "[114.] [115.82341]\n",
      "[55.] [54.1813]\n",
      "[58.] [57.54986]\n",
      "[51.] [50.59749]\n",
      "[55.] [54.45789]\n",
      "[38.] [38.22958]\n",
      "[74.] [74.78655]\n",
      "[67.] [66.9673]\n",
      "[42.] [43.05898]\n",
      "[44.] [43.51778]\n",
      "[48.] [48.008717]\n",
      "[40.] [39.86221]\n",
      "[98.] [90.45369]\n",
      "[51.] [51.35192]\n",
      "[58.] [59.12459]\n",
      "[45.] [46.456264]\n",
      "[60.] [60.745335]\n",
      "[61.] [61.068966]\n",
      "[48.] [45.860806]\n",
      "[72.] [77.08461]\n",
      "[63.] [62.18085]\n",
      "[79.] [78.84096]\n",
      "[40.] [41.028545]\n",
      "[52.] [51.35851]\n",
      "[51.] [51.300438]\n",
      "[49.] [48.47725]\n",
      "[66.] [64.71915]\n",
      "[36.] [37.097645]\n",
      "[78.] [77.885635]\n",
      "[62.] [61.785107]\n",
      "[31.] [32.07022]\n",
      "[49.] [48.463352]\n",
      "[71.] [70.46843]\n",
      "[72.] [72.13263]\n",
      "[74.] [73.31479]\n",
      "[63.] [63.207928]\n",
      "[57.] [54.966335]\n",
      "[49.] [47.9958]\n",
      "[52.] [50.843586]\n",
      "[50.] [50.043724]\n",
      "[64.] [61.54046]\n",
      "[74.] [73.92388]\n",
      "[52.] [51.655453]\n",
      "[58.] [54.137424]\n",
      "[48.] [48.230644]\n",
      "[48.] [47.327675]\n",
      "[60.] [59.124508]\n",
      "[86.] [84.96364]\n",
      "[57.] [55.6695]\n",
      "[48.] [45.779278]\n",
      "[75.] [75.0482]\n",
      "[67.] [66.97819]\n",
      "[57.] [57.08823]\n",
      "[52.] [50.0023]\n",
      "[76.] [74.971855]\n",
      "[45.] [45.30612]\n",
      "[41.] [41.24754]\n",
      "[53.] [52.480156]\n",
      "[41.] [43.064396]\n",
      "[92.] [91.24652]\n",
      "[88.] [86.74077]\n",
      "[64.] [64.12328]\n",
      "[58.] [57.933357]\n",
      "[36.] [37.161705]\n",
      "[69.] [67.95596]\n",
      "[58.] [59.17059]\n",
      "[51.] [51.324726]\n",
      "[69.] [68.00296]\n",
      "[61.] [59.774166]\n",
      "[42.] [42.356533]\n",
      "[42.] [41.64185]\n",
      "[44.] [44.575314]\n",
      "[69.] [68.5004]\n",
      "[44.] [44.91152]\n",
      "[49.] [49.89082]\n",
      "[63.] [61.969536]\n",
      "[50.] [50.386295]\n",
      "[44.] [43.589573]\n",
      "[81.] [85.250854]\n",
      "[72.] [69.456604]\n",
      "[52.] [52.144436]\n",
      "[77.] [76.1601]\n",
      "[71.] [67.436]\n",
      "[53.] [54.674923]\n",
      "[57.] [56.786198]\n",
      "[50.] [50.19237]\n",
      "[68.] [66.60205]\n",
      "[79.] [78.88139]\n",
      "[66.] [66.14282]\n",
      "[49.] [49.48302]\n",
      "[58.] [57.993565]\n",
      "[62.] [61.542248]\n",
      "[48.] [49.185234]\n",
      "[57.] [56.63916]\n",
      "[52.] [50.741753]\n",
      "[80.] [79.11476]\n",
      "[55.] [53.700943]\n",
      "[52.] [51.21654]\n",
      "[58.] [57.428005]\n",
      "[78.] [77.05614]\n",
      "[51.] [51.48375]\n",
      "[63.] [63.297344]\n",
      "[73.] [73.08557]\n",
      "[78.] [75.87776]\n",
      "[74.] [73.315125]\n",
      "[49.] [50.027782]\n",
      "[51.] [51.679295]\n",
      "[46.] [45.764698]\n",
      "[52.] [51.22363]\n",
      "[84.] [82.63145]\n",
      "[47.] [48.96946]\n",
      "[67.] [66.65089]\n",
      "[42.] [41.82342]\n",
      "[72.] [71.76501]\n",
      "[64.] [61.93272]\n",
      "[55.] [54.58373]\n",
      "[46.] [46.726795]\n",
      "[75.] [73.172714]\n",
      "[59.] [60.6212]\n",
      "[39.] [39.02831]\n",
      "[72.] [71.74865]\n",
      "[49.] [49.169735]\n",
      "[68.] [68.75545]\n",
      "[37.] [38.40365]\n",
      "[49.] [49.4862]\n",
      "[59.] [58.453434]\n",
      "[62.] [61.901665]\n",
      "[47.] [45.908115]\n",
      "[58.] [56.607864]\n",
      "[62.] [61.528683]\n",
      "[84.] [79.269775]\n",
      "[44.] [43.877605]\n",
      "[59.] [58.532654]\n",
      "[54.] [54.143]\n",
      "[43.] [44.04841]\n",
      "[57.] [56.29437]\n",
      "[76.] [76.03769]\n",
      "[46.] [46.8732]\n",
      "[56.] [55.32404]\n",
      "[60.] [59.59738]\n",
      "[69.] [69.284615]\n",
      "[46.] [46.693836]\n",
      "[64.] [63.765766]\n",
      "[50.] [49.9493]\n",
      "[105.] [103.896194]\n",
      "[52.] [51.70706]\n",
      "[86.] [85.5542]\n",
      "[50.] [50.272106]\n",
      "[66.] [67.73245]\n",
      "[69.] [67.49356]\n",
      "[54.] [53.9575]\n"
     ]
    }
   ],
   "source": [
    "for t,p in zip(y_train,y_train_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55.] [57.65208]\n",
      "[54.] [66.35748]\n",
      "[71.] [72.815575]\n",
      "[61.] [49.72164]\n",
      "[60.] [73.284454]\n",
      "[55.] [73.66977]\n",
      "[49.] [75.14836]\n",
      "[62.] [60.998425]\n",
      "[67.] [56.71199]\n",
      "[63.] [85.38676]\n",
      "[68.] [60.175327]\n",
      "[70.] [47.831783]\n",
      "[62.] [81.339096]\n",
      "[58.] [64.528946]\n",
      "[39.] [52.316998]\n",
      "[67.] [48.06445]\n",
      "[48.] [40.13069]\n",
      "[70.] [63.943676]\n",
      "[90.] [51.107388]\n",
      "[57.] [72.74913]\n",
      "[60.] [73.59472]\n",
      "[75.] [60.818844]\n",
      "[86.] [68.79204]\n",
      "[56.] [85.98572]\n",
      "[64.] [74.997665]\n",
      "[46.] [63.043194]\n",
      "[46.] [48.12926]\n",
      "[44.] [47.124348]\n",
      "[46.] [52.73319]\n",
      "[63.] [57.661472]\n",
      "[47.] [55.27139]\n",
      "[64.] [67.51537]\n",
      "[53.] [57.465767]\n",
      "[77.] [90.049065]\n",
      "[44.] [38.824123]\n",
      "[76.] [77.2483]\n",
      "[78.] [74.68805]\n",
      "[78.] [80.687614]\n",
      "[69.] [66.26287]\n",
      "[55.] [72.68025]\n",
      "[67.] [55.729664]\n",
      "[67.] [81.69159]\n",
      "[59.] [62.70116]\n",
      "[83.] [63.767345]\n",
      "[51.] [46.665356]\n",
      "[51.] [67.31863]\n",
      "[75.] [79.00946]\n",
      "[69.] [71.88942]\n",
      "[28.] [33.71718]\n",
      "[58.] [66.25381]\n",
      "[75.] [49.091484]\n",
      "[64.] [72.153175]\n",
      "[96.] [68.28693]\n",
      "[52.] [70.31183]\n",
      "[35.] [56.55206]\n",
      "[55.] [48.786236]\n",
      "[58.] [66.7532]\n",
      "[58.] [42.281113]\n",
      "[54.] [39.231968]\n",
      "[40.] [38.605907]\n",
      "[64.] [58.48444]\n",
      "[60.] [53.987644]\n",
      "[64.] [90.90965]\n",
      "[76.] [105.04329]\n",
      "[61.] [45.139248]\n",
      "[73.] [96.57894]\n",
      "[49.] [46.90509]\n",
      "[62.] [66.835846]\n",
      "[79.] [77.835724]\n",
      "[50.] [61.21677]\n",
      "[41.] [42.246258]\n"
     ]
    }
   ],
   "source": [
    "for t,p in zip(y_test,y_test_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#오차 범위 3 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set prediction accuracy: 50.89 %\n",
      "test set prediction accuracy: 56.34 %\n"
     ]
    }
   ],
   "source": [
    "#평균 성능 테스트\n",
    "scores = 0\n",
    "mean=np.mean(Y, axis=0)\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= mean <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"train set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= mean <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"test set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### <오차범위 3>\n",
      "- train set prediction accuracy(+-3): 95.37 % <br>\n",
      "- test set prediction accuracy(+-3): 16.90 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 5>\n",
      "- train set prediction accuracy(+-5): 98.58 % <br>\n",
      "- test set prediction accuracy(+-5): 28.17 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 10>\n",
      "- train set prediction accuracy(+-10): 100.00 % <br>\n",
      "- test set prediction accuracy(+-10): 49.30 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 20>\n",
      "- train set prediction accuracy(+-20): 100.00 % <br>\n",
      "- test set prediction accuracy(+-20): 84.51 % <br>\n"
     ]
    }
   ],
   "source": [
    "######입력용#######\n",
    "\n",
    "#오차 범위 3 설정\n",
    "print('### <오차범위 3>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "print('### <오차범위 5>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "print('### <오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "print('### <오차범위 20>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Y=HDL>\n",
    "## 1. 임의+선별\n",
    "### <오차범위 3>\n",
    "- train set prediction accuracy(+-3): 95.37 % <br>\n",
    "- test set prediction accuracy(+-3): 16.90 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 5>\n",
    "- train set prediction accuracy(+-5): 98.58 % <br>\n",
    "- test set prediction accuracy(+-5): 28.17 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 10>\n",
    "- train set prediction accuracy(+-10): 100.00 % <br>\n",
    "- test set prediction accuracy(+-10): 49.30 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 20>\n",
    "- train set prediction accuracy(+-20): 100.00 % <br>\n",
    "- test set prediction accuracy(+-20): 84.51 % <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

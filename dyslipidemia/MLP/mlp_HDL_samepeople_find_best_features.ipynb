{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sample_ID GROUP  COHORT SEX  AGE     Trait FitbitOX      Fitbit_ID  HTN  \\\n",
      "0         S0001   SMI       2   M   60  fitbit_O        O  sevrance00001  NaN   \n",
      "1         S0002   SMI       2   M   61  fitbit_O        O  sevrance00002  NaN   \n",
      "2         S0003   SMI       2   F   52  fitbit_O        O  sevrance00003  NaN   \n",
      "3         S0004   SMI       2   F   41  fitbit_O        O  sevrance00004  NaN   \n",
      "4         S0005   SMI       2   F   41  fitbit_O        O  sevrance00005  NaN   \n",
      "..          ...   ...     ...  ..  ...       ...      ...            ...  ...   \n",
      "383  MetS_S0280  MetS       1   F   24  fitbit_O        O   gnfmmets+139  NaN   \n",
      "384  MetS_S0281  MetS       1   F   44  fitbit_O        O   gnfmmets+140  NaN   \n",
      "385  MetS_S0282  MetS       1   F   37  fitbit_O        O   gnfmmets+141  1.0   \n",
      "386  MetS_S0283  MetS       1   M   51  fitbit_X        X              X  NaN   \n",
      "387  MetS_S0284  MetS       1   F   42  fitbit_X        X              X  NaN   \n",
      "\n",
      "      DM  ...  BDI_Q13_2 BDI_Q14_2  BDI_Q15_2  BDI_Q16_2 BDI_Q17_2 BDI_Q18_2  \\\n",
      "0    NaN  ...        1.0       1.0        1.0        2.0       1.0       1.0   \n",
      "1    1.0  ...        1.0       1.0        1.0        1.0       2.0       1.0   \n",
      "2    NaN  ...        1.0       1.0        1.0        1.0       1.0       1.0   \n",
      "3    NaN  ...        2.0       2.0        2.0        2.0       2.0       2.0   \n",
      "4    NaN  ...        2.0       1.0        2.0        2.0       2.0       1.0   \n",
      "..   ...  ...        ...       ...        ...        ...       ...       ...   \n",
      "383  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "384  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "385  1.0  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "386  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "387  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "\n",
      "     BDI_Q19_2  BDI_Q20_2  BDI_Q21_2  Diet_2  \n",
      "0          2.0        1.0        2.0     2.0  \n",
      "1          1.0        1.0        1.0     2.0  \n",
      "2          1.0        2.0        4.0     1.0  \n",
      "3          1.0        1.0        1.0     2.0  \n",
      "4          1.0        2.0        1.0     2.0  \n",
      "..         ...        ...        ...     ...  \n",
      "383        NaN        NaN        NaN     NaN  \n",
      "384        NaN        NaN        NaN     NaN  \n",
      "385        NaN        NaN        NaN     NaN  \n",
      "386        NaN        NaN        NaN     NaN  \n",
      "387        NaN        NaN        NaN     NaN  \n",
      "\n",
      "[388 rows x 3527 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('./최종 데이터 그래프그리기용.xlsx') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#빈데이터 많은 Chol, BUN 제거\n",
    "psqi_df=df[['Sample_ID','GROUP','COHORT','AGE','SEX','BMI_1','PSQI_TOTAL_1','Insulin _1','CRP_1','WBC_1','Neutrophil_1','Lym_1','GLU0_1','Creatinine_1','AST_1','ALT_1','TG_1','LDL_1','Muscle_1','Fat_1_x','FatPercentage _1','WHR_1','SBP_1',\n",
    "            'DBP_1','HR_1','Waist_1','HDL_1',\n",
    "          'BMI_2','PSQI_TOTAL_2','Insulin _2','CRP_2','WBC_2','Neutrophil_2','Lym_2','GLU0_2',\n",
    "            'Creatinine_2','AST_2','ALT_2','TG_2','LDL_2','Muscle_2','Fat_2_x','FatPercentage_2','WHR_2','SBP_2',\n",
    "            'DBP_2','HR_2','Waist_2','HDL_2',\n",
    "           'PSQI_C1_2','PSQI_C2_2','PSQI_C3_2','PSQI_C4_2','PSQI_C5_2','PSQI_C6_2','PSQI_C7_2','PSQI_Q1_2','PSQI_Q2_2','PSQI_Q3_2','PSQI_Q4_2',\n",
    "            'PSQI_Q5a_2','PSQI_Q5b_2','PSQI_Q5c_2','PSQI_Q5d_2','PSQI_Q5e_2','PSQI_Q5f_2','PSQI_Q5g_2','PSQI_Q5h_2','PSQI_Q5i_2','PSQI_Q5j_2','PSQI_Q6_2','PSQI_Q7_2','PSQI_Q8_2','PSQI_Q9_2',\n",
    "           'PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>...</th>\n",
       "      <th>PSQI_Q5e_1</th>\n",
       "      <th>PSQI_Q5f_1</th>\n",
       "      <th>PSQI_Q5g_1</th>\n",
       "      <th>PSQI_Q5h_1</th>\n",
       "      <th>PSQI_Q5i_1</th>\n",
       "      <th>PSQI_Q5j_1</th>\n",
       "      <th>PSQI_Q6_1</th>\n",
       "      <th>PSQI_Q7_1</th>\n",
       "      <th>PSQI_Q8_1</th>\n",
       "      <th>PSQI_Q9_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.51</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.85</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.14</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.93</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.82</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT  AGE SEX      BMI_1  PSQI_TOTAL_1 Insulin _1  \\\n",
       "0         S0001   SMI       2   60   M  21.110190           8.0        7.7   \n",
       "1         S0002   SMI       2   61   M  27.782064           4.0        5.4   \n",
       "2         S0003   SMI       2   52   F  24.944742           3.0        5.1   \n",
       "3         S0004   SMI       2   41   F  22.620489           6.0        4.2   \n",
       "4         S0005   SMI       2   41   F  20.524157          10.0        3.2   \n",
       "..          ...   ...     ...  ...  ..        ...           ...        ...   \n",
       "383  MetS_S0280  MetS       1   24   F  34.803410           5.0       11.3   \n",
       "384  MetS_S0281  MetS       1   44   F  30.903615           3.0       10.6   \n",
       "385  MetS_S0282  MetS       1   37   F  28.676533           3.0       12.2   \n",
       "386  MetS_S0283  MetS       1   51   M  24.549738           5.0       10.4   \n",
       "387  MetS_S0284  MetS       1   42   F  24.605921           3.0       10.1   \n",
       "\n",
       "    CRP_1  WBC_1  ...  PSQI_Q5e_1  PSQI_Q5f_1  PSQI_Q5g_1  PSQI_Q5h_1  \\\n",
       "0     0.2   3.91  ...         0.0         0.0         0.0         1.0   \n",
       "1     0.2   5.51  ...         3.0         1.0         1.0         1.0   \n",
       "2     0.7   4.85  ...         3.0         1.0         1.0         0.0   \n",
       "3     0.6   6.14  ...         1.0         0.0         0.0         0.0   \n",
       "4     0.1   4.93  ...         0.0         0.0         0.0         1.0   \n",
       "..    ...    ...  ...         ...         ...         ...         ...   \n",
       "383   0.4   5.32  ...         0.0         0.0         0.0         0.0   \n",
       "384   2.3   5.82  ...         2.0         0.0         1.0         0.0   \n",
       "385     1   6.18  ...         0.0         0.0         0.0         0.0   \n",
       "386   1.2   6.67  ...         0.0         0.0         0.0         0.0   \n",
       "387   0.8   7.03  ...         0.0         0.0         0.0         0.0   \n",
       "\n",
       "     PSQI_Q5i_1  PSQI_Q5j_1  PSQI_Q6_1  PSQI_Q7_1  PSQI_Q8_1  PSQI_Q9_1  \n",
       "0           1.0         0.0        NaN        NaN        2.0        1.0  \n",
       "1           0.0         0.0        NaN        NaN        1.0        1.0  \n",
       "2           0.0         0.0        NaN        NaN        2.0        0.0  \n",
       "3           0.0         0.0        NaN        NaN        2.0        1.0  \n",
       "4           0.0         0.0        NaN        NaN        2.0        1.0  \n",
       "..          ...         ...        ...        ...        ...        ...  \n",
       "383         0.0         1.0        1.0        0.0        0.0        0.0  \n",
       "384         1.0         0.0        1.0        0.0        0.0        0.0  \n",
       "385         0.0         0.0        1.0        0.0        0.0        0.0  \n",
       "386         0.0         0.0        2.0        0.0        0.0        0.0  \n",
       "387         0.0         0.0        1.0        0.0        0.0        0.0  \n",
       "\n",
       "[388 rows x 99 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>...</th>\n",
       "      <th>PSQI_Q5e_1</th>\n",
       "      <th>PSQI_Q5f_1</th>\n",
       "      <th>PSQI_Q5g_1</th>\n",
       "      <th>PSQI_Q5h_1</th>\n",
       "      <th>PSQI_Q5i_1</th>\n",
       "      <th>PSQI_Q5j_1</th>\n",
       "      <th>PSQI_Q6_1</th>\n",
       "      <th>PSQI_Q7_1</th>\n",
       "      <th>PSQI_Q8_1</th>\n",
       "      <th>PSQI_Q9_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.51</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.85</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.14</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.93</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.32</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.82</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.67</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT  AGE SEX      BMI_1  PSQI_TOTAL_1 Insulin _1  \\\n",
       "0         S0001   SMI       2   60   M  21.110190           8.0        7.7   \n",
       "1         S0002   SMI       2   61   M  27.782064           4.0        5.4   \n",
       "2         S0003   SMI       2   52   F  24.944742           3.0        5.1   \n",
       "3         S0004   SMI       2   41   F  22.620489           6.0        4.2   \n",
       "4         S0005   SMI       2   41   F  20.524157          10.0        3.2   \n",
       "..          ...   ...     ...  ...  ..        ...           ...        ...   \n",
       "383  MetS_S0280  MetS       1   24   F  34.803410           5.0       11.3   \n",
       "384  MetS_S0281  MetS       1   44   F  30.903615           3.0       10.6   \n",
       "385  MetS_S0282  MetS       1   37   F  28.676533           3.0       12.2   \n",
       "386  MetS_S0283  MetS       1   51   M  24.549738           5.0       10.4   \n",
       "387  MetS_S0284  MetS       1   42   F  24.605921           3.0       10.1   \n",
       "\n",
       "    CRP_1  WBC_1  ...  PSQI_Q5e_1  PSQI_Q5f_1  PSQI_Q5g_1  PSQI_Q5h_1  \\\n",
       "0     0.2   3.91  ...         0.0         0.0         0.0         1.0   \n",
       "1     0.2   5.51  ...         3.0         1.0         1.0         1.0   \n",
       "2     0.7   4.85  ...         3.0         1.0         1.0         0.0   \n",
       "3     0.6   6.14  ...         1.0         0.0         0.0         0.0   \n",
       "4     0.1   4.93  ...         0.0         0.0         0.0         1.0   \n",
       "..    ...    ...  ...         ...         ...         ...         ...   \n",
       "383   0.4   5.32  ...         0.0         0.0         0.0         0.0   \n",
       "384   2.3   5.82  ...         2.0         0.0         1.0         0.0   \n",
       "385     1   6.18  ...         0.0         0.0         0.0         0.0   \n",
       "386   1.2   6.67  ...         0.0         0.0         0.0         0.0   \n",
       "387   0.8   7.03  ...         0.0         0.0         0.0         0.0   \n",
       "\n",
       "     PSQI_Q5i_1  PSQI_Q5j_1  PSQI_Q6_1  PSQI_Q7_1  PSQI_Q8_1  PSQI_Q9_1  \n",
       "0           1.0         0.0        NaN        NaN        2.0        1.0  \n",
       "1           0.0         0.0        NaN        NaN        1.0        1.0  \n",
       "2           0.0         0.0        NaN        NaN        2.0        0.0  \n",
       "3           0.0         0.0        NaN        NaN        2.0        1.0  \n",
       "4           0.0         0.0        NaN        NaN        2.0        1.0  \n",
       "..          ...         ...        ...        ...        ...        ...  \n",
       "383         0.0         1.0        1.0        0.0        0.0        0.0  \n",
       "384         1.0         0.0        1.0        0.0        0.0        0.0  \n",
       "385         0.0         0.0        1.0        0.0        0.0        0.0  \n",
       "386         0.0         0.0        2.0        0.0        0.0        0.0  \n",
       "387         0.0         0.0        1.0        0.0        0.0        0.0  \n",
       "\n",
       "[317 rows x 99 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#보조 호르몬 요법을 받고 있는 Cohort 3 제거 Filter 적용\n",
    "psqi_df = psqi_df[(psqi_df['COHORT'] != 3)]\n",
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df=psqi_df.dropna()\n",
    "psqi_df.reset_index(drop=True, inplace=True)\n",
    "psqi_df=psqi_df.drop([\"Sample_ID\", \"GROUP\", \"COHORT\"],axis=1)\n",
    "#1분, 매일다름, 정해진간이없음 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"SEX\"] = psqi_df[\"SEX\"].apply(lambda x: 1. if x=='M' else 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"Insulin _1\"] = psqi_df[\"Insulin _1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)\n",
    "psqi_df[\"Insulin _2\"] = psqi_df[\"Insulin _2\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"CRP_1\"] = psqi_df[\"CRP_1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)\n",
    "psqi_df[\"CRP_2\"] = psqi_df[\"CRP_2\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>Neutrophil_1</th>\n",
       "      <th>Lym_1</th>\n",
       "      <th>GLU0_1</th>\n",
       "      <th>...</th>\n",
       "      <th>PSQI_Q5e_1</th>\n",
       "      <th>PSQI_Q5f_1</th>\n",
       "      <th>PSQI_Q5g_1</th>\n",
       "      <th>PSQI_Q5h_1</th>\n",
       "      <th>PSQI_Q5i_1</th>\n",
       "      <th>PSQI_Q5j_1</th>\n",
       "      <th>PSQI_Q6_1</th>\n",
       "      <th>PSQI_Q7_1</th>\n",
       "      <th>PSQI_Q8_1</th>\n",
       "      <th>PSQI_Q9_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.107955</td>\n",
       "      <td>0.306818</td>\n",
       "      <td>23.787859</td>\n",
       "      <td>5.062500</td>\n",
       "      <td>7.715909</td>\n",
       "      <td>0.757955</td>\n",
       "      <td>5.856227</td>\n",
       "      <td>56.110795</td>\n",
       "      <td>34.115909</td>\n",
       "      <td>98.857955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.267045</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.448864</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1.142045</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.460227</td>\n",
       "      <td>0.556818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.451001</td>\n",
       "      <td>0.462489</td>\n",
       "      <td>4.980203</td>\n",
       "      <td>2.844858</td>\n",
       "      <td>4.133429</td>\n",
       "      <td>1.357495</td>\n",
       "      <td>1.420172</td>\n",
       "      <td>8.566716</td>\n",
       "      <td>7.746644</td>\n",
       "      <td>14.580897</td>\n",
       "      <td>...</td>\n",
       "      <td>1.027416</td>\n",
       "      <td>0.652244</td>\n",
       "      <td>0.618335</td>\n",
       "      <td>0.725688</td>\n",
       "      <td>0.930560</td>\n",
       "      <td>0.852727</td>\n",
       "      <td>0.690544</td>\n",
       "      <td>0.559220</td>\n",
       "      <td>0.840821</td>\n",
       "      <td>0.746159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.231576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.820000</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.833309</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.975000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.857500</td>\n",
       "      <td>50.525000</td>\n",
       "      <td>28.975000</td>\n",
       "      <td>91.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.351473</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>5.720000</td>\n",
       "      <td>55.950000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.502662</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.505000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>6.612500</td>\n",
       "      <td>62.025000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>10.550000</td>\n",
       "      <td>78.400000</td>\n",
       "      <td>55.400000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              AGE         SEX       BMI_1  PSQI_TOTAL_1  Insulin _1  \\\n",
       "count  176.000000  176.000000  176.000000    176.000000  176.000000   \n",
       "mean    38.107955    0.306818   23.787859      5.062500    7.715909   \n",
       "std     11.451001    0.462489    4.980203      2.844858    4.133429   \n",
       "min     20.000000    0.000000   15.231576      0.000000    0.100000   \n",
       "25%     29.000000    0.000000   20.833309      3.000000    4.975000   \n",
       "50%     35.000000    0.000000   23.351473      5.000000    6.600000   \n",
       "75%     46.000000    1.000000   25.502662      7.000000    9.505000   \n",
       "max     63.000000    1.000000   67.500000     14.000000   24.700000   \n",
       "\n",
       "            CRP_1       WBC_1  Neutrophil_1       Lym_1      GLU0_1  ...  \\\n",
       "count  176.000000  176.000000    176.000000  176.000000  176.000000  ...   \n",
       "mean     0.757955    5.856227     56.110795   34.115909   98.857955  ...   \n",
       "std      1.357495    1.420172      8.566716    7.746644   14.580897  ...   \n",
       "min      0.000000    2.820000     34.500000   15.100000   63.000000  ...   \n",
       "25%      0.200000    4.857500     50.525000   28.975000   91.750000  ...   \n",
       "50%      0.300000    5.720000     55.950000   34.000000   95.000000  ...   \n",
       "75%      0.700000    6.612500     62.025000   39.000000  102.000000  ...   \n",
       "max     11.100000   10.550000     78.400000   55.400000  182.000000  ...   \n",
       "\n",
       "       PSQI_Q5e_1  PSQI_Q5f_1  PSQI_Q5g_1  PSQI_Q5h_1  PSQI_Q5i_1  PSQI_Q5j_1  \\\n",
       "count  176.000000  176.000000  176.000000  176.000000  176.000000  176.000000   \n",
       "mean     0.636364    0.267045    0.227273    0.397727    0.448864    0.375000   \n",
       "std      1.027416    0.652244    0.618335    0.725688    0.930560    0.852727   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      1.000000    0.000000    0.000000    1.000000    0.000000    0.000000   \n",
       "max      3.000000    3.000000    3.000000    3.000000    3.000000    3.000000   \n",
       "\n",
       "        PSQI_Q6_1   PSQI_Q7_1   PSQI_Q8_1   PSQI_Q9_1  \n",
       "count  176.000000  176.000000  176.000000  176.000000  \n",
       "mean     1.142045    0.136364    0.460227    0.556818  \n",
       "std      0.690544    0.559220    0.840821    0.746159  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      1.000000    0.000000    0.000000    0.000000  \n",
       "50%      1.000000    0.000000    0.000000    0.000000  \n",
       "75%      2.000000    0.000000    1.000000    1.000000  \n",
       "max      3.000000    3.000000    3.000000    3.000000  \n",
       "\n",
       "[8 rows x 95 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    122\n",
       "1.0     54\n",
       "Name: SEX, dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df[\"SEX\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>Neutrophil_1</th>\n",
       "      <th>Lym_1</th>\n",
       "      <th>GLU0_1</th>\n",
       "      <th>...</th>\n",
       "      <th>PSQI_Q5e_1</th>\n",
       "      <th>PSQI_Q5f_1</th>\n",
       "      <th>PSQI_Q5g_1</th>\n",
       "      <th>PSQI_Q5h_1</th>\n",
       "      <th>PSQI_Q5i_1</th>\n",
       "      <th>PSQI_Q5j_1</th>\n",
       "      <th>PSQI_Q6_1</th>\n",
       "      <th>PSQI_Q7_1</th>\n",
       "      <th>PSQI_Q8_1</th>\n",
       "      <th>PSQI_Q9_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.097789</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.82</td>\n",
       "      <td>54.6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.472213</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.46</td>\n",
       "      <td>44.3</td>\n",
       "      <td>43.7</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.744827</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.26</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.99</td>\n",
       "      <td>51.0</td>\n",
       "      <td>37.8</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.616175</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.84</td>\n",
       "      <td>39.1</td>\n",
       "      <td>42.1</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.437500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.22</td>\n",
       "      <td>49.3</td>\n",
       "      <td>39.3</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.259585</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.78</td>\n",
       "      <td>42.3</td>\n",
       "      <td>47.3</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.630719</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.60</td>\n",
       "      <td>51.7</td>\n",
       "      <td>34.6</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.641274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.34</td>\n",
       "      <td>55.9</td>\n",
       "      <td>34.9</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.421366</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.88</td>\n",
       "      <td>40.9</td>\n",
       "      <td>48.0</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.271653</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.28</td>\n",
       "      <td>75.7</td>\n",
       "      <td>15.1</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGE  SEX      BMI_1  PSQI_TOTAL_1  Insulin _1  CRP_1  WBC_1  \\\n",
       "0     35  1.0  24.097789           5.0        5.57    0.0   5.82   \n",
       "1     46  1.0  23.472213           5.0        7.35    0.7   5.46   \n",
       "2     32  1.0  23.744827           2.0        9.26    0.4   3.99   \n",
       "3     33  0.0  20.616175           4.0        3.52    0.0   5.84   \n",
       "4     28  0.0  18.437500           3.0        2.86    0.0   4.22   \n",
       "..   ...  ...        ...           ...         ...    ...    ...   \n",
       "171   63  0.0  26.259585           3.0        4.20    0.2   4.78   \n",
       "172   57  1.0  28.630719           4.0        8.80    3.0   4.60   \n",
       "173   35  0.0  21.641274           1.0        6.30    0.4   6.34   \n",
       "174   61  0.0  20.421366           8.0        4.80    0.2   4.88   \n",
       "175   56  1.0  22.271653           1.0        9.00    0.2   6.28   \n",
       "\n",
       "     Neutrophil_1  Lym_1  GLU0_1  ...  PSQI_Q5e_1  PSQI_Q5f_1  PSQI_Q5g_1  \\\n",
       "0            54.6   35.0      89  ...         0.0         0.0         0.0   \n",
       "1            44.3   43.7      90  ...         3.0         3.0         0.0   \n",
       "2            51.0   37.8      96  ...         0.0         0.0         0.0   \n",
       "3            39.1   42.1      81  ...         0.0         0.0         0.0   \n",
       "4            49.3   39.3      63  ...         0.0         0.0         0.0   \n",
       "..            ...    ...     ...  ...         ...         ...         ...   \n",
       "171          42.3   47.3      96  ...         3.0         0.0         0.0   \n",
       "172          51.7   34.6      94  ...         0.0         0.0         1.0   \n",
       "173          55.9   34.9      87  ...         0.0         0.0         0.0   \n",
       "174          40.9   48.0      93  ...         1.0         0.0         0.0   \n",
       "175          75.7   15.1     125  ...         0.0         0.0         0.0   \n",
       "\n",
       "     PSQI_Q5h_1  PSQI_Q5i_1  PSQI_Q5j_1  PSQI_Q6_1  PSQI_Q7_1  PSQI_Q8_1  \\\n",
       "0           0.0         0.0         0.0        1.0        0.0        1.0   \n",
       "1           0.0         0.0         0.0        2.0        0.0        0.0   \n",
       "2           0.0         0.0         0.0        1.0        0.0        0.0   \n",
       "3           0.0         1.0         1.0        1.0        0.0        1.0   \n",
       "4           0.0         0.0         1.0        1.0        0.0        0.0   \n",
       "..          ...         ...         ...        ...        ...        ...   \n",
       "171         0.0         0.0         0.0        0.0        0.0        0.0   \n",
       "172         0.0         3.0         0.0        1.0        0.0        1.0   \n",
       "173         0.0         0.0         0.0        0.0        0.0        0.0   \n",
       "174         0.0         0.0         0.0        2.0        0.0        0.0   \n",
       "175         0.0         2.0         0.0        0.0        0.0        0.0   \n",
       "\n",
       "     PSQI_Q9_1  \n",
       "0          1.0  \n",
       "1          0.0  \n",
       "2          0.0  \n",
       "3          0.0  \n",
       "4          0.0  \n",
       "..         ...  \n",
       "171        0.0  \n",
       "172        3.0  \n",
       "173        0.0  \n",
       "174        1.0  \n",
       "175        0.0  \n",
       "\n",
       "[176 rows x 96 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (x=쓸 수 있는 모든 특징)\n",
    "X1=psqi_df[['AGE','SEX','BMI_1','PSQI_TOTAL_1','Insulin _1','CRP_1','WBC_1','Neutrophil_1','Lym_1','GLU0_1',\n",
    "            'Creatinine_1','AST_1','ALT_1','TG_1','LDL_1','Muscle_1','Fat_1_x','FatPercentage _1','WHR_1','SBP_1',\n",
    "            'DBP_1','HR_1','Waist_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1',\n",
    "            'PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1',\n",
    "            'PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','SEX','BMI_2','PSQI_TOTAL_2','Insulin _2','CRP_2','WBC_2','Neutrophil_2','Lym_2','GLU0_2',\n",
    "            'Creatinine_2','AST_2','ALT_2','TG_2','LDL_2','Muscle_2','Fat_2_x','FatPercentage_2','WHR_2','SBP_2',\n",
    "            'DBP_2','HR_2','Waist_2','PSQI_C1_2','PSQI_C2_2','PSQI_C3_2','PSQI_C4_2','PSQI_C5_2','PSQI_C6_2','PSQI_C7_2',\n",
    "            'PSQI_Q1_2','PSQI_Q2_2','PSQI_Q3_2','PSQI_Q4_2',\n",
    "            'PSQI_Q5a_2','PSQI_Q5b_2','PSQI_Q5c_2','PSQI_Q5d_2','PSQI_Q5e_2','PSQI_Q5f_2','PSQI_Q5g_2','PSQI_Q5h_2','PSQI_Q5i_2','PSQI_Q5j_2',\n",
    "            'PSQI_Q6_2','PSQI_Q7_2','PSQI_Q8_2','PSQI_Q9_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 352)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((352, 48), (352, 1))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281, 71)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((352, 48), (352, 1))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "71/71 - 1s - loss: 3447.4016 - mse: 3447.4016\n",
      "Epoch 2/150\n",
      "71/71 - 0s - loss: 2632.5325 - mse: 2632.5325\n",
      "Epoch 3/150\n",
      "71/71 - 0s - loss: 1429.1246 - mse: 1429.1246\n",
      "Epoch 4/150\n",
      "71/71 - 0s - loss: 520.0830 - mse: 520.0830\n",
      "Epoch 5/150\n",
      "71/71 - 0s - loss: 292.0315 - mse: 292.0315\n",
      "Epoch 6/150\n",
      "71/71 - 0s - loss: 242.5251 - mse: 242.5251\n",
      "Epoch 7/150\n",
      "71/71 - 0s - loss: 207.2390 - mse: 207.2390\n",
      "Epoch 8/150\n",
      "71/71 - 0s - loss: 177.7427 - mse: 177.7427\n",
      "Epoch 9/150\n",
      "71/71 - 0s - loss: 165.2109 - mse: 165.2109\n",
      "Epoch 10/150\n",
      "71/71 - 0s - loss: 149.7020 - mse: 149.7020\n",
      "Epoch 11/150\n",
      "71/71 - 0s - loss: 137.5908 - mse: 137.5908\n",
      "Epoch 12/150\n",
      "71/71 - 0s - loss: 124.9355 - mse: 124.9355\n",
      "Epoch 13/150\n",
      "71/71 - 0s - loss: 118.4650 - mse: 118.4650\n",
      "Epoch 14/150\n",
      "71/71 - 0s - loss: 109.9347 - mse: 109.9347\n",
      "Epoch 15/150\n",
      "71/71 - 0s - loss: 103.7826 - mse: 103.7826\n",
      "Epoch 16/150\n",
      "71/71 - 0s - loss: 99.8969 - mse: 99.8969\n",
      "Epoch 17/150\n",
      "71/71 - 0s - loss: 94.6168 - mse: 94.6168\n",
      "Epoch 18/150\n",
      "71/71 - 0s - loss: 90.1069 - mse: 90.1069\n",
      "Epoch 19/150\n",
      "71/71 - 0s - loss: 86.6243 - mse: 86.6243\n",
      "Epoch 20/150\n",
      "71/71 - 0s - loss: 83.6105 - mse: 83.6105\n",
      "Epoch 21/150\n",
      "71/71 - 0s - loss: 79.5779 - mse: 79.5779\n",
      "Epoch 22/150\n",
      "71/71 - 0s - loss: 76.7679 - mse: 76.7679\n",
      "Epoch 23/150\n",
      "71/71 - 0s - loss: 74.4445 - mse: 74.4445\n",
      "Epoch 24/150\n",
      "71/71 - 0s - loss: 72.4081 - mse: 72.4081\n",
      "Epoch 25/150\n",
      "71/71 - 0s - loss: 69.1294 - mse: 69.1294\n",
      "Epoch 26/150\n",
      "71/71 - 0s - loss: 67.2292 - mse: 67.2292\n",
      "Epoch 27/150\n",
      "71/71 - 0s - loss: 63.9341 - mse: 63.9341\n",
      "Epoch 28/150\n",
      "71/71 - 0s - loss: 62.6247 - mse: 62.6247\n",
      "Epoch 29/150\n",
      "71/71 - 0s - loss: 60.7826 - mse: 60.7826\n",
      "Epoch 30/150\n",
      "71/71 - 0s - loss: 59.1889 - mse: 59.1889\n",
      "Epoch 31/150\n",
      "71/71 - 0s - loss: 57.9932 - mse: 57.9932\n",
      "Epoch 32/150\n",
      "71/71 - 0s - loss: 54.9756 - mse: 54.9756\n",
      "Epoch 33/150\n",
      "71/71 - 0s - loss: 53.5817 - mse: 53.5817\n",
      "Epoch 34/150\n",
      "71/71 - 0s - loss: 51.6460 - mse: 51.6460\n",
      "Epoch 35/150\n",
      "71/71 - 0s - loss: 51.1464 - mse: 51.1464\n",
      "Epoch 36/150\n",
      "71/71 - 0s - loss: 49.4189 - mse: 49.4189\n",
      "Epoch 37/150\n",
      "71/71 - 0s - loss: 46.8984 - mse: 46.8984\n",
      "Epoch 38/150\n",
      "71/71 - 0s - loss: 45.1846 - mse: 45.1846\n",
      "Epoch 39/150\n",
      "71/71 - 0s - loss: 45.7479 - mse: 45.7479\n",
      "Epoch 40/150\n",
      "71/71 - 0s - loss: 44.5794 - mse: 44.5794\n",
      "Epoch 41/150\n",
      "71/71 - 0s - loss: 43.2691 - mse: 43.2691\n",
      "Epoch 42/150\n",
      "71/71 - 0s - loss: 42.0516 - mse: 42.0516\n",
      "Epoch 43/150\n",
      "71/71 - 0s - loss: 41.1684 - mse: 41.1684\n",
      "Epoch 44/150\n",
      "71/71 - 0s - loss: 40.2243 - mse: 40.2243\n",
      "Epoch 45/150\n",
      "71/71 - 0s - loss: 38.5949 - mse: 38.5949\n",
      "Epoch 46/150\n",
      "71/71 - 0s - loss: 38.4632 - mse: 38.4632\n",
      "Epoch 47/150\n",
      "71/71 - 0s - loss: 37.5639 - mse: 37.5639\n",
      "Epoch 48/150\n",
      "71/71 - 0s - loss: 35.9858 - mse: 35.9858\n",
      "Epoch 49/150\n",
      "71/71 - 0s - loss: 34.9972 - mse: 34.9972\n",
      "Epoch 50/150\n",
      "71/71 - 0s - loss: 34.8991 - mse: 34.8991\n",
      "Epoch 51/150\n",
      "71/71 - 0s - loss: 33.9522 - mse: 33.9522\n",
      "Epoch 52/150\n",
      "71/71 - 0s - loss: 32.2824 - mse: 32.2824\n",
      "Epoch 53/150\n",
      "71/71 - 0s - loss: 32.6370 - mse: 32.6370\n",
      "Epoch 54/150\n",
      "71/71 - 0s - loss: 31.1961 - mse: 31.1961\n",
      "Epoch 55/150\n",
      "71/71 - 0s - loss: 30.8266 - mse: 30.8266\n",
      "Epoch 56/150\n",
      "71/71 - 0s - loss: 28.6906 - mse: 28.6906\n",
      "Epoch 57/150\n",
      "71/71 - 0s - loss: 28.6207 - mse: 28.6207\n",
      "Epoch 58/150\n",
      "71/71 - 0s - loss: 27.6247 - mse: 27.6247\n",
      "Epoch 59/150\n",
      "71/71 - 0s - loss: 26.9735 - mse: 26.9735\n",
      "Epoch 60/150\n",
      "71/71 - 0s - loss: 26.4206 - mse: 26.4206\n",
      "Epoch 61/150\n",
      "71/71 - 0s - loss: 26.1506 - mse: 26.1506\n",
      "Epoch 62/150\n",
      "71/71 - 0s - loss: 24.5132 - mse: 24.5132\n",
      "Epoch 63/150\n",
      "71/71 - 0s - loss: 24.5354 - mse: 24.5354\n",
      "Epoch 64/150\n",
      "71/71 - 0s - loss: 24.0050 - mse: 24.0050\n",
      "Epoch 65/150\n",
      "71/71 - 0s - loss: 22.6447 - mse: 22.6447\n",
      "Epoch 66/150\n",
      "71/71 - 0s - loss: 22.7577 - mse: 22.7577\n",
      "Epoch 67/150\n",
      "71/71 - 0s - loss: 22.2402 - mse: 22.2402\n",
      "Epoch 68/150\n",
      "71/71 - 0s - loss: 21.3483 - mse: 21.3483\n",
      "Epoch 69/150\n",
      "71/71 - 0s - loss: 20.9867 - mse: 20.9867\n",
      "Epoch 70/150\n",
      "71/71 - 0s - loss: 20.2241 - mse: 20.2241\n",
      "Epoch 71/150\n",
      "71/71 - 0s - loss: 19.4241 - mse: 19.4241\n",
      "Epoch 72/150\n",
      "71/71 - 0s - loss: 18.8479 - mse: 18.8479\n",
      "Epoch 73/150\n",
      "71/71 - 0s - loss: 18.2789 - mse: 18.2789\n",
      "Epoch 74/150\n",
      "71/71 - 0s - loss: 18.2349 - mse: 18.2349\n",
      "Epoch 75/150\n",
      "71/71 - 0s - loss: 17.9041 - mse: 17.9041\n",
      "Epoch 76/150\n",
      "71/71 - 0s - loss: 17.2957 - mse: 17.2957\n",
      "Epoch 77/150\n",
      "71/71 - 0s - loss: 16.1594 - mse: 16.1594\n",
      "Epoch 78/150\n",
      "71/71 - 0s - loss: 16.1445 - mse: 16.1445\n",
      "Epoch 79/150\n",
      "71/71 - 0s - loss: 15.7411 - mse: 15.7411\n",
      "Epoch 80/150\n",
      "71/71 - 0s - loss: 14.8003 - mse: 14.8003\n",
      "Epoch 81/150\n",
      "71/71 - 0s - loss: 14.9532 - mse: 14.9532\n",
      "Epoch 82/150\n",
      "71/71 - 0s - loss: 14.8009 - mse: 14.8009\n",
      "Epoch 83/150\n",
      "71/71 - 0s - loss: 14.3089 - mse: 14.3089\n",
      "Epoch 84/150\n",
      "71/71 - 0s - loss: 13.4423 - mse: 13.4423\n",
      "Epoch 85/150\n",
      "71/71 - 0s - loss: 12.8710 - mse: 12.8710\n",
      "Epoch 86/150\n",
      "71/71 - 0s - loss: 12.0424 - mse: 12.0424\n",
      "Epoch 87/150\n",
      "71/71 - 0s - loss: 11.8340 - mse: 11.8340\n",
      "Epoch 88/150\n",
      "71/71 - 0s - loss: 11.1234 - mse: 11.1234\n",
      "Epoch 89/150\n",
      "71/71 - 0s - loss: 11.9400 - mse: 11.9400\n",
      "Epoch 90/150\n",
      "71/71 - 0s - loss: 10.8733 - mse: 10.8733\n",
      "Epoch 91/150\n",
      "71/71 - 0s - loss: 10.6239 - mse: 10.6239\n",
      "Epoch 92/150\n",
      "71/71 - 0s - loss: 10.5273 - mse: 10.5273\n",
      "Epoch 93/150\n",
      "71/71 - 0s - loss: 9.7599 - mse: 9.7599\n",
      "Epoch 94/150\n",
      "71/71 - 0s - loss: 9.6390 - mse: 9.6390\n",
      "Epoch 95/150\n",
      "71/71 - 0s - loss: 9.0155 - mse: 9.0155\n",
      "Epoch 96/150\n",
      "71/71 - 0s - loss: 9.0962 - mse: 9.0962\n",
      "Epoch 97/150\n",
      "71/71 - 0s - loss: 8.1486 - mse: 8.1486\n",
      "Epoch 98/150\n",
      "71/71 - 0s - loss: 8.0405 - mse: 8.0405\n",
      "Epoch 99/150\n",
      "71/71 - 0s - loss: 7.6055 - mse: 7.6055\n",
      "Epoch 100/150\n",
      "71/71 - 0s - loss: 7.8328 - mse: 7.8328\n",
      "Epoch 101/150\n",
      "71/71 - 0s - loss: 7.0189 - mse: 7.0189\n",
      "Epoch 102/150\n",
      "71/71 - 0s - loss: 6.6884 - mse: 6.6884\n",
      "Epoch 103/150\n",
      "71/71 - 0s - loss: 6.7583 - mse: 6.7583\n",
      "Epoch 104/150\n",
      "71/71 - 0s - loss: 6.7290 - mse: 6.7290\n",
      "Epoch 105/150\n",
      "71/71 - 0s - loss: 6.1734 - mse: 6.1734\n",
      "Epoch 106/150\n",
      "71/71 - 0s - loss: 5.9777 - mse: 5.9777\n",
      "Epoch 107/150\n",
      "71/71 - 0s - loss: 5.7012 - mse: 5.7012\n",
      "Epoch 108/150\n",
      "71/71 - 0s - loss: 5.3611 - mse: 5.3611\n",
      "Epoch 109/150\n",
      "71/71 - 0s - loss: 5.3244 - mse: 5.3244\n",
      "Epoch 110/150\n",
      "71/71 - 0s - loss: 5.0015 - mse: 5.0015\n",
      "Epoch 111/150\n",
      "71/71 - 0s - loss: 4.7956 - mse: 4.7956\n",
      "Epoch 112/150\n",
      "71/71 - 0s - loss: 4.6855 - mse: 4.6855\n",
      "Epoch 113/150\n",
      "71/71 - 0s - loss: 4.6794 - mse: 4.6794\n",
      "Epoch 114/150\n",
      "71/71 - 0s - loss: 4.3807 - mse: 4.3807\n",
      "Epoch 115/150\n",
      "71/71 - 0s - loss: 4.1622 - mse: 4.1622\n",
      "Epoch 116/150\n",
      "71/71 - 0s - loss: 4.2754 - mse: 4.2754\n",
      "Epoch 117/150\n",
      "71/71 - 0s - loss: 4.2066 - mse: 4.2066\n",
      "Epoch 118/150\n",
      "71/71 - 0s - loss: 3.6330 - mse: 3.6330\n",
      "Epoch 119/150\n",
      "71/71 - 0s - loss: 3.5799 - mse: 3.5799\n",
      "Epoch 120/150\n",
      "71/71 - 0s - loss: 3.4532 - mse: 3.4532\n",
      "Epoch 121/150\n",
      "71/71 - 0s - loss: 3.3860 - mse: 3.3860\n",
      "Epoch 122/150\n",
      "71/71 - 0s - loss: 3.2193 - mse: 3.2193\n",
      "Epoch 123/150\n",
      "71/71 - 0s - loss: 3.1524 - mse: 3.1524\n",
      "Epoch 124/150\n",
      "71/71 - 0s - loss: 3.2704 - mse: 3.2704\n",
      "Epoch 125/150\n",
      "71/71 - 0s - loss: 2.7118 - mse: 2.7118\n",
      "Epoch 126/150\n",
      "71/71 - 0s - loss: 2.7582 - mse: 2.7582\n",
      "Epoch 127/150\n",
      "71/71 - 0s - loss: 2.5375 - mse: 2.5375\n",
      "Epoch 128/150\n",
      "71/71 - 0s - loss: 3.1529 - mse: 3.1529\n",
      "Epoch 129/150\n",
      "71/71 - 0s - loss: 2.3716 - mse: 2.3716\n",
      "Epoch 130/150\n",
      "71/71 - 0s - loss: 2.6074 - mse: 2.6074\n",
      "Epoch 131/150\n",
      "71/71 - 0s - loss: 2.3725 - mse: 2.3725\n",
      "Epoch 132/150\n",
      "71/71 - 0s - loss: 2.5738 - mse: 2.5738\n",
      "Epoch 133/150\n",
      "71/71 - 0s - loss: 2.2098 - mse: 2.2098\n",
      "Epoch 134/150\n",
      "71/71 - 0s - loss: 2.3066 - mse: 2.3066\n",
      "Epoch 135/150\n",
      "71/71 - 0s - loss: 2.1927 - mse: 2.1927\n",
      "Epoch 136/150\n",
      "71/71 - 0s - loss: 1.9978 - mse: 1.9978\n",
      "Epoch 137/150\n",
      "71/71 - 0s - loss: 2.2940 - mse: 2.2940\n",
      "Epoch 138/150\n",
      "71/71 - 0s - loss: 2.1322 - mse: 2.1322\n",
      "Epoch 139/150\n",
      "71/71 - 0s - loss: 1.5352 - mse: 1.5352\n",
      "Epoch 140/150\n",
      "71/71 - 0s - loss: 1.9098 - mse: 1.9098\n",
      "Epoch 141/150\n",
      "71/71 - 0s - loss: 1.8128 - mse: 1.8128\n",
      "Epoch 142/150\n",
      "71/71 - 0s - loss: 1.8785 - mse: 1.8785\n",
      "Epoch 143/150\n",
      "71/71 - 0s - loss: 1.6623 - mse: 1.6623\n",
      "Epoch 144/150\n",
      "71/71 - 0s - loss: 1.8595 - mse: 1.8595\n",
      "Epoch 145/150\n",
      "71/71 - 0s - loss: 1.6390 - mse: 1.6390\n",
      "Epoch 146/150\n",
      "71/71 - 0s - loss: 1.6712 - mse: 1.6712\n",
      "Epoch 147/150\n",
      "71/71 - 0s - loss: 1.6580 - mse: 1.6580\n",
      "Epoch 148/150\n",
      "71/71 - 0s - loss: 1.6527 - mse: 1.6527\n",
      "Epoch 149/150\n",
      "71/71 - 0s - loss: 1.6773 - mse: 1.6773\n",
      "Epoch 150/150\n",
      "71/71 - 0s - loss: 1.5905 - mse: 1.5905\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x0000014490748670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 158.9037 - mse: 158.9037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[158.90367126464844, 158.90367126464844]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=150, batch_size=4, verbose=2)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,657\n",
      "Trainable params: 2,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set prediction accuracy: 50.89 %\n",
      "test set prediction accuracy: 56.34 %\n"
     ]
    }
   ],
   "source": [
    "#평균 성능 테스트\n",
    "scores = 0\n",
    "mean=np.mean(Y, axis=0)\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= mean <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"train set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= mean <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"test set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### <오차범위 3>\n",
      "- train set prediction accuracy(+-3): 98.22 % <br>\n",
      "- test set prediction accuracy(+-3): 23.94 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 5>\n",
      "- train set prediction accuracy(+-5): 99.29 % <br>\n",
      "- test set prediction accuracy(+-5): 30.99 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 10>\n",
      "- train set prediction accuracy(+-10): 100.00 % <br>\n",
      "- test set prediction accuracy(+-10): 59.15 % <br>\n",
      "<br>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######입력용#######\n",
    "\n",
    "#오차 범위 3 설정\n",
    "print('### <오차범위 3>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "print('### <오차범위 5>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "print('### <오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (시본으로 선별한 특징)\n",
    "X1=psqi_df[['SEX','AGE','PSQI_TOTAL_1','BMI_1','WBC_1','GLU0_1','ALT_1','TG_1','LDL_1',\n",
    "            'Muscle_1','Fat_1_x','SBP_1','DBP_1','HR_1','Waist_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1',\n",
    "            'PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1',\n",
    "            'PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1']].values\n",
    "\n",
    "X2=psqi_df[['SEX','AGE','PSQI_TOTAL_2','BMI_2','WBC_2','GLU0_2','ALT_2','TG_2','LDL_2',\n",
    "            'Muscle_2','Fat_2_x','SBP_2','DBP_2','HR_2','Waist_2','PSQI_C1_2','PSQI_C2_2','PSQI_C3_2','PSQI_C4_2','PSQI_C5_2','PSQI_C6_2','PSQI_C7_2',\n",
    "            'PSQI_Q1_2','PSQI_Q2_2','PSQI_Q3_2','PSQI_Q4_2',\n",
    "            'PSQI_Q5a_2','PSQI_Q5b_2','PSQI_Q5c_2','PSQI_Q5d_2','PSQI_Q5e_2','PSQI_Q5f_2','PSQI_Q5g_2','PSQI_Q5h_2','PSQI_Q5i_2','PSQI_Q5j_2',\n",
    "            'PSQI_Q6_2','PSQI_Q7_2','PSQI_Q8_2','PSQI_Q9_2']].values\n",
    "\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281, 71)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((352, 40), (352, 1))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "71/71 - 2s - loss: 3470.1448 - mse: 3470.1448\n",
      "Epoch 2/150\n",
      "71/71 - 0s - loss: 2628.6985 - mse: 2628.6985\n",
      "Epoch 3/150\n",
      "71/71 - 0s - loss: 1461.1482 - mse: 1461.1482\n",
      "Epoch 4/150\n",
      "71/71 - 0s - loss: 588.1369 - mse: 588.1369\n",
      "Epoch 5/150\n",
      "71/71 - 0s - loss: 351.0075 - mse: 351.0075\n",
      "Epoch 6/150\n",
      "71/71 - 0s - loss: 275.8846 - mse: 275.8846\n",
      "Epoch 7/150\n",
      "71/71 - 0s - loss: 230.2852 - mse: 230.2852\n",
      "Epoch 8/150\n",
      "71/71 - 0s - loss: 199.2744 - mse: 199.2744\n",
      "Epoch 9/150\n",
      "71/71 - 0s - loss: 174.7942 - mse: 174.7942\n",
      "Epoch 10/150\n",
      "71/71 - 0s - loss: 157.0444 - mse: 157.0444\n",
      "Epoch 11/150\n",
      "71/71 - 0s - loss: 142.6048 - mse: 142.6048\n",
      "Epoch 12/150\n",
      "71/71 - 0s - loss: 131.4588 - mse: 131.4588\n",
      "Epoch 13/150\n",
      "71/71 - 0s - loss: 122.1623 - mse: 122.1623\n",
      "Epoch 14/150\n",
      "71/71 - 0s - loss: 116.2028 - mse: 116.2028\n",
      "Epoch 15/150\n",
      "71/71 - 0s - loss: 107.9194 - mse: 107.9194\n",
      "Epoch 16/150\n",
      "71/71 - 0s - loss: 103.2931 - mse: 103.2931\n",
      "Epoch 17/150\n",
      "71/71 - 0s - loss: 98.9787 - mse: 98.9787\n",
      "Epoch 18/150\n",
      "71/71 - 0s - loss: 93.5791 - mse: 93.5791\n",
      "Epoch 19/150\n",
      "71/71 - 0s - loss: 89.5156 - mse: 89.5156\n",
      "Epoch 20/150\n",
      "71/71 - 0s - loss: 86.2303 - mse: 86.2303\n",
      "Epoch 21/150\n",
      "71/71 - 0s - loss: 83.5851 - mse: 83.5851\n",
      "Epoch 22/150\n",
      "71/71 - 0s - loss: 78.8381 - mse: 78.8381\n",
      "Epoch 23/150\n",
      "71/71 - 0s - loss: 77.4703 - mse: 77.4703\n",
      "Epoch 24/150\n",
      "71/71 - 0s - loss: 73.5879 - mse: 73.5879\n",
      "Epoch 25/150\n",
      "71/71 - 0s - loss: 72.6380 - mse: 72.6380\n",
      "Epoch 26/150\n",
      "71/71 - 0s - loss: 70.7417 - mse: 70.7417\n",
      "Epoch 27/150\n",
      "71/71 - 0s - loss: 67.6577 - mse: 67.6577\n",
      "Epoch 28/150\n",
      "71/71 - 0s - loss: 66.7893 - mse: 66.7893\n",
      "Epoch 29/150\n",
      "71/71 - 0s - loss: 64.6087 - mse: 64.6087\n",
      "Epoch 30/150\n",
      "71/71 - 0s - loss: 62.7495 - mse: 62.7495\n",
      "Epoch 31/150\n",
      "71/71 - 0s - loss: 62.3965 - mse: 62.3965\n",
      "Epoch 32/150\n",
      "71/71 - 0s - loss: 59.9364 - mse: 59.9364\n",
      "Epoch 33/150\n",
      "71/71 - 0s - loss: 57.8089 - mse: 57.8089\n",
      "Epoch 34/150\n",
      "71/71 - 0s - loss: 56.3701 - mse: 56.3701\n",
      "Epoch 35/150\n",
      "71/71 - 0s - loss: 54.7645 - mse: 54.7645\n",
      "Epoch 36/150\n",
      "71/71 - 0s - loss: 53.8357 - mse: 53.8357\n",
      "Epoch 37/150\n",
      "71/71 - 0s - loss: 53.6680 - mse: 53.6680\n",
      "Epoch 38/150\n",
      "71/71 - 0s - loss: 50.9044 - mse: 50.9044\n",
      "Epoch 39/150\n",
      "71/71 - 0s - loss: 49.5829 - mse: 49.5829\n",
      "Epoch 40/150\n",
      "71/71 - 0s - loss: 48.6595 - mse: 48.6595\n",
      "Epoch 41/150\n",
      "71/71 - 0s - loss: 48.4878 - mse: 48.4878\n",
      "Epoch 42/150\n",
      "71/71 - 0s - loss: 46.8442 - mse: 46.8442\n",
      "Epoch 43/150\n",
      "71/71 - 0s - loss: 46.8915 - mse: 46.8915\n",
      "Epoch 44/150\n",
      "71/71 - 0s - loss: 44.9788 - mse: 44.9788\n",
      "Epoch 45/150\n",
      "71/71 - 0s - loss: 44.7856 - mse: 44.7856\n",
      "Epoch 46/150\n",
      "71/71 - 0s - loss: 43.0920 - mse: 43.0920\n",
      "Epoch 47/150\n",
      "71/71 - 0s - loss: 42.5070 - mse: 42.5070\n",
      "Epoch 48/150\n",
      "71/71 - 0s - loss: 41.9482 - mse: 41.9482\n",
      "Epoch 49/150\n",
      "71/71 - 0s - loss: 41.1972 - mse: 41.1972\n",
      "Epoch 50/150\n",
      "71/71 - 0s - loss: 40.2540 - mse: 40.2540\n",
      "Epoch 51/150\n",
      "71/71 - 0s - loss: 39.4189 - mse: 39.4189\n",
      "Epoch 52/150\n",
      "71/71 - 0s - loss: 38.3225 - mse: 38.3225\n",
      "Epoch 53/150\n",
      "71/71 - 0s - loss: 37.5852 - mse: 37.5852\n",
      "Epoch 54/150\n",
      "71/71 - 0s - loss: 37.3833 - mse: 37.3833\n",
      "Epoch 55/150\n",
      "71/71 - 0s - loss: 36.7516 - mse: 36.7516\n",
      "Epoch 56/150\n",
      "71/71 - 0s - loss: 35.1764 - mse: 35.1764\n",
      "Epoch 57/150\n",
      "71/71 - 0s - loss: 35.2178 - mse: 35.2178\n",
      "Epoch 58/150\n",
      "71/71 - 0s - loss: 33.4749 - mse: 33.4749\n",
      "Epoch 59/150\n",
      "71/71 - 0s - loss: 33.2723 - mse: 33.2723\n",
      "Epoch 60/150\n",
      "71/71 - 0s - loss: 32.4976 - mse: 32.4976\n",
      "Epoch 61/150\n",
      "71/71 - 0s - loss: 31.7483 - mse: 31.7483\n",
      "Epoch 62/150\n",
      "71/71 - 0s - loss: 31.4505 - mse: 31.4505\n",
      "Epoch 63/150\n",
      "71/71 - 0s - loss: 30.5973 - mse: 30.5973\n",
      "Epoch 64/150\n",
      "71/71 - 0s - loss: 29.8274 - mse: 29.8274\n",
      "Epoch 65/150\n",
      "71/71 - 0s - loss: 28.5103 - mse: 28.5103\n",
      "Epoch 66/150\n",
      "71/71 - 0s - loss: 27.7798 - mse: 27.7798\n",
      "Epoch 67/150\n",
      "71/71 - 0s - loss: 27.0546 - mse: 27.0546\n",
      "Epoch 68/150\n",
      "71/71 - 0s - loss: 26.9418 - mse: 26.9418\n",
      "Epoch 69/150\n",
      "71/71 - 0s - loss: 25.8934 - mse: 25.8934\n",
      "Epoch 70/150\n",
      "71/71 - 0s - loss: 25.2403 - mse: 25.2403\n",
      "Epoch 71/150\n",
      "71/71 - 0s - loss: 24.8168 - mse: 24.8168\n",
      "Epoch 72/150\n",
      "71/71 - 0s - loss: 24.1669 - mse: 24.1669\n",
      "Epoch 73/150\n",
      "71/71 - 0s - loss: 23.3180 - mse: 23.3180\n",
      "Epoch 74/150\n",
      "71/71 - 0s - loss: 22.8915 - mse: 22.8915\n",
      "Epoch 75/150\n",
      "71/71 - 0s - loss: 22.3695 - mse: 22.3695\n",
      "Epoch 76/150\n",
      "71/71 - 0s - loss: 21.5385 - mse: 21.5385\n",
      "Epoch 77/150\n",
      "71/71 - 0s - loss: 20.2259 - mse: 20.2259\n",
      "Epoch 78/150\n",
      "71/71 - 0s - loss: 20.3639 - mse: 20.3639\n",
      "Epoch 79/150\n",
      "71/71 - 0s - loss: 20.0505 - mse: 20.0505\n",
      "Epoch 80/150\n",
      "71/71 - 0s - loss: 19.4373 - mse: 19.4373\n",
      "Epoch 81/150\n",
      "71/71 - 0s - loss: 18.8093 - mse: 18.8093\n",
      "Epoch 82/150\n",
      "71/71 - 0s - loss: 17.4346 - mse: 17.4346\n",
      "Epoch 83/150\n",
      "71/71 - 0s - loss: 17.9090 - mse: 17.9090\n",
      "Epoch 84/150\n",
      "71/71 - 0s - loss: 16.7030 - mse: 16.7030\n",
      "Epoch 85/150\n",
      "71/71 - 0s - loss: 16.4835 - mse: 16.4835\n",
      "Epoch 86/150\n",
      "71/71 - 0s - loss: 15.4613 - mse: 15.4613\n",
      "Epoch 87/150\n",
      "71/71 - 0s - loss: 15.5859 - mse: 15.5859\n",
      "Epoch 88/150\n",
      "71/71 - 0s - loss: 14.8438 - mse: 14.8438\n",
      "Epoch 89/150\n",
      "71/71 - 0s - loss: 14.2640 - mse: 14.2640\n",
      "Epoch 90/150\n",
      "71/71 - 0s - loss: 13.6107 - mse: 13.6107\n",
      "Epoch 91/150\n",
      "71/71 - 0s - loss: 13.4159 - mse: 13.4159\n",
      "Epoch 92/150\n",
      "71/71 - 0s - loss: 12.9401 - mse: 12.9401\n",
      "Epoch 93/150\n",
      "71/71 - 0s - loss: 12.4802 - mse: 12.4802\n",
      "Epoch 94/150\n",
      "71/71 - 0s - loss: 11.5822 - mse: 11.5822\n",
      "Epoch 95/150\n",
      "71/71 - 0s - loss: 11.3358 - mse: 11.3358\n",
      "Epoch 96/150\n",
      "71/71 - 0s - loss: 11.4197 - mse: 11.4197\n",
      "Epoch 97/150\n",
      "71/71 - 0s - loss: 10.8741 - mse: 10.8741\n",
      "Epoch 98/150\n",
      "71/71 - 0s - loss: 10.2957 - mse: 10.2957\n",
      "Epoch 99/150\n",
      "71/71 - 0s - loss: 10.0654 - mse: 10.0654\n",
      "Epoch 100/150\n",
      "71/71 - 0s - loss: 9.3478 - mse: 9.3478\n",
      "Epoch 101/150\n",
      "71/71 - 0s - loss: 8.9414 - mse: 8.9414\n",
      "Epoch 102/150\n",
      "71/71 - 0s - loss: 8.3434 - mse: 8.3434\n",
      "Epoch 103/150\n",
      "71/71 - 0s - loss: 8.3874 - mse: 8.3874\n",
      "Epoch 104/150\n",
      "71/71 - 0s - loss: 8.4118 - mse: 8.4118\n",
      "Epoch 105/150\n",
      "71/71 - 0s - loss: 7.6195 - mse: 7.6195\n",
      "Epoch 106/150\n",
      "71/71 - 0s - loss: 7.3059 - mse: 7.3059\n",
      "Epoch 107/150\n",
      "71/71 - 0s - loss: 7.0329 - mse: 7.0329\n",
      "Epoch 108/150\n",
      "71/71 - 0s - loss: 7.1246 - mse: 7.1246\n",
      "Epoch 109/150\n",
      "71/71 - 0s - loss: 6.2732 - mse: 6.2732\n",
      "Epoch 110/150\n",
      "71/71 - 0s - loss: 6.4311 - mse: 6.4311\n",
      "Epoch 111/150\n",
      "71/71 - 0s - loss: 5.8356 - mse: 5.8356\n",
      "Epoch 112/150\n",
      "71/71 - 0s - loss: 5.8643 - mse: 5.8643\n",
      "Epoch 113/150\n",
      "71/71 - 0s - loss: 5.3862 - mse: 5.3862\n",
      "Epoch 114/150\n",
      "71/71 - 0s - loss: 4.9478 - mse: 4.9478\n",
      "Epoch 115/150\n",
      "71/71 - 0s - loss: 5.4371 - mse: 5.4371\n",
      "Epoch 116/150\n",
      "71/71 - 0s - loss: 4.9904 - mse: 4.9904\n",
      "Epoch 117/150\n",
      "71/71 - 0s - loss: 4.4631 - mse: 4.4631\n",
      "Epoch 118/150\n",
      "71/71 - 0s - loss: 4.3890 - mse: 4.3890\n",
      "Epoch 119/150\n",
      "71/71 - 0s - loss: 4.2014 - mse: 4.2014\n",
      "Epoch 120/150\n",
      "71/71 - 0s - loss: 4.0122 - mse: 4.0122\n",
      "Epoch 121/150\n",
      "71/71 - 0s - loss: 4.0570 - mse: 4.0570\n",
      "Epoch 122/150\n",
      "71/71 - 0s - loss: 3.9677 - mse: 3.9677\n",
      "Epoch 123/150\n",
      "71/71 - 0s - loss: 3.7655 - mse: 3.7655\n",
      "Epoch 124/150\n",
      "71/71 - 0s - loss: 3.5076 - mse: 3.5076\n",
      "Epoch 125/150\n",
      "71/71 - 0s - loss: 3.4600 - mse: 3.4600\n",
      "Epoch 126/150\n",
      "71/71 - 0s - loss: 3.3028 - mse: 3.3028\n",
      "Epoch 127/150\n",
      "71/71 - 0s - loss: 2.9774 - mse: 2.9774\n",
      "Epoch 128/150\n",
      "71/71 - 0s - loss: 3.0288 - mse: 3.0288\n",
      "Epoch 129/150\n",
      "71/71 - 0s - loss: 3.0144 - mse: 3.0144\n",
      "Epoch 130/150\n",
      "71/71 - 0s - loss: 2.8135 - mse: 2.8135\n",
      "Epoch 131/150\n",
      "71/71 - 0s - loss: 2.5413 - mse: 2.5413\n",
      "Epoch 132/150\n",
      "71/71 - 0s - loss: 2.6462 - mse: 2.6462\n",
      "Epoch 133/150\n",
      "71/71 - 0s - loss: 2.3126 - mse: 2.3126\n",
      "Epoch 134/150\n",
      "71/71 - 0s - loss: 2.2904 - mse: 2.2904\n",
      "Epoch 135/150\n",
      "71/71 - 0s - loss: 2.1573 - mse: 2.1573\n",
      "Epoch 136/150\n",
      "71/71 - 0s - loss: 2.2260 - mse: 2.2260\n",
      "Epoch 137/150\n",
      "71/71 - 0s - loss: 2.2401 - mse: 2.2401\n",
      "Epoch 138/150\n",
      "71/71 - 0s - loss: 2.0547 - mse: 2.0547\n",
      "Epoch 139/150\n",
      "71/71 - 0s - loss: 2.0022 - mse: 2.0022\n",
      "Epoch 140/150\n",
      "71/71 - 0s - loss: 1.8916 - mse: 1.8916\n",
      "Epoch 141/150\n",
      "71/71 - 0s - loss: 1.8913 - mse: 1.8913\n",
      "Epoch 142/150\n",
      "71/71 - 0s - loss: 1.7869 - mse: 1.7869\n",
      "Epoch 143/150\n",
      "71/71 - 0s - loss: 1.9903 - mse: 1.9903\n",
      "Epoch 144/150\n",
      "71/71 - 0s - loss: 1.6245 - mse: 1.6245\n",
      "Epoch 145/150\n",
      "71/71 - 0s - loss: 1.6594 - mse: 1.6594\n",
      "Epoch 146/150\n",
      "71/71 - 0s - loss: 1.7249 - mse: 1.7249\n",
      "Epoch 147/150\n",
      "71/71 - 0s - loss: 1.8549 - mse: 1.8549\n",
      "Epoch 148/150\n",
      "71/71 - 0s - loss: 1.6869 - mse: 1.6869\n",
      "Epoch 149/150\n",
      "71/71 - 0s - loss: 1.5358 - mse: 1.5358\n",
      "Epoch 150/150\n",
      "71/71 - 0s - loss: 1.5836 - mse: 1.5836\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x00000144904AF9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 1s 3ms/step - loss: 188.9903 - mse: 188.9903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[188.99034118652344, 188.99034118652344]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=150, batch_size=4, verbose=2)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 32)                1312      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,401\n",
      "Trainable params: 2,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set prediction accuracy: 50.89 %\n",
      "test set prediction accuracy: 56.34 %\n"
     ]
    }
   ],
   "source": [
    "#평균 성능 테스트\n",
    "scores = 0\n",
    "mean=np.mean(Y, axis=0)\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= mean <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"train set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= mean <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"test set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### <오차범위 3>\n",
      "- train set prediction accuracy(+-3): 93.24 % <br>\n",
      "- test set prediction accuracy(+-3): 8.45 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 5>\n",
      "- train set prediction accuracy(+-5): 98.93 % <br>\n",
      "- test set prediction accuracy(+-5): 23.94 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 10>\n",
      "- train set prediction accuracy(+-10): 100.00 % <br>\n",
      "- test set prediction accuracy(+-10): 46.48 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 20>\n",
      "- train set prediction accuracy(+-20): 100.00 % <br>\n",
      "- test set prediction accuracy(+-20): 88.73 % <br>\n"
     ]
    }
   ],
   "source": [
    "######입력용#######\n",
    "\n",
    "#오차 범위 3 설정\n",
    "print('### <오차범위 3>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "print('### <오차범위 5>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "print('### <오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "print('### <오차범위 20>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (피검사 안하고 할 수 있는 수치)\n",
    "X1=psqi_df[['AGE','SEX','BMI_1','PSQI_TOTAL_1','Muscle_1','Fat_1_x','FatPercentage _1','WHR_1','SBP_1',\n",
    "            'DBP_1','HR_1','Waist_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1',\n",
    "            'PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1',\n",
    "            'PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','SEX','BMI_2','PSQI_TOTAL_2','Muscle_2','Fat_2_x','FatPercentage_2','WHR_2','SBP_2',\n",
    "            'DBP_2','HR_2','Waist_2','PSQI_C1_2','PSQI_C2_2','PSQI_C3_2','PSQI_C4_2','PSQI_C5_2','PSQI_C6_2','PSQI_C7_2',\n",
    "            'PSQI_Q1_2','PSQI_Q2_2','PSQI_Q3_2','PSQI_Q4_2',\n",
    "            'PSQI_Q5a_2','PSQI_Q5b_2','PSQI_Q5c_2','PSQI_Q5d_2','PSQI_Q5e_2','PSQI_Q5f_2','PSQI_Q5g_2','PSQI_Q5h_2','PSQI_Q5i_2','PSQI_Q5j_2',\n",
    "            'PSQI_Q6_2','PSQI_Q7_2','PSQI_Q8_2','PSQI_Q9_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281, 71)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((352, 37), (352, 1))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "71/71 - 1s - loss: 3461.4929 - mse: 3461.4929\n",
      "Epoch 2/150\n",
      "71/71 - 0s - loss: 2645.7688 - mse: 2645.7688\n",
      "Epoch 3/150\n",
      "71/71 - 0s - loss: 1487.6998 - mse: 1487.6998\n",
      "Epoch 4/150\n",
      "71/71 - 0s - loss: 595.7690 - mse: 595.7690\n",
      "Epoch 5/150\n",
      "71/71 - 0s - loss: 314.3575 - mse: 314.3575\n",
      "Epoch 6/150\n",
      "71/71 - 0s - loss: 249.4058 - mse: 249.4058\n",
      "Epoch 7/150\n",
      "71/71 - 0s - loss: 209.5905 - mse: 209.5905\n",
      "Epoch 8/150\n",
      "71/71 - 0s - loss: 187.2278 - mse: 187.2278\n",
      "Epoch 9/150\n",
      "71/71 - 0s - loss: 169.3305 - mse: 169.3305\n",
      "Epoch 10/150\n",
      "71/71 - 0s - loss: 152.9837 - mse: 152.9837\n",
      "Epoch 11/150\n",
      "71/71 - 0s - loss: 146.4853 - mse: 146.4853\n",
      "Epoch 12/150\n",
      "71/71 - 0s - loss: 137.8122 - mse: 137.8122\n",
      "Epoch 13/150\n",
      "71/71 - 0s - loss: 130.3012 - mse: 130.3012\n",
      "Epoch 14/150\n",
      "71/71 - 0s - loss: 123.0998 - mse: 123.0998\n",
      "Epoch 15/150\n",
      "71/71 - 0s - loss: 118.3086 - mse: 118.3086\n",
      "Epoch 16/150\n",
      "71/71 - 0s - loss: 114.1258 - mse: 114.1258\n",
      "Epoch 17/150\n",
      "71/71 - 0s - loss: 109.1127 - mse: 109.1127\n",
      "Epoch 18/150\n",
      "71/71 - 0s - loss: 106.1779 - mse: 106.1779\n",
      "Epoch 19/150\n",
      "71/71 - 0s - loss: 99.4820 - mse: 99.4820\n",
      "Epoch 20/150\n",
      "71/71 - 0s - loss: 97.2678 - mse: 97.2678\n",
      "Epoch 21/150\n",
      "71/71 - 0s - loss: 94.5362 - mse: 94.5362\n",
      "Epoch 22/150\n",
      "71/71 - 0s - loss: 91.4956 - mse: 91.4956\n",
      "Epoch 23/150\n",
      "71/71 - 0s - loss: 88.5271 - mse: 88.5271\n",
      "Epoch 24/150\n",
      "71/71 - 0s - loss: 87.3134 - mse: 87.3134\n",
      "Epoch 25/150\n",
      "71/71 - 0s - loss: 83.0359 - mse: 83.0359\n",
      "Epoch 26/150\n",
      "71/71 - 0s - loss: 82.5134 - mse: 82.5134\n",
      "Epoch 27/150\n",
      "71/71 - 0s - loss: 79.3907 - mse: 79.3907\n",
      "Epoch 28/150\n",
      "71/71 - 0s - loss: 77.6964 - mse: 77.6964\n",
      "Epoch 29/150\n",
      "71/71 - 0s - loss: 75.2468 - mse: 75.2468\n",
      "Epoch 30/150\n",
      "71/71 - 0s - loss: 74.7572 - mse: 74.7572\n",
      "Epoch 31/150\n",
      "71/71 - 0s - loss: 70.3876 - mse: 70.3876\n",
      "Epoch 32/150\n",
      "71/71 - 0s - loss: 70.7578 - mse: 70.7578\n",
      "Epoch 33/150\n",
      "71/71 - 0s - loss: 68.2594 - mse: 68.2594\n",
      "Epoch 34/150\n",
      "71/71 - 0s - loss: 67.5372 - mse: 67.5372\n",
      "Epoch 35/150\n",
      "71/71 - 0s - loss: 65.8681 - mse: 65.8681\n",
      "Epoch 36/150\n",
      "71/71 - 0s - loss: 64.9688 - mse: 64.9688\n",
      "Epoch 37/150\n",
      "71/71 - 0s - loss: 63.5100 - mse: 63.5100\n",
      "Epoch 38/150\n",
      "71/71 - 0s - loss: 62.2113 - mse: 62.2113\n",
      "Epoch 39/150\n",
      "71/71 - 0s - loss: 60.8287 - mse: 60.8287\n",
      "Epoch 40/150\n",
      "71/71 - 0s - loss: 59.3514 - mse: 59.3514\n",
      "Epoch 41/150\n",
      "71/71 - 0s - loss: 58.4814 - mse: 58.4814\n",
      "Epoch 42/150\n",
      "71/71 - 0s - loss: 56.9418 - mse: 56.9418\n",
      "Epoch 43/150\n",
      "71/71 - 0s - loss: 56.4682 - mse: 56.4682\n",
      "Epoch 44/150\n",
      "71/71 - 0s - loss: 55.2843 - mse: 55.2843\n",
      "Epoch 45/150\n",
      "71/71 - 0s - loss: 53.4734 - mse: 53.4734\n",
      "Epoch 46/150\n",
      "71/71 - 0s - loss: 52.8773 - mse: 52.8773\n",
      "Epoch 47/150\n",
      "71/71 - 0s - loss: 52.5255 - mse: 52.5255\n",
      "Epoch 48/150\n",
      "71/71 - 0s - loss: 51.8832 - mse: 51.8832\n",
      "Epoch 49/150\n",
      "71/71 - 0s - loss: 49.8701 - mse: 49.8701\n",
      "Epoch 50/150\n",
      "71/71 - 0s - loss: 48.9493 - mse: 48.9493\n",
      "Epoch 51/150\n",
      "71/71 - 0s - loss: 48.9493 - mse: 48.9493\n",
      "Epoch 52/150\n",
      "71/71 - 0s - loss: 46.7299 - mse: 46.7299\n",
      "Epoch 53/150\n",
      "71/71 - 0s - loss: 46.3875 - mse: 46.3875\n",
      "Epoch 54/150\n",
      "71/71 - 0s - loss: 45.9346 - mse: 45.9346\n",
      "Epoch 55/150\n",
      "71/71 - 0s - loss: 44.8844 - mse: 44.8844\n",
      "Epoch 56/150\n",
      "71/71 - 0s - loss: 43.4163 - mse: 43.4163\n",
      "Epoch 57/150\n",
      "71/71 - 0s - loss: 43.9307 - mse: 43.9307\n",
      "Epoch 58/150\n",
      "71/71 - 0s - loss: 42.1151 - mse: 42.1151\n",
      "Epoch 59/150\n",
      "71/71 - 0s - loss: 41.8274 - mse: 41.8274\n",
      "Epoch 60/150\n",
      "71/71 - 0s - loss: 40.9081 - mse: 40.9081\n",
      "Epoch 61/150\n",
      "71/71 - 0s - loss: 40.5420 - mse: 40.5420\n",
      "Epoch 62/150\n",
      "71/71 - 0s - loss: 39.2166 - mse: 39.2166\n",
      "Epoch 63/150\n",
      "71/71 - 0s - loss: 38.0834 - mse: 38.0834\n",
      "Epoch 64/150\n",
      "71/71 - 0s - loss: 38.9580 - mse: 38.9580\n",
      "Epoch 65/150\n",
      "71/71 - 0s - loss: 37.2361 - mse: 37.2361\n",
      "Epoch 66/150\n",
      "71/71 - 0s - loss: 37.0461 - mse: 37.0461\n",
      "Epoch 67/150\n",
      "71/71 - 0s - loss: 36.3529 - mse: 36.3529\n",
      "Epoch 68/150\n",
      "71/71 - 0s - loss: 36.0299 - mse: 36.0299\n",
      "Epoch 69/150\n",
      "71/71 - 0s - loss: 34.9165 - mse: 34.9165\n",
      "Epoch 70/150\n",
      "71/71 - 0s - loss: 33.6837 - mse: 33.6837\n",
      "Epoch 71/150\n",
      "71/71 - 0s - loss: 34.2104 - mse: 34.2104\n",
      "Epoch 72/150\n",
      "71/71 - 0s - loss: 32.4663 - mse: 32.4663\n",
      "Epoch 73/150\n",
      "71/71 - 0s - loss: 32.8216 - mse: 32.8216\n",
      "Epoch 74/150\n",
      "71/71 - 0s - loss: 31.5587 - mse: 31.5587\n",
      "Epoch 75/150\n",
      "71/71 - 0s - loss: 30.9975 - mse: 30.9975\n",
      "Epoch 76/150\n",
      "71/71 - 0s - loss: 30.8117 - mse: 30.8117\n",
      "Epoch 77/150\n",
      "71/71 - 0s - loss: 30.3043 - mse: 30.3043\n",
      "Epoch 78/150\n",
      "71/71 - 0s - loss: 30.2698 - mse: 30.2698\n",
      "Epoch 79/150\n",
      "71/71 - 0s - loss: 29.0608 - mse: 29.0608\n",
      "Epoch 80/150\n",
      "71/71 - 0s - loss: 28.0572 - mse: 28.0572\n",
      "Epoch 81/150\n",
      "71/71 - 0s - loss: 27.8494 - mse: 27.8494\n",
      "Epoch 82/150\n",
      "71/71 - 0s - loss: 27.6834 - mse: 27.6834\n",
      "Epoch 83/150\n",
      "71/71 - 0s - loss: 26.9910 - mse: 26.9910\n",
      "Epoch 84/150\n",
      "71/71 - 0s - loss: 26.7956 - mse: 26.7956\n",
      "Epoch 85/150\n",
      "71/71 - 0s - loss: 25.8141 - mse: 25.8141\n",
      "Epoch 86/150\n",
      "71/71 - 0s - loss: 25.6904 - mse: 25.6904\n",
      "Epoch 87/150\n",
      "71/71 - 0s - loss: 25.0755 - mse: 25.0755\n",
      "Epoch 88/150\n",
      "71/71 - 0s - loss: 24.5388 - mse: 24.5388\n",
      "Epoch 89/150\n",
      "71/71 - 0s - loss: 24.1644 - mse: 24.1644\n",
      "Epoch 90/150\n",
      "71/71 - 0s - loss: 23.6461 - mse: 23.6461\n",
      "Epoch 91/150\n",
      "71/71 - 0s - loss: 23.6218 - mse: 23.6218\n",
      "Epoch 92/150\n",
      "71/71 - 0s - loss: 22.6389 - mse: 22.6389\n",
      "Epoch 93/150\n",
      "71/71 - 0s - loss: 22.0395 - mse: 22.0395\n",
      "Epoch 94/150\n",
      "71/71 - 0s - loss: 21.8554 - mse: 21.8554\n",
      "Epoch 95/150\n",
      "71/71 - 0s - loss: 21.2472 - mse: 21.2472\n",
      "Epoch 96/150\n",
      "71/71 - 0s - loss: 20.8826 - mse: 20.8826\n",
      "Epoch 97/150\n",
      "71/71 - 0s - loss: 20.6073 - mse: 20.6073\n",
      "Epoch 98/150\n",
      "71/71 - 0s - loss: 20.4932 - mse: 20.4932\n",
      "Epoch 99/150\n",
      "71/71 - 0s - loss: 19.6007 - mse: 19.6007\n",
      "Epoch 100/150\n",
      "71/71 - 0s - loss: 19.5940 - mse: 19.5940\n",
      "Epoch 101/150\n",
      "71/71 - 0s - loss: 18.7861 - mse: 18.7861\n",
      "Epoch 102/150\n",
      "71/71 - 0s - loss: 19.0236 - mse: 19.0236\n",
      "Epoch 103/150\n",
      "71/71 - 0s - loss: 17.9674 - mse: 17.9674\n",
      "Epoch 104/150\n",
      "71/71 - 0s - loss: 17.3353 - mse: 17.3353\n",
      "Epoch 105/150\n",
      "71/71 - 0s - loss: 17.4779 - mse: 17.4779\n",
      "Epoch 106/150\n",
      "71/71 - 0s - loss: 16.7167 - mse: 16.7167\n",
      "Epoch 107/150\n",
      "71/71 - 0s - loss: 16.7185 - mse: 16.7185\n",
      "Epoch 108/150\n",
      "71/71 - 0s - loss: 15.7405 - mse: 15.7405\n",
      "Epoch 109/150\n",
      "71/71 - 0s - loss: 15.8580 - mse: 15.8580\n",
      "Epoch 110/150\n",
      "71/71 - 0s - loss: 15.8732 - mse: 15.8732\n",
      "Epoch 111/150\n",
      "71/71 - 0s - loss: 14.7056 - mse: 14.7056\n",
      "Epoch 112/150\n",
      "71/71 - 0s - loss: 14.6544 - mse: 14.6544\n",
      "Epoch 113/150\n",
      "71/71 - 0s - loss: 13.8939 - mse: 13.8939\n",
      "Epoch 114/150\n",
      "71/71 - 0s - loss: 14.0503 - mse: 14.0503\n",
      "Epoch 115/150\n",
      "71/71 - 0s - loss: 14.0693 - mse: 14.0693\n",
      "Epoch 116/150\n",
      "71/71 - 0s - loss: 13.0687 - mse: 13.0687\n",
      "Epoch 117/150\n",
      "71/71 - 0s - loss: 12.5389 - mse: 12.5389\n",
      "Epoch 118/150\n",
      "71/71 - 0s - loss: 12.6947 - mse: 12.6947\n",
      "Epoch 119/150\n",
      "71/71 - 0s - loss: 11.9823 - mse: 11.9823\n",
      "Epoch 120/150\n",
      "71/71 - 0s - loss: 12.3994 - mse: 12.3994\n",
      "Epoch 121/150\n",
      "71/71 - 0s - loss: 11.2822 - mse: 11.2822\n",
      "Epoch 122/150\n",
      "71/71 - 0s - loss: 11.2984 - mse: 11.2984\n",
      "Epoch 123/150\n",
      "71/71 - 0s - loss: 11.0652 - mse: 11.0652\n",
      "Epoch 124/150\n",
      "71/71 - 0s - loss: 10.8500 - mse: 10.8500\n",
      "Epoch 125/150\n",
      "71/71 - 0s - loss: 10.6952 - mse: 10.6952\n",
      "Epoch 126/150\n",
      "71/71 - 0s - loss: 10.4478 - mse: 10.4478\n",
      "Epoch 127/150\n",
      "71/71 - 0s - loss: 10.0774 - mse: 10.0774\n",
      "Epoch 128/150\n",
      "71/71 - 0s - loss: 9.5511 - mse: 9.5511\n",
      "Epoch 129/150\n",
      "71/71 - 0s - loss: 9.0561 - mse: 9.0561\n",
      "Epoch 130/150\n",
      "71/71 - 0s - loss: 9.6708 - mse: 9.6708\n",
      "Epoch 131/150\n",
      "71/71 - 0s - loss: 9.3287 - mse: 9.3287\n",
      "Epoch 132/150\n",
      "71/71 - 0s - loss: 8.8134 - mse: 8.8134\n",
      "Epoch 133/150\n",
      "71/71 - 0s - loss: 8.7654 - mse: 8.7654\n",
      "Epoch 134/150\n",
      "71/71 - 0s - loss: 8.5634 - mse: 8.5634\n",
      "Epoch 135/150\n",
      "71/71 - 0s - loss: 7.7944 - mse: 7.7944\n",
      "Epoch 136/150\n",
      "71/71 - 0s - loss: 8.0567 - mse: 8.0567\n",
      "Epoch 137/150\n",
      "71/71 - 0s - loss: 7.7786 - mse: 7.7786\n",
      "Epoch 138/150\n",
      "71/71 - 0s - loss: 7.7815 - mse: 7.7815\n",
      "Epoch 139/150\n",
      "71/71 - 0s - loss: 7.5463 - mse: 7.5463\n",
      "Epoch 140/150\n",
      "71/71 - 0s - loss: 7.0054 - mse: 7.0054\n",
      "Epoch 141/150\n",
      "71/71 - 0s - loss: 7.1588 - mse: 7.1588\n",
      "Epoch 142/150\n",
      "71/71 - 0s - loss: 6.9539 - mse: 6.9539\n",
      "Epoch 143/150\n",
      "71/71 - 0s - loss: 7.2490 - mse: 7.2490\n",
      "Epoch 144/150\n",
      "71/71 - 0s - loss: 6.4608 - mse: 6.4608\n",
      "Epoch 145/150\n",
      "71/71 - 0s - loss: 6.0612 - mse: 6.0612\n",
      "Epoch 146/150\n",
      "71/71 - 0s - loss: 6.6173 - mse: 6.6173\n",
      "Epoch 147/150\n",
      "71/71 - 0s - loss: 6.3599 - mse: 6.3599\n",
      "Epoch 148/150\n",
      "71/71 - 0s - loss: 5.7025 - mse: 5.7025\n",
      "Epoch 149/150\n",
      "71/71 - 0s - loss: 6.1396 - mse: 6.1396\n",
      "Epoch 150/150\n",
      "71/71 - 0s - loss: 5.9734 - mse: 5.9734\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 228.2457 - mse: 228.2457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[228.2456817626953, 228.2456817626953]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=150, batch_size=4, verbose=2)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 32)                1216      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,305\n",
      "Trainable params: 2,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set prediction accuracy: 50.89 %\n",
      "test set prediction accuracy: 56.34 %\n"
     ]
    }
   ],
   "source": [
    "#평균 성능 테스트\n",
    "scores = 0\n",
    "mean=np.mean(Y, axis=0)\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= mean <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"train set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= mean <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"test set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### <오차범위 3>\n",
      "- train set prediction accuracy(+-3): 86.12 % <br>\n",
      "- test set prediction accuracy(+-3): 14.08 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 5>\n",
      "- train set prediction accuracy(+-5): 95.37 % <br>\n",
      "- test set prediction accuracy(+-5): 23.94 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 10>\n",
      "- train set prediction accuracy(+-10): 99.64 % <br>\n",
      "- test set prediction accuracy(+-10): 56.34 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 20>\n",
      "- train set prediction accuracy(+-20): 100.00 % <br>\n",
      "- test set prediction accuracy(+-20): 83.10 % <br>\n"
     ]
    }
   ],
   "source": [
    "######입력용#######\n",
    "\n",
    "#오차 범위 3 설정\n",
    "print('### <오차범위 3>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "print('### <오차범위 5>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "print('### <오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "print('### <오차범위 20>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다쓴거\n",
    "### <오차범위 3>\n",
    "- train_all set prediction accuracy(+-3): 88.89 % <br>\n",
    "- test_all set prediction accuracy(+-3): 31.94 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 5>\n",
    "- train_all set prediction accuracy(+-5): 96.53 % <br>\n",
    "- test_all set prediction accuracy(+-5): 55.56 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 10>\n",
    "- train_all set prediction accuracy(+-10): 100.00 % <br>\n",
    "- test_all set prediction accuracy(+-10): 83.33 % <br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다안쓴거\n",
    "### <오차범위 3>\n",
    "- train_some set prediction accuracy(+-3): 32.99 % <br>\n",
    "- test_some set prediction accuracy(+-3): 27.78 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 5>\n",
    "- train_some set prediction accuracy(+-5): 54.86 % <br>\n",
    "- test_some set prediction accuracy(+-5): 40.28 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 10>\n",
    "- train_some set prediction accuracy(+-10): 82.29 % <br>\n",
    "- test_some set prediction accuracy(+-10): 59.72 % <br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

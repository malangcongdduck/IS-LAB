{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FONT 깨질때 폰트깨질때\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname = \"C:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font',family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sample_ID GROUP  COHORT SEX  AGE     Trait FitbitOX      Fitbit_ID  HTN  \\\n",
      "0         S0001   SMI       2   M   60  fitbit_O        O  sevrance00001  NaN   \n",
      "1         S0002   SMI       2   M   61  fitbit_O        O  sevrance00002  NaN   \n",
      "2         S0003   SMI       2   F   52  fitbit_O        O  sevrance00003  NaN   \n",
      "3         S0004   SMI       2   F   41  fitbit_O        O  sevrance00004  NaN   \n",
      "4         S0005   SMI       2   F   41  fitbit_O        O  sevrance00005  NaN   \n",
      "..          ...   ...     ...  ..  ...       ...      ...            ...  ...   \n",
      "383  MetS_S0280  MetS       1   F   24  fitbit_O        O   gnfmmets+139  NaN   \n",
      "384  MetS_S0281  MetS       1   F   44  fitbit_O        O   gnfmmets+140  NaN   \n",
      "385  MetS_S0282  MetS       1   F   37  fitbit_O        O   gnfmmets+141  1.0   \n",
      "386  MetS_S0283  MetS       1   M   51  fitbit_X        X              X  NaN   \n",
      "387  MetS_S0284  MetS       1   F   42  fitbit_X        X              X  NaN   \n",
      "\n",
      "      DM  ...  BDI_Q13_2 BDI_Q14_2  BDI_Q15_2  BDI_Q16_2 BDI_Q17_2 BDI_Q18_2  \\\n",
      "0    NaN  ...        1.0       1.0        1.0        2.0       1.0       1.0   \n",
      "1    1.0  ...        1.0       1.0        1.0        1.0       2.0       1.0   \n",
      "2    NaN  ...        1.0       1.0        1.0        1.0       1.0       1.0   \n",
      "3    NaN  ...        2.0       2.0        2.0        2.0       2.0       2.0   \n",
      "4    NaN  ...        2.0       1.0        2.0        2.0       2.0       1.0   \n",
      "..   ...  ...        ...       ...        ...        ...       ...       ...   \n",
      "383  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "384  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "385  1.0  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "386  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "387  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "\n",
      "     BDI_Q19_2  BDI_Q20_2  BDI_Q21_2  Diet_2  \n",
      "0          2.0        1.0        2.0     2.0  \n",
      "1          1.0        1.0        1.0     2.0  \n",
      "2          1.0        2.0        4.0     1.0  \n",
      "3          1.0        1.0        1.0     2.0  \n",
      "4          1.0        2.0        1.0     2.0  \n",
      "..         ...        ...        ...     ...  \n",
      "383        NaN        NaN        NaN     NaN  \n",
      "384        NaN        NaN        NaN     NaN  \n",
      "385        NaN        NaN        NaN     NaN  \n",
      "386        NaN        NaN        NaN     NaN  \n",
      "387        NaN        NaN        NaN     NaN  \n",
      "\n",
      "[388 rows x 3527 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('./최종 데이터 그래프그리기용.xlsx') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df=df[['Sample_ID','GROUP','COHORT','SEX','AGE','Insulin _1','FatPercentage _1','TG_1','BMI_1','AST_1','BUN_1','HDL_1','DBP_1','Waist_1','SBP_1','Fat_1_x','LDL_1',\n",
    "            'PSQI_TOTAL_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1',\n",
    "              'Insulin _2','FatPercentage_2','TG_2','BMI_2','AST_2','BUN_2','HDL_2','DBP_2','Waist_2','SBP_2','Fat_2_x','LDL_2',\n",
    "            'PSQI_TOTAL_2','PSQI_C1_2','PSQI_C2_2','PSQI_C3_2','PSQI_C4_2','PSQI_C5_2','PSQI_C6_2','PSQI_C7_2','PSQI_Q1_2','PSQI_Q2_2','PSQI_Q3_2','PSQI_Q4_2',\n",
    "            'PSQI_Q5a_2','PSQI_Q5b_2','PSQI_Q5c_2','PSQI_Q5d_2','PSQI_Q5e_2','PSQI_Q5f_2','PSQI_Q5g_2','PSQI_Q5h_2','PSQI_Q5i_2','PSQI_Q5j_2','PSQI_Q6_2','PSQI_Q7_2','PSQI_Q8_2','PSQI_Q9_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>FatPercentage _1</th>\n",
       "      <th>TG_1</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>AST_1</th>\n",
       "      <th>...</th>\n",
       "      <th>PSQI_Q5e_2</th>\n",
       "      <th>PSQI_Q5f_2</th>\n",
       "      <th>PSQI_Q5g_2</th>\n",
       "      <th>PSQI_Q5h_2</th>\n",
       "      <th>PSQI_Q5i_2</th>\n",
       "      <th>PSQI_Q5j_2</th>\n",
       "      <th>PSQI_Q6_2</th>\n",
       "      <th>PSQI_Q7_2</th>\n",
       "      <th>PSQI_Q8_2</th>\n",
       "      <th>PSQI_Q9_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>60</td>\n",
       "      <td>7.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>81</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>61</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.5</td>\n",
       "      <td>106</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>5.1</td>\n",
       "      <td>39.1</td>\n",
       "      <td>231</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>4.2</td>\n",
       "      <td>29.1</td>\n",
       "      <td>94</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>3.2</td>\n",
       "      <td>24.6</td>\n",
       "      <td>70</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>24</td>\n",
       "      <td>11.3</td>\n",
       "      <td>34.4</td>\n",
       "      <td>51</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>44</td>\n",
       "      <td>10.6</td>\n",
       "      <td>43.8</td>\n",
       "      <td>104</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>12.2</td>\n",
       "      <td>35.8</td>\n",
       "      <td>128</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>10.4</td>\n",
       "      <td>26.8</td>\n",
       "      <td>163</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>42</td>\n",
       "      <td>10.1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>90</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT SEX  AGE Insulin _1  FatPercentage _1  TG_1  \\\n",
       "0         S0001   SMI       2   M   60        7.7              15.0    81   \n",
       "1         S0002   SMI       2   M   61        5.4              29.5   106   \n",
       "2         S0003   SMI       2   F   52        5.1              39.1   231   \n",
       "3         S0004   SMI       2   F   41        4.2              29.1    94   \n",
       "4         S0005   SMI       2   F   41        3.2              24.6    70   \n",
       "..          ...   ...     ...  ..  ...        ...               ...   ...   \n",
       "383  MetS_S0280  MetS       1   F   24       11.3              34.4    51   \n",
       "384  MetS_S0281  MetS       1   F   44       10.6              43.8   104   \n",
       "385  MetS_S0282  MetS       1   F   37       12.2              35.8   128   \n",
       "386  MetS_S0283  MetS       1   M   51       10.4              26.8   163   \n",
       "387  MetS_S0284  MetS       1   F   42       10.1              32.6    90   \n",
       "\n",
       "         BMI_1  AST_1  ...  PSQI_Q5e_2  PSQI_Q5f_2  PSQI_Q5g_2  PSQI_Q5h_2  \\\n",
       "0    21.110190   21.0  ...         0.0         0.0         0.0         1.0   \n",
       "1    27.782064   29.0  ...         3.0         0.0         2.0         0.0   \n",
       "2    24.944742   16.0  ...         3.0         0.0         3.0         0.0   \n",
       "3    22.620489   16.0  ...         1.0         0.0         0.0         0.0   \n",
       "4    20.524157   26.0  ...         0.0         0.0         0.0         1.0   \n",
       "..         ...    ...  ...         ...         ...         ...         ...   \n",
       "383  34.803410   14.0  ...         NaN         NaN         NaN         NaN   \n",
       "384  30.903615   27.0  ...         NaN         NaN         NaN         NaN   \n",
       "385  28.676533   61.0  ...         NaN         NaN         NaN         NaN   \n",
       "386  24.549738   81.0  ...         NaN         NaN         NaN         NaN   \n",
       "387  24.605921   32.0  ...         NaN         NaN         NaN         NaN   \n",
       "\n",
       "     PSQI_Q5i_2  PSQI_Q5j_2  PSQI_Q6_2  PSQI_Q7_2  PSQI_Q8_2  PSQI_Q9_2  \n",
       "0           0.0         0.0        1.0        0.0        1.0        0.0  \n",
       "1           0.0         0.0        1.0        0.0        2.0        1.0  \n",
       "2           0.0         0.0        1.0        0.0        2.0        0.0  \n",
       "3           0.0         0.0        1.0        0.0        2.0        1.0  \n",
       "4           1.0         1.0        3.0        0.0        2.0        1.0  \n",
       "..          ...         ...        ...        ...        ...        ...  \n",
       "383         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "384         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "385         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "386         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "387         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "\n",
       "[388 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>FatPercentage _1</th>\n",
       "      <th>TG_1</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>AST_1</th>\n",
       "      <th>...</th>\n",
       "      <th>PSQI_Q5e_2</th>\n",
       "      <th>PSQI_Q5f_2</th>\n",
       "      <th>PSQI_Q5g_2</th>\n",
       "      <th>PSQI_Q5h_2</th>\n",
       "      <th>PSQI_Q5i_2</th>\n",
       "      <th>PSQI_Q5j_2</th>\n",
       "      <th>PSQI_Q6_2</th>\n",
       "      <th>PSQI_Q7_2</th>\n",
       "      <th>PSQI_Q8_2</th>\n",
       "      <th>PSQI_Q9_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>60</td>\n",
       "      <td>7.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>81</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>61</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.5</td>\n",
       "      <td>106</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>5.1</td>\n",
       "      <td>39.1</td>\n",
       "      <td>231</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>4.2</td>\n",
       "      <td>29.1</td>\n",
       "      <td>94</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>3.2</td>\n",
       "      <td>24.6</td>\n",
       "      <td>70</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>24</td>\n",
       "      <td>11.3</td>\n",
       "      <td>34.4</td>\n",
       "      <td>51</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>44</td>\n",
       "      <td>10.6</td>\n",
       "      <td>43.8</td>\n",
       "      <td>104</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>12.2</td>\n",
       "      <td>35.8</td>\n",
       "      <td>128</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>10.4</td>\n",
       "      <td>26.8</td>\n",
       "      <td>163</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>42</td>\n",
       "      <td>10.1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>90</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT SEX  AGE Insulin _1  FatPercentage _1  TG_1  \\\n",
       "0         S0001   SMI       2   M   60        7.7              15.0    81   \n",
       "1         S0002   SMI       2   M   61        5.4              29.5   106   \n",
       "2         S0003   SMI       2   F   52        5.1              39.1   231   \n",
       "3         S0004   SMI       2   F   41        4.2              29.1    94   \n",
       "4         S0005   SMI       2   F   41        3.2              24.6    70   \n",
       "..          ...   ...     ...  ..  ...        ...               ...   ...   \n",
       "383  MetS_S0280  MetS       1   F   24       11.3              34.4    51   \n",
       "384  MetS_S0281  MetS       1   F   44       10.6              43.8   104   \n",
       "385  MetS_S0282  MetS       1   F   37       12.2              35.8   128   \n",
       "386  MetS_S0283  MetS       1   M   51       10.4              26.8   163   \n",
       "387  MetS_S0284  MetS       1   F   42       10.1              32.6    90   \n",
       "\n",
       "         BMI_1  AST_1  ...  PSQI_Q5e_2  PSQI_Q5f_2  PSQI_Q5g_2  PSQI_Q5h_2  \\\n",
       "0    21.110190   21.0  ...         0.0         0.0         0.0         1.0   \n",
       "1    27.782064   29.0  ...         3.0         0.0         2.0         0.0   \n",
       "2    24.944742   16.0  ...         3.0         0.0         3.0         0.0   \n",
       "3    22.620489   16.0  ...         1.0         0.0         0.0         0.0   \n",
       "4    20.524157   26.0  ...         0.0         0.0         0.0         1.0   \n",
       "..         ...    ...  ...         ...         ...         ...         ...   \n",
       "383  34.803410   14.0  ...         NaN         NaN         NaN         NaN   \n",
       "384  30.903615   27.0  ...         NaN         NaN         NaN         NaN   \n",
       "385  28.676533   61.0  ...         NaN         NaN         NaN         NaN   \n",
       "386  24.549738   81.0  ...         NaN         NaN         NaN         NaN   \n",
       "387  24.605921   32.0  ...         NaN         NaN         NaN         NaN   \n",
       "\n",
       "     PSQI_Q5i_2  PSQI_Q5j_2  PSQI_Q6_2  PSQI_Q7_2  PSQI_Q8_2  PSQI_Q9_2  \n",
       "0           0.0         0.0        1.0        0.0        1.0        0.0  \n",
       "1           0.0         0.0        1.0        0.0        2.0        1.0  \n",
       "2           0.0         0.0        1.0        0.0        2.0        0.0  \n",
       "3           0.0         0.0        1.0        0.0        2.0        1.0  \n",
       "4           1.0         1.0        3.0        0.0        2.0        1.0  \n",
       "..          ...         ...        ...        ...        ...        ...  \n",
       "383         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "384         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "385         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "386         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "387         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "\n",
       "[317 rows x 81 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#보조 호르몬 요법을 받고 있는 Cohort 3 제거 Filter 적용\n",
    "psqi_df = psqi_df[(psqi_df['COHORT'] != 3)]\n",
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df=psqi_df.dropna()\n",
    "psqi_df.reset_index(drop=True, inplace=True)\n",
    "psqi_df.isnull().sum()\n",
    "psqi_df=psqi_df.drop([\"Sample_ID\", \"GROUP\", \"COHORT\"],axis=1)\n",
    "#1분, 매일다름, 정해진간이없음 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"SEX\"] = psqi_df[\"SEX\"].apply(lambda x: 1. if x=='M' else 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"Insulin _1\"] = psqi_df[\"Insulin _1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)\n",
    "psqi_df[\"Insulin _2\"] = psqi_df[\"Insulin _1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>FatPercentage _1</th>\n",
       "      <th>TG_1</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>AST_1</th>\n",
       "      <th>BUN_1</th>\n",
       "      <th>HDL_1</th>\n",
       "      <th>DBP_1</th>\n",
       "      <th>...</th>\n",
       "      <th>PSQI_Q5e_2</th>\n",
       "      <th>PSQI_Q5f_2</th>\n",
       "      <th>PSQI_Q5g_2</th>\n",
       "      <th>PSQI_Q5h_2</th>\n",
       "      <th>PSQI_Q5i_2</th>\n",
       "      <th>PSQI_Q5j_2</th>\n",
       "      <th>PSQI_Q6_2</th>\n",
       "      <th>PSQI_Q7_2</th>\n",
       "      <th>PSQI_Q8_2</th>\n",
       "      <th>PSQI_Q9_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>176.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.306818</td>\n",
       "      <td>38.107955</td>\n",
       "      <td>7.715909</td>\n",
       "      <td>29.548523</td>\n",
       "      <td>105.295455</td>\n",
       "      <td>23.787859</td>\n",
       "      <td>22.783295</td>\n",
       "      <td>13.456818</td>\n",
       "      <td>60.755682</td>\n",
       "      <td>75.210227</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488636</td>\n",
       "      <td>0.119318</td>\n",
       "      <td>0.164773</td>\n",
       "      <td>0.278409</td>\n",
       "      <td>0.397727</td>\n",
       "      <td>0.261364</td>\n",
       "      <td>1.056818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.443182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.462489</td>\n",
       "      <td>11.451001</td>\n",
       "      <td>4.133429</td>\n",
       "      <td>6.793497</td>\n",
       "      <td>90.584787</td>\n",
       "      <td>4.980203</td>\n",
       "      <td>9.643329</td>\n",
       "      <td>3.504358</td>\n",
       "      <td>14.626101</td>\n",
       "      <td>10.480246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925750</td>\n",
       "      <td>0.456661</td>\n",
       "      <td>0.535706</td>\n",
       "      <td>0.592129</td>\n",
       "      <td>0.842307</td>\n",
       "      <td>0.676027</td>\n",
       "      <td>0.542122</td>\n",
       "      <td>0.444300</td>\n",
       "      <td>0.819883</td>\n",
       "      <td>0.602053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>13.100000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>15.231576</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>4.975000</td>\n",
       "      <td>24.400000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>20.833309</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>11.275000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>67.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>29.300000</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>23.351473</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>12.900000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>9.505000</td>\n",
       "      <td>33.925000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>25.502662</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>15.025000</td>\n",
       "      <td>69.500000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>49.800000</td>\n",
       "      <td>936.000000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>38.900000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              SEX         AGE  Insulin _1  FatPercentage _1        TG_1  \\\n",
       "count  176.000000  176.000000  176.000000        176.000000  176.000000   \n",
       "mean     0.306818   38.107955    7.715909         29.548523  105.295455   \n",
       "std      0.462489   11.451001    4.133429          6.793497   90.584787   \n",
       "min      0.000000   20.000000    0.100000         13.100000   38.000000   \n",
       "25%      0.000000   29.000000    4.975000         24.400000   61.000000   \n",
       "50%      0.000000   35.000000    6.600000         29.300000   84.500000   \n",
       "75%      1.000000   46.000000    9.505000         33.925000  123.000000   \n",
       "max      1.000000   63.000000   24.700000         49.800000  936.000000   \n",
       "\n",
       "            BMI_1       AST_1       BUN_1       HDL_1       DBP_1  ...  \\\n",
       "count  176.000000  176.000000  176.000000  176.000000  176.000000  ...   \n",
       "mean    23.787859   22.783295   13.456818   60.755682   75.210227  ...   \n",
       "std      4.980203    9.643329    3.504358   14.626101   10.480246  ...   \n",
       "min     15.231576    0.860000    7.700000   28.000000   50.000000  ...   \n",
       "25%     20.833309   18.000000   11.275000   50.000000   67.750000  ...   \n",
       "50%     23.351473   21.000000   12.900000   58.000000   74.000000  ...   \n",
       "75%     25.502662   25.000000   15.025000   69.500000   82.000000  ...   \n",
       "max     67.500000   91.000000   38.900000  114.000000  123.000000  ...   \n",
       "\n",
       "       PSQI_Q5e_2  PSQI_Q5f_2  PSQI_Q5g_2  PSQI_Q5h_2  PSQI_Q5i_2  PSQI_Q5j_2  \\\n",
       "count  176.000000  176.000000  176.000000  176.000000  176.000000  176.000000   \n",
       "mean     0.488636    0.119318    0.164773    0.278409    0.397727    0.261364   \n",
       "std      0.925750    0.456661    0.535706    0.592129    0.842307    0.676027   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.250000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      3.000000    3.000000    3.000000    3.000000    3.000000    3.000000   \n",
       "\n",
       "        PSQI_Q6_2   PSQI_Q7_2   PSQI_Q8_2   PSQI_Q9_2  \n",
       "count  176.000000  176.000000  176.000000  176.000000  \n",
       "mean     1.056818    0.090909    0.454545    0.443182  \n",
       "std      0.542122    0.444300    0.819883    0.602053  \n",
       "min      0.000000    0.000000    0.000000    0.000000  \n",
       "25%      1.000000    0.000000    0.000000    0.000000  \n",
       "50%      1.000000    0.000000    0.000000    0.000000  \n",
       "75%      1.000000    0.000000    1.000000    1.000000  \n",
       "max      3.000000    3.000000    3.000000    3.000000  \n",
       "\n",
       "[8 rows x 77 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    122\n",
       "1.0     54\n",
       "Name: SEX, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df[\"SEX\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#x 배열 생성 (x=임의+선별)\n",
    "#선별: 'AGE','HDL_1','DBP_1','Waist_1','SBP_1','Fat_1_x','Insulin _1','FatPercentage _1','LDL_1','AST_1','BUN_1'\n",
    "X1=psqi_df[['AGE','LDL_1','DBP_1','Waist_1','SBP_1','Fat_1_x','Insulin _1','FatPercentage _1','AST_1','BUN_1','BMI_1','TG_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','LDL_2','DBP_2','Waist_2','SBP_2','Fat_2_x','Insulin _2','FatPercentage_2','AST_2','BUN_2','BMI_2','TG_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (x=임의+선별+PSQI)\n",
    "X1=psqi_df[['AGE','LDL_1','DBP_1','Waist_1','Insulin _1','SBP_1','Fat_1_x','TG_1','FatPercentage _1','AST_1','BUN_1','BMI_1',\n",
    "            'PSQI_TOTAL_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','LDL_2','DBP_2','Waist_2','Insulin _2','SBP_2','Fat_2_x','TG_2','FatPercentage_2','AST_2','BUN_2','BMI_2',\n",
    "            'PSQI_TOTAL_2','PSQI_C1_2','PSQI_C2_2','PSQI_C3_2','PSQI_C4_2','PSQI_C5_2','PSQI_C6_2','PSQI_C7_2','PSQI_Q1_2','PSQI_Q2_2','PSQI_Q3_2','PSQI_Q4_2',\n",
    "            'PSQI_Q5a_2','PSQI_Q5b_2','PSQI_Q5c_2','PSQI_Q5d_2','PSQI_Q5e_2','PSQI_Q5f_2','PSQI_Q5g_2','PSQI_Q5h_2','PSQI_Q5i_2','PSQI_Q5j_2','PSQI_Q6_2','PSQI_Q7_2','PSQI_Q8_2','PSQI_Q9_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#x 배열 생성 (x=AGE, SEX, PSQI, BMI, Waist, Fat, FatPercentage)\n",
    "X1=psqi_df[['AGE','SEX','BMI_1','Waist_1','Fat_1_x','FatPercentage _1',\n",
    "           'PSQI_TOTAL_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','SEX','BMI_2','Waist_2','Fat_2_x','FatPercentage_2',\n",
    "           'PSQI_TOTAL_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (x=AGE, SEX, PSQI, BMI)\n",
    "X1=psqi_df[['AGE','SEX','BMI_1',\n",
    "           'PSQI_TOTAL_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','SEX','BMI_2',\n",
    "           'PSQI_TOTAL_2','PSQI_C1_2','PSQI_C2_2','PSQI_C3_2','PSQI_C4_2','PSQI_C5_2','PSQI_C6_2','PSQI_C7_2','PSQI_Q1_2','PSQI_Q2_2','PSQI_Q3_2','PSQI_Q4_2',\n",
    "            'PSQI_Q5a_2','PSQI_Q5b_2','PSQI_Q5c_2','PSQI_Q5d_2','PSQI_Q5e_2','PSQI_Q5f_2','PSQI_Q5g_2','PSQI_Q5h_2','PSQI_Q5i_2','PSQI_Q5j_2','PSQI_Q6_2','PSQI_Q7_2','PSQI_Q8_2','PSQI_Q9_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 352)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((352, 29), (352, 1))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((352, 29), (352, 1))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "71/71 [==============================] - 1s 2ms/step - loss: 3507.2476 - mse: 3507.2476\n",
      "Epoch 2/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 2764.3108 - mse: 2764.3108\n",
      "Epoch 3/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 1665.5316 - mse: 1665.5316\n",
      "Epoch 4/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 763.9295 - mse: 763.9295\n",
      "Epoch 5/150\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 445.7760 - mse: 445.7760\n",
      "Epoch 6/150\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 339.6848 - mse: 339.6848\n",
      "Epoch 7/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 275.6596 - mse: 275.6596\n",
      "Epoch 8/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 240.3865 - mse: 240.3865\n",
      "Epoch 9/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 214.8790 - mse: 214.8790\n",
      "Epoch 10/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 199.6272 - mse: 199.6272\n",
      "Epoch 11/150\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 185.8285 - mse: 185.8285\n",
      "Epoch 12/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 176.3955 - mse: 176.3955\n",
      "Epoch 13/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 167.6705 - mse: 167.6705\n",
      "Epoch 14/150\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 161.9641 - mse: 161.9641\n",
      "Epoch 15/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 156.2301 - mse: 156.2301\n",
      "Epoch 16/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 150.6310 - mse: 150.6310\n",
      "Epoch 17/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 147.6698 - mse: 147.6698\n",
      "Epoch 18/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 144.1446 - mse: 144.1446A: 0s - loss: 144.1917 - mse: 144.191\n",
      "Epoch 19/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 140.2917 - mse: 140.2917\n",
      "Epoch 20/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 136.2695 - mse: 136.2695\n",
      "Epoch 21/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 132.0901 - mse: 132.0901\n",
      "Epoch 22/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 130.1293 - mse: 130.1293\n",
      "Epoch 23/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 126.8360 - mse: 126.8360\n",
      "Epoch 24/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 124.0249 - mse: 124.0249\n",
      "Epoch 25/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 123.1301 - mse: 123.1301\n",
      "Epoch 26/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 119.0849 - mse: 119.0849\n",
      "Epoch 27/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 117.2343 - mse: 117.2343\n",
      "Epoch 28/150\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 114.8869 - mse: 114.8869\n",
      "Epoch 29/150\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 110.9197 - mse: 110.9197\n",
      "Epoch 30/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 109.6425 - mse: 109.6425\n",
      "Epoch 31/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 108.1305 - mse: 108.1305\n",
      "Epoch 32/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 105.0482 - mse: 105.0482\n",
      "Epoch 33/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 103.3545 - mse: 103.3545\n",
      "Epoch 34/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 102.5858 - mse: 102.5858\n",
      "Epoch 35/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 101.8222 - mse: 101.8222\n",
      "Epoch 36/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 100.4302 - mse: 100.4302\n",
      "Epoch 37/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 98.9656 - mse: 98.9656\n",
      "Epoch 38/150\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 96.3127 - mse: 96.3127\n",
      "Epoch 39/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 95.5409 - mse: 95.5409\n",
      "Epoch 40/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 94.1102 - mse: 94.1102\n",
      "Epoch 41/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 92.3088 - mse: 92.3088\n",
      "Epoch 42/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 91.2208 - mse: 91.2208\n",
      "Epoch 43/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 90.5956 - mse: 90.5956\n",
      "Epoch 44/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 89.0049 - mse: 89.0049\n",
      "Epoch 45/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 88.9020 - mse: 88.9020\n",
      "Epoch 46/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 85.7886 - mse: 85.7886\n",
      "Epoch 47/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 86.3832 - mse: 86.3832\n",
      "Epoch 48/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 84.9824 - mse: 84.9824\n",
      "Epoch 49/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 84.3026 - mse: 84.3026\n",
      "Epoch 50/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 83.3471 - mse: 83.3471\n",
      "Epoch 51/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 82.0801 - mse: 82.0801\n",
      "Epoch 52/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 81.2543 - mse: 81.2543\n",
      "Epoch 53/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 79.8502 - mse: 79.8502\n",
      "Epoch 54/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 79.3609 - mse: 79.3609\n",
      "Epoch 55/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 77.5652 - mse: 77.5652\n",
      "Epoch 56/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 76.5701 - mse: 76.5701\n",
      "Epoch 57/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 76.4085 - mse: 76.4085\n",
      "Epoch 58/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 74.7511 - mse: 74.7511\n",
      "Epoch 59/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 74.7899 - mse: 74.7899\n",
      "Epoch 60/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 73.6949 - mse: 73.6949\n",
      "Epoch 61/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 71.6287 - mse: 71.6287\n",
      "Epoch 62/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 71.2466 - mse: 71.2466\n",
      "Epoch 63/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 70.8696 - mse: 70.8696\n",
      "Epoch 64/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 69.5183 - mse: 69.5183\n",
      "Epoch 65/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 67.2686 - mse: 67.2686\n",
      "Epoch 66/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 68.5687 - mse: 68.5687\n",
      "Epoch 67/150\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 67.3250 - mse: 67.3250\n",
      "Epoch 68/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 67.0745 - mse: 67.0745\n",
      "Epoch 69/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 66.2347 - mse: 66.2347\n",
      "Epoch 70/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 63.9907 - mse: 63.9907\n",
      "Epoch 71/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 64.0174 - mse: 64.0174\n",
      "Epoch 72/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 63.5101 - mse: 63.5101\n",
      "Epoch 73/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 61.6243 - mse: 61.6243\n",
      "Epoch 74/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 62.5393 - mse: 62.5393\n",
      "Epoch 75/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 60.8303 - mse: 60.8303\n",
      "Epoch 76/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 59.7869 - mse: 59.7869\n",
      "Epoch 77/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 59.2721 - mse: 59.2721\n",
      "Epoch 78/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 59.5200 - mse: 59.5200\n",
      "Epoch 79/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 57.5210 - mse: 57.5210\n",
      "Epoch 80/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 58.3933 - mse: 58.3933\n",
      "Epoch 81/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 56.3673 - mse: 56.3673\n",
      "Epoch 82/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 57.0046 - mse: 57.0046\n",
      "Epoch 83/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 55.7321 - mse: 55.7321\n",
      "Epoch 84/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 55.6183 - mse: 55.6183\n",
      "Epoch 85/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 55.1330 - mse: 55.1330\n",
      "Epoch 86/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 54.0798 - mse: 54.0798ETA: 0s - loss: 51.6849 - mse: 51.684\n",
      "Epoch 87/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 54.1154 - mse: 54.1154\n",
      "Epoch 88/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 53.4281 - mse: 53.4281\n",
      "Epoch 89/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 52.4184 - mse: 52.4184\n",
      "Epoch 90/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 51.8979 - mse: 51.8979\n",
      "Epoch 91/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 50.9279 - mse: 50.9279\n",
      "Epoch 92/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 51.3598 - mse: 51.3598\n",
      "Epoch 93/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 50.1779 - mse: 50.1779\n",
      "Epoch 94/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 49.5857 - mse: 49.5857\n",
      "Epoch 95/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 48.7879 - mse: 48.7879\n",
      "Epoch 96/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 48.7750 - mse: 48.7750\n",
      "Epoch 97/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 47.5090 - mse: 47.5090\n",
      "Epoch 98/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 47.1031 - mse: 47.1031\n",
      "Epoch 99/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 47.1593 - mse: 47.1593\n",
      "Epoch 100/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 45.5529 - mse: 45.5529\n",
      "Epoch 101/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 46.0559 - mse: 46.0559\n",
      "Epoch 102/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 44.9921 - mse: 44.9921\n",
      "Epoch 103/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 44.5840 - mse: 44.5840\n",
      "Epoch 104/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 44.3067 - mse: 44.3067\n",
      "Epoch 105/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 43.0377 - mse: 43.0377\n",
      "Epoch 106/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 43.4072 - mse: 43.4072\n",
      "Epoch 107/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 40.9779 - mse: 40.9779\n",
      "Epoch 108/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 42.3142 - mse: 42.3142\n",
      "Epoch 109/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 41.0788 - mse: 41.0788\n",
      "Epoch 110/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 40.5992 - mse: 40.5992\n",
      "Epoch 111/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 40.2168 - mse: 40.2168\n",
      "Epoch 112/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 38.9864 - mse: 38.9864\n",
      "Epoch 113/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 38.0256 - mse: 38.0256\n",
      "Epoch 114/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 37.9064 - mse: 37.9064\n",
      "Epoch 115/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 37.4588 - mse: 37.4588\n",
      "Epoch 116/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 37.1780 - mse: 37.1780\n",
      "Epoch 117/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 36.7749 - mse: 36.7749\n",
      "Epoch 118/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 35.8444 - mse: 35.8444\n",
      "Epoch 119/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 35.9876 - mse: 35.9876\n",
      "Epoch 120/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 34.8793 - mse: 34.8793\n",
      "Epoch 121/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 35.0392 - mse: 35.0392\n",
      "Epoch 122/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 34.6167 - mse: 34.6167\n",
      "Epoch 123/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 33.1392 - mse: 33.1392\n",
      "Epoch 124/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 32.5524 - mse: 32.5524\n",
      "Epoch 125/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 32.5150 - mse: 32.5150\n",
      "Epoch 126/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 31.6902 - mse: 31.6902\n",
      "Epoch 127/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 32.4290 - mse: 32.4290\n",
      "Epoch 128/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 31.4912 - mse: 31.4912\n",
      "Epoch 129/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 30.3002 - mse: 30.3002\n",
      "Epoch 130/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 29.7142 - mse: 29.7142\n",
      "Epoch 131/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 30.3059 - mse: 30.3059\n",
      "Epoch 132/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 29.9346 - mse: 29.9346\n",
      "Epoch 133/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 28.8937 - mse: 28.8937A: 0s - loss: 38.8182 - mse: 38.81\n",
      "Epoch 134/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 28.4629 - mse: 28.4629\n",
      "Epoch 135/150\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 27.9780 - mse: 27.9780\n",
      "Epoch 136/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 27.1823 - mse: 27.1823\n",
      "Epoch 137/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 26.5871 - mse: 26.5871\n",
      "Epoch 138/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 25.3710 - mse: 25.3710\n",
      "Epoch 139/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 25.8411 - mse: 25.8411\n",
      "Epoch 140/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 26.1029 - mse: 26.1029\n",
      "Epoch 141/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 25.3440 - mse: 25.3440\n",
      "Epoch 142/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 24.9918 - mse: 24.9918\n",
      "Epoch 143/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 23.5839 - mse: 23.5839\n",
      "Epoch 144/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 25.3395 - mse: 25.3395\n",
      "Epoch 145/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 23.9954 - mse: 23.9954\n",
      "Epoch 146/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 23.6040 - mse: 23.6040\n",
      "Epoch 147/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 23.3983 - mse: 23.3983\n",
      "Epoch 148/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 23.2026 - mse: 23.2026\n",
      "Epoch 149/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 21.4420 - mse: 21.4420\n",
      "Epoch 150/150\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 21.9688 - mse: 21.9688\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 208.5349 - mse: 208.5349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[208.534912109375, 208.534912109375]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=150, batch_size=4)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                960       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,049\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77.] [75.372505]\n",
      "[80.] [75.33072]\n",
      "[58.] [58.27698]\n",
      "[46.] [47.05804]\n",
      "[47.] [48.086704]\n",
      "[49.] [47.224308]\n",
      "[49.] [52.77231]\n",
      "[72.] [68.141556]\n",
      "[66.] [63.949036]\n",
      "[56.] [63.950542]\n",
      "[65.] [61.16671]\n",
      "[70.] [69.75861]\n",
      "[99.] [86.89263]\n",
      "[83.] [78.79604]\n",
      "[49.] [49.587845]\n",
      "[116.] [107.19602]\n",
      "[53.] [48.19782]\n",
      "[60.] [59.27808]\n",
      "[53.] [63.04964]\n",
      "[68.] [65.28047]\n",
      "[50.] [55.617573]\n",
      "[50.] [51.67477]\n",
      "[48.] [45.803036]\n",
      "[46.] [43.60545]\n",
      "[47.] [45.51141]\n",
      "[78.] [76.47857]\n",
      "[54.] [54.215355]\n",
      "[91.] [85.71529]\n",
      "[49.] [49.232758]\n",
      "[50.] [50.006855]\n",
      "[50.] [51.018394]\n",
      "[46.] [45.42317]\n",
      "[49.] [46.397903]\n",
      "[50.] [54.891163]\n",
      "[61.] [61.332108]\n",
      "[80.] [63.42942]\n",
      "[45.] [45.835995]\n",
      "[42.] [44.028572]\n",
      "[69.] [72.54487]\n",
      "[82.] [81.70629]\n",
      "[44.] [60.757874]\n",
      "[80.] [78.86194]\n",
      "[49.] [50.306423]\n",
      "[79.] [78.955215]\n",
      "[48.] [42.312035]\n",
      "[66.] [63.398315]\n",
      "[65.] [63.002773]\n",
      "[53.] [51.3451]\n",
      "[54.] [54.875053]\n",
      "[57.] [56.28923]\n",
      "[50.] [56.362633]\n",
      "[50.] [52.272705]\n",
      "[48.] [47.607105]\n",
      "[68.] [69.20607]\n",
      "[58.] [58.203594]\n",
      "[69.] [68.997086]\n",
      "[50.] [62.98537]\n",
      "[64.] [63.08632]\n",
      "[75.] [71.61409]\n",
      "[72.] [71.596664]\n",
      "[45.] [46.55212]\n",
      "[74.] [73.541466]\n",
      "[74.] [72.7266]\n",
      "[66.] [69.060814]\n",
      "[51.] [56.9594]\n",
      "[57.] [56.627132]\n",
      "[42.] [47.34318]\n",
      "[51.] [66.50617]\n",
      "[57.] [54.52097]\n",
      "[99.] [94.54866]\n",
      "[72.] [71.568726]\n",
      "[75.] [69.936874]\n",
      "[62.] [62.78903]\n",
      "[29.] [30.634722]\n",
      "[52.] [52.66962]\n",
      "[60.] [61.253094]\n",
      "[63.] [70.36843]\n",
      "[71.] [68.42678]\n",
      "[55.] [55.63542]\n",
      "[47.] [48.706272]\n",
      "[88.] [84.999825]\n",
      "[88.] [79.12417]\n",
      "[55.] [54.656055]\n",
      "[57.] [58.79229]\n",
      "[72.] [81.3931]\n",
      "[52.] [55.348324]\n",
      "[52.] [52.015965]\n",
      "[86.] [79.693115]\n",
      "[37.] [36.642025]\n",
      "[47.] [54.93958]\n",
      "[62.] [60.650116]\n",
      "[98.] [84.43677]\n",
      "[45.] [49.997604]\n",
      "[66.] [68.043175]\n",
      "[56.] [54.460938]\n",
      "[50.] [53.34424]\n",
      "[81.] [82.451546]\n",
      "[58.] [59.43571]\n",
      "[42.] [43.374138]\n",
      "[52.] [61.11047]\n",
      "[58.] [59.73178]\n",
      "[58.] [58.897797]\n",
      "[58.] [60.890377]\n",
      "[60.] [61.43685]\n",
      "[68.] [65.49517]\n",
      "[66.] [63.198685]\n",
      "[61.] [58.975075]\n",
      "[83.] [83.661766]\n",
      "[57.] [53.118546]\n",
      "[52.] [55.244022]\n",
      "[52.] [52.590992]\n",
      "[64.] [60.23021]\n",
      "[39.] [41.485]\n",
      "[56.] [59.95358]\n",
      "[62.] [60.085003]\n",
      "[86.] [77.4051]\n",
      "[38.] [39.107376]\n",
      "[51.] [51.730747]\n",
      "[33.] [33.7297]\n",
      "[75.] [60.208893]\n",
      "[43.] [43.555862]\n",
      "[50.] [58.706978]\n",
      "[67.] [66.684456]\n",
      "[58.] [57.877716]\n",
      "[40.] [39.54877]\n",
      "[46.] [46.546707]\n",
      "[79.] [78.73601]\n",
      "[57.] [55.185432]\n",
      "[85.] [85.07811]\n",
      "[51.] [50.523808]\n",
      "[114.] [113.60139]\n",
      "[55.] [56.74969]\n",
      "[58.] [56.17411]\n",
      "[51.] [47.11987]\n",
      "[55.] [54.388836]\n",
      "[38.] [38.022064]\n",
      "[74.] [67.81944]\n",
      "[67.] [58.642117]\n",
      "[42.] [43.524197]\n",
      "[44.] [42.94551]\n",
      "[48.] [48.494175]\n",
      "[40.] [38.89865]\n",
      "[98.] [81.663315]\n",
      "[51.] [47.20325]\n",
      "[58.] [50.668705]\n",
      "[45.] [47.71068]\n",
      "[60.] [67.06851]\n",
      "[61.] [62.55413]\n",
      "[48.] [50.23247]\n",
      "[72.] [80.40244]\n",
      "[63.] [59.197033]\n",
      "[79.] [75.10953]\n",
      "[40.] [40.294586]\n",
      "[52.] [54.9631]\n",
      "[51.] [48.38461]\n",
      "[49.] [49.735203]\n",
      "[66.] [65.51838]\n",
      "[36.] [40.00443]\n",
      "[78.] [79.88406]\n",
      "[62.] [60.68098]\n",
      "[31.] [44.12985]\n",
      "[49.] [57.92722]\n",
      "[71.] [69.05225]\n",
      "[72.] [61.194523]\n",
      "[74.] [69.82644]\n",
      "[63.] [67.41074]\n",
      "[57.] [58.617588]\n",
      "[49.] [48.941486]\n",
      "[52.] [49.51634]\n",
      "[50.] [50.94076]\n",
      "[64.] [56.131443]\n",
      "[74.] [75.26522]\n",
      "[52.] [60.00784]\n",
      "[58.] [58.83428]\n",
      "[48.] [49.881283]\n",
      "[48.] [49.842636]\n",
      "[60.] [61.5803]\n",
      "[86.] [81.02591]\n",
      "[57.] [56.46625]\n",
      "[48.] [50.168995]\n",
      "[75.] [77.411125]\n",
      "[67.] [62.937347]\n",
      "[57.] [58.715393]\n",
      "[52.] [49.35462]\n",
      "[76.] [75.19776]\n",
      "[45.] [46.80216]\n",
      "[41.] [40.46169]\n",
      "[53.] [49.804005]\n",
      "[41.] [40.908787]\n",
      "[92.] [93.13317]\n",
      "[88.] [85.17571]\n",
      "[64.] [61.596004]\n",
      "[58.] [54.991657]\n",
      "[36.] [39.998596]\n",
      "[69.] [66.54366]\n",
      "[58.] [63.728424]\n",
      "[51.] [51.176777]\n",
      "[69.] [68.14971]\n",
      "[61.] [57.701405]\n",
      "[42.] [41.94882]\n",
      "[42.] [41.71056]\n",
      "[44.] [43.833225]\n",
      "[69.] [72.85338]\n",
      "[44.] [45.956486]\n",
      "[49.] [49.150333]\n",
      "[63.] [62.417305]\n",
      "[50.] [52.60853]\n",
      "[44.] [46.06411]\n",
      "[81.] [81.87687]\n",
      "[72.] [72.20644]\n",
      "[52.] [51.601788]\n",
      "[77.] [78.08955]\n",
      "[71.] [69.35964]\n",
      "[53.] [52.54679]\n",
      "[57.] [54.631073]\n",
      "[50.] [51.48412]\n",
      "[68.] [69.21749]\n",
      "[79.] [78.110344]\n",
      "[66.] [62.096424]\n",
      "[49.] [48.17641]\n",
      "[58.] [55.948566]\n",
      "[62.] [59.58047]\n",
      "[48.] [47.89546]\n",
      "[57.] [61.38636]\n",
      "[52.] [56.14716]\n",
      "[80.] [79.43164]\n",
      "[55.] [59.264988]\n",
      "[52.] [52.623528]\n",
      "[58.] [56.42088]\n",
      "[78.] [81.50301]\n",
      "[51.] [51.44642]\n",
      "[63.] [57.917366]\n",
      "[73.] [66.23992]\n",
      "[78.] [77.9848]\n",
      "[74.] [71.09672]\n",
      "[49.] [51.436497]\n",
      "[51.] [50.170258]\n",
      "[46.] [45.39948]\n",
      "[52.] [51.1909]\n",
      "[84.] [75.99321]\n",
      "[47.] [48.925205]\n",
      "[67.] [67.25302]\n",
      "[42.] [42.129993]\n",
      "[72.] [76.93079]\n",
      "[64.] [60.77709]\n",
      "[55.] [52.37718]\n",
      "[46.] [46.094017]\n",
      "[75.] [69.282234]\n",
      "[59.] [65.12028]\n",
      "[39.] [37.071598]\n",
      "[72.] [72.70225]\n",
      "[49.] [54.62209]\n",
      "[68.] [61.556286]\n",
      "[37.] [43.06778]\n",
      "[49.] [51.273956]\n",
      "[59.] [57.49641]\n",
      "[62.] [65.16494]\n",
      "[47.] [58.45903]\n",
      "[58.] [58.42513]\n",
      "[62.] [68.677895]\n",
      "[84.] [74.18755]\n",
      "[44.] [46.262817]\n",
      "[59.] [59.584625]\n",
      "[54.] [54.273872]\n",
      "[43.] [48.4384]\n",
      "[57.] [56.043465]\n",
      "[76.] [74.24282]\n",
      "[46.] [42.914116]\n",
      "[56.] [57.037704]\n",
      "[60.] [63.75649]\n",
      "[69.] [71.77665]\n",
      "[46.] [54.953457]\n",
      "[64.] [67.13384]\n",
      "[50.] [51.626404]\n",
      "[105.] [100.37285]\n",
      "[52.] [50.191082]\n",
      "[86.] [85.76906]\n",
      "[50.] [53.67971]\n",
      "[66.] [64.72578]\n",
      "[69.] [70.5726]\n",
      "[54.] [55.775692]\n"
     ]
    }
   ],
   "source": [
    "for t,p in zip(y_train,y_train_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55.] [71.78274]\n",
      "[54.] [56.187862]\n",
      "[71.] [77.31738]\n",
      "[61.] [59.400528]\n",
      "[60.] [73.04129]\n",
      "[55.] [60.803867]\n",
      "[49.] [71.00953]\n",
      "[62.] [56.78609]\n",
      "[67.] [59.077587]\n",
      "[63.] [79.70097]\n",
      "[68.] [64.80239]\n",
      "[70.] [53.42452]\n",
      "[62.] [69.21937]\n",
      "[58.] [70.059425]\n",
      "[39.] [48.403095]\n",
      "[67.] [57.281563]\n",
      "[48.] [41.547]\n",
      "[70.] [58.954983]\n",
      "[90.] [56.708584]\n",
      "[57.] [81.924614]\n",
      "[60.] [68.97947]\n",
      "[75.] [55.431477]\n",
      "[86.] [75.9854]\n",
      "[56.] [82.6187]\n",
      "[64.] [91.357216]\n",
      "[46.] [52.687794]\n",
      "[46.] [45.76324]\n",
      "[44.] [55.425144]\n",
      "[46.] [57.471004]\n",
      "[63.] [64.90165]\n",
      "[47.] [46.635624]\n",
      "[64.] [69.48034]\n",
      "[53.] [58.26128]\n",
      "[77.] [85.824844]\n",
      "[44.] [47.514046]\n",
      "[76.] [74.1575]\n",
      "[78.] [64.85242]\n",
      "[78.] [66.66119]\n",
      "[69.] [95.946754]\n",
      "[55.] [50.662792]\n",
      "[67.] [53.517864]\n",
      "[67.] [90.98553]\n",
      "[59.] [61.913483]\n",
      "[83.] [65.82554]\n",
      "[51.] [38.356487]\n",
      "[51.] [33.22801]\n",
      "[75.] [79.33791]\n",
      "[69.] [76.478065]\n",
      "[28.] [53.327435]\n",
      "[58.] [57.900547]\n",
      "[75.] [68.547745]\n",
      "[64.] [72.78455]\n",
      "[96.] [52.880604]\n",
      "[52.] [70.53034]\n",
      "[35.] [46.65237]\n",
      "[55.] [44.737972]\n",
      "[58.] [71.11284]\n",
      "[58.] [47.10877]\n",
      "[54.] [57.20378]\n",
      "[40.] [42.510242]\n",
      "[64.] [76.646614]\n",
      "[60.] [76.476715]\n",
      "[64.] [85.45757]\n",
      "[76.] [67.00704]\n",
      "[61.] [30.418331]\n",
      "[73.] [71.58933]\n",
      "[49.] [45.97822]\n",
      "[62.] [64.60357]\n",
      "[79.] [73.8907]\n",
      "[50.] [58.716946]\n",
      "[41.] [54.49764]\n"
     ]
    }
   ],
   "source": [
    "for t,p in zip(y_test,y_test_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#오차 범위 3 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set prediction accuracy: 50.89 %\n",
      "test set prediction accuracy: 56.34 %\n"
     ]
    }
   ],
   "source": [
    "#평균 성능 테스트\n",
    "scores = 0\n",
    "mean=np.mean(Y, axis=0)\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= mean <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"train set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= mean <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"test set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### <오차범위 3>\n",
      "- train set prediction accuracy(+-3): 65.84 % <br>\n",
      "- test set prediction accuracy(+-3): 15.49 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 5>\n",
      "- train set prediction accuracy(+-5): 82.21 % <br>\n",
      "- test set prediction accuracy(+-5): 23.94 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 10>\n",
      "- train set prediction accuracy(+-10): 95.73 % <br>\n",
      "- test set prediction accuracy(+-10): 50.70 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 20>\n",
      "- train set prediction accuracy(+-20): 100.00 % <br>\n",
      "- test set prediction accuracy(+-20): 84.51 % <br>\n"
     ]
    }
   ],
   "source": [
    "######입력용#######\n",
    "\n",
    "#오차 범위 3 설정\n",
    "print('### <오차범위 3>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "print('### <오차범위 5>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "print('### <오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "print('### <오차범위 20>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Y=HDL>\n",
    "## 1. 임의+선별\n",
    "### <오차범위 3>\n",
    "- train set prediction accuracy(+-3): 95.37 % <br>\n",
    "- test set prediction accuracy(+-3): 16.90 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 5>\n",
    "- train set prediction accuracy(+-5): 98.58 % <br>\n",
    "- test set prediction accuracy(+-5): 28.17 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 10>\n",
    "- train set prediction accuracy(+-10): 100.00 % <br>\n",
    "- test set prediction accuracy(+-10): 49.30 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 20>\n",
    "- train set prediction accuracy(+-20): 100.00 % <br>\n",
    "- test set prediction accuracy(+-20): 84.51 % <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

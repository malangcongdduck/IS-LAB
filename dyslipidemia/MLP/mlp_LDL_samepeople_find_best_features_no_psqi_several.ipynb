{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sample_ID GROUP  COHORT SEX  AGE     Trait FitbitOX      Fitbit_ID  HTN  \\\n",
      "0         S0001   SMI       2   M   60  fitbit_O        O  sevrance00001  NaN   \n",
      "1         S0002   SMI       2   M   61  fitbit_O        O  sevrance00002  NaN   \n",
      "2         S0003   SMI       2   F   52  fitbit_O        O  sevrance00003  NaN   \n",
      "3         S0004   SMI       2   F   41  fitbit_O        O  sevrance00004  NaN   \n",
      "4         S0005   SMI       2   F   41  fitbit_O        O  sevrance00005  NaN   \n",
      "..          ...   ...     ...  ..  ...       ...      ...            ...  ...   \n",
      "383  MetS_S0280  MetS       1   F   24  fitbit_O        O   gnfmmets+139  NaN   \n",
      "384  MetS_S0281  MetS       1   F   44  fitbit_O        O   gnfmmets+140  NaN   \n",
      "385  MetS_S0282  MetS       1   F   37  fitbit_O        O   gnfmmets+141  1.0   \n",
      "386  MetS_S0283  MetS       1   M   51  fitbit_X        X              X  NaN   \n",
      "387  MetS_S0284  MetS       1   F   42  fitbit_X        X              X  NaN   \n",
      "\n",
      "      DM  ...  BDI_Q13_2 BDI_Q14_2  BDI_Q15_2  BDI_Q16_2 BDI_Q17_2 BDI_Q18_2  \\\n",
      "0    NaN  ...        1.0       1.0        1.0        2.0       1.0       1.0   \n",
      "1    1.0  ...        1.0       1.0        1.0        1.0       2.0       1.0   \n",
      "2    NaN  ...        1.0       1.0        1.0        1.0       1.0       1.0   \n",
      "3    NaN  ...        2.0       2.0        2.0        2.0       2.0       2.0   \n",
      "4    NaN  ...        2.0       1.0        2.0        2.0       2.0       1.0   \n",
      "..   ...  ...        ...       ...        ...        ...       ...       ...   \n",
      "383  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "384  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "385  1.0  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "386  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "387  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "\n",
      "     BDI_Q19_2  BDI_Q20_2  BDI_Q21_2  Diet_2  \n",
      "0          2.0        1.0        2.0     2.0  \n",
      "1          1.0        1.0        1.0     2.0  \n",
      "2          1.0        2.0        4.0     1.0  \n",
      "3          1.0        1.0        1.0     2.0  \n",
      "4          1.0        2.0        1.0     2.0  \n",
      "..         ...        ...        ...     ...  \n",
      "383        NaN        NaN        NaN     NaN  \n",
      "384        NaN        NaN        NaN     NaN  \n",
      "385        NaN        NaN        NaN     NaN  \n",
      "386        NaN        NaN        NaN     NaN  \n",
      "387        NaN        NaN        NaN     NaN  \n",
      "\n",
      "[388 rows x 3527 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('./최종 데이터 그래프그리기용.xlsx') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#빈데이터 많은 Chol, BUN 삭제\n",
    "psqi_df=df[['Sample_ID','GROUP','COHORT','AGE','SEX','BMI_1','PSQI_TOTAL_1','Insulin _1','CRP_1','WBC_1','Neutrophil_1','Lym_1','GLU0_1','Creatinine_1','AST_1','ALT_1','TG_1','LDL_1','Muscle_1','Fat_1_x','FatPercentage _1','WHR_1','SBP_1',\n",
    "            'DBP_1','HR_1','Waist_1','HDL_1',\n",
    "          'BMI_2','PSQI_TOTAL_2','Insulin _2','CRP_2','WBC_2','Neutrophil_2','Lym_2','GLU0_2',\n",
    "            'Creatinine_2','AST_2','ALT_2','TG_2','LDL_2','Muscle_2','Fat_2_x','FatPercentage_2','WHR_2','SBP_2',\n",
    "            'DBP_2','HR_2','Waist_2','HDL_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#빈데이터 많은 Chol, BUN 추가\n",
    "psqi_df=df[['Sample_ID','GROUP','COHORT','AGE','SEX',\n",
    "            'BMI_1','PSQI_TOTAL_1','Insulin _1','CRP_1','WBC_1','Neutrophil_1','Lym_1','GLU0_1',\n",
    "            'Creatinine_1','AST_1','ALT_1','TG_1','LDL_1','Muscle_1','Fat_1_x','FatPercentage _1','WHR_1','SBP_1',\n",
    "            'DBP_1','HR_1','Waist_1','HDL_1','BUN_1','Chol_1',\n",
    "          'BMI_2','PSQI_TOTAL_2','Insulin _2','CRP_2','WBC_2','Neutrophil_2','Lym_2','GLU0_2',\n",
    "            'Creatinine_2','AST_2','ALT_2','TG_2','LDL_2','Muscle_2','Fat_2_x','FatPercentage_2','WHR_2','SBP_2',\n",
    "            'DBP_2','HR_2','Waist_2','HDL_2','BUN_2','Chol_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>HDL_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>Chol_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.89</td>\n",
       "      <td>108.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.51</td>\n",
       "      <td>...</td>\n",
       "      <td>19.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>0.99</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>90.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.85</td>\n",
       "      <td>...</td>\n",
       "      <td>22.6</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>127.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.14</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.82</td>\n",
       "      <td>119.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.93</td>\n",
       "      <td>...</td>\n",
       "      <td>14.9</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>110.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>66.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.82</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.67</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.03</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT  AGE SEX      BMI_1  PSQI_TOTAL_1 Insulin _1  \\\n",
       "0         S0001   SMI       2   60   M  21.110190           8.0        7.7   \n",
       "1         S0002   SMI       2   61   M  27.782064           4.0        5.4   \n",
       "2         S0003   SMI       2   52   F  24.944742           3.0        5.1   \n",
       "3         S0004   SMI       2   41   F  22.620489           6.0        4.2   \n",
       "4         S0005   SMI       2   41   F  20.524157          10.0        3.2   \n",
       "..          ...   ...     ...  ...  ..        ...           ...        ...   \n",
       "383  MetS_S0280  MetS       1   24   F  34.803410           5.0       11.3   \n",
       "384  MetS_S0281  MetS       1   44   F  30.903615           3.0       10.6   \n",
       "385  MetS_S0282  MetS       1   37   F  28.676533           3.0       12.2   \n",
       "386  MetS_S0283  MetS       1   51   M  24.549738           5.0       10.4   \n",
       "387  MetS_S0284  MetS       1   42   F  24.605921           3.0       10.1   \n",
       "\n",
       "    CRP_1  WBC_1  ...  Fat_2_x  FatPercentage_2  WHR_2  SBP_2  DBP_2  HR_2  \\\n",
       "0     0.2   3.91  ...      9.7             15.9   0.89  108.0   78.0  87.0   \n",
       "1     0.2   5.51  ...     19.9             27.9   0.99  138.0   92.0  73.0   \n",
       "2     0.7   4.85  ...     22.6             36.7   0.89  127.0   80.0  66.0   \n",
       "3     0.6   6.14  ...     16.0             30.9   0.82  119.0   83.0  77.0   \n",
       "4     0.1   4.93  ...     14.9             26.8   0.80  110.0   68.0  67.0   \n",
       "..    ...    ...  ...      ...              ...    ...    ...    ...   ...   \n",
       "383   0.4   5.32  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "384   2.3   5.82  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "385     1   6.18  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "386   1.2   6.67  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "387   0.8   7.03  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "\n",
       "     Waist_2  HDL_2  BUN_2  Chol_2  \n",
       "0       83.0   77.0   13.1     NaN  \n",
       "1       90.5   59.0   19.2     NaN  \n",
       "2       86.5   40.0   17.1     NaN  \n",
       "3       77.0   54.0   12.2     NaN  \n",
       "4       66.5   72.0   16.5     NaN  \n",
       "..       ...    ...    ...     ...  \n",
       "383      NaN    NaN    NaN     NaN  \n",
       "384      NaN    NaN    NaN     NaN  \n",
       "385      NaN    NaN    NaN     NaN  \n",
       "386      NaN    NaN    NaN     NaN  \n",
       "387      NaN    NaN    NaN     NaN  \n",
       "\n",
       "[388 rows x 53 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>HDL_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>Chol_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.89</td>\n",
       "      <td>108.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.51</td>\n",
       "      <td>...</td>\n",
       "      <td>19.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>0.99</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>90.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.85</td>\n",
       "      <td>...</td>\n",
       "      <td>22.6</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>127.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.14</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.82</td>\n",
       "      <td>119.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.93</td>\n",
       "      <td>...</td>\n",
       "      <td>14.9</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>110.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>66.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.82</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.67</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.03</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT  AGE SEX      BMI_1  PSQI_TOTAL_1 Insulin _1  \\\n",
       "0         S0001   SMI       2   60   M  21.110190           8.0        7.7   \n",
       "1         S0002   SMI       2   61   M  27.782064           4.0        5.4   \n",
       "2         S0003   SMI       2   52   F  24.944742           3.0        5.1   \n",
       "3         S0004   SMI       2   41   F  22.620489           6.0        4.2   \n",
       "4         S0005   SMI       2   41   F  20.524157          10.0        3.2   \n",
       "..          ...   ...     ...  ...  ..        ...           ...        ...   \n",
       "383  MetS_S0280  MetS       1   24   F  34.803410           5.0       11.3   \n",
       "384  MetS_S0281  MetS       1   44   F  30.903615           3.0       10.6   \n",
       "385  MetS_S0282  MetS       1   37   F  28.676533           3.0       12.2   \n",
       "386  MetS_S0283  MetS       1   51   M  24.549738           5.0       10.4   \n",
       "387  MetS_S0284  MetS       1   42   F  24.605921           3.0       10.1   \n",
       "\n",
       "    CRP_1  WBC_1  ...  Fat_2_x  FatPercentage_2  WHR_2  SBP_2  DBP_2  HR_2  \\\n",
       "0     0.2   3.91  ...      9.7             15.9   0.89  108.0   78.0  87.0   \n",
       "1     0.2   5.51  ...     19.9             27.9   0.99  138.0   92.0  73.0   \n",
       "2     0.7   4.85  ...     22.6             36.7   0.89  127.0   80.0  66.0   \n",
       "3     0.6   6.14  ...     16.0             30.9   0.82  119.0   83.0  77.0   \n",
       "4     0.1   4.93  ...     14.9             26.8   0.80  110.0   68.0  67.0   \n",
       "..    ...    ...  ...      ...              ...    ...    ...    ...   ...   \n",
       "383   0.4   5.32  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "384   2.3   5.82  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "385     1   6.18  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "386   1.2   6.67  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "387   0.8   7.03  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "\n",
       "     Waist_2  HDL_2  BUN_2  Chol_2  \n",
       "0       83.0   77.0   13.1     NaN  \n",
       "1       90.5   59.0   19.2     NaN  \n",
       "2       86.5   40.0   17.1     NaN  \n",
       "3       77.0   54.0   12.2     NaN  \n",
       "4       66.5   72.0   16.5     NaN  \n",
       "..       ...    ...    ...     ...  \n",
       "383      NaN    NaN    NaN     NaN  \n",
       "384      NaN    NaN    NaN     NaN  \n",
       "385      NaN    NaN    NaN     NaN  \n",
       "386      NaN    NaN    NaN     NaN  \n",
       "387      NaN    NaN    NaN     NaN  \n",
       "\n",
       "[317 rows x 53 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#보조 호르몬 요법을 받고 있는 Cohort 3 제거 Filter 적용\n",
    "psqi_df = psqi_df[(psqi_df['COHORT'] != 3)]\n",
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df=psqi_df.dropna()\n",
    "psqi_df.reset_index(drop=True, inplace=True)\n",
    "psqi_df=psqi_df.drop([\"Sample_ID\", \"GROUP\", \"COHORT\"],axis=1)\n",
    "#1분, 매일다름, 정해진간이없음 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"SEX\"] = psqi_df[\"SEX\"].apply(lambda x: 1. if x=='M' else 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"Insulin _1\"] = psqi_df[\"Insulin _1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)\n",
    "psqi_df[\"Insulin _2\"] = psqi_df[\"Insulin _2\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"CRP_1\"] = psqi_df[\"CRP_1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)\n",
    "psqi_df[\"CRP_2\"] = psqi_df[\"CRP_2\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>Neutrophil_1</th>\n",
       "      <th>Lym_1</th>\n",
       "      <th>GLU0_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>HDL_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>Chol_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.00000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.366667</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>23.799644</td>\n",
       "      <td>5.105556</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.748889</td>\n",
       "      <td>5.844867</td>\n",
       "      <td>56.086111</td>\n",
       "      <td>34.113333</td>\n",
       "      <td>98.90000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.053333</td>\n",
       "      <td>28.888333</td>\n",
       "      <td>0.862444</td>\n",
       "      <td>114.605556</td>\n",
       "      <td>72.477778</td>\n",
       "      <td>75.644444</td>\n",
       "      <td>81.328889</td>\n",
       "      <td>59.20000</td>\n",
       "      <td>12.984444</td>\n",
       "      <td>190.922222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.589776</td>\n",
       "      <td>0.461927</td>\n",
       "      <td>4.936177</td>\n",
       "      <td>2.893833</td>\n",
       "      <td>4.105985</td>\n",
       "      <td>1.344157</td>\n",
       "      <td>1.412280</td>\n",
       "      <td>8.502880</td>\n",
       "      <td>7.708889</td>\n",
       "      <td>14.43773</td>\n",
       "      <td>...</td>\n",
       "      <td>6.616151</td>\n",
       "      <td>7.098802</td>\n",
       "      <td>0.071696</td>\n",
       "      <td>13.213544</td>\n",
       "      <td>9.091991</td>\n",
       "      <td>10.306814</td>\n",
       "      <td>10.251265</td>\n",
       "      <td>14.01372</td>\n",
       "      <td>3.508550</td>\n",
       "      <td>32.017358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.231576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.820000</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>63.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>29.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.833309</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.857500</td>\n",
       "      <td>50.525000</td>\n",
       "      <td>28.975000</td>\n",
       "      <td>92.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>24.275000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>73.875000</td>\n",
       "      <td>49.00000</td>\n",
       "      <td>10.675000</td>\n",
       "      <td>167.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.422889</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>5.720000</td>\n",
       "      <td>55.950000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>95.50000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.950000</td>\n",
       "      <td>28.450000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>80.500000</td>\n",
       "      <td>57.00000</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.502662</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.505000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>6.580000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>102.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.125000</td>\n",
       "      <td>33.450000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>77.250000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>69.00000</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>10.550000</td>\n",
       "      <td>78.400000</td>\n",
       "      <td>55.400000</td>\n",
       "      <td>182.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>46.100000</td>\n",
       "      <td>48.300000</td>\n",
       "      <td>1.070000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>116.00000</td>\n",
       "      <td>36.400000</td>\n",
       "      <td>296.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              AGE         SEX       BMI_1  PSQI_TOTAL_1  Insulin _1  \\\n",
       "count  180.000000  180.000000  180.000000    180.000000  180.000000   \n",
       "mean    38.366667    0.305556   23.799644      5.105556    7.700000   \n",
       "std     11.589776    0.461927    4.936177      2.893833    4.105985   \n",
       "min     20.000000    0.000000   15.231576      0.000000    0.100000   \n",
       "25%     29.000000    0.000000   20.833309      3.000000    5.000000   \n",
       "50%     35.500000    0.000000   23.422889      5.000000    6.500000   \n",
       "75%     46.000000    1.000000   25.502662      7.000000    9.505000   \n",
       "max     63.000000    1.000000   67.500000     14.000000   24.700000   \n",
       "\n",
       "            CRP_1       WBC_1  Neutrophil_1       Lym_1     GLU0_1  ...  \\\n",
       "count  180.000000  180.000000    180.000000  180.000000  180.00000  ...   \n",
       "mean     0.748889    5.844867     56.086111   34.113333   98.90000  ...   \n",
       "std      1.344157    1.412280      8.502880    7.708889   14.43773  ...   \n",
       "min      0.000000    2.820000     34.500000   15.100000   63.00000  ...   \n",
       "25%      0.200000    4.857500     50.525000   28.975000   92.00000  ...   \n",
       "50%      0.300000    5.720000     55.950000   34.000000   95.50000  ...   \n",
       "75%      0.700000    6.580000     62.000000   39.000000  102.00000  ...   \n",
       "max     11.100000   10.550000     78.400000   55.400000  182.00000  ...   \n",
       "\n",
       "          Fat_2_x  FatPercentage_2       WHR_2       SBP_2       DBP_2  \\\n",
       "count  180.000000       180.000000  180.000000  180.000000  180.000000   \n",
       "mean    19.053333        28.888333    0.862444  114.605556   72.477778   \n",
       "std      6.616151         7.098802    0.071696   13.213544    9.091991   \n",
       "min      7.700000        11.500000    0.700000   91.000000   57.000000   \n",
       "25%     14.200000        24.275000    0.820000  104.000000   67.000000   \n",
       "50%     17.950000        28.450000    0.850000  114.000000   71.000000   \n",
       "75%     22.125000        33.450000    0.900000  123.000000   77.250000   \n",
       "max     46.100000        48.300000    1.070000  158.000000  107.000000   \n",
       "\n",
       "             HR_2     Waist_2      HDL_2       BUN_2      Chol_2  \n",
       "count  180.000000  180.000000  180.00000  180.000000  180.000000  \n",
       "mean    75.644444   81.328889   59.20000   12.984444  190.922222  \n",
       "std     10.306814   10.251265   14.01372    3.508550   32.017358  \n",
       "min     54.000000   61.000000   29.00000    6.000000  109.000000  \n",
       "25%     68.000000   73.875000   49.00000   10.675000  167.750000  \n",
       "50%     75.000000   80.500000   57.00000   12.700000  188.000000  \n",
       "75%     82.000000   89.000000   69.00000   14.600000  211.000000  \n",
       "max    112.000000  118.000000  116.00000   36.400000  296.000000  \n",
       "\n",
       "[8 rows x 50 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    125\n",
       "1.0     55\n",
       "Name: SEX, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df[\"SEX\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>Neutrophil_1</th>\n",
       "      <th>Lym_1</th>\n",
       "      <th>GLU0_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>HDL_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>Chol_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.097789</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.82</td>\n",
       "      <td>54.6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>20.4</td>\n",
       "      <td>26.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>131.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>88.5</td>\n",
       "      <td>53.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.472213</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.46</td>\n",
       "      <td>44.3</td>\n",
       "      <td>43.7</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>126.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.744827</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.26</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.99</td>\n",
       "      <td>51.0</td>\n",
       "      <td>37.8</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>17.8</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.89</td>\n",
       "      <td>131.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.616175</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.84</td>\n",
       "      <td>39.1</td>\n",
       "      <td>42.1</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>12.8</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.78</td>\n",
       "      <td>102.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.437500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.22</td>\n",
       "      <td>49.3</td>\n",
       "      <td>39.3</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>12.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>106.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.259585</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.78</td>\n",
       "      <td>42.3</td>\n",
       "      <td>47.3</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>27.3</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.94</td>\n",
       "      <td>134.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.630719</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.60</td>\n",
       "      <td>51.7</td>\n",
       "      <td>34.6</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>22.1</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.95</td>\n",
       "      <td>113.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>51.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.641274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.34</td>\n",
       "      <td>55.9</td>\n",
       "      <td>34.9</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>17.5</td>\n",
       "      <td>29.9</td>\n",
       "      <td>0.84</td>\n",
       "      <td>107.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>80.5</td>\n",
       "      <td>49.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.421366</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.88</td>\n",
       "      <td>40.9</td>\n",
       "      <td>48.0</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>15.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>106.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.271653</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.28</td>\n",
       "      <td>75.7</td>\n",
       "      <td>15.1</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>9.3</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>104.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGE  SEX      BMI_1  PSQI_TOTAL_1  Insulin _1  CRP_1  WBC_1  \\\n",
       "0     35  1.0  24.097789           5.0        5.57    0.0   5.82   \n",
       "1     46  1.0  23.472213           5.0        7.35    0.7   5.46   \n",
       "2     32  1.0  23.744827           2.0        9.26    0.4   3.99   \n",
       "3     33  0.0  20.616175           4.0        3.52    0.0   5.84   \n",
       "4     28  0.0  18.437500           3.0        2.86    0.0   4.22   \n",
       "..   ...  ...        ...           ...         ...    ...    ...   \n",
       "175   63  0.0  26.259585           3.0        4.20    0.2   4.78   \n",
       "176   57  1.0  28.630719           4.0        8.80    3.0   4.60   \n",
       "177   35  0.0  21.641274           1.0        6.30    0.4   6.34   \n",
       "178   61  0.0  20.421366           8.0        4.80    0.2   4.88   \n",
       "179   56  1.0  22.271653           1.0        9.00    0.2   6.28   \n",
       "\n",
       "     Neutrophil_1  Lym_1  GLU0_1  ...  Fat_2_x  FatPercentage_2  WHR_2  SBP_2  \\\n",
       "0            54.6   35.0      89  ...     20.4             26.8   1.00  131.0   \n",
       "1            44.3   43.7      90  ...     14.5             18.6   0.84  126.0   \n",
       "2            51.0   37.8      96  ...     17.8             25.6   0.89  131.0   \n",
       "3            39.1   42.1      81  ...     12.8             21.9   0.78  102.0   \n",
       "4            49.3   39.3      63  ...     12.3             25.6   0.80  106.0   \n",
       "..            ...    ...     ...  ...      ...              ...    ...    ...   \n",
       "175          42.3   47.3      96  ...     27.3             39.3   0.94  134.0   \n",
       "176          51.7   34.6      94  ...     22.1             25.7   0.95  113.0   \n",
       "177          55.9   34.9      87  ...     17.5             29.9   0.84  107.0   \n",
       "178          40.9   48.0      93  ...     15.3             29.0   0.81  106.0   \n",
       "179          75.7   15.1     125  ...      9.3             13.1   0.85  104.0   \n",
       "\n",
       "     DBP_2   HR_2  Waist_2  HDL_2  BUN_2  Chol_2  \n",
       "0     74.0   66.0     88.5   53.0   17.5   180.0  \n",
       "1     87.0  108.0     85.0   64.0   14.4   203.0  \n",
       "2     77.0   87.0     81.0   49.0   14.1   196.0  \n",
       "3     62.0   70.0     69.0   98.0   10.5   224.0  \n",
       "4     72.0   69.0     61.0   71.0   11.3   168.0  \n",
       "..     ...    ...      ...    ...    ...     ...  \n",
       "175   89.0   81.0     98.0   66.0   17.1   141.0  \n",
       "176   76.0   66.0     97.5   51.0   14.6   134.0  \n",
       "177   72.0   64.0     80.5   49.0    9.7   147.0  \n",
       "178   76.0   92.0     79.0   60.0   10.2   134.0  \n",
       "179   73.0   79.0     91.0   31.0   36.4   148.0  \n",
       "\n",
       "[180 rows x 50 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (x=쓸 수 있는 모든 특징)\n",
    "X1=psqi_df[['AGE','SEX','BMI_1','PSQI_TOTAL_1','Insulin _1','CRP_1','WBC_1','Neutrophil_1','Lym_1','GLU0_1',\n",
    "            'Creatinine_1','AST_1','ALT_1','HDL_1','TG_1','Muscle_1','Fat_1_x','FatPercentage _1','WHR_1','SBP_1',\n",
    "            'DBP_1','HR_1','Waist_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','SEX','BMI_2','PSQI_TOTAL_2','Insulin _2','CRP_2','WBC_2','Neutrophil_2','Lym_2','GLU0_2',\n",
    "            'Creatinine_2','AST_2','ALT_2','HDL_2','TG_2','Muscle_2','Fat_2_x','FatPercentage_2','WHR_2','SBP_2',\n",
    "            'DBP_2','HR_2','Waist_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "\n",
    "#y 배열 생성 (y=LDL)\n",
    "Y1= psqi_df[['LDL_1']].values\n",
    "Y2= psqi_df[['LDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 360)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 23), (360, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 72)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 23), (360, 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "72/72 - 0s - loss: 12279.2227 - mse: 12279.2227\n",
      "Epoch 2/1000\n",
      "72/72 - 0s - loss: 10407.7344 - mse: 10407.7344\n",
      "Epoch 3/1000\n",
      "72/72 - 0s - loss: 7342.1562 - mse: 7342.1562\n",
      "Epoch 4/1000\n",
      "72/72 - 0s - loss: 4036.4714 - mse: 4036.4714\n",
      "Epoch 5/1000\n",
      "72/72 - 0s - loss: 1858.0112 - mse: 1858.0112\n",
      "Epoch 6/1000\n",
      "72/72 - 0s - loss: 1292.1658 - mse: 1292.1658\n",
      "Epoch 7/1000\n",
      "72/72 - 0s - loss: 1161.1307 - mse: 1161.1307\n",
      "Epoch 8/1000\n",
      "72/72 - 0s - loss: 1070.9340 - mse: 1070.9340\n",
      "Epoch 9/1000\n",
      "72/72 - 0s - loss: 1005.5892 - mse: 1005.5892\n",
      "Epoch 10/1000\n",
      "72/72 - 0s - loss: 958.0283 - mse: 958.0283\n",
      "Epoch 11/1000\n",
      "72/72 - 0s - loss: 916.0247 - mse: 916.0247\n",
      "Epoch 12/1000\n",
      "72/72 - 0s - loss: 884.9627 - mse: 884.9627\n",
      "Epoch 13/1000\n",
      "72/72 - 0s - loss: 854.7992 - mse: 854.7992\n",
      "Epoch 14/1000\n",
      "72/72 - 0s - loss: 836.4276 - mse: 836.4276\n",
      "Epoch 15/1000\n",
      "72/72 - 0s - loss: 809.3678 - mse: 809.3678\n",
      "Epoch 16/1000\n",
      "72/72 - 0s - loss: 790.6620 - mse: 790.6620\n",
      "Epoch 17/1000\n",
      "72/72 - 0s - loss: 772.9847 - mse: 772.9847\n",
      "Epoch 18/1000\n",
      "72/72 - 0s - loss: 760.1069 - mse: 760.1069\n",
      "Epoch 19/1000\n",
      "72/72 - 0s - loss: 739.0818 - mse: 739.0818\n",
      "Epoch 20/1000\n",
      "72/72 - 0s - loss: 731.5129 - mse: 731.5129\n",
      "Epoch 21/1000\n",
      "72/72 - 0s - loss: 713.6537 - mse: 713.6537\n",
      "Epoch 22/1000\n",
      "72/72 - 0s - loss: 705.3408 - mse: 705.3408\n",
      "Epoch 23/1000\n",
      "72/72 - 0s - loss: 694.9960 - mse: 694.9960\n",
      "Epoch 24/1000\n",
      "72/72 - 0s - loss: 684.6725 - mse: 684.6725\n",
      "Epoch 25/1000\n",
      "72/72 - 0s - loss: 676.4920 - mse: 676.4920\n",
      "Epoch 26/1000\n",
      "72/72 - 0s - loss: 662.6461 - mse: 662.6461\n",
      "Epoch 27/1000\n",
      "72/72 - 0s - loss: 663.0585 - mse: 663.0585\n",
      "Epoch 28/1000\n",
      "72/72 - 0s - loss: 646.3096 - mse: 646.3096\n",
      "Epoch 29/1000\n",
      "72/72 - 0s - loss: 638.3536 - mse: 638.3536\n",
      "Epoch 30/1000\n",
      "72/72 - 0s - loss: 630.5381 - mse: 630.5381\n",
      "Epoch 31/1000\n",
      "72/72 - 0s - loss: 623.7485 - mse: 623.7485\n",
      "Epoch 32/1000\n",
      "72/72 - 0s - loss: 614.1028 - mse: 614.1028\n",
      "Epoch 33/1000\n",
      "72/72 - 0s - loss: 612.8997 - mse: 612.8997\n",
      "Epoch 34/1000\n",
      "72/72 - 0s - loss: 604.1049 - mse: 604.1049\n",
      "Epoch 35/1000\n",
      "72/72 - 0s - loss: 600.3140 - mse: 600.3140\n",
      "Epoch 36/1000\n",
      "72/72 - 0s - loss: 596.7820 - mse: 596.7820\n",
      "Epoch 37/1000\n",
      "72/72 - 0s - loss: 590.2864 - mse: 590.2864\n",
      "Epoch 38/1000\n",
      "72/72 - 0s - loss: 590.3680 - mse: 590.3680\n",
      "Epoch 39/1000\n",
      "72/72 - 0s - loss: 575.2360 - mse: 575.2360\n",
      "Epoch 40/1000\n",
      "72/72 - 0s - loss: 576.5768 - mse: 576.5768\n",
      "Epoch 41/1000\n",
      "72/72 - 0s - loss: 575.5689 - mse: 575.5689\n",
      "Epoch 42/1000\n",
      "72/72 - 0s - loss: 566.6803 - mse: 566.6803\n",
      "Epoch 43/1000\n",
      "72/72 - 0s - loss: 566.7534 - mse: 566.7534\n",
      "Epoch 44/1000\n",
      "72/72 - 0s - loss: 559.3480 - mse: 559.3480\n",
      "Epoch 45/1000\n",
      "72/72 - 0s - loss: 563.8972 - mse: 563.8972\n",
      "Epoch 46/1000\n",
      "72/72 - 0s - loss: 553.3581 - mse: 553.3581\n",
      "Epoch 47/1000\n",
      "72/72 - 0s - loss: 553.5762 - mse: 553.5762\n",
      "Epoch 48/1000\n",
      "72/72 - 0s - loss: 555.2892 - mse: 555.2892\n",
      "Epoch 49/1000\n",
      "72/72 - 0s - loss: 548.1210 - mse: 548.1210\n",
      "Epoch 50/1000\n",
      "72/72 - 0s - loss: 537.6110 - mse: 537.6110\n",
      "Epoch 51/1000\n",
      "72/72 - 0s - loss: 541.5995 - mse: 541.5995\n",
      "Epoch 52/1000\n",
      "72/72 - 0s - loss: 536.0955 - mse: 536.0955\n",
      "Epoch 53/1000\n",
      "72/72 - 0s - loss: 531.9187 - mse: 531.9187\n",
      "Epoch 54/1000\n",
      "72/72 - 0s - loss: 529.2066 - mse: 529.2066\n",
      "Epoch 55/1000\n",
      "72/72 - 0s - loss: 522.6182 - mse: 522.6182\n",
      "Epoch 56/1000\n",
      "72/72 - 0s - loss: 515.8630 - mse: 515.8630\n",
      "Epoch 57/1000\n",
      "72/72 - 0s - loss: 517.8333 - mse: 517.8333\n",
      "Epoch 58/1000\n",
      "72/72 - 0s - loss: 516.0700 - mse: 516.0700\n",
      "Epoch 59/1000\n",
      "72/72 - 0s - loss: 513.3019 - mse: 513.3019\n",
      "Epoch 60/1000\n",
      "72/72 - 0s - loss: 510.3298 - mse: 510.3298\n",
      "Epoch 61/1000\n",
      "72/72 - 0s - loss: 508.2912 - mse: 508.2912\n",
      "Epoch 62/1000\n",
      "72/72 - 0s - loss: 510.5516 - mse: 510.5516\n",
      "Epoch 63/1000\n",
      "72/72 - 0s - loss: 504.5949 - mse: 504.5949\n",
      "Epoch 64/1000\n",
      "72/72 - 0s - loss: 505.1219 - mse: 505.1219\n",
      "Epoch 65/1000\n",
      "72/72 - 0s - loss: 497.7324 - mse: 497.7324\n",
      "Epoch 66/1000\n",
      "72/72 - 0s - loss: 502.1031 - mse: 502.1031\n",
      "Epoch 67/1000\n",
      "72/72 - 0s - loss: 495.7672 - mse: 495.7672\n",
      "Epoch 68/1000\n",
      "72/72 - 0s - loss: 492.7997 - mse: 492.7997\n",
      "Epoch 69/1000\n",
      "72/72 - 0s - loss: 491.0024 - mse: 491.0024\n",
      "Epoch 70/1000\n",
      "72/72 - 0s - loss: 487.4048 - mse: 487.4048\n",
      "Epoch 71/1000\n",
      "72/72 - 0s - loss: 478.9282 - mse: 478.9282\n",
      "Epoch 72/1000\n",
      "72/72 - 0s - loss: 483.4721 - mse: 483.4721\n",
      "Epoch 73/1000\n",
      "72/72 - 0s - loss: 480.5481 - mse: 480.5481\n",
      "Epoch 74/1000\n",
      "72/72 - 0s - loss: 475.1850 - mse: 475.1850\n",
      "Epoch 75/1000\n",
      "72/72 - 0s - loss: 472.0832 - mse: 472.0832\n",
      "Epoch 76/1000\n",
      "72/72 - 0s - loss: 474.3099 - mse: 474.3099\n",
      "Epoch 77/1000\n",
      "72/72 - 0s - loss: 474.7758 - mse: 474.7758\n",
      "Epoch 78/1000\n",
      "72/72 - 0s - loss: 472.5941 - mse: 472.5941\n",
      "Epoch 79/1000\n",
      "72/72 - 0s - loss: 467.1899 - mse: 467.1899\n",
      "Epoch 80/1000\n",
      "72/72 - 0s - loss: 468.7342 - mse: 468.7342\n",
      "Epoch 81/1000\n",
      "72/72 - 0s - loss: 460.7128 - mse: 460.7128\n",
      "Epoch 82/1000\n",
      "72/72 - 0s - loss: 460.5542 - mse: 460.5542\n",
      "Epoch 83/1000\n",
      "72/72 - 0s - loss: 460.6461 - mse: 460.6461\n",
      "Epoch 84/1000\n",
      "72/72 - 0s - loss: 463.5500 - mse: 463.5500\n",
      "Epoch 85/1000\n",
      "72/72 - 0s - loss: 463.9923 - mse: 463.9923\n",
      "Epoch 86/1000\n",
      "72/72 - 0s - loss: 456.7972 - mse: 456.7972\n",
      "Epoch 87/1000\n",
      "72/72 - 0s - loss: 462.0760 - mse: 462.0760\n",
      "Epoch 88/1000\n",
      "72/72 - 0s - loss: 454.5231 - mse: 454.5231\n",
      "Epoch 89/1000\n",
      "72/72 - 0s - loss: 459.7401 - mse: 459.7401\n",
      "Epoch 90/1000\n",
      "72/72 - 0s - loss: 455.6006 - mse: 455.6006\n",
      "Epoch 91/1000\n",
      "72/72 - 0s - loss: 449.3125 - mse: 449.3125\n",
      "Epoch 92/1000\n",
      "72/72 - 0s - loss: 449.2060 - mse: 449.2060\n",
      "Epoch 93/1000\n",
      "72/72 - 0s - loss: 450.9237 - mse: 450.9237\n",
      "Epoch 94/1000\n",
      "72/72 - 0s - loss: 442.5747 - mse: 442.5747\n",
      "Epoch 95/1000\n",
      "72/72 - 0s - loss: 448.8885 - mse: 448.8885\n",
      "Epoch 96/1000\n",
      "72/72 - 0s - loss: 445.6513 - mse: 445.6513\n",
      "Epoch 97/1000\n",
      "72/72 - 0s - loss: 442.9531 - mse: 442.9531\n",
      "Epoch 98/1000\n",
      "72/72 - 0s - loss: 441.2695 - mse: 441.2695\n",
      "Epoch 99/1000\n",
      "72/72 - 0s - loss: 438.8137 - mse: 438.8137\n",
      "Epoch 100/1000\n",
      "72/72 - 0s - loss: 434.8591 - mse: 434.8591\n",
      "Epoch 101/1000\n",
      "72/72 - 0s - loss: 431.1628 - mse: 431.1628\n",
      "Epoch 102/1000\n",
      "72/72 - 0s - loss: 437.8046 - mse: 437.8046\n",
      "Epoch 103/1000\n",
      "72/72 - 0s - loss: 434.9991 - mse: 434.9991\n",
      "Epoch 104/1000\n",
      "72/72 - 0s - loss: 428.1494 - mse: 428.1494\n",
      "Epoch 105/1000\n",
      "72/72 - 0s - loss: 432.5180 - mse: 432.5180\n",
      "Epoch 106/1000\n",
      "72/72 - 0s - loss: 432.0689 - mse: 432.0689\n",
      "Epoch 107/1000\n",
      "72/72 - 0s - loss: 426.1893 - mse: 426.1893\n",
      "Epoch 108/1000\n",
      "72/72 - 0s - loss: 426.6602 - mse: 426.6602\n",
      "Epoch 109/1000\n",
      "72/72 - 0s - loss: 426.6113 - mse: 426.6113\n",
      "Epoch 110/1000\n",
      "72/72 - 0s - loss: 417.3502 - mse: 417.3502\n",
      "Epoch 111/1000\n",
      "72/72 - 0s - loss: 426.5880 - mse: 426.5880\n",
      "Epoch 112/1000\n",
      "72/72 - 0s - loss: 420.7896 - mse: 420.7896\n",
      "Epoch 113/1000\n",
      "72/72 - 0s - loss: 418.1528 - mse: 418.1528\n",
      "Epoch 114/1000\n",
      "72/72 - 0s - loss: 415.7599 - mse: 415.7599\n",
      "Epoch 115/1000\n",
      "72/72 - 0s - loss: 415.5631 - mse: 415.5631\n",
      "Epoch 116/1000\n",
      "72/72 - 0s - loss: 409.5587 - mse: 409.5587\n",
      "Epoch 117/1000\n",
      "72/72 - 0s - loss: 411.9303 - mse: 411.9303\n",
      "Epoch 118/1000\n",
      "72/72 - 0s - loss: 410.0097 - mse: 410.0097\n",
      "Epoch 119/1000\n",
      "72/72 - 0s - loss: 407.4028 - mse: 407.4028\n",
      "Epoch 120/1000\n",
      "72/72 - 0s - loss: 403.3683 - mse: 403.3683\n",
      "Epoch 121/1000\n",
      "72/72 - 0s - loss: 399.8126 - mse: 399.8126\n",
      "Epoch 122/1000\n",
      "72/72 - 0s - loss: 399.0174 - mse: 399.0174\n",
      "Epoch 123/1000\n",
      "72/72 - 0s - loss: 394.4537 - mse: 394.4537\n",
      "Epoch 124/1000\n",
      "72/72 - 0s - loss: 396.7409 - mse: 396.7409\n",
      "Epoch 125/1000\n",
      "72/72 - 0s - loss: 395.1801 - mse: 395.1801\n",
      "Epoch 126/1000\n",
      "72/72 - 0s - loss: 392.8981 - mse: 392.8981\n",
      "Epoch 127/1000\n",
      "72/72 - 0s - loss: 385.9309 - mse: 385.9309\n",
      "Epoch 128/1000\n",
      "72/72 - 0s - loss: 387.3771 - mse: 387.3771\n",
      "Epoch 129/1000\n",
      "72/72 - 0s - loss: 389.1345 - mse: 389.1345\n",
      "Epoch 130/1000\n",
      "72/72 - 0s - loss: 381.6097 - mse: 381.6097\n",
      "Epoch 131/1000\n",
      "72/72 - 0s - loss: 382.5910 - mse: 382.5910\n",
      "Epoch 132/1000\n",
      "72/72 - 0s - loss: 381.8770 - mse: 381.8770\n",
      "Epoch 133/1000\n",
      "72/72 - 0s - loss: 379.0614 - mse: 379.0614\n",
      "Epoch 134/1000\n",
      "72/72 - 0s - loss: 381.7022 - mse: 381.7022\n",
      "Epoch 135/1000\n",
      "72/72 - 0s - loss: 372.7599 - mse: 372.7599\n",
      "Epoch 136/1000\n",
      "72/72 - 0s - loss: 378.2348 - mse: 378.2348\n",
      "Epoch 137/1000\n",
      "72/72 - 0s - loss: 372.3981 - mse: 372.3981\n",
      "Epoch 138/1000\n",
      "72/72 - 0s - loss: 370.0648 - mse: 370.0648\n",
      "Epoch 139/1000\n",
      "72/72 - 0s - loss: 366.7902 - mse: 366.7902\n",
      "Epoch 140/1000\n",
      "72/72 - 0s - loss: 370.7026 - mse: 370.7026\n",
      "Epoch 141/1000\n",
      "72/72 - 0s - loss: 369.5779 - mse: 369.5779\n",
      "Epoch 142/1000\n",
      "72/72 - 0s - loss: 368.6107 - mse: 368.6107\n",
      "Epoch 143/1000\n",
      "72/72 - 0s - loss: 363.6014 - mse: 363.6014\n",
      "Epoch 144/1000\n",
      "72/72 - 0s - loss: 360.2647 - mse: 360.2647\n",
      "Epoch 145/1000\n",
      "72/72 - 0s - loss: 358.4678 - mse: 358.4678\n",
      "Epoch 146/1000\n",
      "72/72 - 0s - loss: 354.4995 - mse: 354.4995\n",
      "Epoch 147/1000\n",
      "72/72 - 0s - loss: 352.3351 - mse: 352.3351\n",
      "Epoch 148/1000\n",
      "72/72 - 0s - loss: 352.6090 - mse: 352.6090\n",
      "Epoch 149/1000\n",
      "72/72 - 0s - loss: 352.0110 - mse: 352.0110\n",
      "Epoch 150/1000\n",
      "72/72 - 0s - loss: 345.4078 - mse: 345.4078\n",
      "Epoch 151/1000\n",
      "72/72 - 0s - loss: 346.0346 - mse: 346.0346\n",
      "Epoch 152/1000\n",
      "72/72 - 0s - loss: 350.0934 - mse: 350.0934\n",
      "Epoch 153/1000\n",
      "72/72 - 0s - loss: 342.2955 - mse: 342.2955\n",
      "Epoch 154/1000\n",
      "72/72 - 0s - loss: 341.7763 - mse: 341.7763\n",
      "Epoch 155/1000\n",
      "72/72 - 0s - loss: 339.9601 - mse: 339.9601\n",
      "Epoch 156/1000\n",
      "72/72 - 0s - loss: 336.4873 - mse: 336.4873\n",
      "Epoch 157/1000\n",
      "72/72 - 0s - loss: 330.9073 - mse: 330.9073\n",
      "Epoch 158/1000\n",
      "72/72 - 0s - loss: 334.2837 - mse: 334.2837\n",
      "Epoch 159/1000\n",
      "72/72 - 0s - loss: 335.4725 - mse: 335.4725\n",
      "Epoch 160/1000\n",
      "72/72 - 0s - loss: 332.0926 - mse: 332.0926\n",
      "Epoch 161/1000\n",
      "72/72 - 0s - loss: 327.5084 - mse: 327.5084\n",
      "Epoch 162/1000\n",
      "72/72 - 0s - loss: 327.6626 - mse: 327.6626\n",
      "Epoch 163/1000\n",
      "72/72 - 0s - loss: 325.5225 - mse: 325.5225\n",
      "Epoch 164/1000\n",
      "72/72 - 0s - loss: 320.7130 - mse: 320.7130\n",
      "Epoch 165/1000\n",
      "72/72 - 0s - loss: 320.7803 - mse: 320.7803\n",
      "Epoch 166/1000\n",
      "72/72 - 0s - loss: 318.7016 - mse: 318.7016\n",
      "Epoch 167/1000\n",
      "72/72 - 0s - loss: 318.9999 - mse: 318.9999\n",
      "Epoch 168/1000\n",
      "72/72 - 0s - loss: 315.6780 - mse: 315.6780\n",
      "Epoch 169/1000\n",
      "72/72 - 0s - loss: 313.0840 - mse: 313.0840\n",
      "Epoch 170/1000\n",
      "72/72 - 0s - loss: 311.3129 - mse: 311.3129\n",
      "Epoch 171/1000\n",
      "72/72 - 0s - loss: 311.6271 - mse: 311.6271\n",
      "Epoch 172/1000\n",
      "72/72 - 0s - loss: 310.3182 - mse: 310.3182\n",
      "Epoch 173/1000\n",
      "72/72 - 0s - loss: 307.7079 - mse: 307.7079\n",
      "Epoch 174/1000\n",
      "72/72 - 0s - loss: 309.3231 - mse: 309.3231\n",
      "Epoch 175/1000\n",
      "72/72 - 0s - loss: 306.5986 - mse: 306.5986\n",
      "Epoch 176/1000\n",
      "72/72 - 0s - loss: 302.2545 - mse: 302.2545\n",
      "Epoch 177/1000\n",
      "72/72 - 0s - loss: 302.8533 - mse: 302.8533\n",
      "Epoch 178/1000\n",
      "72/72 - 0s - loss: 299.3166 - mse: 299.3166\n",
      "Epoch 179/1000\n",
      "72/72 - 0s - loss: 296.5152 - mse: 296.5152\n",
      "Epoch 180/1000\n",
      "72/72 - 0s - loss: 296.1550 - mse: 296.1550\n",
      "Epoch 181/1000\n",
      "72/72 - 0s - loss: 294.8943 - mse: 294.8943\n",
      "Epoch 182/1000\n",
      "72/72 - 0s - loss: 292.7588 - mse: 292.7588\n",
      "Epoch 183/1000\n",
      "72/72 - 0s - loss: 292.8992 - mse: 292.8992\n",
      "Epoch 184/1000\n",
      "72/72 - 0s - loss: 296.1534 - mse: 296.1534\n",
      "Epoch 185/1000\n",
      "72/72 - 0s - loss: 285.4859 - mse: 285.4859\n",
      "Epoch 186/1000\n",
      "72/72 - 0s - loss: 287.1493 - mse: 287.1493\n",
      "Epoch 187/1000\n",
      "72/72 - 0s - loss: 285.3100 - mse: 285.3100\n",
      "Epoch 188/1000\n",
      "72/72 - 0s - loss: 279.2393 - mse: 279.2393\n",
      "Epoch 189/1000\n",
      "72/72 - 0s - loss: 284.0141 - mse: 284.0141\n",
      "Epoch 190/1000\n",
      "72/72 - 0s - loss: 280.2785 - mse: 280.2785\n",
      "Epoch 191/1000\n",
      "72/72 - 0s - loss: 281.1557 - mse: 281.1557\n",
      "Epoch 192/1000\n",
      "72/72 - 0s - loss: 278.2776 - mse: 278.2776\n",
      "Epoch 193/1000\n",
      "72/72 - 0s - loss: 275.6309 - mse: 275.6309\n",
      "Epoch 194/1000\n",
      "72/72 - 0s - loss: 274.7072 - mse: 274.7072\n",
      "Epoch 195/1000\n",
      "72/72 - 0s - loss: 271.4239 - mse: 271.4239\n",
      "Epoch 196/1000\n",
      "72/72 - 0s - loss: 265.1158 - mse: 265.1158\n",
      "Epoch 197/1000\n",
      "72/72 - 0s - loss: 269.7565 - mse: 269.7565\n",
      "Epoch 198/1000\n",
      "72/72 - 0s - loss: 261.4792 - mse: 261.4792\n",
      "Epoch 199/1000\n",
      "72/72 - 0s - loss: 266.5990 - mse: 266.5990\n",
      "Epoch 200/1000\n",
      "72/72 - 0s - loss: 268.4923 - mse: 268.4923\n",
      "Epoch 201/1000\n",
      "72/72 - 0s - loss: 260.3047 - mse: 260.3047\n",
      "Epoch 202/1000\n",
      "72/72 - 0s - loss: 260.6985 - mse: 260.6985\n",
      "Epoch 203/1000\n",
      "72/72 - 0s - loss: 256.8072 - mse: 256.8072\n",
      "Epoch 204/1000\n",
      "72/72 - 0s - loss: 259.1083 - mse: 259.1083\n",
      "Epoch 205/1000\n",
      "72/72 - 0s - loss: 253.3642 - mse: 253.3642\n",
      "Epoch 206/1000\n",
      "72/72 - 0s - loss: 251.5090 - mse: 251.5090\n",
      "Epoch 207/1000\n",
      "72/72 - 0s - loss: 252.5704 - mse: 252.5704\n",
      "Epoch 208/1000\n",
      "72/72 - 0s - loss: 245.6466 - mse: 245.6466\n",
      "Epoch 209/1000\n",
      "72/72 - 0s - loss: 250.7381 - mse: 250.7381\n",
      "Epoch 210/1000\n",
      "72/72 - 0s - loss: 242.3524 - mse: 242.3524\n",
      "Epoch 211/1000\n",
      "72/72 - 0s - loss: 247.3496 - mse: 247.3496\n",
      "Epoch 212/1000\n",
      "72/72 - 0s - loss: 244.6391 - mse: 244.6391\n",
      "Epoch 213/1000\n",
      "72/72 - 0s - loss: 242.0018 - mse: 242.0018\n",
      "Epoch 214/1000\n",
      "72/72 - 0s - loss: 236.6986 - mse: 236.6986\n",
      "Epoch 215/1000\n",
      "72/72 - 0s - loss: 238.1860 - mse: 238.1860\n",
      "Epoch 216/1000\n",
      "72/72 - 0s - loss: 241.0100 - mse: 241.0100\n",
      "Epoch 217/1000\n",
      "72/72 - 0s - loss: 230.9580 - mse: 230.9580\n",
      "Epoch 218/1000\n",
      "72/72 - 0s - loss: 232.0667 - mse: 232.0667\n",
      "Epoch 219/1000\n",
      "72/72 - 0s - loss: 232.7361 - mse: 232.7361\n",
      "Epoch 220/1000\n",
      "72/72 - 0s - loss: 231.5044 - mse: 231.5044\n",
      "Epoch 221/1000\n",
      "72/72 - 0s - loss: 228.6762 - mse: 228.6762\n",
      "Epoch 222/1000\n",
      "72/72 - 0s - loss: 225.3889 - mse: 225.3889\n",
      "Epoch 223/1000\n",
      "72/72 - 0s - loss: 224.0894 - mse: 224.0894\n",
      "Epoch 224/1000\n",
      "72/72 - 0s - loss: 226.1001 - mse: 226.1001\n",
      "Epoch 225/1000\n",
      "72/72 - 0s - loss: 220.6590 - mse: 220.6590\n",
      "Epoch 226/1000\n",
      "72/72 - 0s - loss: 216.2838 - mse: 216.2838\n",
      "Epoch 227/1000\n",
      "72/72 - 0s - loss: 217.9332 - mse: 217.9332\n",
      "Epoch 228/1000\n",
      "72/72 - 0s - loss: 217.8180 - mse: 217.8180\n",
      "Epoch 229/1000\n",
      "72/72 - 0s - loss: 213.1403 - mse: 213.1403\n",
      "Epoch 230/1000\n",
      "72/72 - 0s - loss: 209.4472 - mse: 209.4472\n",
      "Epoch 231/1000\n",
      "72/72 - 0s - loss: 214.3194 - mse: 214.3194\n",
      "Epoch 232/1000\n",
      "72/72 - 0s - loss: 211.3627 - mse: 211.3627\n",
      "Epoch 233/1000\n",
      "72/72 - 0s - loss: 206.2550 - mse: 206.2550\n",
      "Epoch 234/1000\n",
      "72/72 - 0s - loss: 208.4349 - mse: 208.4349\n",
      "Epoch 235/1000\n",
      "72/72 - 0s - loss: 199.5397 - mse: 199.5397\n",
      "Epoch 236/1000\n",
      "72/72 - 0s - loss: 203.7885 - mse: 203.7885\n",
      "Epoch 237/1000\n",
      "72/72 - 0s - loss: 196.3557 - mse: 196.3557\n",
      "Epoch 238/1000\n",
      "72/72 - 0s - loss: 202.3007 - mse: 202.3007\n",
      "Epoch 239/1000\n",
      "72/72 - 0s - loss: 200.9394 - mse: 200.9394\n",
      "Epoch 240/1000\n",
      "72/72 - 0s - loss: 196.8412 - mse: 196.8412\n",
      "Epoch 241/1000\n",
      "72/72 - 0s - loss: 195.2010 - mse: 195.2010\n",
      "Epoch 242/1000\n",
      "72/72 - 0s - loss: 194.5166 - mse: 194.5166\n",
      "Epoch 243/1000\n",
      "72/72 - 0s - loss: 194.7065 - mse: 194.7065\n",
      "Epoch 244/1000\n",
      "72/72 - 0s - loss: 190.0030 - mse: 190.0030\n",
      "Epoch 245/1000\n",
      "72/72 - 0s - loss: 188.7802 - mse: 188.7802\n",
      "Epoch 246/1000\n",
      "72/72 - 0s - loss: 191.3620 - mse: 191.3620\n",
      "Epoch 247/1000\n",
      "72/72 - 0s - loss: 184.9571 - mse: 184.9571\n",
      "Epoch 248/1000\n",
      "72/72 - 0s - loss: 187.1056 - mse: 187.1056\n",
      "Epoch 249/1000\n",
      "72/72 - 0s - loss: 183.8743 - mse: 183.8743\n",
      "Epoch 250/1000\n",
      "72/72 - 0s - loss: 183.0071 - mse: 183.0071\n",
      "Epoch 251/1000\n",
      "72/72 - 0s - loss: 178.0424 - mse: 178.0424\n",
      "Epoch 252/1000\n",
      "72/72 - 0s - loss: 177.5889 - mse: 177.5889\n",
      "Epoch 253/1000\n",
      "72/72 - 0s - loss: 175.5642 - mse: 175.5642\n",
      "Epoch 254/1000\n",
      "72/72 - 0s - loss: 177.6312 - mse: 177.6312\n",
      "Epoch 255/1000\n",
      "72/72 - 0s - loss: 173.6433 - mse: 173.6433\n",
      "Epoch 256/1000\n",
      "72/72 - 0s - loss: 171.3270 - mse: 171.3270\n",
      "Epoch 257/1000\n",
      "72/72 - 0s - loss: 172.5845 - mse: 172.5845\n",
      "Epoch 258/1000\n",
      "72/72 - 0s - loss: 172.1292 - mse: 172.1292\n",
      "Epoch 259/1000\n",
      "72/72 - 0s - loss: 166.1694 - mse: 166.1694\n",
      "Epoch 260/1000\n",
      "72/72 - 0s - loss: 168.3413 - mse: 168.3413\n",
      "Epoch 261/1000\n",
      "72/72 - 0s - loss: 164.8680 - mse: 164.8680\n",
      "Epoch 262/1000\n",
      "72/72 - 0s - loss: 163.5954 - mse: 163.5954\n",
      "Epoch 263/1000\n",
      "72/72 - 0s - loss: 166.0117 - mse: 166.0117\n",
      "Epoch 264/1000\n",
      "72/72 - 0s - loss: 162.2335 - mse: 162.2335\n",
      "Epoch 265/1000\n",
      "72/72 - 0s - loss: 157.7772 - mse: 157.7772\n",
      "Epoch 266/1000\n",
      "72/72 - 0s - loss: 158.5530 - mse: 158.5530\n",
      "Epoch 267/1000\n",
      "72/72 - 0s - loss: 153.6800 - mse: 153.6800\n",
      "Epoch 268/1000\n",
      "72/72 - 0s - loss: 153.1743 - mse: 153.1743\n",
      "Epoch 269/1000\n",
      "72/72 - 0s - loss: 153.5399 - mse: 153.5399\n",
      "Epoch 270/1000\n",
      "72/72 - 0s - loss: 151.0520 - mse: 151.0520\n",
      "Epoch 271/1000\n",
      "72/72 - 0s - loss: 153.2754 - mse: 153.2754\n",
      "Epoch 272/1000\n",
      "72/72 - 0s - loss: 144.2374 - mse: 144.2374\n",
      "Epoch 273/1000\n",
      "72/72 - 0s - loss: 153.8737 - mse: 153.8737\n",
      "Epoch 274/1000\n",
      "72/72 - 0s - loss: 150.1009 - mse: 150.1009\n",
      "Epoch 275/1000\n",
      "72/72 - 0s - loss: 143.8752 - mse: 143.8752\n",
      "Epoch 276/1000\n",
      "72/72 - 0s - loss: 144.6953 - mse: 144.6953\n",
      "Epoch 277/1000\n",
      "72/72 - 0s - loss: 142.3209 - mse: 142.3209\n",
      "Epoch 278/1000\n",
      "72/72 - 0s - loss: 142.2462 - mse: 142.2462\n",
      "Epoch 279/1000\n",
      "72/72 - 0s - loss: 142.9549 - mse: 142.9549\n",
      "Epoch 280/1000\n",
      "72/72 - 0s - loss: 140.7866 - mse: 140.7866\n",
      "Epoch 281/1000\n",
      "72/72 - 0s - loss: 135.9662 - mse: 135.9662\n",
      "Epoch 282/1000\n",
      "72/72 - 0s - loss: 136.0183 - mse: 136.0183\n",
      "Epoch 283/1000\n",
      "72/72 - 0s - loss: 136.8073 - mse: 136.8073\n",
      "Epoch 284/1000\n",
      "72/72 - 0s - loss: 133.5433 - mse: 133.5433\n",
      "Epoch 285/1000\n",
      "72/72 - 0s - loss: 134.8199 - mse: 134.8199\n",
      "Epoch 286/1000\n",
      "72/72 - 0s - loss: 133.6666 - mse: 133.6666\n",
      "Epoch 287/1000\n",
      "72/72 - 0s - loss: 129.0310 - mse: 129.0310\n",
      "Epoch 288/1000\n",
      "72/72 - 0s - loss: 131.0160 - mse: 131.0160\n",
      "Epoch 289/1000\n",
      "72/72 - 0s - loss: 128.9459 - mse: 128.9459\n",
      "Epoch 290/1000\n",
      "72/72 - 0s - loss: 130.3720 - mse: 130.3720\n",
      "Epoch 291/1000\n",
      "72/72 - 0s - loss: 119.0734 - mse: 119.0734\n",
      "Epoch 292/1000\n",
      "72/72 - 0s - loss: 127.9427 - mse: 127.9427\n",
      "Epoch 293/1000\n",
      "72/72 - 0s - loss: 123.2762 - mse: 123.2762\n",
      "Epoch 294/1000\n",
      "72/72 - 0s - loss: 125.5348 - mse: 125.5348\n",
      "Epoch 295/1000\n",
      "72/72 - 0s - loss: 122.4876 - mse: 122.4876\n",
      "Epoch 296/1000\n",
      "72/72 - 0s - loss: 119.4962 - mse: 119.4962\n",
      "Epoch 297/1000\n",
      "72/72 - 0s - loss: 122.6131 - mse: 122.6131\n",
      "Epoch 298/1000\n",
      "72/72 - 0s - loss: 115.4082 - mse: 115.4082\n",
      "Epoch 299/1000\n",
      "72/72 - 0s - loss: 120.4071 - mse: 120.4071\n",
      "Epoch 300/1000\n",
      "72/72 - 0s - loss: 116.5155 - mse: 116.5155\n",
      "Epoch 301/1000\n",
      "72/72 - 0s - loss: 116.0738 - mse: 116.0738\n",
      "Epoch 302/1000\n",
      "72/72 - 0s - loss: 116.9158 - mse: 116.9158\n",
      "Epoch 303/1000\n",
      "72/72 - 0s - loss: 114.2936 - mse: 114.2936\n",
      "Epoch 304/1000\n",
      "72/72 - 0s - loss: 113.5981 - mse: 113.5981\n",
      "Epoch 305/1000\n",
      "72/72 - 0s - loss: 113.0724 - mse: 113.0724\n",
      "Epoch 306/1000\n",
      "72/72 - 0s - loss: 106.1026 - mse: 106.1026\n",
      "Epoch 307/1000\n",
      "72/72 - 0s - loss: 110.5880 - mse: 110.5880\n",
      "Epoch 308/1000\n",
      "72/72 - 0s - loss: 107.4531 - mse: 107.4531\n",
      "Epoch 309/1000\n",
      "72/72 - 0s - loss: 110.3336 - mse: 110.3336\n",
      "Epoch 310/1000\n",
      "72/72 - 0s - loss: 105.3448 - mse: 105.3448\n",
      "Epoch 311/1000\n",
      "72/72 - 0s - loss: 108.3482 - mse: 108.3482\n",
      "Epoch 312/1000\n",
      "72/72 - 0s - loss: 103.5638 - mse: 103.5638\n",
      "Epoch 313/1000\n",
      "72/72 - 0s - loss: 106.2158 - mse: 106.2158\n",
      "Epoch 314/1000\n",
      "72/72 - 0s - loss: 101.1950 - mse: 101.1950\n",
      "Epoch 315/1000\n",
      "72/72 - 0s - loss: 101.6561 - mse: 101.6561\n",
      "Epoch 316/1000\n",
      "72/72 - 0s - loss: 97.6202 - mse: 97.6202\n",
      "Epoch 317/1000\n",
      "72/72 - 0s - loss: 102.1191 - mse: 102.1191\n",
      "Epoch 318/1000\n",
      "72/72 - 0s - loss: 98.6680 - mse: 98.6680\n",
      "Epoch 319/1000\n",
      "72/72 - 0s - loss: 98.8502 - mse: 98.8502\n",
      "Epoch 320/1000\n",
      "72/72 - 0s - loss: 99.4463 - mse: 99.4463\n",
      "Epoch 321/1000\n",
      "72/72 - 0s - loss: 97.0159 - mse: 97.0159\n",
      "Epoch 322/1000\n",
      "72/72 - 0s - loss: 93.7794 - mse: 93.7794\n",
      "Epoch 323/1000\n",
      "72/72 - 0s - loss: 92.3046 - mse: 92.3046\n",
      "Epoch 324/1000\n",
      "72/72 - 0s - loss: 97.5177 - mse: 97.5177\n",
      "Epoch 325/1000\n",
      "72/72 - 0s - loss: 90.3058 - mse: 90.3058\n",
      "Epoch 326/1000\n",
      "72/72 - 0s - loss: 94.0376 - mse: 94.0376\n",
      "Epoch 327/1000\n",
      "72/72 - 0s - loss: 91.4680 - mse: 91.4680\n",
      "Epoch 328/1000\n",
      "72/72 - 0s - loss: 94.5819 - mse: 94.5819\n",
      "Epoch 329/1000\n",
      "72/72 - 0s - loss: 89.2813 - mse: 89.2813\n",
      "Epoch 330/1000\n",
      "72/72 - 0s - loss: 90.8648 - mse: 90.8648\n",
      "Epoch 331/1000\n",
      "72/72 - 0s - loss: 81.8454 - mse: 81.8454\n",
      "Epoch 332/1000\n",
      "72/72 - 0s - loss: 85.5536 - mse: 85.5536\n",
      "Epoch 333/1000\n",
      "72/72 - 0s - loss: 86.8609 - mse: 86.8609\n",
      "Epoch 334/1000\n",
      "72/72 - 0s - loss: 83.4415 - mse: 83.4415\n",
      "Epoch 335/1000\n",
      "72/72 - 0s - loss: 84.6300 - mse: 84.6300\n",
      "Epoch 336/1000\n",
      "72/72 - 0s - loss: 81.8440 - mse: 81.8440\n",
      "Epoch 337/1000\n",
      "72/72 - 0s - loss: 83.8525 - mse: 83.8525\n",
      "Epoch 338/1000\n",
      "72/72 - 0s - loss: 79.8500 - mse: 79.8500\n",
      "Epoch 339/1000\n",
      "72/72 - 0s - loss: 82.2923 - mse: 82.2923\n",
      "Epoch 340/1000\n",
      "72/72 - 0s - loss: 82.1768 - mse: 82.1768\n",
      "Epoch 341/1000\n",
      "72/72 - 0s - loss: 79.3142 - mse: 79.3142\n",
      "Epoch 342/1000\n",
      "72/72 - 0s - loss: 76.4735 - mse: 76.4735\n",
      "Epoch 343/1000\n",
      "72/72 - 0s - loss: 77.6988 - mse: 77.6988\n",
      "Epoch 344/1000\n",
      "72/72 - 0s - loss: 77.9506 - mse: 77.9506\n",
      "Epoch 345/1000\n",
      "72/72 - 0s - loss: 77.6940 - mse: 77.6940\n",
      "Epoch 346/1000\n",
      "72/72 - 0s - loss: 74.8661 - mse: 74.8661\n",
      "Epoch 347/1000\n",
      "72/72 - 0s - loss: 74.3840 - mse: 74.3840\n",
      "Epoch 348/1000\n",
      "72/72 - 0s - loss: 71.7489 - mse: 71.7489\n",
      "Epoch 349/1000\n",
      "72/72 - 0s - loss: 70.8106 - mse: 70.8106\n",
      "Epoch 350/1000\n",
      "72/72 - 0s - loss: 72.6001 - mse: 72.6001\n",
      "Epoch 351/1000\n",
      "72/72 - 0s - loss: 73.5284 - mse: 73.5284\n",
      "Epoch 352/1000\n",
      "72/72 - 0s - loss: 70.1851 - mse: 70.1851\n",
      "Epoch 353/1000\n",
      "72/72 - 0s - loss: 71.2530 - mse: 71.2530\n",
      "Epoch 354/1000\n",
      "72/72 - 0s - loss: 68.5930 - mse: 68.5930\n",
      "Epoch 355/1000\n",
      "72/72 - 0s - loss: 68.6611 - mse: 68.6611\n",
      "Epoch 356/1000\n",
      "72/72 - 0s - loss: 65.8958 - mse: 65.8958\n",
      "Epoch 357/1000\n",
      "72/72 - 0s - loss: 67.6030 - mse: 67.6030\n",
      "Epoch 358/1000\n",
      "72/72 - 0s - loss: 67.0299 - mse: 67.0299\n",
      "Epoch 359/1000\n",
      "72/72 - 0s - loss: 65.9199 - mse: 65.9199\n",
      "Epoch 360/1000\n",
      "72/72 - 0s - loss: 63.0581 - mse: 63.0581\n",
      "Epoch 361/1000\n",
      "72/72 - 0s - loss: 65.8885 - mse: 65.8885\n",
      "Epoch 362/1000\n",
      "72/72 - 0s - loss: 61.0115 - mse: 61.0115\n",
      "Epoch 363/1000\n",
      "72/72 - 0s - loss: 62.6908 - mse: 62.6908\n",
      "Epoch 364/1000\n",
      "72/72 - 0s - loss: 62.4110 - mse: 62.4110\n",
      "Epoch 365/1000\n",
      "72/72 - 0s - loss: 60.3226 - mse: 60.3226\n",
      "Epoch 366/1000\n",
      "72/72 - 0s - loss: 61.4916 - mse: 61.4916\n",
      "Epoch 367/1000\n",
      "72/72 - 0s - loss: 60.6142 - mse: 60.6142\n",
      "Epoch 368/1000\n",
      "72/72 - 0s - loss: 57.7957 - mse: 57.7957\n",
      "Epoch 369/1000\n",
      "72/72 - 0s - loss: 56.9382 - mse: 56.9382\n",
      "Epoch 370/1000\n",
      "72/72 - 0s - loss: 56.7672 - mse: 56.7672\n",
      "Epoch 371/1000\n",
      "72/72 - 0s - loss: 57.5443 - mse: 57.5443\n",
      "Epoch 372/1000\n",
      "72/72 - 0s - loss: 55.9020 - mse: 55.9020\n",
      "Epoch 373/1000\n",
      "72/72 - 0s - loss: 54.8626 - mse: 54.8626\n",
      "Epoch 374/1000\n",
      "72/72 - 0s - loss: 54.6487 - mse: 54.6487\n",
      "Epoch 375/1000\n",
      "72/72 - 0s - loss: 52.7892 - mse: 52.7892\n",
      "Epoch 376/1000\n",
      "72/72 - 0s - loss: 51.9200 - mse: 51.9200\n",
      "Epoch 377/1000\n",
      "72/72 - 0s - loss: 51.9090 - mse: 51.9090\n",
      "Epoch 378/1000\n",
      "72/72 - 0s - loss: 49.6325 - mse: 49.6325\n",
      "Epoch 379/1000\n",
      "72/72 - 0s - loss: 49.6721 - mse: 49.6721\n",
      "Epoch 380/1000\n",
      "72/72 - 0s - loss: 51.7000 - mse: 51.7000\n",
      "Epoch 381/1000\n",
      "72/72 - 0s - loss: 50.6534 - mse: 50.6534\n",
      "Epoch 382/1000\n",
      "72/72 - 0s - loss: 46.7796 - mse: 46.7796\n",
      "Epoch 383/1000\n",
      "72/72 - 0s - loss: 48.9200 - mse: 48.9200\n",
      "Epoch 384/1000\n",
      "72/72 - 0s - loss: 47.7104 - mse: 47.7104\n",
      "Epoch 385/1000\n",
      "72/72 - 0s - loss: 46.5738 - mse: 46.5738\n",
      "Epoch 386/1000\n",
      "72/72 - 0s - loss: 47.6115 - mse: 47.6115\n",
      "Epoch 387/1000\n",
      "72/72 - 0s - loss: 45.4580 - mse: 45.4580\n",
      "Epoch 388/1000\n",
      "72/72 - 0s - loss: 41.8809 - mse: 41.8809\n",
      "Epoch 389/1000\n",
      "72/72 - 0s - loss: 41.1868 - mse: 41.1868\n",
      "Epoch 390/1000\n",
      "72/72 - 0s - loss: 44.8851 - mse: 44.8851\n",
      "Epoch 391/1000\n",
      "72/72 - 0s - loss: 42.7234 - mse: 42.7234\n",
      "Epoch 392/1000\n",
      "72/72 - 0s - loss: 40.6512 - mse: 40.6512\n",
      "Epoch 393/1000\n",
      "72/72 - 0s - loss: 41.7604 - mse: 41.7604\n",
      "Epoch 394/1000\n",
      "72/72 - 0s - loss: 40.9658 - mse: 40.9658\n",
      "Epoch 395/1000\n",
      "72/72 - 0s - loss: 41.4628 - mse: 41.4628\n",
      "Epoch 396/1000\n",
      "72/72 - 0s - loss: 38.8483 - mse: 38.8483\n",
      "Epoch 397/1000\n",
      "72/72 - 0s - loss: 37.2286 - mse: 37.2286\n",
      "Epoch 398/1000\n",
      "72/72 - 0s - loss: 36.7550 - mse: 36.7550\n",
      "Epoch 399/1000\n",
      "72/72 - 0s - loss: 36.2615 - mse: 36.2615\n",
      "Epoch 400/1000\n",
      "72/72 - 0s - loss: 37.3574 - mse: 37.3574\n",
      "Epoch 401/1000\n",
      "72/72 - 0s - loss: 36.1233 - mse: 36.1233\n",
      "Epoch 402/1000\n",
      "72/72 - 0s - loss: 36.0351 - mse: 36.0351\n",
      "Epoch 403/1000\n",
      "72/72 - 0s - loss: 35.8884 - mse: 35.8884\n",
      "Epoch 404/1000\n",
      "72/72 - 0s - loss: 33.9092 - mse: 33.9092\n",
      "Epoch 405/1000\n",
      "72/72 - 0s - loss: 32.1664 - mse: 32.1664\n",
      "Epoch 406/1000\n",
      "72/72 - 0s - loss: 32.6219 - mse: 32.6219\n",
      "Epoch 407/1000\n",
      "72/72 - 0s - loss: 33.7866 - mse: 33.7866\n",
      "Epoch 408/1000\n",
      "72/72 - 0s - loss: 31.5958 - mse: 31.5958\n",
      "Epoch 409/1000\n",
      "72/72 - 0s - loss: 34.2139 - mse: 34.2139\n",
      "Epoch 410/1000\n",
      "72/72 - 0s - loss: 31.5878 - mse: 31.5878\n",
      "Epoch 411/1000\n",
      "72/72 - 0s - loss: 30.3424 - mse: 30.3424\n",
      "Epoch 412/1000\n",
      "72/72 - 0s - loss: 30.6656 - mse: 30.6656\n",
      "Epoch 413/1000\n",
      "72/72 - 0s - loss: 28.7434 - mse: 28.7434\n",
      "Epoch 414/1000\n",
      "72/72 - 0s - loss: 29.8691 - mse: 29.8691\n",
      "Epoch 415/1000\n",
      "72/72 - 0s - loss: 28.5381 - mse: 28.5381\n",
      "Epoch 416/1000\n",
      "72/72 - 0s - loss: 28.1376 - mse: 28.1376\n",
      "Epoch 417/1000\n",
      "72/72 - 0s - loss: 27.5907 - mse: 27.5907\n",
      "Epoch 418/1000\n",
      "72/72 - 0s - loss: 27.1781 - mse: 27.1781\n",
      "Epoch 419/1000\n",
      "72/72 - 0s - loss: 26.9834 - mse: 26.9834\n",
      "Epoch 420/1000\n",
      "72/72 - 0s - loss: 26.9900 - mse: 26.9900\n",
      "Epoch 421/1000\n",
      "72/72 - 0s - loss: 26.3179 - mse: 26.3179\n",
      "Epoch 422/1000\n",
      "72/72 - 0s - loss: 26.0774 - mse: 26.0774\n",
      "Epoch 423/1000\n",
      "72/72 - 0s - loss: 25.4806 - mse: 25.4806\n",
      "Epoch 424/1000\n",
      "72/72 - 0s - loss: 25.1541 - mse: 25.1541\n",
      "Epoch 425/1000\n",
      "72/72 - 0s - loss: 25.1258 - mse: 25.1258\n",
      "Epoch 426/1000\n",
      "72/72 - 0s - loss: 24.0565 - mse: 24.0565\n",
      "Epoch 427/1000\n",
      "72/72 - 0s - loss: 23.5880 - mse: 23.5880\n",
      "Epoch 428/1000\n",
      "72/72 - 0s - loss: 24.6620 - mse: 24.6620\n",
      "Epoch 429/1000\n",
      "72/72 - 0s - loss: 22.3954 - mse: 22.3954\n",
      "Epoch 430/1000\n",
      "72/72 - 0s - loss: 23.4918 - mse: 23.4918\n",
      "Epoch 431/1000\n",
      "72/72 - 0s - loss: 23.4765 - mse: 23.4765\n",
      "Epoch 432/1000\n",
      "72/72 - 0s - loss: 22.4846 - mse: 22.4846\n",
      "Epoch 433/1000\n",
      "72/72 - 0s - loss: 21.5106 - mse: 21.5106\n",
      "Epoch 434/1000\n",
      "72/72 - 0s - loss: 22.6153 - mse: 22.6153\n",
      "Epoch 435/1000\n",
      "72/72 - 0s - loss: 21.3835 - mse: 21.3835\n",
      "Epoch 436/1000\n",
      "72/72 - 0s - loss: 21.2965 - mse: 21.2965\n",
      "Epoch 437/1000\n",
      "72/72 - 0s - loss: 21.3526 - mse: 21.3526\n",
      "Epoch 438/1000\n",
      "72/72 - 0s - loss: 20.0122 - mse: 20.0122\n",
      "Epoch 439/1000\n",
      "72/72 - 0s - loss: 20.0151 - mse: 20.0151\n",
      "Epoch 440/1000\n",
      "72/72 - 0s - loss: 21.0930 - mse: 21.0930\n",
      "Epoch 441/1000\n",
      "72/72 - 0s - loss: 20.1030 - mse: 20.1030\n",
      "Epoch 442/1000\n",
      "72/72 - 0s - loss: 19.0947 - mse: 19.0947\n",
      "Epoch 443/1000\n",
      "72/72 - 0s - loss: 18.8933 - mse: 18.8933\n",
      "Epoch 444/1000\n",
      "72/72 - 0s - loss: 18.3658 - mse: 18.3658\n",
      "Epoch 445/1000\n",
      "72/72 - 0s - loss: 18.1835 - mse: 18.1835\n",
      "Epoch 446/1000\n",
      "72/72 - 0s - loss: 18.1571 - mse: 18.1571\n",
      "Epoch 447/1000\n",
      "72/72 - 0s - loss: 17.4913 - mse: 17.4913\n",
      "Epoch 448/1000\n",
      "72/72 - 0s - loss: 16.9360 - mse: 16.9360\n",
      "Epoch 449/1000\n",
      "72/72 - 0s - loss: 17.4872 - mse: 17.4872\n",
      "Epoch 450/1000\n",
      "72/72 - 0s - loss: 17.1170 - mse: 17.1170\n",
      "Epoch 451/1000\n",
      "72/72 - 0s - loss: 17.2333 - mse: 17.2333\n",
      "Epoch 452/1000\n",
      "72/72 - 0s - loss: 15.9411 - mse: 15.9411\n",
      "Epoch 453/1000\n",
      "72/72 - 0s - loss: 15.3887 - mse: 15.3887\n",
      "Epoch 454/1000\n",
      "72/72 - 0s - loss: 16.0185 - mse: 16.0185\n",
      "Epoch 455/1000\n",
      "72/72 - 0s - loss: 14.8418 - mse: 14.8418\n",
      "Epoch 456/1000\n",
      "72/72 - 0s - loss: 15.7029 - mse: 15.7029\n",
      "Epoch 457/1000\n",
      "72/72 - 0s - loss: 14.9532 - mse: 14.9532\n",
      "Epoch 458/1000\n",
      "72/72 - 0s - loss: 15.3563 - mse: 15.3563\n",
      "Epoch 459/1000\n",
      "72/72 - 0s - loss: 14.3612 - mse: 14.3612\n",
      "Epoch 460/1000\n",
      "72/72 - 0s - loss: 14.6251 - mse: 14.6251\n",
      "Epoch 461/1000\n",
      "72/72 - 0s - loss: 14.3382 - mse: 14.3382\n",
      "Epoch 462/1000\n",
      "72/72 - 0s - loss: 13.5645 - mse: 13.5645\n",
      "Epoch 463/1000\n",
      "72/72 - 0s - loss: 12.9579 - mse: 12.9579\n",
      "Epoch 464/1000\n",
      "72/72 - 0s - loss: 12.7063 - mse: 12.7063\n",
      "Epoch 465/1000\n",
      "72/72 - 0s - loss: 12.9622 - mse: 12.9622\n",
      "Epoch 466/1000\n",
      "72/72 - 0s - loss: 12.5024 - mse: 12.5024\n",
      "Epoch 467/1000\n",
      "72/72 - 0s - loss: 13.0869 - mse: 13.0869\n",
      "Epoch 468/1000\n",
      "72/72 - 0s - loss: 12.6705 - mse: 12.6705\n",
      "Epoch 469/1000\n",
      "72/72 - 0s - loss: 11.7855 - mse: 11.7855\n",
      "Epoch 470/1000\n",
      "72/72 - 0s - loss: 12.1974 - mse: 12.1974\n",
      "Epoch 471/1000\n",
      "72/72 - 0s - loss: 11.1717 - mse: 11.1717\n",
      "Epoch 472/1000\n",
      "72/72 - 0s - loss: 12.2037 - mse: 12.2037\n",
      "Epoch 473/1000\n",
      "72/72 - 0s - loss: 11.4201 - mse: 11.4201\n",
      "Epoch 474/1000\n",
      "72/72 - 0s - loss: 11.7229 - mse: 11.7229\n",
      "Epoch 475/1000\n",
      "72/72 - 0s - loss: 10.8263 - mse: 10.8263\n",
      "Epoch 476/1000\n",
      "72/72 - 0s - loss: 10.1078 - mse: 10.1078\n",
      "Epoch 477/1000\n",
      "72/72 - 0s - loss: 10.9788 - mse: 10.9788\n",
      "Epoch 478/1000\n",
      "72/72 - 0s - loss: 11.1661 - mse: 11.1661\n",
      "Epoch 479/1000\n",
      "72/72 - 0s - loss: 10.3670 - mse: 10.3670\n",
      "Epoch 480/1000\n",
      "72/72 - 0s - loss: 9.8677 - mse: 9.8677\n",
      "Epoch 481/1000\n",
      "72/72 - 0s - loss: 10.7074 - mse: 10.7074\n",
      "Epoch 482/1000\n",
      "72/72 - 0s - loss: 10.6728 - mse: 10.6728\n",
      "Epoch 483/1000\n",
      "72/72 - 0s - loss: 10.0514 - mse: 10.0514\n",
      "Epoch 484/1000\n",
      "72/72 - 0s - loss: 10.3526 - mse: 10.3526\n",
      "Epoch 485/1000\n",
      "72/72 - 0s - loss: 10.2266 - mse: 10.2266\n",
      "Epoch 486/1000\n",
      "72/72 - 0s - loss: 9.4796 - mse: 9.4796\n",
      "Epoch 487/1000\n",
      "72/72 - 0s - loss: 10.0212 - mse: 10.0212\n",
      "Epoch 488/1000\n",
      "72/72 - 0s - loss: 8.5922 - mse: 8.5922\n",
      "Epoch 489/1000\n",
      "72/72 - 0s - loss: 9.5068 - mse: 9.5068\n",
      "Epoch 490/1000\n",
      "72/72 - 0s - loss: 8.7505 - mse: 8.7505\n",
      "Epoch 491/1000\n",
      "72/72 - 0s - loss: 8.6503 - mse: 8.6503\n",
      "Epoch 492/1000\n",
      "72/72 - 0s - loss: 8.5155 - mse: 8.5155\n",
      "Epoch 493/1000\n",
      "72/72 - 0s - loss: 8.3373 - mse: 8.3373\n",
      "Epoch 494/1000\n",
      "72/72 - 0s - loss: 8.3314 - mse: 8.3314\n",
      "Epoch 495/1000\n",
      "72/72 - 0s - loss: 8.0342 - mse: 8.0342\n",
      "Epoch 496/1000\n",
      "72/72 - 0s - loss: 8.7201 - mse: 8.7201\n",
      "Epoch 497/1000\n",
      "72/72 - 0s - loss: 7.5418 - mse: 7.5418\n",
      "Epoch 498/1000\n",
      "72/72 - 0s - loss: 8.7897 - mse: 8.7897\n",
      "Epoch 499/1000\n",
      "72/72 - 0s - loss: 7.0661 - mse: 7.0661\n",
      "Epoch 500/1000\n",
      "72/72 - 0s - loss: 7.2858 - mse: 7.2858\n",
      "Epoch 501/1000\n",
      "72/72 - 0s - loss: 8.0674 - mse: 8.0674\n",
      "Epoch 502/1000\n",
      "72/72 - 0s - loss: 8.2714 - mse: 8.2714\n",
      "Epoch 503/1000\n",
      "72/72 - 0s - loss: 6.9306 - mse: 6.9306\n",
      "Epoch 504/1000\n",
      "72/72 - 0s - loss: 7.9192 - mse: 7.9192\n",
      "Epoch 505/1000\n",
      "72/72 - 0s - loss: 6.9168 - mse: 6.9168\n",
      "Epoch 506/1000\n",
      "72/72 - 0s - loss: 7.0771 - mse: 7.0771\n",
      "Epoch 507/1000\n",
      "72/72 - 0s - loss: 7.0999 - mse: 7.0999\n",
      "Epoch 508/1000\n",
      "72/72 - 0s - loss: 6.2790 - mse: 6.2790\n",
      "Epoch 509/1000\n",
      "72/72 - 0s - loss: 7.3368 - mse: 7.3368\n",
      "Epoch 510/1000\n",
      "72/72 - 0s - loss: 7.1389 - mse: 7.1389\n",
      "Epoch 511/1000\n",
      "72/72 - 0s - loss: 7.1822 - mse: 7.1822\n",
      "Epoch 512/1000\n",
      "72/72 - 0s - loss: 5.8776 - mse: 5.8776\n",
      "Epoch 513/1000\n",
      "72/72 - 0s - loss: 6.9881 - mse: 6.9881\n",
      "Epoch 514/1000\n",
      "72/72 - 0s - loss: 6.6034 - mse: 6.6034\n",
      "Epoch 515/1000\n",
      "72/72 - 0s - loss: 6.7023 - mse: 6.7023\n",
      "Epoch 516/1000\n",
      "72/72 - 0s - loss: 6.5136 - mse: 6.5136\n",
      "Epoch 517/1000\n",
      "72/72 - 0s - loss: 6.3606 - mse: 6.3606\n",
      "Epoch 518/1000\n",
      "72/72 - 0s - loss: 6.2326 - mse: 6.2326\n",
      "Epoch 519/1000\n",
      "72/72 - 0s - loss: 5.9310 - mse: 5.9310\n",
      "Epoch 520/1000\n",
      "72/72 - 0s - loss: 6.3268 - mse: 6.3268\n",
      "Epoch 521/1000\n",
      "72/72 - 0s - loss: 5.3601 - mse: 5.3601\n",
      "Epoch 522/1000\n",
      "72/72 - 0s - loss: 5.8861 - mse: 5.8861\n",
      "Epoch 523/1000\n",
      "72/72 - 0s - loss: 6.7524 - mse: 6.7524\n",
      "Epoch 524/1000\n",
      "72/72 - 0s - loss: 6.6376 - mse: 6.6376\n",
      "Epoch 525/1000\n",
      "72/72 - 0s - loss: 5.1784 - mse: 5.1784\n",
      "Epoch 526/1000\n",
      "72/72 - 0s - loss: 6.5675 - mse: 6.5675\n",
      "Epoch 527/1000\n",
      "72/72 - 0s - loss: 5.1014 - mse: 5.1014\n",
      "Epoch 528/1000\n",
      "72/72 - 0s - loss: 5.4359 - mse: 5.4359\n",
      "Epoch 529/1000\n",
      "72/72 - 0s - loss: 5.1529 - mse: 5.1529\n",
      "Epoch 530/1000\n",
      "72/72 - 0s - loss: 5.6209 - mse: 5.6209\n",
      "Epoch 531/1000\n",
      "72/72 - 0s - loss: 5.5756 - mse: 5.5756\n",
      "Epoch 532/1000\n",
      "72/72 - 0s - loss: 6.0003 - mse: 6.0003\n",
      "Epoch 533/1000\n",
      "72/72 - 0s - loss: 5.2326 - mse: 5.2326\n",
      "Epoch 534/1000\n",
      "72/72 - 0s - loss: 4.6900 - mse: 4.6900\n",
      "Epoch 535/1000\n",
      "72/72 - 0s - loss: 5.3859 - mse: 5.3859\n",
      "Epoch 536/1000\n",
      "72/72 - 0s - loss: 5.3108 - mse: 5.3108\n",
      "Epoch 537/1000\n",
      "72/72 - 0s - loss: 4.8981 - mse: 4.8981\n",
      "Epoch 538/1000\n",
      "72/72 - 0s - loss: 4.9388 - mse: 4.9388\n",
      "Epoch 539/1000\n",
      "72/72 - 0s - loss: 4.8002 - mse: 4.8002\n",
      "Epoch 540/1000\n",
      "72/72 - 0s - loss: 5.1546 - mse: 5.1546\n",
      "Epoch 541/1000\n",
      "72/72 - 0s - loss: 5.2418 - mse: 5.2418\n",
      "Epoch 542/1000\n",
      "72/72 - 0s - loss: 4.6024 - mse: 4.6024\n",
      "Epoch 543/1000\n",
      "72/72 - 0s - loss: 4.6367 - mse: 4.6367\n",
      "Epoch 544/1000\n",
      "72/72 - 0s - loss: 4.4303 - mse: 4.4303\n",
      "Epoch 545/1000\n",
      "72/72 - 0s - loss: 4.1597 - mse: 4.1597\n",
      "Epoch 546/1000\n",
      "72/72 - 0s - loss: 5.4072 - mse: 5.4072\n",
      "Epoch 547/1000\n",
      "72/72 - 0s - loss: 4.4176 - mse: 4.4176\n",
      "Epoch 548/1000\n",
      "72/72 - 0s - loss: 4.9164 - mse: 4.9164\n",
      "Epoch 549/1000\n",
      "72/72 - 0s - loss: 4.5446 - mse: 4.5446\n",
      "Epoch 550/1000\n",
      "72/72 - 0s - loss: 5.1092 - mse: 5.1092\n",
      "Epoch 551/1000\n",
      "72/72 - 0s - loss: 4.4188 - mse: 4.4188\n",
      "Epoch 552/1000\n",
      "72/72 - 0s - loss: 4.4956 - mse: 4.4956\n",
      "Epoch 553/1000\n",
      "72/72 - 0s - loss: 4.4989 - mse: 4.4989\n",
      "Epoch 554/1000\n",
      "72/72 - 0s - loss: 4.5267 - mse: 4.5267\n",
      "Epoch 555/1000\n",
      "72/72 - 0s - loss: 4.6368 - mse: 4.6368\n",
      "Epoch 556/1000\n",
      "72/72 - 0s - loss: 3.8001 - mse: 3.8001\n",
      "Epoch 557/1000\n",
      "72/72 - 0s - loss: 4.1344 - mse: 4.1344\n",
      "Epoch 558/1000\n",
      "72/72 - 0s - loss: 4.3081 - mse: 4.3081\n",
      "Epoch 559/1000\n",
      "72/72 - 0s - loss: 4.4037 - mse: 4.4037\n",
      "Epoch 560/1000\n",
      "72/72 - 0s - loss: 4.0179 - mse: 4.0179\n",
      "Epoch 561/1000\n",
      "72/72 - 0s - loss: 4.4431 - mse: 4.4431\n",
      "Epoch 562/1000\n",
      "72/72 - 0s - loss: 3.9805 - mse: 3.9805\n",
      "Epoch 563/1000\n",
      "72/72 - 0s - loss: 4.2027 - mse: 4.2027\n",
      "Epoch 564/1000\n",
      "72/72 - 0s - loss: 4.3798 - mse: 4.3798\n",
      "Epoch 565/1000\n",
      "72/72 - 0s - loss: 3.6768 - mse: 3.6768\n",
      "Epoch 566/1000\n",
      "72/72 - 0s - loss: 3.8902 - mse: 3.8902\n",
      "Epoch 567/1000\n",
      "72/72 - 0s - loss: 4.6483 - mse: 4.6483\n",
      "Epoch 568/1000\n",
      "72/72 - 0s - loss: 4.3977 - mse: 4.3977\n",
      "Epoch 569/1000\n",
      "72/72 - 0s - loss: 3.5601 - mse: 3.5601\n",
      "Epoch 570/1000\n",
      "72/72 - 0s - loss: 3.9953 - mse: 3.9953\n",
      "Epoch 571/1000\n",
      "72/72 - 0s - loss: 3.8075 - mse: 3.8075\n",
      "Epoch 572/1000\n",
      "72/72 - 0s - loss: 3.7873 - mse: 3.7873\n",
      "Epoch 573/1000\n",
      "72/72 - 0s - loss: 4.2240 - mse: 4.2240\n",
      "Epoch 574/1000\n",
      "72/72 - 0s - loss: 3.9028 - mse: 3.9028\n",
      "Epoch 575/1000\n",
      "72/72 - 0s - loss: 4.1194 - mse: 4.1194\n",
      "Epoch 576/1000\n",
      "72/72 - 0s - loss: 3.6675 - mse: 3.6675\n",
      "Epoch 577/1000\n",
      "72/72 - 0s - loss: 4.5159 - mse: 4.5159\n",
      "Epoch 578/1000\n",
      "72/72 - 0s - loss: 3.4405 - mse: 3.4405\n",
      "Epoch 579/1000\n",
      "72/72 - 0s - loss: 3.9483 - mse: 3.9483\n",
      "Epoch 580/1000\n",
      "72/72 - 0s - loss: 3.7935 - mse: 3.7935\n",
      "Epoch 581/1000\n",
      "72/72 - 0s - loss: 3.4720 - mse: 3.4720\n",
      "Epoch 582/1000\n",
      "72/72 - 0s - loss: 3.8190 - mse: 3.8190\n",
      "Epoch 583/1000\n",
      "72/72 - 0s - loss: 3.7394 - mse: 3.7394\n",
      "Epoch 584/1000\n",
      "72/72 - 0s - loss: 4.1156 - mse: 4.1156\n",
      "Epoch 585/1000\n",
      "72/72 - 0s - loss: 3.5630 - mse: 3.5630\n",
      "Epoch 586/1000\n",
      "72/72 - 0s - loss: 3.8069 - mse: 3.8069\n",
      "Epoch 587/1000\n",
      "72/72 - 0s - loss: 3.3126 - mse: 3.3126\n",
      "Epoch 588/1000\n",
      "72/72 - 0s - loss: 3.6507 - mse: 3.6507\n",
      "Epoch 589/1000\n",
      "72/72 - 0s - loss: 3.5360 - mse: 3.5360\n",
      "Epoch 590/1000\n",
      "72/72 - 0s - loss: 3.7211 - mse: 3.7211\n",
      "Epoch 591/1000\n",
      "72/72 - 0s - loss: 3.0997 - mse: 3.0997\n",
      "Epoch 592/1000\n",
      "72/72 - 0s - loss: 3.7469 - mse: 3.7469\n",
      "Epoch 593/1000\n",
      "72/72 - 0s - loss: 4.3420 - mse: 4.3420\n",
      "Epoch 594/1000\n",
      "72/72 - 0s - loss: 4.0981 - mse: 4.0981\n",
      "Epoch 595/1000\n",
      "72/72 - 0s - loss: 3.6416 - mse: 3.6416\n",
      "Epoch 596/1000\n",
      "72/72 - 0s - loss: 3.4717 - mse: 3.4717\n",
      "Epoch 597/1000\n",
      "72/72 - 0s - loss: 4.3001 - mse: 4.3001\n",
      "Epoch 598/1000\n",
      "72/72 - 0s - loss: 3.7703 - mse: 3.7703\n",
      "Epoch 599/1000\n",
      "72/72 - 0s - loss: 3.5040 - mse: 3.5040\n",
      "Epoch 600/1000\n",
      "72/72 - 0s - loss: 3.6612 - mse: 3.6612\n",
      "Epoch 601/1000\n",
      "72/72 - 0s - loss: 3.3158 - mse: 3.3158\n",
      "Epoch 602/1000\n",
      "72/72 - 0s - loss: 4.2921 - mse: 4.2921\n",
      "Epoch 603/1000\n",
      "72/72 - 0s - loss: 3.2845 - mse: 3.2845\n",
      "Epoch 604/1000\n",
      "72/72 - 0s - loss: 3.5842 - mse: 3.5842\n",
      "Epoch 605/1000\n",
      "72/72 - 0s - loss: 3.5536 - mse: 3.5536\n",
      "Epoch 606/1000\n",
      "72/72 - 0s - loss: 3.1878 - mse: 3.1878\n",
      "Epoch 607/1000\n",
      "72/72 - 0s - loss: 3.6285 - mse: 3.6285\n",
      "Epoch 608/1000\n",
      "72/72 - 0s - loss: 2.6399 - mse: 2.6399\n",
      "Epoch 609/1000\n",
      "72/72 - 0s - loss: 4.1239 - mse: 4.1239\n",
      "Epoch 610/1000\n",
      "72/72 - 0s - loss: 3.2099 - mse: 3.2099\n",
      "Epoch 611/1000\n",
      "72/72 - 0s - loss: 3.3897 - mse: 3.3897\n",
      "Epoch 612/1000\n",
      "72/72 - 0s - loss: 3.6221 - mse: 3.6221\n",
      "Epoch 613/1000\n",
      "72/72 - 0s - loss: 3.4892 - mse: 3.4892\n",
      "Epoch 614/1000\n",
      "72/72 - 0s - loss: 3.3504 - mse: 3.3504\n",
      "Epoch 615/1000\n",
      "72/72 - 0s - loss: 3.4946 - mse: 3.4946\n",
      "Epoch 616/1000\n",
      "72/72 - 0s - loss: 3.4067 - mse: 3.4067\n",
      "Epoch 617/1000\n",
      "72/72 - 0s - loss: 3.5302 - mse: 3.5302\n",
      "Epoch 618/1000\n",
      "72/72 - 0s - loss: 3.2867 - mse: 3.2867\n",
      "Epoch 619/1000\n",
      "72/72 - 0s - loss: 3.4102 - mse: 3.4102\n",
      "Epoch 620/1000\n",
      "72/72 - 0s - loss: 2.9995 - mse: 2.9995\n",
      "Epoch 621/1000\n",
      "72/72 - 0s - loss: 3.3580 - mse: 3.3580\n",
      "Epoch 622/1000\n",
      "72/72 - 0s - loss: 3.5030 - mse: 3.5030\n",
      "Epoch 623/1000\n",
      "72/72 - 0s - loss: 2.9135 - mse: 2.9135\n",
      "Epoch 624/1000\n",
      "72/72 - 0s - loss: 3.7506 - mse: 3.7506\n",
      "Epoch 625/1000\n",
      "72/72 - 0s - loss: 3.9002 - mse: 3.9002\n",
      "Epoch 626/1000\n",
      "72/72 - 0s - loss: 3.1420 - mse: 3.1420\n",
      "Epoch 627/1000\n",
      "72/72 - 0s - loss: 3.2747 - mse: 3.2747\n",
      "Epoch 628/1000\n",
      "72/72 - 0s - loss: 3.8866 - mse: 3.8866\n",
      "Epoch 629/1000\n",
      "72/72 - 0s - loss: 3.3084 - mse: 3.3084\n",
      "Epoch 630/1000\n",
      "72/72 - 0s - loss: 3.3444 - mse: 3.3444\n",
      "Epoch 631/1000\n",
      "72/72 - 0s - loss: 2.9778 - mse: 2.9778\n",
      "Epoch 632/1000\n",
      "72/72 - 0s - loss: 3.3325 - mse: 3.3325\n",
      "Epoch 633/1000\n",
      "72/72 - 0s - loss: 3.4294 - mse: 3.4294\n",
      "Epoch 634/1000\n",
      "72/72 - 0s - loss: 3.5499 - mse: 3.5499\n",
      "Epoch 635/1000\n",
      "72/72 - 0s - loss: 2.9982 - mse: 2.9982\n",
      "Epoch 636/1000\n",
      "72/72 - 0s - loss: 3.5739 - mse: 3.5739\n",
      "Epoch 637/1000\n",
      "72/72 - 0s - loss: 3.3916 - mse: 3.3916\n",
      "Epoch 638/1000\n",
      "72/72 - 0s - loss: 3.3189 - mse: 3.3189\n",
      "Epoch 639/1000\n",
      "72/72 - 0s - loss: 3.0442 - mse: 3.0442\n",
      "Epoch 640/1000\n",
      "72/72 - 0s - loss: 2.9425 - mse: 2.9425\n",
      "Epoch 641/1000\n",
      "72/72 - 0s - loss: 3.4875 - mse: 3.4875\n",
      "Epoch 642/1000\n",
      "72/72 - 0s - loss: 3.3273 - mse: 3.3273\n",
      "Epoch 643/1000\n",
      "72/72 - 0s - loss: 3.5309 - mse: 3.5309\n",
      "Epoch 644/1000\n",
      "72/72 - 0s - loss: 3.7554 - mse: 3.7554\n",
      "Epoch 645/1000\n",
      "72/72 - 0s - loss: 3.4331 - mse: 3.4331\n",
      "Epoch 646/1000\n",
      "72/72 - 0s - loss: 3.5057 - mse: 3.5057\n",
      "Epoch 647/1000\n",
      "72/72 - 0s - loss: 3.4077 - mse: 3.4077\n",
      "Epoch 648/1000\n",
      "72/72 - 0s - loss: 2.9932 - mse: 2.9932\n",
      "Epoch 649/1000\n",
      "72/72 - 0s - loss: 3.6935 - mse: 3.6935\n",
      "Epoch 650/1000\n",
      "72/72 - 0s - loss: 3.3427 - mse: 3.3427\n",
      "Epoch 651/1000\n",
      "72/72 - 0s - loss: 2.8608 - mse: 2.8608\n",
      "Epoch 652/1000\n",
      "72/72 - 0s - loss: 3.2201 - mse: 3.2201\n",
      "Epoch 653/1000\n",
      "72/72 - 0s - loss: 2.5926 - mse: 2.5926\n",
      "Epoch 654/1000\n",
      "72/72 - 0s - loss: 3.9908 - mse: 3.9908\n",
      "Epoch 655/1000\n",
      "72/72 - 0s - loss: 3.0698 - mse: 3.0698\n",
      "Epoch 656/1000\n",
      "72/72 - 0s - loss: 2.5116 - mse: 2.5116\n",
      "Epoch 657/1000\n",
      "72/72 - 0s - loss: 3.9826 - mse: 3.9826\n",
      "Epoch 658/1000\n",
      "72/72 - 0s - loss: 2.8497 - mse: 2.8497\n",
      "Epoch 659/1000\n",
      "72/72 - 0s - loss: 3.1063 - mse: 3.1063\n",
      "Epoch 660/1000\n",
      "72/72 - 0s - loss: 3.3784 - mse: 3.3784\n",
      "Epoch 661/1000\n",
      "72/72 - 0s - loss: 3.7870 - mse: 3.7870\n",
      "Epoch 662/1000\n",
      "72/72 - 0s - loss: 3.1300 - mse: 3.1300\n",
      "Epoch 663/1000\n",
      "72/72 - 0s - loss: 2.7504 - mse: 2.7504\n",
      "Epoch 664/1000\n",
      "72/72 - 0s - loss: 3.4886 - mse: 3.4886\n",
      "Epoch 665/1000\n",
      "72/72 - 0s - loss: 3.6680 - mse: 3.6680\n",
      "Epoch 666/1000\n",
      "72/72 - 0s - loss: 3.0351 - mse: 3.0351\n",
      "Epoch 667/1000\n",
      "72/72 - 0s - loss: 3.6333 - mse: 3.6333\n",
      "Epoch 668/1000\n",
      "72/72 - 0s - loss: 3.1546 - mse: 3.1546\n",
      "Epoch 669/1000\n",
      "72/72 - 0s - loss: 2.6022 - mse: 2.6022\n",
      "Epoch 670/1000\n",
      "72/72 - 0s - loss: 3.8947 - mse: 3.8947\n",
      "Epoch 671/1000\n",
      "72/72 - 0s - loss: 4.0722 - mse: 4.0722\n",
      "Epoch 672/1000\n",
      "72/72 - 0s - loss: 3.2248 - mse: 3.2248\n",
      "Epoch 673/1000\n",
      "72/72 - 0s - loss: 3.8354 - mse: 3.8354\n",
      "Epoch 674/1000\n",
      "72/72 - 0s - loss: 3.0482 - mse: 3.0482\n",
      "Epoch 675/1000\n",
      "72/72 - 0s - loss: 2.6991 - mse: 2.6991\n",
      "Epoch 676/1000\n",
      "72/72 - 0s - loss: 3.3793 - mse: 3.3793\n",
      "Epoch 677/1000\n",
      "72/72 - 0s - loss: 3.6077 - mse: 3.6077\n",
      "Epoch 678/1000\n",
      "72/72 - 0s - loss: 3.3979 - mse: 3.3979\n",
      "Epoch 679/1000\n",
      "72/72 - 0s - loss: 2.9620 - mse: 2.9620\n",
      "Epoch 680/1000\n",
      "72/72 - 0s - loss: 3.3554 - mse: 3.3554\n",
      "Epoch 681/1000\n",
      "72/72 - 0s - loss: 3.9525 - mse: 3.9525\n",
      "Epoch 682/1000\n",
      "72/72 - 0s - loss: 2.5788 - mse: 2.5788\n",
      "Epoch 683/1000\n",
      "72/72 - 0s - loss: 3.5059 - mse: 3.5059\n",
      "Epoch 684/1000\n",
      "72/72 - 0s - loss: 3.7941 - mse: 3.7941\n",
      "Epoch 685/1000\n",
      "72/72 - 0s - loss: 3.0722 - mse: 3.0722\n",
      "Epoch 686/1000\n",
      "72/72 - 0s - loss: 3.7843 - mse: 3.7843\n",
      "Epoch 687/1000\n",
      "72/72 - 0s - loss: 3.2985 - mse: 3.2985\n",
      "Epoch 688/1000\n",
      "72/72 - 0s - loss: 2.7825 - mse: 2.7825\n",
      "Epoch 689/1000\n",
      "72/72 - 0s - loss: 3.4749 - mse: 3.4749\n",
      "Epoch 690/1000\n",
      "72/72 - 0s - loss: 3.1219 - mse: 3.1219\n",
      "Epoch 691/1000\n",
      "72/72 - 0s - loss: 3.2681 - mse: 3.2681\n",
      "Epoch 692/1000\n",
      "72/72 - 0s - loss: 2.9036 - mse: 2.9036\n",
      "Epoch 693/1000\n",
      "72/72 - 0s - loss: 3.8104 - mse: 3.8104\n",
      "Epoch 694/1000\n",
      "72/72 - 0s - loss: 3.6696 - mse: 3.6696\n",
      "Epoch 695/1000\n",
      "72/72 - 0s - loss: 3.1999 - mse: 3.1999\n",
      "Epoch 696/1000\n",
      "72/72 - 0s - loss: 3.3384 - mse: 3.3384\n",
      "Epoch 697/1000\n",
      "72/72 - 0s - loss: 3.5985 - mse: 3.5985\n",
      "Epoch 698/1000\n",
      "72/72 - 0s - loss: 2.5124 - mse: 2.5124\n",
      "Epoch 699/1000\n",
      "72/72 - 0s - loss: 2.9708 - mse: 2.9708\n",
      "Epoch 700/1000\n",
      "72/72 - 0s - loss: 4.0834 - mse: 4.0834\n",
      "Epoch 701/1000\n",
      "72/72 - 0s - loss: 3.1861 - mse: 3.1861\n",
      "Epoch 702/1000\n",
      "72/72 - 0s - loss: 3.1819 - mse: 3.1819\n",
      "Epoch 703/1000\n",
      "72/72 - 0s - loss: 2.8654 - mse: 2.8654\n",
      "Epoch 704/1000\n",
      "72/72 - 0s - loss: 3.0799 - mse: 3.0799\n",
      "Epoch 705/1000\n",
      "72/72 - 0s - loss: 3.3117 - mse: 3.3117\n",
      "Epoch 706/1000\n",
      "72/72 - 0s - loss: 3.5217 - mse: 3.5217\n",
      "Epoch 707/1000\n",
      "72/72 - 0s - loss: 3.6441 - mse: 3.6441\n",
      "Epoch 708/1000\n",
      "72/72 - 0s - loss: 3.3791 - mse: 3.3791\n",
      "Epoch 709/1000\n",
      "72/72 - 0s - loss: 3.5191 - mse: 3.5191\n",
      "Epoch 710/1000\n",
      "72/72 - 0s - loss: 2.9420 - mse: 2.9420\n",
      "Epoch 711/1000\n",
      "72/72 - 0s - loss: 2.8644 - mse: 2.8644\n",
      "Epoch 712/1000\n",
      "72/72 - 0s - loss: 3.4424 - mse: 3.4424\n",
      "Epoch 713/1000\n",
      "72/72 - 0s - loss: 3.0175 - mse: 3.0175\n",
      "Epoch 714/1000\n",
      "72/72 - 0s - loss: 2.7268 - mse: 2.7268\n",
      "Epoch 715/1000\n",
      "72/72 - 0s - loss: 3.4265 - mse: 3.4265\n",
      "Epoch 716/1000\n",
      "72/72 - 0s - loss: 3.1357 - mse: 3.1357\n",
      "Epoch 717/1000\n",
      "72/72 - 0s - loss: 3.3972 - mse: 3.3972\n",
      "Epoch 718/1000\n",
      "72/72 - 0s - loss: 3.5170 - mse: 3.5170\n",
      "Epoch 719/1000\n",
      "72/72 - 0s - loss: 2.9923 - mse: 2.9923\n",
      "Epoch 720/1000\n",
      "72/72 - 0s - loss: 3.3651 - mse: 3.3651\n",
      "Epoch 721/1000\n",
      "72/72 - 0s - loss: 3.2769 - mse: 3.2769\n",
      "Epoch 722/1000\n",
      "72/72 - 0s - loss: 2.7046 - mse: 2.7046\n",
      "Epoch 723/1000\n",
      "72/72 - 0s - loss: 3.8757 - mse: 3.8757\n",
      "Epoch 724/1000\n",
      "72/72 - 0s - loss: 3.1795 - mse: 3.1795\n",
      "Epoch 725/1000\n",
      "72/72 - 0s - loss: 2.4345 - mse: 2.4345\n",
      "Epoch 726/1000\n",
      "72/72 - 0s - loss: 3.7464 - mse: 3.7464\n",
      "Epoch 727/1000\n",
      "72/72 - 0s - loss: 2.9836 - mse: 2.9836\n",
      "Epoch 728/1000\n",
      "72/72 - 0s - loss: 3.2298 - mse: 3.2298\n",
      "Epoch 729/1000\n",
      "72/72 - 0s - loss: 3.2694 - mse: 3.2694\n",
      "Epoch 730/1000\n",
      "72/72 - 0s - loss: 3.0115 - mse: 3.0115\n",
      "Epoch 731/1000\n",
      "72/72 - 0s - loss: 3.6320 - mse: 3.6320\n",
      "Epoch 732/1000\n",
      "72/72 - 0s - loss: 2.6406 - mse: 2.6406\n",
      "Epoch 733/1000\n",
      "72/72 - 0s - loss: 2.7676 - mse: 2.7676\n",
      "Epoch 734/1000\n",
      "72/72 - 0s - loss: 3.9245 - mse: 3.9245\n",
      "Epoch 735/1000\n",
      "72/72 - 0s - loss: 3.0802 - mse: 3.0802\n",
      "Epoch 736/1000\n",
      "72/72 - 0s - loss: 2.9710 - mse: 2.9710\n",
      "Epoch 737/1000\n",
      "72/72 - 0s - loss: 3.5821 - mse: 3.5821\n",
      "Epoch 738/1000\n",
      "72/72 - 0s - loss: 3.2345 - mse: 3.2345\n",
      "Epoch 739/1000\n",
      "72/72 - 0s - loss: 3.0394 - mse: 3.0394\n",
      "Epoch 740/1000\n",
      "72/72 - 0s - loss: 3.2072 - mse: 3.2072\n",
      "Epoch 741/1000\n",
      "72/72 - 0s - loss: 2.7411 - mse: 2.7411\n",
      "Epoch 742/1000\n",
      "72/72 - 0s - loss: 3.1394 - mse: 3.1394\n",
      "Epoch 743/1000\n",
      "72/72 - 0s - loss: 2.7508 - mse: 2.7508\n",
      "Epoch 744/1000\n",
      "72/72 - 0s - loss: 4.4347 - mse: 4.4347\n",
      "Epoch 745/1000\n",
      "72/72 - 0s - loss: 2.6442 - mse: 2.6442\n",
      "Epoch 746/1000\n",
      "72/72 - 0s - loss: 2.6785 - mse: 2.6785\n",
      "Epoch 747/1000\n",
      "72/72 - 0s - loss: 3.1701 - mse: 3.1701\n",
      "Epoch 748/1000\n",
      "72/72 - 0s - loss: 3.9376 - mse: 3.9376\n",
      "Epoch 749/1000\n",
      "72/72 - 0s - loss: 2.8509 - mse: 2.8509\n",
      "Epoch 750/1000\n",
      "72/72 - 0s - loss: 3.0153 - mse: 3.0153\n",
      "Epoch 751/1000\n",
      "72/72 - 0s - loss: 3.4217 - mse: 3.4217\n",
      "Epoch 752/1000\n",
      "72/72 - 0s - loss: 2.6588 - mse: 2.6588\n",
      "Epoch 753/1000\n",
      "72/72 - 0s - loss: 3.3348 - mse: 3.3348\n",
      "Epoch 754/1000\n",
      "72/72 - 0s - loss: 2.7648 - mse: 2.7648\n",
      "Epoch 755/1000\n",
      "72/72 - 0s - loss: 2.7861 - mse: 2.7861\n",
      "Epoch 756/1000\n",
      "72/72 - 0s - loss: 3.1355 - mse: 3.1355\n",
      "Epoch 757/1000\n",
      "72/72 - 0s - loss: 3.4840 - mse: 3.4840\n",
      "Epoch 758/1000\n",
      "72/72 - 0s - loss: 3.2006 - mse: 3.2006\n",
      "Epoch 759/1000\n",
      "72/72 - 0s - loss: 4.0013 - mse: 4.0013\n",
      "Epoch 760/1000\n",
      "72/72 - 0s - loss: 3.5005 - mse: 3.5005\n",
      "Epoch 761/1000\n",
      "72/72 - 0s - loss: 2.9139 - mse: 2.9139\n",
      "Epoch 762/1000\n",
      "72/72 - 0s - loss: 3.0514 - mse: 3.0514\n",
      "Epoch 763/1000\n",
      "72/72 - 0s - loss: 2.5936 - mse: 2.5936\n",
      "Epoch 764/1000\n",
      "72/72 - 0s - loss: 3.5745 - mse: 3.5745\n",
      "Epoch 765/1000\n",
      "72/72 - 0s - loss: 2.9496 - mse: 2.9496\n",
      "Epoch 766/1000\n",
      "72/72 - 0s - loss: 3.7052 - mse: 3.7052\n",
      "Epoch 767/1000\n",
      "72/72 - 0s - loss: 3.0664 - mse: 3.0664\n",
      "Epoch 768/1000\n",
      "72/72 - 0s - loss: 3.2792 - mse: 3.2792\n",
      "Epoch 769/1000\n",
      "72/72 - 0s - loss: 3.6213 - mse: 3.6213\n",
      "Epoch 770/1000\n",
      "72/72 - 0s - loss: 3.1364 - mse: 3.1364\n",
      "Epoch 771/1000\n",
      "72/72 - 0s - loss: 3.2277 - mse: 3.2277\n",
      "Epoch 772/1000\n",
      "72/72 - 0s - loss: 2.7098 - mse: 2.7098\n",
      "Epoch 773/1000\n",
      "72/72 - 0s - loss: 3.1458 - mse: 3.1458\n",
      "Epoch 774/1000\n",
      "72/72 - 0s - loss: 3.3386 - mse: 3.3386\n",
      "Epoch 775/1000\n",
      "72/72 - 0s - loss: 3.0371 - mse: 3.0371\n",
      "Epoch 776/1000\n",
      "72/72 - 0s - loss: 3.7594 - mse: 3.7594\n",
      "Epoch 777/1000\n",
      "72/72 - 0s - loss: 3.1868 - mse: 3.1868\n",
      "Epoch 778/1000\n",
      "72/72 - 0s - loss: 3.6543 - mse: 3.6543\n",
      "Epoch 779/1000\n",
      "72/72 - 0s - loss: 2.7374 - mse: 2.7374\n",
      "Epoch 780/1000\n",
      "72/72 - 0s - loss: 2.7539 - mse: 2.7539\n",
      "Epoch 781/1000\n",
      "72/72 - 0s - loss: 3.6378 - mse: 3.6378\n",
      "Epoch 782/1000\n",
      "72/72 - 0s - loss: 3.0874 - mse: 3.0874\n",
      "Epoch 783/1000\n",
      "72/72 - 0s - loss: 3.4951 - mse: 3.4951\n",
      "Epoch 784/1000\n",
      "72/72 - 0s - loss: 3.1467 - mse: 3.1467\n",
      "Epoch 785/1000\n",
      "72/72 - 0s - loss: 2.6440 - mse: 2.6440\n",
      "Epoch 786/1000\n",
      "72/72 - 0s - loss: 3.0839 - mse: 3.0839\n",
      "Epoch 787/1000\n",
      "72/72 - 0s - loss: 3.1122 - mse: 3.1122\n",
      "Epoch 788/1000\n",
      "72/72 - 0s - loss: 3.0584 - mse: 3.0584\n",
      "Epoch 789/1000\n",
      "72/72 - 0s - loss: 3.1370 - mse: 3.1370\n",
      "Epoch 790/1000\n",
      "72/72 - 0s - loss: 2.9416 - mse: 2.9416\n",
      "Epoch 791/1000\n",
      "72/72 - 0s - loss: 3.3276 - mse: 3.3276\n",
      "Epoch 792/1000\n",
      "72/72 - 0s - loss: 2.9811 - mse: 2.9811\n",
      "Epoch 793/1000\n",
      "72/72 - 0s - loss: 3.3950 - mse: 3.3950\n",
      "Epoch 794/1000\n",
      "72/72 - 0s - loss: 2.9124 - mse: 2.9124\n",
      "Epoch 795/1000\n",
      "72/72 - 0s - loss: 3.2306 - mse: 3.2306\n",
      "Epoch 796/1000\n",
      "72/72 - 0s - loss: 2.6467 - mse: 2.6467\n",
      "Epoch 797/1000\n",
      "72/72 - 0s - loss: 2.9966 - mse: 2.9966\n",
      "Epoch 798/1000\n",
      "72/72 - 0s - loss: 2.7586 - mse: 2.7586\n",
      "Epoch 799/1000\n",
      "72/72 - 0s - loss: 3.4965 - mse: 3.4965\n",
      "Epoch 800/1000\n",
      "72/72 - 0s - loss: 3.1159 - mse: 3.1159\n",
      "Epoch 801/1000\n",
      "72/72 - 0s - loss: 2.9238 - mse: 2.9238\n",
      "Epoch 802/1000\n",
      "72/72 - 0s - loss: 3.1526 - mse: 3.1526\n",
      "Epoch 803/1000\n",
      "72/72 - 0s - loss: 3.2042 - mse: 3.2042\n",
      "Epoch 804/1000\n",
      "72/72 - 0s - loss: 3.6268 - mse: 3.6268\n",
      "Epoch 805/1000\n",
      "72/72 - 0s - loss: 2.5956 - mse: 2.5956\n",
      "Epoch 806/1000\n",
      "72/72 - 0s - loss: 4.0470 - mse: 4.0470\n",
      "Epoch 807/1000\n",
      "72/72 - 0s - loss: 3.1001 - mse: 3.1001\n",
      "Epoch 808/1000\n",
      "72/72 - 0s - loss: 3.3480 - mse: 3.3480\n",
      "Epoch 809/1000\n",
      "72/72 - 0s - loss: 2.5978 - mse: 2.5978\n",
      "Epoch 810/1000\n",
      "72/72 - 0s - loss: 3.8465 - mse: 3.8465\n",
      "Epoch 811/1000\n",
      "72/72 - 0s - loss: 2.9559 - mse: 2.9559\n",
      "Epoch 812/1000\n",
      "72/72 - 0s - loss: 2.9994 - mse: 2.9994\n",
      "Epoch 813/1000\n",
      "72/72 - 0s - loss: 2.7604 - mse: 2.7604\n",
      "Epoch 814/1000\n",
      "72/72 - 0s - loss: 3.1228 - mse: 3.1228\n",
      "Epoch 815/1000\n",
      "72/72 - 0s - loss: 3.4630 - mse: 3.4630\n",
      "Epoch 816/1000\n",
      "72/72 - 0s - loss: 3.4920 - mse: 3.4920\n",
      "Epoch 817/1000\n",
      "72/72 - 0s - loss: 3.0540 - mse: 3.0540\n",
      "Epoch 818/1000\n",
      "72/72 - 0s - loss: 3.1841 - mse: 3.1841\n",
      "Epoch 819/1000\n",
      "72/72 - 0s - loss: 3.5940 - mse: 3.5940\n",
      "Epoch 820/1000\n",
      "72/72 - 0s - loss: 3.0303 - mse: 3.0303\n",
      "Epoch 821/1000\n",
      "72/72 - 0s - loss: 3.6786 - mse: 3.6786\n",
      "Epoch 822/1000\n",
      "72/72 - 0s - loss: 2.7609 - mse: 2.7609\n",
      "Epoch 823/1000\n",
      "72/72 - 0s - loss: 3.1034 - mse: 3.1034\n",
      "Epoch 824/1000\n",
      "72/72 - 0s - loss: 2.5050 - mse: 2.5050\n",
      "Epoch 825/1000\n",
      "72/72 - 0s - loss: 3.3937 - mse: 3.3937\n",
      "Epoch 826/1000\n",
      "72/72 - 0s - loss: 2.9289 - mse: 2.9289\n",
      "Epoch 827/1000\n",
      "72/72 - 0s - loss: 3.4811 - mse: 3.4811\n",
      "Epoch 828/1000\n",
      "72/72 - 0s - loss: 2.4468 - mse: 2.4468\n",
      "Epoch 829/1000\n",
      "72/72 - 0s - loss: 3.9121 - mse: 3.9121\n",
      "Epoch 830/1000\n",
      "72/72 - 0s - loss: 2.8981 - mse: 2.8981\n",
      "Epoch 831/1000\n",
      "72/72 - 0s - loss: 2.9648 - mse: 2.9648\n",
      "Epoch 832/1000\n",
      "72/72 - 0s - loss: 3.2528 - mse: 3.2528\n",
      "Epoch 833/1000\n",
      "72/72 - 0s - loss: 2.4419 - mse: 2.4419\n",
      "Epoch 834/1000\n",
      "72/72 - 0s - loss: 3.2688 - mse: 3.2688\n",
      "Epoch 835/1000\n",
      "72/72 - 0s - loss: 3.2983 - mse: 3.2983\n",
      "Epoch 836/1000\n",
      "72/72 - 0s - loss: 3.0007 - mse: 3.0007\n",
      "Epoch 837/1000\n",
      "72/72 - 0s - loss: 3.0116 - mse: 3.0116\n",
      "Epoch 838/1000\n",
      "72/72 - 0s - loss: 2.8963 - mse: 2.8963\n",
      "Epoch 839/1000\n",
      "72/72 - 0s - loss: 2.5048 - mse: 2.5048\n",
      "Epoch 840/1000\n",
      "72/72 - 0s - loss: 3.6447 - mse: 3.6447\n",
      "Epoch 841/1000\n",
      "72/72 - 0s - loss: 2.9183 - mse: 2.9183\n",
      "Epoch 842/1000\n",
      "72/72 - 0s - loss: 3.3945 - mse: 3.3945\n",
      "Epoch 843/1000\n",
      "72/72 - 0s - loss: 2.6619 - mse: 2.6619\n",
      "Epoch 844/1000\n",
      "72/72 - 0s - loss: 2.6564 - mse: 2.6564\n",
      "Epoch 845/1000\n",
      "72/72 - 0s - loss: 4.0450 - mse: 4.0450\n",
      "Epoch 846/1000\n",
      "72/72 - 0s - loss: 3.3338 - mse: 3.3338\n",
      "Epoch 847/1000\n",
      "72/72 - 0s - loss: 2.9854 - mse: 2.9854\n",
      "Epoch 848/1000\n",
      "72/72 - 0s - loss: 3.5219 - mse: 3.5219\n",
      "Epoch 849/1000\n",
      "72/72 - 0s - loss: 3.0119 - mse: 3.0119\n",
      "Epoch 850/1000\n",
      "72/72 - 0s - loss: 3.2479 - mse: 3.2479\n",
      "Epoch 851/1000\n",
      "72/72 - 0s - loss: 3.3994 - mse: 3.3994\n",
      "Epoch 852/1000\n",
      "72/72 - 0s - loss: 2.9221 - mse: 2.9221\n",
      "Epoch 853/1000\n",
      "72/72 - 0s - loss: 2.7154 - mse: 2.7154\n",
      "Epoch 854/1000\n",
      "72/72 - 0s - loss: 3.5143 - mse: 3.5143\n",
      "Epoch 855/1000\n",
      "72/72 - 0s - loss: 2.5393 - mse: 2.5393\n",
      "Epoch 856/1000\n",
      "72/72 - 0s - loss: 3.1083 - mse: 3.1083\n",
      "Epoch 857/1000\n",
      "72/72 - 0s - loss: 3.3635 - mse: 3.3635\n",
      "Epoch 858/1000\n",
      "72/72 - 0s - loss: 2.6059 - mse: 2.6059\n",
      "Epoch 859/1000\n",
      "72/72 - 0s - loss: 2.9774 - mse: 2.9774\n",
      "Epoch 860/1000\n",
      "72/72 - 0s - loss: 3.2949 - mse: 3.2949\n",
      "Epoch 861/1000\n",
      "72/72 - 0s - loss: 3.6096 - mse: 3.6096\n",
      "Epoch 862/1000\n",
      "72/72 - 0s - loss: 2.6016 - mse: 2.6016\n",
      "Epoch 863/1000\n",
      "72/72 - 0s - loss: 3.0631 - mse: 3.0631\n",
      "Epoch 864/1000\n",
      "72/72 - 0s - loss: 3.0556 - mse: 3.0556\n",
      "Epoch 865/1000\n",
      "72/72 - 0s - loss: 3.8360 - mse: 3.8360\n",
      "Epoch 866/1000\n",
      "72/72 - 0s - loss: 3.0729 - mse: 3.0729\n",
      "Epoch 867/1000\n",
      "72/72 - 0s - loss: 2.7398 - mse: 2.7398\n",
      "Epoch 868/1000\n",
      "72/72 - 0s - loss: 2.9453 - mse: 2.9453\n",
      "Epoch 869/1000\n",
      "72/72 - 0s - loss: 2.6760 - mse: 2.6760\n",
      "Epoch 870/1000\n",
      "72/72 - 0s - loss: 3.4804 - mse: 3.4804\n",
      "Epoch 871/1000\n",
      "72/72 - 0s - loss: 3.1977 - mse: 3.1977\n",
      "Epoch 872/1000\n",
      "72/72 - 0s - loss: 2.8476 - mse: 2.8476\n",
      "Epoch 873/1000\n",
      "72/72 - 0s - loss: 3.0674 - mse: 3.0674\n",
      "Epoch 874/1000\n",
      "72/72 - 0s - loss: 3.0070 - mse: 3.0070\n",
      "Epoch 875/1000\n",
      "72/72 - 0s - loss: 3.1237 - mse: 3.1237\n",
      "Epoch 876/1000\n",
      "72/72 - 0s - loss: 2.6697 - mse: 2.6697\n",
      "Epoch 877/1000\n",
      "72/72 - 0s - loss: 3.0061 - mse: 3.0061\n",
      "Epoch 878/1000\n",
      "72/72 - 0s - loss: 3.1334 - mse: 3.1334\n",
      "Epoch 879/1000\n",
      "72/72 - 0s - loss: 4.3200 - mse: 4.3200\n",
      "Epoch 880/1000\n",
      "72/72 - 0s - loss: 2.6985 - mse: 2.6985\n",
      "Epoch 881/1000\n",
      "72/72 - 0s - loss: 2.8386 - mse: 2.8386\n",
      "Epoch 882/1000\n",
      "72/72 - 0s - loss: 3.9689 - mse: 3.9689\n",
      "Epoch 883/1000\n",
      "72/72 - 0s - loss: 2.7557 - mse: 2.7557\n",
      "Epoch 884/1000\n",
      "72/72 - 0s - loss: 2.8495 - mse: 2.8495\n",
      "Epoch 885/1000\n",
      "72/72 - 0s - loss: 3.2105 - mse: 3.2105\n",
      "Epoch 886/1000\n",
      "72/72 - 0s - loss: 3.3425 - mse: 3.3425\n",
      "Epoch 887/1000\n",
      "72/72 - 0s - loss: 2.7699 - mse: 2.7699\n",
      "Epoch 888/1000\n",
      "72/72 - 0s - loss: 2.4701 - mse: 2.4701\n",
      "Epoch 889/1000\n",
      "72/72 - 0s - loss: 3.0044 - mse: 3.0044\n",
      "Epoch 890/1000\n",
      "72/72 - 0s - loss: 3.1965 - mse: 3.1965\n",
      "Epoch 891/1000\n",
      "72/72 - 0s - loss: 2.9165 - mse: 2.9165\n",
      "Epoch 892/1000\n",
      "72/72 - 0s - loss: 3.1718 - mse: 3.1718\n",
      "Epoch 893/1000\n",
      "72/72 - 0s - loss: 2.7802 - mse: 2.7802\n",
      "Epoch 894/1000\n",
      "72/72 - 0s - loss: 2.7684 - mse: 2.7684\n",
      "Epoch 895/1000\n",
      "72/72 - 0s - loss: 2.9652 - mse: 2.9652\n",
      "Epoch 896/1000\n",
      "72/72 - 0s - loss: 3.0325 - mse: 3.0325\n",
      "Epoch 897/1000\n",
      "72/72 - 0s - loss: 3.4089 - mse: 3.4089\n",
      "Epoch 898/1000\n",
      "72/72 - 0s - loss: 2.4360 - mse: 2.4360\n",
      "Epoch 899/1000\n",
      "72/72 - 0s - loss: 3.2335 - mse: 3.2335\n",
      "Epoch 900/1000\n",
      "72/72 - 0s - loss: 3.0878 - mse: 3.0878\n",
      "Epoch 901/1000\n",
      "72/72 - 0s - loss: 3.1588 - mse: 3.1588\n",
      "Epoch 902/1000\n",
      "72/72 - 0s - loss: 3.3030 - mse: 3.3030\n",
      "Epoch 903/1000\n",
      "72/72 - 0s - loss: 2.7390 - mse: 2.7390\n",
      "Epoch 904/1000\n",
      "72/72 - 0s - loss: 3.8375 - mse: 3.8375\n",
      "Epoch 905/1000\n",
      "72/72 - 0s - loss: 2.7458 - mse: 2.7458\n",
      "Epoch 906/1000\n",
      "72/72 - 0s - loss: 3.0580 - mse: 3.0580\n",
      "Epoch 907/1000\n",
      "72/72 - 0s - loss: 2.3846 - mse: 2.3846\n",
      "Epoch 908/1000\n",
      "72/72 - 0s - loss: 3.0492 - mse: 3.0492\n",
      "Epoch 909/1000\n",
      "72/72 - 0s - loss: 2.8328 - mse: 2.8328\n",
      "Epoch 910/1000\n",
      "72/72 - 0s - loss: 3.2561 - mse: 3.2561\n",
      "Epoch 911/1000\n",
      "72/72 - 0s - loss: 2.0283 - mse: 2.0283\n",
      "Epoch 912/1000\n",
      "72/72 - 0s - loss: 2.5681 - mse: 2.5681\n",
      "Epoch 913/1000\n",
      "72/72 - 0s - loss: 3.1250 - mse: 3.1250\n",
      "Epoch 914/1000\n",
      "72/72 - 0s - loss: 3.1064 - mse: 3.1064\n",
      "Epoch 915/1000\n",
      "72/72 - 0s - loss: 2.8683 - mse: 2.8683\n",
      "Epoch 916/1000\n",
      "72/72 - 0s - loss: 2.6351 - mse: 2.6351\n",
      "Epoch 917/1000\n",
      "72/72 - 0s - loss: 3.3061 - mse: 3.3061\n",
      "Epoch 918/1000\n",
      "72/72 - 0s - loss: 2.6465 - mse: 2.6465\n",
      "Epoch 919/1000\n",
      "72/72 - 0s - loss: 2.7710 - mse: 2.7710\n",
      "Epoch 920/1000\n",
      "72/72 - 0s - loss: 3.0357 - mse: 3.0357\n",
      "Epoch 921/1000\n",
      "72/72 - 0s - loss: 2.9912 - mse: 2.9912\n",
      "Epoch 922/1000\n",
      "72/72 - 0s - loss: 3.0276 - mse: 3.0276\n",
      "Epoch 923/1000\n",
      "72/72 - 0s - loss: 2.6844 - mse: 2.6844\n",
      "Epoch 924/1000\n",
      "72/72 - 0s - loss: 2.8568 - mse: 2.8568\n",
      "Epoch 925/1000\n",
      "72/72 - 0s - loss: 3.1677 - mse: 3.1677\n",
      "Epoch 926/1000\n",
      "72/72 - 0s - loss: 2.8702 - mse: 2.8702\n",
      "Epoch 927/1000\n",
      "72/72 - 0s - loss: 2.7947 - mse: 2.7947\n",
      "Epoch 928/1000\n",
      "72/72 - 0s - loss: 3.0827 - mse: 3.0827\n",
      "Epoch 929/1000\n",
      "72/72 - 0s - loss: 2.5395 - mse: 2.5395\n",
      "Epoch 930/1000\n",
      "72/72 - 0s - loss: 3.2704 - mse: 3.2704\n",
      "Epoch 931/1000\n",
      "72/72 - 0s - loss: 2.8502 - mse: 2.8502\n",
      "Epoch 932/1000\n",
      "72/72 - 0s - loss: 3.1740 - mse: 3.1740\n",
      "Epoch 933/1000\n",
      "72/72 - 0s - loss: 2.9428 - mse: 2.9428\n",
      "Epoch 934/1000\n",
      "72/72 - 0s - loss: 2.8857 - mse: 2.8857\n",
      "Epoch 935/1000\n",
      "72/72 - 0s - loss: 2.7342 - mse: 2.7342\n",
      "Epoch 936/1000\n",
      "72/72 - 0s - loss: 2.9044 - mse: 2.9044\n",
      "Epoch 937/1000\n",
      "72/72 - 0s - loss: 2.9394 - mse: 2.9394\n",
      "Epoch 938/1000\n",
      "72/72 - 0s - loss: 2.7561 - mse: 2.7561\n",
      "Epoch 939/1000\n",
      "72/72 - 0s - loss: 4.2557 - mse: 4.2557\n",
      "Epoch 940/1000\n",
      "72/72 - 0s - loss: 2.4466 - mse: 2.4466\n",
      "Epoch 941/1000\n",
      "72/72 - 0s - loss: 2.3644 - mse: 2.3644\n",
      "Epoch 942/1000\n",
      "72/72 - 0s - loss: 3.5331 - mse: 3.5331\n",
      "Epoch 943/1000\n",
      "72/72 - 0s - loss: 2.6231 - mse: 2.6231\n",
      "Epoch 944/1000\n",
      "72/72 - 0s - loss: 3.2361 - mse: 3.2361\n",
      "Epoch 945/1000\n",
      "72/72 - 0s - loss: 2.9322 - mse: 2.9322\n",
      "Epoch 946/1000\n",
      "72/72 - 0s - loss: 2.9195 - mse: 2.9195\n",
      "Epoch 947/1000\n",
      "72/72 - 0s - loss: 3.3916 - mse: 3.3916\n",
      "Epoch 948/1000\n",
      "72/72 - 0s - loss: 2.9479 - mse: 2.9479\n",
      "Epoch 949/1000\n",
      "72/72 - 0s - loss: 3.4932 - mse: 3.4932\n",
      "Epoch 950/1000\n",
      "72/72 - 0s - loss: 2.4842 - mse: 2.4842\n",
      "Epoch 951/1000\n",
      "72/72 - 0s - loss: 3.6335 - mse: 3.6335\n",
      "Epoch 952/1000\n",
      "72/72 - 0s - loss: 2.7620 - mse: 2.7620\n",
      "Epoch 953/1000\n",
      "72/72 - 0s - loss: 2.6504 - mse: 2.6504\n",
      "Epoch 954/1000\n",
      "72/72 - 0s - loss: 3.2013 - mse: 3.2013\n",
      "Epoch 955/1000\n",
      "72/72 - 0s - loss: 2.4702 - mse: 2.4702\n",
      "Epoch 956/1000\n",
      "72/72 - 0s - loss: 2.8638 - mse: 2.8638\n",
      "Epoch 957/1000\n",
      "72/72 - 0s - loss: 3.6083 - mse: 3.6083\n",
      "Epoch 958/1000\n",
      "72/72 - 0s - loss: 2.4618 - mse: 2.4618\n",
      "Epoch 959/1000\n",
      "72/72 - 0s - loss: 2.9070 - mse: 2.9070\n",
      "Epoch 960/1000\n",
      "72/72 - 0s - loss: 2.9807 - mse: 2.9807\n",
      "Epoch 961/1000\n",
      "72/72 - 0s - loss: 3.4092 - mse: 3.4092\n",
      "Epoch 962/1000\n",
      "72/72 - 0s - loss: 3.0491 - mse: 3.0491\n",
      "Epoch 963/1000\n",
      "72/72 - 0s - loss: 2.9220 - mse: 2.9220\n",
      "Epoch 964/1000\n",
      "72/72 - 0s - loss: 2.7909 - mse: 2.7909\n",
      "Epoch 965/1000\n",
      "72/72 - 0s - loss: 3.3864 - mse: 3.3864\n",
      "Epoch 966/1000\n",
      "72/72 - 0s - loss: 3.4417 - mse: 3.4417\n",
      "Epoch 967/1000\n",
      "72/72 - 0s - loss: 2.9757 - mse: 2.9757\n",
      "Epoch 968/1000\n",
      "72/72 - 0s - loss: 3.0102 - mse: 3.0102\n",
      "Epoch 969/1000\n",
      "72/72 - 0s - loss: 2.6009 - mse: 2.6009\n",
      "Epoch 970/1000\n",
      "72/72 - 0s - loss: 2.8859 - mse: 2.8859\n",
      "Epoch 971/1000\n",
      "72/72 - 0s - loss: 2.6230 - mse: 2.6230\n",
      "Epoch 972/1000\n",
      "72/72 - 0s - loss: 2.9487 - mse: 2.9487\n",
      "Epoch 973/1000\n",
      "72/72 - 0s - loss: 3.4462 - mse: 3.4462\n",
      "Epoch 974/1000\n",
      "72/72 - 0s - loss: 2.5928 - mse: 2.5928\n",
      "Epoch 975/1000\n",
      "72/72 - 0s - loss: 2.7487 - mse: 2.7487\n",
      "Epoch 976/1000\n",
      "72/72 - 0s - loss: 3.1099 - mse: 3.1099\n",
      "Epoch 977/1000\n",
      "72/72 - 0s - loss: 3.2517 - mse: 3.2517\n",
      "Epoch 978/1000\n",
      "72/72 - 0s - loss: 1.8763 - mse: 1.8763\n",
      "Epoch 979/1000\n",
      "72/72 - 0s - loss: 3.7209 - mse: 3.7209\n",
      "Epoch 980/1000\n",
      "72/72 - 0s - loss: 2.1912 - mse: 2.1912\n",
      "Epoch 981/1000\n",
      "72/72 - 0s - loss: 3.4438 - mse: 3.4438\n",
      "Epoch 982/1000\n",
      "72/72 - 0s - loss: 2.8324 - mse: 2.8324\n",
      "Epoch 983/1000\n",
      "72/72 - 0s - loss: 2.9043 - mse: 2.9043\n",
      "Epoch 984/1000\n",
      "72/72 - 0s - loss: 2.8475 - mse: 2.8475\n",
      "Epoch 985/1000\n",
      "72/72 - 0s - loss: 3.0918 - mse: 3.0918\n",
      "Epoch 986/1000\n",
      "72/72 - 0s - loss: 3.1289 - mse: 3.1289\n",
      "Epoch 987/1000\n",
      "72/72 - 0s - loss: 2.4920 - mse: 2.4920\n",
      "Epoch 988/1000\n",
      "72/72 - 0s - loss: 2.9866 - mse: 2.9866\n",
      "Epoch 989/1000\n",
      "72/72 - 0s - loss: 2.5944 - mse: 2.5944\n",
      "Epoch 990/1000\n",
      "72/72 - 0s - loss: 3.0047 - mse: 3.0047\n",
      "Epoch 991/1000\n",
      "72/72 - 0s - loss: 2.7194 - mse: 2.7194\n",
      "Epoch 992/1000\n",
      "72/72 - 0s - loss: 2.7527 - mse: 2.7527\n",
      "Epoch 993/1000\n",
      "72/72 - 0s - loss: 3.8483 - mse: 3.8483\n",
      "Epoch 994/1000\n",
      "72/72 - 0s - loss: 2.7625 - mse: 2.7625\n",
      "Epoch 995/1000\n",
      "72/72 - 0s - loss: 2.4845 - mse: 2.4845\n",
      "Epoch 996/1000\n",
      "72/72 - 0s - loss: 2.3210 - mse: 2.3210\n",
      "Epoch 997/1000\n",
      "72/72 - 0s - loss: 3.7136 - mse: 3.7136\n",
      "Epoch 998/1000\n",
      "72/72 - 0s - loss: 3.4137 - mse: 3.4137\n",
      "Epoch 999/1000\n",
      "72/72 - 0s - loss: 3.1801 - mse: 3.1801\n",
      "Epoch 1000/1000\n",
      "72/72 - 0s - loss: 2.3095 - mse: 2.3095\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 29793.3438 - mse: 29793.3438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[29793.34375, 29793.34375]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=1000, batch_size=4, verbose=2)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                768       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,857\n",
      "Trainable params: 1,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set prediction accuracy: 28.12 %\n",
      "test set prediction accuracy: 27.78 %\n"
     ]
    }
   ],
   "source": [
    "#평균 성능 테스트\n",
    "scores = 0\n",
    "mean=np.mean(Y, axis=0)\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= mean <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"train set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= mean <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"test set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### <오차범위 3>\n",
      "- train set prediction accuracy(+-3): 96.53 % <br>\n",
      "- test set prediction accuracy(+-3): 11.11 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 5>\n",
      "- train set prediction accuracy(+-5): 98.96 % <br>\n",
      "- test set prediction accuracy(+-5): 13.89 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 10>\n",
      "- train set prediction accuracy(+-10): 100.00 % <br>\n",
      "- test set prediction accuracy(+-10): 22.22 % <br>\n",
      "<br>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######입력용#######\n",
    "\n",
    "#오차 범위 3 설정\n",
    "print('### <오차범위 3>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "print('### <오차범위 5>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "print('### <오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (시본으로 선별한 특징)\n",
    "X1=psqi_df[['SEX','AGE','PSQI_TOTAL_1','BMI_1','WBC_1','Insulin _1','Neutrophil_1','HDL_1','GLU0_1',\n",
    "            'Muscle_1','FatPercentage _1','SBP_1','DBP_1','HR_1','Waist_1']].values\n",
    "\n",
    "X2=psqi_df[['SEX','AGE','PSQI_TOTAL_2','BMI_2','WBC_2','Insulin _2','Neutrophil_2','HDL_2','GLU0_2',\n",
    "            'Muscle_2','FatPercentage_2','SBP_2','DBP_2','HR_2','Waist_2']].values\n",
    "\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=LDL)\n",
    "Y1= psqi_df[['LDL_1']].values\n",
    "Y2= psqi_df[['LDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 72)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 15), (360, 1))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "72/72 - 1s - loss: 14851.0625 - mse: 14851.0625\n",
      "Epoch 2/150\n",
      "72/72 - 0s - loss: 14373.9219 - mse: 14373.9219\n",
      "Epoch 3/150\n",
      "72/72 - 0s - loss: 13366.1816 - mse: 13366.1816\n",
      "Epoch 4/150\n",
      "72/72 - 0s - loss: 11835.8730 - mse: 11835.8730\n",
      "Epoch 5/150\n",
      "72/72 - 0s - loss: 9569.8633 - mse: 9569.8633\n",
      "Epoch 6/150\n",
      "72/72 - 0s - loss: 7183.9243 - mse: 7183.9243\n",
      "Epoch 7/150\n",
      "72/72 - 0s - loss: 5075.7915 - mse: 5075.7915\n",
      "Epoch 8/150\n",
      "72/72 - 0s - loss: 4061.9722 - mse: 4061.9722\n",
      "Epoch 9/150\n",
      "72/72 - 0s - loss: 3631.3821 - mse: 3631.3821\n",
      "Epoch 10/150\n",
      "72/72 - 0s - loss: 3468.8340 - mse: 3468.8340\n",
      "Epoch 11/150\n",
      "72/72 - 0s - loss: 3373.6628 - mse: 3373.6628\n",
      "Epoch 12/150\n",
      "72/72 - 0s - loss: 3276.3738 - mse: 3276.3738\n",
      "Epoch 13/150\n",
      "72/72 - 0s - loss: 3229.0830 - mse: 3229.0830\n",
      "Epoch 14/150\n",
      "72/72 - 0s - loss: 3168.7351 - mse: 3168.7351\n",
      "Epoch 15/150\n",
      "72/72 - 0s - loss: 3119.7937 - mse: 3119.7937\n",
      "Epoch 16/150\n",
      "72/72 - 0s - loss: 3086.7119 - mse: 3086.7119\n",
      "Epoch 17/150\n",
      "72/72 - 0s - loss: 3021.8777 - mse: 3021.8777\n",
      "Epoch 18/150\n",
      "72/72 - 0s - loss: 3012.0596 - mse: 3012.0596\n",
      "Epoch 19/150\n",
      "72/72 - 0s - loss: 2982.4873 - mse: 2982.4873\n",
      "Epoch 20/150\n",
      "72/72 - 0s - loss: 2960.3003 - mse: 2960.3003\n",
      "Epoch 21/150\n",
      "72/72 - 0s - loss: 2939.7141 - mse: 2939.7141\n",
      "Epoch 22/150\n",
      "72/72 - 0s - loss: 2905.7520 - mse: 2905.7520\n",
      "Epoch 23/150\n",
      "72/72 - 0s - loss: 2901.4937 - mse: 2901.4937\n",
      "Epoch 24/150\n",
      "72/72 - 0s - loss: 2882.9385 - mse: 2882.9385\n",
      "Epoch 25/150\n",
      "72/72 - 0s - loss: 2861.0823 - mse: 2861.0823\n",
      "Epoch 26/150\n",
      "72/72 - 0s - loss: 2854.7156 - mse: 2854.7156\n",
      "Epoch 27/150\n",
      "72/72 - 0s - loss: 2830.1096 - mse: 2830.1096\n",
      "Epoch 28/150\n",
      "72/72 - 0s - loss: 2820.1934 - mse: 2820.1934\n",
      "Epoch 29/150\n",
      "72/72 - 0s - loss: 2814.7563 - mse: 2814.7563\n",
      "Epoch 30/150\n",
      "72/72 - 0s - loss: 2796.9385 - mse: 2796.9385\n",
      "Epoch 31/150\n",
      "72/72 - 0s - loss: 2781.5901 - mse: 2781.5901\n",
      "Epoch 32/150\n",
      "72/72 - 0s - loss: 2779.3428 - mse: 2779.3428\n",
      "Epoch 33/150\n",
      "72/72 - 0s - loss: 2767.5168 - mse: 2767.5168\n",
      "Epoch 34/150\n",
      "72/72 - 0s - loss: 2753.3406 - mse: 2753.3406\n",
      "Epoch 35/150\n",
      "72/72 - 0s - loss: 2759.6433 - mse: 2759.6433\n",
      "Epoch 36/150\n",
      "72/72 - 0s - loss: 2736.4326 - mse: 2736.4326\n",
      "Epoch 37/150\n",
      "72/72 - 0s - loss: 2738.3977 - mse: 2738.3977\n",
      "Epoch 38/150\n",
      "72/72 - 0s - loss: 2721.5496 - mse: 2721.5496\n",
      "Epoch 39/150\n",
      "72/72 - 0s - loss: 2729.7290 - mse: 2729.7290\n",
      "Epoch 40/150\n",
      "72/72 - 0s - loss: 2732.2434 - mse: 2732.2434\n",
      "Epoch 41/150\n",
      "72/72 - 0s - loss: 2714.2153 - mse: 2714.2153\n",
      "Epoch 42/150\n",
      "72/72 - 0s - loss: 2703.6260 - mse: 2703.6260\n",
      "Epoch 43/150\n",
      "72/72 - 0s - loss: 2701.7502 - mse: 2701.7502\n",
      "Epoch 44/150\n",
      "72/72 - 0s - loss: 2687.6602 - mse: 2687.6602\n",
      "Epoch 45/150\n",
      "72/72 - 0s - loss: 2690.5830 - mse: 2690.5830\n",
      "Epoch 46/150\n",
      "72/72 - 0s - loss: 2678.2524 - mse: 2678.2524\n",
      "Epoch 47/150\n",
      "72/72 - 0s - loss: 2671.9695 - mse: 2671.9695\n",
      "Epoch 48/150\n",
      "72/72 - 0s - loss: 2674.3975 - mse: 2674.3975\n",
      "Epoch 49/150\n",
      "72/72 - 0s - loss: 2669.4795 - mse: 2669.4795\n",
      "Epoch 50/150\n",
      "72/72 - 0s - loss: 2662.8760 - mse: 2662.8760\n",
      "Epoch 51/150\n",
      "72/72 - 0s - loss: 2655.9480 - mse: 2655.9480\n",
      "Epoch 52/150\n",
      "72/72 - 0s - loss: 2658.9851 - mse: 2658.9851\n",
      "Epoch 53/150\n",
      "72/72 - 0s - loss: 2646.4182 - mse: 2646.4182\n",
      "Epoch 54/150\n",
      "72/72 - 0s - loss: 2652.1960 - mse: 2652.1960\n",
      "Epoch 55/150\n",
      "72/72 - 0s - loss: 2632.1841 - mse: 2632.1841\n",
      "Epoch 56/150\n",
      "72/72 - 0s - loss: 2657.4731 - mse: 2657.4731\n",
      "Epoch 57/150\n",
      "72/72 - 0s - loss: 2626.5562 - mse: 2626.5562\n",
      "Epoch 58/150\n",
      "72/72 - 0s - loss: 2621.1755 - mse: 2621.1755\n",
      "Epoch 59/150\n",
      "72/72 - 0s - loss: 2625.2549 - mse: 2625.2549\n",
      "Epoch 60/150\n",
      "72/72 - 0s - loss: 2617.7717 - mse: 2617.7717\n",
      "Epoch 61/150\n",
      "72/72 - 0s - loss: 2612.3584 - mse: 2612.3584\n",
      "Epoch 62/150\n",
      "72/72 - 0s - loss: 2595.5066 - mse: 2595.5066\n",
      "Epoch 63/150\n",
      "72/72 - 0s - loss: 2561.0752 - mse: 2561.0752\n",
      "Epoch 64/150\n",
      "72/72 - 0s - loss: 2606.1167 - mse: 2606.1167\n",
      "Epoch 65/150\n",
      "72/72 - 0s - loss: 2591.0483 - mse: 2591.0483\n",
      "Epoch 66/150\n",
      "72/72 - 0s - loss: 2585.7163 - mse: 2585.7163\n",
      "Epoch 67/150\n",
      "72/72 - 0s - loss: 2580.0911 - mse: 2580.0911\n",
      "Epoch 68/150\n",
      "72/72 - 0s - loss: 2574.1123 - mse: 2574.1123\n",
      "Epoch 69/150\n",
      "72/72 - 0s - loss: 2582.3857 - mse: 2582.3857\n",
      "Epoch 70/150\n",
      "72/72 - 0s - loss: 2566.8879 - mse: 2566.8879\n",
      "Epoch 71/150\n",
      "72/72 - 0s - loss: 2553.3455 - mse: 2553.3455\n",
      "Epoch 72/150\n",
      "72/72 - 0s - loss: 2577.1021 - mse: 2577.1021\n",
      "Epoch 73/150\n",
      "72/72 - 0s - loss: 2546.3147 - mse: 2546.3147\n",
      "Epoch 74/150\n",
      "72/72 - 0s - loss: 2562.4231 - mse: 2562.4231\n",
      "Epoch 75/150\n",
      "72/72 - 0s - loss: 2554.4150 - mse: 2554.4150\n",
      "Epoch 76/150\n",
      "72/72 - 0s - loss: 2550.2002 - mse: 2550.2002\n",
      "Epoch 77/150\n",
      "72/72 - 0s - loss: 2545.3599 - mse: 2545.3599\n",
      "Epoch 78/150\n",
      "72/72 - 0s - loss: 2550.9380 - mse: 2550.9380\n",
      "Epoch 79/150\n",
      "72/72 - 0s - loss: 2545.4006 - mse: 2545.4006\n",
      "Epoch 80/150\n",
      "72/72 - 0s - loss: 2541.0410 - mse: 2541.0410\n",
      "Epoch 81/150\n",
      "72/72 - 0s - loss: 2535.6208 - mse: 2535.6208\n",
      "Epoch 82/150\n",
      "72/72 - 0s - loss: 2535.0920 - mse: 2535.0920\n",
      "Epoch 83/150\n",
      "72/72 - 0s - loss: 2531.0649 - mse: 2531.0649\n",
      "Epoch 84/150\n",
      "72/72 - 0s - loss: 2533.3035 - mse: 2533.3035\n",
      "Epoch 85/150\n",
      "72/72 - 0s - loss: 2512.7185 - mse: 2512.7185\n",
      "Epoch 86/150\n",
      "72/72 - 0s - loss: 2508.4382 - mse: 2508.4382\n",
      "Epoch 87/150\n",
      "72/72 - 0s - loss: 2507.0156 - mse: 2507.0156\n",
      "Epoch 88/150\n",
      "72/72 - 0s - loss: 2511.4417 - mse: 2511.4417\n",
      "Epoch 89/150\n",
      "72/72 - 0s - loss: 2497.2583 - mse: 2497.2583\n",
      "Epoch 90/150\n",
      "72/72 - 0s - loss: 2512.2383 - mse: 2512.2383\n",
      "Epoch 91/150\n",
      "72/72 - 0s - loss: 2507.0066 - mse: 2507.0066\n",
      "Epoch 92/150\n",
      "72/72 - 0s - loss: 2519.0315 - mse: 2519.0315\n",
      "Epoch 93/150\n",
      "72/72 - 0s - loss: 2492.1067 - mse: 2492.1067\n",
      "Epoch 94/150\n",
      "72/72 - 0s - loss: 2498.5244 - mse: 2498.5244\n",
      "Epoch 95/150\n",
      "72/72 - 0s - loss: 2484.1614 - mse: 2484.1614\n",
      "Epoch 96/150\n",
      "72/72 - 0s - loss: 2478.6672 - mse: 2478.6672\n",
      "Epoch 97/150\n",
      "72/72 - 0s - loss: 2484.2041 - mse: 2484.2041\n",
      "Epoch 98/150\n",
      "72/72 - 0s - loss: 2474.7288 - mse: 2474.7288\n",
      "Epoch 99/150\n",
      "72/72 - 0s - loss: 2487.2600 - mse: 2487.2600\n",
      "Epoch 100/150\n",
      "72/72 - 0s - loss: 2472.2729 - mse: 2472.2729\n",
      "Epoch 101/150\n",
      "72/72 - 0s - loss: 2480.7998 - mse: 2480.7998\n",
      "Epoch 102/150\n",
      "72/72 - 0s - loss: 2462.3401 - mse: 2462.3401\n",
      "Epoch 103/150\n",
      "72/72 - 0s - loss: 2474.0994 - mse: 2474.0994\n",
      "Epoch 104/150\n",
      "72/72 - 0s - loss: 2467.9377 - mse: 2467.9377\n",
      "Epoch 105/150\n",
      "72/72 - 0s - loss: 2443.2693 - mse: 2443.2693\n",
      "Epoch 106/150\n",
      "72/72 - 0s - loss: 2467.1750 - mse: 2467.1750\n",
      "Epoch 107/150\n",
      "72/72 - 0s - loss: 2434.0894 - mse: 2434.0894\n",
      "Epoch 108/150\n",
      "72/72 - 0s - loss: 2457.1746 - mse: 2457.1746\n",
      "Epoch 109/150\n",
      "72/72 - 0s - loss: 2452.7236 - mse: 2452.7236\n",
      "Epoch 110/150\n",
      "72/72 - 0s - loss: 2462.5791 - mse: 2462.5791\n",
      "Epoch 111/150\n",
      "72/72 - 0s - loss: 2451.2502 - mse: 2451.2502\n",
      "Epoch 112/150\n",
      "72/72 - 0s - loss: 2450.5291 - mse: 2450.5291\n",
      "Epoch 113/150\n",
      "72/72 - 0s - loss: 2439.0693 - mse: 2439.0693\n",
      "Epoch 114/150\n",
      "72/72 - 0s - loss: 2454.5652 - mse: 2454.5652\n",
      "Epoch 115/150\n",
      "72/72 - 0s - loss: 2447.4028 - mse: 2447.4028\n",
      "Epoch 116/150\n",
      "72/72 - 0s - loss: 2446.2634 - mse: 2446.2634\n",
      "Epoch 117/150\n",
      "72/72 - 0s - loss: 2431.1174 - mse: 2431.1174\n",
      "Epoch 118/150\n",
      "72/72 - 0s - loss: 2442.4568 - mse: 2442.4568\n",
      "Epoch 119/150\n",
      "72/72 - 0s - loss: 2418.0930 - mse: 2418.0930\n",
      "Epoch 120/150\n",
      "72/72 - 0s - loss: 2412.1689 - mse: 2412.1689\n",
      "Epoch 121/150\n",
      "72/72 - 0s - loss: 2425.3792 - mse: 2425.3792\n",
      "Epoch 122/150\n",
      "72/72 - 0s - loss: 2422.3926 - mse: 2422.3926\n",
      "Epoch 123/150\n",
      "72/72 - 0s - loss: 2412.2852 - mse: 2412.2852\n",
      "Epoch 124/150\n",
      "72/72 - 0s - loss: 2399.7524 - mse: 2399.7524\n",
      "Epoch 125/150\n",
      "72/72 - 0s - loss: 2401.4277 - mse: 2401.4277\n",
      "Epoch 126/150\n",
      "72/72 - 0s - loss: 2400.3491 - mse: 2400.3491\n",
      "Epoch 127/150\n",
      "72/72 - 0s - loss: 2398.4590 - mse: 2398.4590\n",
      "Epoch 128/150\n",
      "72/72 - 0s - loss: 2410.0718 - mse: 2410.0718\n",
      "Epoch 129/150\n",
      "72/72 - 0s - loss: 2390.0435 - mse: 2390.0435\n",
      "Epoch 130/150\n",
      "72/72 - 0s - loss: 2392.1733 - mse: 2392.1733\n",
      "Epoch 131/150\n",
      "72/72 - 0s - loss: 2385.8723 - mse: 2385.8723\n",
      "Epoch 132/150\n",
      "72/72 - 0s - loss: 2378.7249 - mse: 2378.7249\n",
      "Epoch 133/150\n",
      "72/72 - 0s - loss: 2370.8330 - mse: 2370.8330\n",
      "Epoch 134/150\n",
      "72/72 - 0s - loss: 2364.6943 - mse: 2364.6943\n",
      "Epoch 135/150\n",
      "72/72 - 0s - loss: 2371.6865 - mse: 2371.6865\n",
      "Epoch 136/150\n",
      "72/72 - 0s - loss: 2369.5825 - mse: 2369.5825\n",
      "Epoch 137/150\n",
      "72/72 - 0s - loss: 2358.6243 - mse: 2358.6243\n",
      "Epoch 138/150\n",
      "72/72 - 0s - loss: 2363.5657 - mse: 2363.5657\n",
      "Epoch 139/150\n",
      "72/72 - 0s - loss: 2364.3821 - mse: 2364.3821\n",
      "Epoch 140/150\n",
      "72/72 - 0s - loss: 2352.0740 - mse: 2352.0740\n",
      "Epoch 141/150\n",
      "72/72 - 0s - loss: 2347.4343 - mse: 2347.4343\n",
      "Epoch 142/150\n",
      "72/72 - 0s - loss: 2338.9497 - mse: 2338.9497\n",
      "Epoch 143/150\n",
      "72/72 - 0s - loss: 2346.1265 - mse: 2346.1265\n",
      "Epoch 144/150\n",
      "72/72 - 0s - loss: 2327.8401 - mse: 2327.8401\n",
      "Epoch 145/150\n",
      "72/72 - 0s - loss: 2333.3845 - mse: 2333.3845\n",
      "Epoch 146/150\n",
      "72/72 - 0s - loss: 2327.3149 - mse: 2327.3149\n",
      "Epoch 147/150\n",
      "72/72 - 0s - loss: 2318.7678 - mse: 2318.7678\n",
      "Epoch 148/150\n",
      "72/72 - 0s - loss: 2319.7947 - mse: 2319.7947\n",
      "Epoch 149/150\n",
      "72/72 - 0s - loss: 2313.7593 - mse: 2313.7593\n",
      "Epoch 150/150\n",
      "72/72 - 0s - loss: 2306.0115 - mse: 2306.0115\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 9658.2314 - mse: 9658.2314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9658.2314453125, 9658.2314453125]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=150, batch_size=4, verbose=2)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                512       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,601\n",
      "Trainable params: 1,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set prediction accuracy: 11.46 %\n",
      "test set prediction accuracy: 8.33 %\n"
     ]
    }
   ],
   "source": [
    "#평균 성능 테스트\n",
    "scores = 0\n",
    "mean=np.mean(Y, axis=0)\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= mean <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"train set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= mean <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"test set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### <오차범위 3>\n",
      "- train set prediction accuracy(+-3): 7.64 % <br>\n",
      "- test set prediction accuracy(+-3): 6.94 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 5>\n",
      "- train set prediction accuracy(+-5): 13.19 % <br>\n",
      "- test set prediction accuracy(+-5): 9.72 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 10>\n",
      "- train set prediction accuracy(+-10): 25.35 % <br>\n",
      "- test set prediction accuracy(+-10): 25.00 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 20>\n",
      "- train set prediction accuracy(+-20): 48.96 % <br>\n",
      "- test set prediction accuracy(+-20): 54.17 % <br>\n"
     ]
    }
   ],
   "source": [
    "######입력용#######\n",
    "\n",
    "#오차 범위 3 설정\n",
    "print('### <오차범위 3>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "print('### <오차범위 5>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "print('### <오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "print('### <오차범위 20>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (피검사 안하고 할 수 있는 수치)\n",
    "X1=psqi_df[['SEX','AGE','PSQI_TOTAL_1','BMI_1',\n",
    "            'Muscle_1','FatPercentage _1','SBP_1','DBP_1','HR_1','Waist_1']].values\n",
    "\n",
    "X2=psqi_df[['SEX','AGE','PSQI_TOTAL_2','BMI_2',\n",
    "            'Muscle_2','FatPercentage_2','SBP_2','DBP_2','HR_2','Waist_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "\n",
    "#y 배열 생성 (y=TG)\n",
    "Y1= psqi_df[['TG_1']].values\n",
    "Y2= psqi_df[['TG_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 72)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 10), (360, 1))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "72/72 - 1s - loss: 14555.7432 - mse: 14555.7432\n",
      "Epoch 2/150\n",
      "72/72 - 0s - loss: 13647.1133 - mse: 13647.1133\n",
      "Epoch 3/150\n",
      "72/72 - 0s - loss: 12046.6699 - mse: 12046.6699\n",
      "Epoch 4/150\n",
      "72/72 - 0s - loss: 9738.7324 - mse: 9738.7324\n",
      "Epoch 5/150\n",
      "72/72 - 0s - loss: 7297.1816 - mse: 7297.1816\n",
      "Epoch 6/150\n",
      "72/72 - 0s - loss: 5274.3525 - mse: 5274.3525\n",
      "Epoch 7/150\n",
      "72/72 - 0s - loss: 4257.6792 - mse: 4257.6792\n",
      "Epoch 8/150\n",
      "72/72 - 0s - loss: 3866.3499 - mse: 3866.3499\n",
      "Epoch 9/150\n",
      "72/72 - 0s - loss: 3755.8481 - mse: 3755.8481\n",
      "Epoch 10/150\n",
      "72/72 - 0s - loss: 3695.7512 - mse: 3695.7512\n",
      "Epoch 11/150\n",
      "72/72 - 0s - loss: 3646.7622 - mse: 3646.7622\n",
      "Epoch 12/150\n",
      "72/72 - 0s - loss: 3616.5178 - mse: 3616.5178\n",
      "Epoch 13/150\n",
      "72/72 - 0s - loss: 3589.9465 - mse: 3589.9465\n",
      "Epoch 14/150\n",
      "72/72 - 0s - loss: 3549.6084 - mse: 3549.6084\n",
      "Epoch 15/150\n",
      "72/72 - 0s - loss: 3539.3721 - mse: 3539.3721\n",
      "Epoch 16/150\n",
      "72/72 - 0s - loss: 3513.3745 - mse: 3513.3745\n",
      "Epoch 17/150\n",
      "72/72 - 0s - loss: 3497.9146 - mse: 3497.9146\n",
      "Epoch 18/150\n",
      "72/72 - 0s - loss: 3489.1946 - mse: 3489.1946\n",
      "Epoch 19/150\n",
      "72/72 - 0s - loss: 3450.2749 - mse: 3450.2749\n",
      "Epoch 20/150\n",
      "72/72 - 0s - loss: 3446.6616 - mse: 3446.6616\n",
      "Epoch 21/150\n",
      "72/72 - 0s - loss: 3428.5576 - mse: 3428.5576\n",
      "Epoch 22/150\n",
      "72/72 - 0s - loss: 3413.8977 - mse: 3413.8977\n",
      "Epoch 23/150\n",
      "72/72 - 0s - loss: 3398.7251 - mse: 3398.7251\n",
      "Epoch 24/150\n",
      "72/72 - 0s - loss: 3392.7373 - mse: 3392.7373\n",
      "Epoch 25/150\n",
      "72/72 - 0s - loss: 3379.9136 - mse: 3379.9136\n",
      "Epoch 26/150\n",
      "72/72 - 0s - loss: 3370.0271 - mse: 3370.0271\n",
      "Epoch 27/150\n",
      "72/72 - 0s - loss: 3361.1685 - mse: 3361.1685\n",
      "Epoch 28/150\n",
      "72/72 - 0s - loss: 3345.4473 - mse: 3345.4473\n",
      "Epoch 29/150\n",
      "72/72 - 0s - loss: 3342.0308 - mse: 3342.0308\n",
      "Epoch 30/150\n",
      "72/72 - 0s - loss: 3328.7683 - mse: 3328.7683\n",
      "Epoch 31/150\n",
      "72/72 - 0s - loss: 3316.3464 - mse: 3316.3464\n",
      "Epoch 32/150\n",
      "72/72 - 0s - loss: 3309.2200 - mse: 3309.2200\n",
      "Epoch 33/150\n",
      "72/72 - 0s - loss: 3302.1697 - mse: 3302.1697\n",
      "Epoch 34/150\n",
      "72/72 - 0s - loss: 3303.9045 - mse: 3303.9045\n",
      "Epoch 35/150\n",
      "72/72 - 0s - loss: 3290.7461 - mse: 3290.7461\n",
      "Epoch 36/150\n",
      "72/72 - 0s - loss: 3292.2705 - mse: 3292.2705\n",
      "Epoch 37/150\n",
      "72/72 - 0s - loss: 3277.5591 - mse: 3277.5591\n",
      "Epoch 38/150\n",
      "72/72 - 0s - loss: 3279.5986 - mse: 3279.5986\n",
      "Epoch 39/150\n",
      "72/72 - 0s - loss: 3268.2617 - mse: 3268.2617\n",
      "Epoch 40/150\n",
      "72/72 - 0s - loss: 3268.2776 - mse: 3268.2776\n",
      "Epoch 41/150\n",
      "72/72 - 0s - loss: 3256.9575 - mse: 3256.9575\n",
      "Epoch 42/150\n",
      "72/72 - 0s - loss: 3245.5479 - mse: 3245.5479\n",
      "Epoch 43/150\n",
      "72/72 - 0s - loss: 3244.0447 - mse: 3244.0447\n",
      "Epoch 44/150\n",
      "72/72 - 0s - loss: 3244.9041 - mse: 3244.9041\n",
      "Epoch 45/150\n",
      "72/72 - 0s - loss: 3244.3689 - mse: 3244.3689\n",
      "Epoch 46/150\n",
      "72/72 - 0s - loss: 3234.7295 - mse: 3234.7295\n",
      "Epoch 47/150\n",
      "72/72 - 0s - loss: 3225.2856 - mse: 3225.2856\n",
      "Epoch 48/150\n",
      "72/72 - 0s - loss: 3216.2297 - mse: 3216.2297\n",
      "Epoch 49/150\n",
      "72/72 - 0s - loss: 3214.5547 - mse: 3214.5547\n",
      "Epoch 50/150\n",
      "72/72 - 0s - loss: 3212.8569 - mse: 3212.8569\n",
      "Epoch 51/150\n",
      "72/72 - 0s - loss: 3211.5752 - mse: 3211.5752\n",
      "Epoch 52/150\n",
      "72/72 - 0s - loss: 3190.6392 - mse: 3190.6392\n",
      "Epoch 53/150\n",
      "72/72 - 0s - loss: 3196.5771 - mse: 3196.5771\n",
      "Epoch 54/150\n",
      "72/72 - 0s - loss: 3187.6782 - mse: 3187.6782\n",
      "Epoch 55/150\n",
      "72/72 - 0s - loss: 3180.0276 - mse: 3180.0276\n",
      "Epoch 56/150\n",
      "72/72 - 0s - loss: 3188.6997 - mse: 3188.6997\n",
      "Epoch 57/150\n",
      "72/72 - 0s - loss: 3189.7070 - mse: 3189.7070\n",
      "Epoch 58/150\n",
      "72/72 - 0s - loss: 3171.2817 - mse: 3171.2817\n",
      "Epoch 59/150\n",
      "72/72 - 0s - loss: 3175.8838 - mse: 3175.8838\n",
      "Epoch 60/150\n",
      "72/72 - 0s - loss: 3162.9077 - mse: 3162.9077\n",
      "Epoch 61/150\n",
      "72/72 - 0s - loss: 3166.5037 - mse: 3166.5037\n",
      "Epoch 62/150\n",
      "72/72 - 0s - loss: 3162.4062 - mse: 3162.4062\n",
      "Epoch 63/150\n",
      "72/72 - 0s - loss: 3162.6240 - mse: 3162.6240\n",
      "Epoch 64/150\n",
      "72/72 - 0s - loss: 3156.6719 - mse: 3156.6719\n",
      "Epoch 65/150\n",
      "72/72 - 0s - loss: 3153.1516 - mse: 3153.1516\n",
      "Epoch 66/150\n",
      "72/72 - 0s - loss: 3141.7354 - mse: 3141.7354\n",
      "Epoch 67/150\n",
      "72/72 - 0s - loss: 3159.9841 - mse: 3159.9841\n",
      "Epoch 68/150\n",
      "72/72 - 0s - loss: 3139.2693 - mse: 3139.2693\n",
      "Epoch 69/150\n",
      "72/72 - 0s - loss: 3139.0469 - mse: 3139.0469\n",
      "Epoch 70/150\n",
      "72/72 - 0s - loss: 3136.2041 - mse: 3136.2041\n",
      "Epoch 71/150\n",
      "72/72 - 0s - loss: 3138.9656 - mse: 3138.9656\n",
      "Epoch 72/150\n",
      "72/72 - 0s - loss: 3124.2295 - mse: 3124.2295\n",
      "Epoch 73/150\n",
      "72/72 - 0s - loss: 3125.1333 - mse: 3125.1333\n",
      "Epoch 74/150\n",
      "72/72 - 0s - loss: 3124.3801 - mse: 3124.3801\n",
      "Epoch 75/150\n",
      "72/72 - 0s - loss: 3127.7859 - mse: 3127.7859\n",
      "Epoch 76/150\n",
      "72/72 - 0s - loss: 3125.6689 - mse: 3125.6689\n",
      "Epoch 77/150\n",
      "72/72 - 0s - loss: 3113.9500 - mse: 3113.9500\n",
      "Epoch 78/150\n",
      "72/72 - 0s - loss: 3113.6040 - mse: 3113.6040\n",
      "Epoch 79/150\n",
      "72/72 - 0s - loss: 3112.2581 - mse: 3112.2581\n",
      "Epoch 80/150\n",
      "72/72 - 0s - loss: 3107.4424 - mse: 3107.4424\n",
      "Epoch 81/150\n",
      "72/72 - 0s - loss: 3107.6790 - mse: 3107.6790\n",
      "Epoch 82/150\n",
      "72/72 - 0s - loss: 3104.0872 - mse: 3104.0872\n",
      "Epoch 83/150\n",
      "72/72 - 0s - loss: 3099.1816 - mse: 3099.1816\n",
      "Epoch 84/150\n",
      "72/72 - 0s - loss: 3095.8599 - mse: 3095.8599\n",
      "Epoch 85/150\n",
      "72/72 - 0s - loss: 3076.6294 - mse: 3076.6294\n",
      "Epoch 86/150\n",
      "72/72 - 0s - loss: 3081.2471 - mse: 3081.2471\n",
      "Epoch 87/150\n",
      "72/72 - 0s - loss: 3092.4866 - mse: 3092.4866\n",
      "Epoch 88/150\n",
      "72/72 - 0s - loss: 3077.2959 - mse: 3077.2959\n",
      "Epoch 89/150\n",
      "72/72 - 0s - loss: 3082.4187 - mse: 3082.4187\n",
      "Epoch 90/150\n",
      "72/72 - 0s - loss: 3083.7898 - mse: 3083.7898\n",
      "Epoch 91/150\n",
      "72/72 - 0s - loss: 3067.4893 - mse: 3067.4893\n",
      "Epoch 92/150\n",
      "72/72 - 0s - loss: 3081.7373 - mse: 3081.7373\n",
      "Epoch 93/150\n",
      "72/72 - 0s - loss: 3068.2803 - mse: 3068.2803\n",
      "Epoch 94/150\n",
      "72/72 - 0s - loss: 3056.5352 - mse: 3056.5352\n",
      "Epoch 95/150\n",
      "72/72 - 0s - loss: 3069.8193 - mse: 3069.8193\n",
      "Epoch 96/150\n",
      "72/72 - 0s - loss: 3066.4153 - mse: 3066.4153\n",
      "Epoch 97/150\n",
      "72/72 - 0s - loss: 3064.9014 - mse: 3064.9014\n",
      "Epoch 98/150\n",
      "72/72 - 0s - loss: 3049.6245 - mse: 3049.6245\n",
      "Epoch 99/150\n",
      "72/72 - 0s - loss: 3050.4370 - mse: 3050.4370\n",
      "Epoch 100/150\n",
      "72/72 - 0s - loss: 3044.3430 - mse: 3044.3430\n",
      "Epoch 101/150\n",
      "72/72 - 0s - loss: 3047.2217 - mse: 3047.2217\n",
      "Epoch 102/150\n",
      "72/72 - 0s - loss: 3024.4688 - mse: 3024.4688\n",
      "Epoch 103/150\n",
      "72/72 - 0s - loss: 3035.9492 - mse: 3035.9492\n",
      "Epoch 104/150\n",
      "72/72 - 0s - loss: 3028.5728 - mse: 3028.5728\n",
      "Epoch 105/150\n",
      "72/72 - 0s - loss: 3038.4817 - mse: 3038.4817\n",
      "Epoch 106/150\n",
      "72/72 - 0s - loss: 3031.2317 - mse: 3031.2317\n",
      "Epoch 107/150\n",
      "72/72 - 0s - loss: 3036.5342 - mse: 3036.5342\n",
      "Epoch 108/150\n",
      "72/72 - 0s - loss: 3026.3369 - mse: 3026.3369\n",
      "Epoch 109/150\n",
      "72/72 - 0s - loss: 3016.5842 - mse: 3016.5842\n",
      "Epoch 110/150\n",
      "72/72 - 0s - loss: 3016.5413 - mse: 3016.5413\n",
      "Epoch 111/150\n",
      "72/72 - 0s - loss: 3011.0100 - mse: 3011.0100\n",
      "Epoch 112/150\n",
      "72/72 - 0s - loss: 3011.6143 - mse: 3011.6143\n",
      "Epoch 113/150\n",
      "72/72 - 0s - loss: 3010.4702 - mse: 3010.4702\n",
      "Epoch 114/150\n",
      "72/72 - 0s - loss: 2999.8599 - mse: 2999.8599\n",
      "Epoch 115/150\n",
      "72/72 - 0s - loss: 3004.2280 - mse: 3004.2280\n",
      "Epoch 116/150\n",
      "72/72 - 0s - loss: 2993.3660 - mse: 2993.3660\n",
      "Epoch 117/150\n",
      "72/72 - 0s - loss: 2995.0522 - mse: 2995.0522\n",
      "Epoch 118/150\n",
      "72/72 - 0s - loss: 2989.5864 - mse: 2989.5864\n",
      "Epoch 119/150\n",
      "72/72 - 0s - loss: 2998.1665 - mse: 2998.1665\n",
      "Epoch 120/150\n",
      "72/72 - 0s - loss: 2993.9443 - mse: 2993.9443\n",
      "Epoch 121/150\n",
      "72/72 - 0s - loss: 2987.5759 - mse: 2987.5759\n",
      "Epoch 122/150\n",
      "72/72 - 0s - loss: 2977.9253 - mse: 2977.9253\n",
      "Epoch 123/150\n",
      "72/72 - 0s - loss: 2989.2163 - mse: 2989.2163\n",
      "Epoch 124/150\n",
      "72/72 - 0s - loss: 2970.9500 - mse: 2970.9500\n",
      "Epoch 125/150\n",
      "72/72 - 0s - loss: 2961.9541 - mse: 2961.9541\n",
      "Epoch 126/150\n",
      "72/72 - 0s - loss: 2965.8279 - mse: 2965.8279\n",
      "Epoch 127/150\n",
      "72/72 - 0s - loss: 2963.4604 - mse: 2963.4604\n",
      "Epoch 128/150\n",
      "72/72 - 0s - loss: 2962.1592 - mse: 2962.1592\n",
      "Epoch 129/150\n",
      "72/72 - 0s - loss: 2964.0718 - mse: 2964.0718\n",
      "Epoch 130/150\n",
      "72/72 - 0s - loss: 2949.2429 - mse: 2949.2429\n",
      "Epoch 131/150\n",
      "72/72 - 0s - loss: 2954.4517 - mse: 2954.4517\n",
      "Epoch 132/150\n",
      "72/72 - 0s - loss: 2949.9138 - mse: 2949.9138\n",
      "Epoch 133/150\n",
      "72/72 - 0s - loss: 2942.1101 - mse: 2942.1101\n",
      "Epoch 134/150\n",
      "72/72 - 0s - loss: 2930.0415 - mse: 2930.0415\n",
      "Epoch 135/150\n",
      "72/72 - 0s - loss: 2943.1514 - mse: 2943.1514\n",
      "Epoch 136/150\n",
      "72/72 - 0s - loss: 2934.1729 - mse: 2934.1729\n",
      "Epoch 137/150\n",
      "72/72 - 0s - loss: 2928.3931 - mse: 2928.3931\n",
      "Epoch 138/150\n",
      "72/72 - 0s - loss: 2916.6135 - mse: 2916.6135\n",
      "Epoch 139/150\n",
      "72/72 - 0s - loss: 2922.2576 - mse: 2922.2576\n",
      "Epoch 140/150\n",
      "72/72 - 0s - loss: 2921.1914 - mse: 2921.1914\n",
      "Epoch 141/150\n",
      "72/72 - 0s - loss: 2916.9236 - mse: 2916.9236\n",
      "Epoch 142/150\n",
      "72/72 - 0s - loss: 2922.1587 - mse: 2922.1587\n",
      "Epoch 143/150\n",
      "72/72 - 0s - loss: 2900.3586 - mse: 2900.3586\n",
      "Epoch 144/150\n",
      "72/72 - 0s - loss: 2901.9307 - mse: 2901.9307\n",
      "Epoch 145/150\n",
      "72/72 - 0s - loss: 2896.4539 - mse: 2896.4539\n",
      "Epoch 146/150\n",
      "72/72 - 0s - loss: 2897.3372 - mse: 2897.3372\n",
      "Epoch 147/150\n",
      "72/72 - 0s - loss: 2892.3906 - mse: 2892.3906\n",
      "Epoch 148/150\n",
      "72/72 - 0s - loss: 2868.2024 - mse: 2868.2024\n",
      "Epoch 149/150\n",
      "72/72 - 0s - loss: 2887.3352 - mse: 2887.3352\n",
      "Epoch 150/150\n",
      "72/72 - 0s - loss: 2885.8484 - mse: 2885.8484\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 10358.7793 - mse: 10358.7793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10358.779296875, 10358.779296875]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=150, batch_size=4, verbose=2)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,441\n",
      "Trainable params: 1,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set prediction accuracy: 11.46 %\n",
      "test set prediction accuracy: 8.33 %\n"
     ]
    }
   ],
   "source": [
    "#평균 성능 테스트\n",
    "scores = 0\n",
    "mean=np.mean(Y, axis=0)\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= mean <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"train set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= mean <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"test set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### <오차범위 3>\n",
      "- train set prediction accuracy(+-3): 6.25 % <br>\n",
      "- test set prediction accuracy(+-3): 8.33 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 5>\n",
      "- train set prediction accuracy(+-5): 11.81 % <br>\n",
      "- test set prediction accuracy(+-5): 15.28 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 10>\n",
      "- train set prediction accuracy(+-10): 23.96 % <br>\n",
      "- test set prediction accuracy(+-10): 29.17 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 20>\n",
      "- train set prediction accuracy(+-20): 45.49 % <br>\n",
      "- test set prediction accuracy(+-20): 45.83 % <br>\n"
     ]
    }
   ],
   "source": [
    "######입력용#######\n",
    "\n",
    "#오차 범위 3 설정\n",
    "print('### <오차범위 3>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "print('### <오차범위 5>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "print('### <오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "print('### <오차범위 20>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다쓴거\n",
    "### <오차범위 3>\n",
    "- train_all set prediction accuracy(+-3): 88.89 % <br>\n",
    "- test_all set prediction accuracy(+-3): 31.94 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 5>\n",
    "- train_all set prediction accuracy(+-5): 96.53 % <br>\n",
    "- test_all set prediction accuracy(+-5): 55.56 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 10>\n",
    "- train_all set prediction accuracy(+-10): 100.00 % <br>\n",
    "- test_all set prediction accuracy(+-10): 83.33 % <br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다안쓴거\n",
    "### <오차범위 3>\n",
    "- train_some set prediction accuracy(+-3): 32.99 % <br>\n",
    "- test_some set prediction accuracy(+-3): 27.78 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 5>\n",
    "- train_some set prediction accuracy(+-5): 54.86 % <br>\n",
    "- test_some set prediction accuracy(+-5): 40.28 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 10>\n",
    "- train_some set prediction accuracy(+-10): 82.29 % <br>\n",
    "- test_some set prediction accuracy(+-10): 59.72 % <br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONT 깨질때 폰트깨질때\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname = \"C:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font',family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sample_ID GROUP  COHORT SEX  AGE     Trait FitbitOX      Fitbit_ID  HTN  \\\n",
      "0         S0001   SMI       2   M   60  fitbit_O        O  sevrance00001  NaN   \n",
      "1         S0002   SMI       2   M   61  fitbit_O        O  sevrance00002  NaN   \n",
      "2         S0003   SMI       2   F   52  fitbit_O        O  sevrance00003  NaN   \n",
      "3         S0004   SMI       2   F   41  fitbit_O        O  sevrance00004  NaN   \n",
      "4         S0005   SMI       2   F   41  fitbit_O        O  sevrance00005  NaN   \n",
      "..          ...   ...     ...  ..  ...       ...      ...            ...  ...   \n",
      "383  MetS_S0280  MetS       1   F   24  fitbit_O        O   gnfmmets+139  NaN   \n",
      "384  MetS_S0281  MetS       1   F   44  fitbit_O        O   gnfmmets+140  NaN   \n",
      "385  MetS_S0282  MetS       1   F   37  fitbit_O        O   gnfmmets+141  1.0   \n",
      "386  MetS_S0283  MetS       1   M   51  fitbit_X        X              X  NaN   \n",
      "387  MetS_S0284  MetS       1   F   42  fitbit_X        X              X  NaN   \n",
      "\n",
      "      DM  ...  BDI_Q13_2 BDI_Q14_2  BDI_Q15_2  BDI_Q16_2 BDI_Q17_2 BDI_Q18_2  \\\n",
      "0    NaN  ...        1.0       1.0        1.0        2.0       1.0       1.0   \n",
      "1    1.0  ...        1.0       1.0        1.0        1.0       2.0       1.0   \n",
      "2    NaN  ...        1.0       1.0        1.0        1.0       1.0       1.0   \n",
      "3    NaN  ...        2.0       2.0        2.0        2.0       2.0       2.0   \n",
      "4    NaN  ...        2.0       1.0        2.0        2.0       2.0       1.0   \n",
      "..   ...  ...        ...       ...        ...        ...       ...       ...   \n",
      "383  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "384  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "385  1.0  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "386  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "387  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "\n",
      "     BDI_Q19_2  BDI_Q20_2  BDI_Q21_2  Diet_2  \n",
      "0          2.0        1.0        2.0     2.0  \n",
      "1          1.0        1.0        1.0     2.0  \n",
      "2          1.0        2.0        4.0     1.0  \n",
      "3          1.0        1.0        1.0     2.0  \n",
      "4          1.0        2.0        1.0     2.0  \n",
      "..         ...        ...        ...     ...  \n",
      "383        NaN        NaN        NaN     NaN  \n",
      "384        NaN        NaN        NaN     NaN  \n",
      "385        NaN        NaN        NaN     NaN  \n",
      "386        NaN        NaN        NaN     NaN  \n",
      "387        NaN        NaN        NaN     NaN  \n",
      "\n",
      "[388 rows x 3527 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('./최종 데이터 그래프그리기용.xlsx') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df=df[['Sample_ID','GROUP','COHORT','SEX','AGE','Insulin _1','FatPercentage _1','TG_1','BMI_1','AST_1','BUN_1','HDL_1','DBP_1','Waist_1','SBP_1','Fat_1_x','LDL_1',\n",
    "            'PSQI_TOTAL_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1',\n",
    "              'Insulin _2','FatPercentage_2','TG_2','BMI_2','AST_2','BUN_2','HDL_2','DBP_2','Waist_2','SBP_2','Fat_2_x','LDL_2',\n",
    "            'PSQI_TOTAL_2','PSQI_C1_2','PSQI_C2_2','PSQI_C3_2','PSQI_C4_2','PSQI_C5_2','PSQI_C6_2','PSQI_C7_2','PSQI_Q1_2','PSQI_Q2_2','PSQI_Q3_2','PSQI_Q4_2',\n",
    "            'PSQI_Q5a_2','PSQI_Q5b_2','PSQI_Q5c_2','PSQI_Q5d_2','PSQI_Q5e_2','PSQI_Q5f_2','PSQI_Q5g_2','PSQI_Q5h_2','PSQI_Q5i_2','PSQI_Q5j_2','PSQI_Q6_2','PSQI_Q7_2','PSQI_Q8_2','PSQI_Q9_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>FatPercentage _1</th>\n",
       "      <th>TG_1</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>AST_1</th>\n",
       "      <th>...</th>\n",
       "      <th>PSQI_Q5e_2</th>\n",
       "      <th>PSQI_Q5f_2</th>\n",
       "      <th>PSQI_Q5g_2</th>\n",
       "      <th>PSQI_Q5h_2</th>\n",
       "      <th>PSQI_Q5i_2</th>\n",
       "      <th>PSQI_Q5j_2</th>\n",
       "      <th>PSQI_Q6_2</th>\n",
       "      <th>PSQI_Q7_2</th>\n",
       "      <th>PSQI_Q8_2</th>\n",
       "      <th>PSQI_Q9_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>60</td>\n",
       "      <td>7.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>81</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>61</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.5</td>\n",
       "      <td>106</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>5.1</td>\n",
       "      <td>39.1</td>\n",
       "      <td>231</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>4.2</td>\n",
       "      <td>29.1</td>\n",
       "      <td>94</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>3.2</td>\n",
       "      <td>24.6</td>\n",
       "      <td>70</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>24</td>\n",
       "      <td>11.3</td>\n",
       "      <td>34.4</td>\n",
       "      <td>51</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>44</td>\n",
       "      <td>10.6</td>\n",
       "      <td>43.8</td>\n",
       "      <td>104</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>12.2</td>\n",
       "      <td>35.8</td>\n",
       "      <td>128</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>10.4</td>\n",
       "      <td>26.8</td>\n",
       "      <td>163</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>42</td>\n",
       "      <td>10.1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>90</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT SEX  AGE Insulin _1  FatPercentage _1  TG_1  \\\n",
       "0         S0001   SMI       2   M   60        7.7              15.0    81   \n",
       "1         S0002   SMI       2   M   61        5.4              29.5   106   \n",
       "2         S0003   SMI       2   F   52        5.1              39.1   231   \n",
       "3         S0004   SMI       2   F   41        4.2              29.1    94   \n",
       "4         S0005   SMI       2   F   41        3.2              24.6    70   \n",
       "..          ...   ...     ...  ..  ...        ...               ...   ...   \n",
       "383  MetS_S0280  MetS       1   F   24       11.3              34.4    51   \n",
       "384  MetS_S0281  MetS       1   F   44       10.6              43.8   104   \n",
       "385  MetS_S0282  MetS       1   F   37       12.2              35.8   128   \n",
       "386  MetS_S0283  MetS       1   M   51       10.4              26.8   163   \n",
       "387  MetS_S0284  MetS       1   F   42       10.1              32.6    90   \n",
       "\n",
       "         BMI_1  AST_1  ...  PSQI_Q5e_2  PSQI_Q5f_2  PSQI_Q5g_2  PSQI_Q5h_2  \\\n",
       "0    21.110190   21.0  ...         0.0         0.0         0.0         1.0   \n",
       "1    27.782064   29.0  ...         3.0         0.0         2.0         0.0   \n",
       "2    24.944742   16.0  ...         3.0         0.0         3.0         0.0   \n",
       "3    22.620489   16.0  ...         1.0         0.0         0.0         0.0   \n",
       "4    20.524157   26.0  ...         0.0         0.0         0.0         1.0   \n",
       "..         ...    ...  ...         ...         ...         ...         ...   \n",
       "383  34.803410   14.0  ...         NaN         NaN         NaN         NaN   \n",
       "384  30.903615   27.0  ...         NaN         NaN         NaN         NaN   \n",
       "385  28.676533   61.0  ...         NaN         NaN         NaN         NaN   \n",
       "386  24.549738   81.0  ...         NaN         NaN         NaN         NaN   \n",
       "387  24.605921   32.0  ...         NaN         NaN         NaN         NaN   \n",
       "\n",
       "     PSQI_Q5i_2  PSQI_Q5j_2  PSQI_Q6_2  PSQI_Q7_2  PSQI_Q8_2  PSQI_Q9_2  \n",
       "0           0.0         0.0        1.0        0.0        1.0        0.0  \n",
       "1           0.0         0.0        1.0        0.0        2.0        1.0  \n",
       "2           0.0         0.0        1.0        0.0        2.0        0.0  \n",
       "3           0.0         0.0        1.0        0.0        2.0        1.0  \n",
       "4           1.0         1.0        3.0        0.0        2.0        1.0  \n",
       "..          ...         ...        ...        ...        ...        ...  \n",
       "383         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "384         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "385         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "386         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "387         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "\n",
       "[388 rows x 81 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>FatPercentage _1</th>\n",
       "      <th>TG_1</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>AST_1</th>\n",
       "      <th>...</th>\n",
       "      <th>PSQI_Q5e_2</th>\n",
       "      <th>PSQI_Q5f_2</th>\n",
       "      <th>PSQI_Q5g_2</th>\n",
       "      <th>PSQI_Q5h_2</th>\n",
       "      <th>PSQI_Q5i_2</th>\n",
       "      <th>PSQI_Q5j_2</th>\n",
       "      <th>PSQI_Q6_2</th>\n",
       "      <th>PSQI_Q7_2</th>\n",
       "      <th>PSQI_Q8_2</th>\n",
       "      <th>PSQI_Q9_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>60</td>\n",
       "      <td>7.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>81</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>61</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.5</td>\n",
       "      <td>106</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>5.1</td>\n",
       "      <td>39.1</td>\n",
       "      <td>231</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>4.2</td>\n",
       "      <td>29.1</td>\n",
       "      <td>94</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>3.2</td>\n",
       "      <td>24.6</td>\n",
       "      <td>70</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>24</td>\n",
       "      <td>11.3</td>\n",
       "      <td>34.4</td>\n",
       "      <td>51</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>44</td>\n",
       "      <td>10.6</td>\n",
       "      <td>43.8</td>\n",
       "      <td>104</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>12.2</td>\n",
       "      <td>35.8</td>\n",
       "      <td>128</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>10.4</td>\n",
       "      <td>26.8</td>\n",
       "      <td>163</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>42</td>\n",
       "      <td>10.1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>90</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT SEX  AGE Insulin _1  FatPercentage _1  TG_1  \\\n",
       "0         S0001   SMI       2   M   60        7.7              15.0    81   \n",
       "1         S0002   SMI       2   M   61        5.4              29.5   106   \n",
       "2         S0003   SMI       2   F   52        5.1              39.1   231   \n",
       "3         S0004   SMI       2   F   41        4.2              29.1    94   \n",
       "4         S0005   SMI       2   F   41        3.2              24.6    70   \n",
       "..          ...   ...     ...  ..  ...        ...               ...   ...   \n",
       "383  MetS_S0280  MetS       1   F   24       11.3              34.4    51   \n",
       "384  MetS_S0281  MetS       1   F   44       10.6              43.8   104   \n",
       "385  MetS_S0282  MetS       1   F   37       12.2              35.8   128   \n",
       "386  MetS_S0283  MetS       1   M   51       10.4              26.8   163   \n",
       "387  MetS_S0284  MetS       1   F   42       10.1              32.6    90   \n",
       "\n",
       "         BMI_1  AST_1  ...  PSQI_Q5e_2  PSQI_Q5f_2  PSQI_Q5g_2  PSQI_Q5h_2  \\\n",
       "0    21.110190   21.0  ...         0.0         0.0         0.0         1.0   \n",
       "1    27.782064   29.0  ...         3.0         0.0         2.0         0.0   \n",
       "2    24.944742   16.0  ...         3.0         0.0         3.0         0.0   \n",
       "3    22.620489   16.0  ...         1.0         0.0         0.0         0.0   \n",
       "4    20.524157   26.0  ...         0.0         0.0         0.0         1.0   \n",
       "..         ...    ...  ...         ...         ...         ...         ...   \n",
       "383  34.803410   14.0  ...         NaN         NaN         NaN         NaN   \n",
       "384  30.903615   27.0  ...         NaN         NaN         NaN         NaN   \n",
       "385  28.676533   61.0  ...         NaN         NaN         NaN         NaN   \n",
       "386  24.549738   81.0  ...         NaN         NaN         NaN         NaN   \n",
       "387  24.605921   32.0  ...         NaN         NaN         NaN         NaN   \n",
       "\n",
       "     PSQI_Q5i_2  PSQI_Q5j_2  PSQI_Q6_2  PSQI_Q7_2  PSQI_Q8_2  PSQI_Q9_2  \n",
       "0           0.0         0.0        1.0        0.0        1.0        0.0  \n",
       "1           0.0         0.0        1.0        0.0        2.0        1.0  \n",
       "2           0.0         0.0        1.0        0.0        2.0        0.0  \n",
       "3           0.0         0.0        1.0        0.0        2.0        1.0  \n",
       "4           1.0         1.0        3.0        0.0        2.0        1.0  \n",
       "..          ...         ...        ...        ...        ...        ...  \n",
       "383         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "384         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "385         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "386         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "387         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "\n",
       "[317 rows x 81 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#보조 호르몬 요법을 받고 있는 Cohort 3 제거 Filter 적용\n",
    "psqi_df = psqi_df[(psqi_df['COHORT'] != 3)]\n",
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df=psqi_df.dropna()\n",
    "psqi_df.reset_index(drop=True, inplace=True)\n",
    "psqi_df.isnull().sum()\n",
    "psqi_df=psqi_df.drop([\"Sample_ID\", \"GROUP\", \"COHORT\"],axis=1)\n",
    "#1분, 매일다름, 정해진간이없음 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"SEX\"] = psqi_df[\"SEX\"].apply(lambda x: 1. if x=='M' else 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"Insulin _1\"] = psqi_df[\"Insulin _1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)\n",
    "psqi_df[\"Insulin _2\"] = psqi_df[\"Insulin _1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (x=임의+선별)\n",
    "#선별: 'AGE','HDL_1','DBP_1','Waist_1','SBP_1','Fat_1_x','Insulin _1','FatPercentage _1','LDL_1','AST_1','BUN_1'\n",
    "X1=psqi_df[['AGE','HDL_1','DBP_1','Waist_1','SBP_1','Fat_1_x','Insulin _1','FatPercentage _1','AST_1','BUN_1','BMI_1','TG_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','HDL_2','DBP_2','Waist_2','SBP_2','Fat_2_x','Insulin _2','FatPercentage_2','AST_2','BUN_2','BMI_2','TG_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=LDL)\n",
    "Y1= psqi_df[['LDL_1']].values\n",
    "Y2= psqi_df[['LDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (x=임의+선별+PSQI)\n",
    "X1=psqi_df[['AGE','HDL_1','DBP_1','Waist_1','Insulin _1','SBP_1','Fat_1_x','TG_1','FatPercentage _1','AST_1','BUN_1','BMI_1',\n",
    "            'PSQI_TOTAL_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','HDL_2','DBP_2','Waist_2','Insulin _2','SBP_2','Fat_2_x','TG_2','FatPercentage_2','AST_2','BUN_2','BMI_2',\n",
    "            'PSQI_TOTAL_2','PSQI_C1_2','PSQI_C2_2','PSQI_C3_2','PSQI_C4_2','PSQI_C5_2','PSQI_C6_2','PSQI_C7_2','PSQI_Q1_2','PSQI_Q2_2','PSQI_Q3_2','PSQI_Q4_2',\n",
    "            'PSQI_Q5a_2','PSQI_Q5b_2','PSQI_Q5c_2','PSQI_Q5d_2','PSQI_Q5e_2','PSQI_Q5f_2','PSQI_Q5g_2','PSQI_Q5h_2','PSQI_Q5i_2','PSQI_Q5j_2','PSQI_Q6_2','PSQI_Q7_2','PSQI_Q8_2','PSQI_Q9_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=LDL)\n",
    "Y1= psqi_df[['LDL_1']].values\n",
    "Y2= psqi_df[['LDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (x=AGE, SEX, PSQI, BMI, Waist, Fat, FatPercentage)\n",
    "X1=psqi_df[['AGE','SEX','BMI_1','Waist_1','Fat_1_x','FatPercentage _1',\n",
    "           'PSQI_TOTAL_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','SEX','BMI_2','Waist_2','Fat_2_x','FatPercentage_2',\n",
    "           'PSQI_TOTAL_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=LDL)\n",
    "Y1= psqi_df[['LDL_1']].values\n",
    "Y2= psqi_df[['LDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 352)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((352, 38), (352, 1))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((352, 38), (352, 1))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 798us/step - loss: 12294.4111 - mse: 12294.4111\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 791us/step - loss: 10860.0635 - mse: 10860.0635\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 712us/step - loss: 8422.3945 - mse: 8422.3945\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 779us/step - loss: 5273.6602 - mse: 5273.6602\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 926us/step - loss: 2625.2200 - mse: 2625.2200\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 811us/step - loss: 1607.0482 - mse: 1607.0482\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 741us/step - loss: 1375.7628 - mse: 1375.7628\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 883us/step - loss: 1256.1666 - mse: 1256.1666\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 714us/step - loss: 1166.6475 - mse: 1166.6475\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 629us/step - loss: 1081.2629 - mse: 1081.2629\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 784us/step - loss: 1022.3355 - mse: 1022.3355\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 784us/step - loss: 965.3536 - mse: 965.3536\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 712us/step - loss: 919.7787 - mse: 919.7787\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 670us/step - loss: 882.4630 - mse: 882.4630\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 865us/step - loss: 850.1927 - mse: 850.1927\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 812us/step - loss: 821.0316 - mse: 821.0316\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 698us/step - loss: 785.2972 - mse: 785.2972\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 641us/step - loss: 768.1952 - mse: 768.1952\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 707us/step - loss: 746.2256 - mse: 746.2256\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 765us/step - loss: 728.1234 - mse: 728.1234\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 754us/step - loss: 710.9222 - mse: 710.9222\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 784us/step - loss: 690.5217 - mse: 690.5217\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 784us/step - loss: 677.4346 - mse: 677.4346\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 877us/step - loss: 668.1254 - mse: 668.1254\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 846us/step - loss: 651.2497 - mse: 651.2497\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 955us/step - loss: 634.7291 - mse: 634.7291\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 959us/step - loss: 616.5877 - mse: 616.5877\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 941us/step - loss: 612.9346 - mse: 612.9346\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 917us/step - loss: 597.8030 - mse: 597.8030\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 978us/step - loss: 591.9822 - mse: 591.9822\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 957us/step - loss: 581.2871 - mse: 581.2871\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 997us/step - loss: 566.5678 - mse: 566.5678\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 565.5335 - mse: 565.5335\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 977us/step - loss: 554.4507 - mse: 554.4507\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 997us/step - loss: 544.4524 - mse: 544.4524\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 532.4043 - mse: 532.4043\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 525.7024 - mse: 525.7024\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 998us/step - loss: 513.8459 - mse: 513.8459\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 960us/step - loss: 507.2623 - mse: 507.2623\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 500.9859 - mse: 500.9859\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 998us/step - loss: 491.6373 - mse: 491.6373\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 490.1193 - mse: 490.1193\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 486.1370 - mse: 486.1370\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 470.2424 - mse: 470.2424\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 474.9394 - mse: 474.9394\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 470.4710 - mse: 470.4710\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 462.3474 - mse: 462.3474\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 451.0417 - mse: 451.0417\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 997us/step - loss: 446.4667 - mse: 446.4667\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 445.6193 - mse: 445.6193\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 439.2757 - mse: 439.2757\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 430.1476 - mse: 430.1476\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 430.1315 - mse: 430.1315\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 425.5028 - mse: 425.5028\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 420.4902 - mse: 420.4902\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 414.7331 - mse: 414.7331\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 404.9114 - mse: 404.9114\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 998us/step - loss: 399.5102 - mse: 399.5102\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 402.8322 - mse: 402.8322\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 397.9307 - mse: 397.9307\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 389.8135 - mse: 389.8135\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 385.1953 - mse: 385.1953\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 389.0242 - mse: 389.0242\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 381.1094 - mse: 381.1094\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 368.2466 - mse: 368.2466\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 377.2101 - mse: 377.2101\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 362.8986 - mse: 362.8986\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 365.9714 - mse: 365.9714\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 353.8189 - mse: 353.8189\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 352.5683 - mse: 352.5683\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 347.5487 - mse: 347.5487\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 349.5452 - mse: 349.5452\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 342.6228 - mse: 342.6228\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 335.6152 - mse: 335.6152\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 340.5981 - mse: 340.5981\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 334.9276 - mse: 334.9276\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 330.3319 - mse: 330.3319\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 323.4822 - mse: 323.4822\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 323.3761 - mse: 323.3761\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 309.5813 - mse: 309.5813\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 325.2430 - mse: 325.2430\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 315.4689 - mse: 315.4689\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 310.8064 - mse: 310.8064\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 310.5591 - mse: 310.5591\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 301.9349 - mse: 301.9349\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 298.9118 - mse: 298.9118\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 295.3591 - mse: 295.3591\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 298.2444 - mse: 298.2444\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 288.4015 - mse: 288.4015\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 283.8655 - mse: 283.8655\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 282.2017 - mse: 282.2017\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 281.9333 - mse: 281.9333\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 277.0666 - mse: 277.0666 0s - loss: 218.2330 - mse: 218.233\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 280.9782 - mse: 280.9782\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 273.8462 - mse: 273.8462\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 272.6691 - mse: 272.6691\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 264.4022 - mse: 264.4022\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 261.8867 - mse: 261.8867\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 260.0706 - mse: 260.0706\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 253.3232 - mse: 253.3232\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 978.8572 - mse: 978.8572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[978.857177734375, 978.857177734375]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=100, batch_size=4)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 32)                1248      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,337\n",
      "Trainable params: 2,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85.] [83.61638]\n",
      "[83.] [79.038]\n",
      "[99.] [93.968864]\n",
      "[124.] [126.64356]\n",
      "[78.] [103.588844]\n",
      "[72.] [90.75785]\n",
      "[100.] [105.209785]\n",
      "[126.] [129.29279]\n",
      "[56.] [97.08538]\n",
      "[95.] [95.36916]\n",
      "[87.] [92.64941]\n",
      "[121.] [116.812454]\n",
      "[108.] [101.15858]\n",
      "[104.] [113.24918]\n",
      "[123.] [129.1494]\n",
      "[92.] [101.029816]\n",
      "[132.] [125.96317]\n",
      "[113.] [117.22849]\n",
      "[69.] [79.215546]\n",
      "[78.] [105.58965]\n",
      "[160.] [148.26863]\n",
      "[102.] [105.652374]\n",
      "[296.] [186.04883]\n",
      "[165.] [136.60667]\n",
      "[89.] [91.51185]\n",
      "[77.] [87.64111]\n",
      "[89.] [92.02411]\n",
      "[122.] [107.94306]\n",
      "[112.] [117.96844]\n",
      "[93.] [96.91661]\n",
      "[113.] [121.05526]\n",
      "[49.] [52.2534]\n",
      "[118.] [128.83585]\n",
      "[123.] [109.70064]\n",
      "[125.] [122.87744]\n",
      "[95.] [95.08866]\n",
      "[121.] [134.13828]\n",
      "[130.] [134.14108]\n",
      "[78.] [89.1323]\n",
      "[97.] [102.025856]\n",
      "[132.] [119.16329]\n",
      "[57.] [76.92338]\n",
      "[115.] [119.44145]\n",
      "[92.] [96.44747]\n",
      "[115.] [120.5183]\n",
      "[127.] [127.80203]\n",
      "[110.] [98.374916]\n",
      "[90.] [91.01672]\n",
      "[83.] [82.877495]\n",
      "[111.] [86.29777]\n",
      "[101.] [104.07835]\n",
      "[151.] [166.81839]\n",
      "[128.] [127.12895]\n",
      "[105.] [109.00897]\n",
      "[87.] [98.43642]\n",
      "[100.] [88.50537]\n",
      "[97.] [110.00319]\n",
      "[121.] [126.191216]\n",
      "[89.] [94.593796]\n",
      "[80.] [78.304756]\n",
      "[149.] [136.02536]\n",
      "[63.] [96.6077]\n",
      "[87.] [80.7111]\n",
      "[101.] [104.6121]\n",
      "[92.] [92.33695]\n",
      "[132.] [121.08992]\n",
      "[98.] [108.08843]\n",
      "[97.] [121.51455]\n",
      "[64.] [82.06086]\n",
      "[138.] [136.06284]\n",
      "[137.] [125.872215]\n",
      "[111.] [104.067726]\n",
      "[112.] [113.5998]\n",
      "[174.] [161.11307]\n",
      "[147.] [125.040665]\n",
      "[122.] [118.32663]\n",
      "[104.] [112.54292]\n",
      "[96.] [100.28593]\n",
      "[65.] [78.59998]\n",
      "[114.] [122.64616]\n",
      "[92.] [89.34277]\n",
      "[82.] [84.09887]\n",
      "[121.] [125.162415]\n",
      "[91.] [85.03561]\n",
      "[102.] [105.353165]\n",
      "[94.] [112.63076]\n",
      "[144.] [145.15149]\n",
      "[111.] [114.84977]\n",
      "[201.] [187.50272]\n",
      "[132.] [133.96663]\n",
      "[151.] [142.97507]\n",
      "[128.] [121.03578]\n",
      "[77.] [91.715096]\n",
      "[104.] [102.61942]\n",
      "[78.] [83.023994]\n",
      "[119.] [128.11774]\n",
      "[115.] [117.26232]\n",
      "[96.] [115.88126]\n",
      "[136.] [127.37141]\n",
      "[90.] [97.13673]\n",
      "[152.] [161.2969]\n",
      "[109.] [100.09527]\n",
      "[126.] [118.13013]\n",
      "[80.] [94.495]\n",
      "[66.] [74.55967]\n",
      "[92.] [105.69612]\n",
      "[158.] [139.14839]\n",
      "[134.] [134.42479]\n",
      "[131.] [131.76468]\n",
      "[102.] [90.87988]\n",
      "[126.] [134.48265]\n",
      "[115.] [124.16851]\n",
      "[119.] [119.99152]\n",
      "[128.] [130.30803]\n",
      "[190.] [174.37839]\n",
      "[78.] [76.50927]\n",
      "[123.] [129.14017]\n",
      "[107.] [107.83698]\n",
      "[102.] [111.18818]\n",
      "[133.] [88.4601]\n",
      "[130.] [133.88913]\n",
      "[91.] [106.82923]\n",
      "[76.] [89.570366]\n",
      "[101.] [103.68074]\n",
      "[122.] [126.34407]\n",
      "[102.] [87.999596]\n",
      "[98.] [105.22619]\n",
      "[127.] [120.161705]\n",
      "[121.] [121.42887]\n",
      "[169.] [164.25586]\n",
      "[47.] [52.8811]\n",
      "[77.] [82.834175]\n",
      "[106.] [116.58862]\n",
      "[66.] [78.52238]\n",
      "[77.] [88.84835]\n",
      "[121.] [133.27357]\n",
      "[79.] [96.53241]\n",
      "[80.] [87.544044]\n",
      "[92.] [113.620964]\n",
      "[103.] [115.90723]\n",
      "[94.] [103.65324]\n",
      "[138.] [146.4454]\n",
      "[103.] [87.63131]\n",
      "[123.] [127.76605]\n",
      "[166.] [128.93787]\n",
      "[131.] [143.05147]\n",
      "[92.] [84.398476]\n",
      "[133.] [132.55911]\n",
      "[69.] [103.7136]\n",
      "[72.] [75.49306]\n",
      "[88.] [97.043846]\n",
      "[102.] [106.49708]\n",
      "[185.] [131.8797]\n",
      "[114.] [122.353264]\n",
      "[138.] [130.93169]\n",
      "[105.] [120.40832]\n",
      "[93.] [92.6051]\n",
      "[73.] [161.56845]\n",
      "[129.] [109.86227]\n",
      "[148.] [154.73674]\n",
      "[82.] [114.009445]\n",
      "[96.] [110.24523]\n",
      "[106.] [111.369095]\n",
      "[73.] [73.88034]\n",
      "[123.] [119.366394]\n",
      "[95.] [104.944466]\n",
      "[108.] [107.50235]\n",
      "[110.] [114.77613]\n",
      "[106.] [115.348366]\n",
      "[143.] [118.34941]\n",
      "[116.] [128.97859]\n",
      "[95.] [102.9463]\n",
      "[61.] [101.041756]\n",
      "[94.] [85.98433]\n",
      "[52.] [81.469894]\n",
      "[176.] [141.84529]\n",
      "[114.] [117.62227]\n",
      "[109.] [94.12285]\n",
      "[124.] [124.268196]\n",
      "[144.] [133.26385]\n",
      "[91.] [81.20539]\n",
      "[146.] [149.88045]\n",
      "[89.] [89.44863]\n",
      "[82.] [78.88795]\n",
      "[105.] [95.18795]\n",
      "[107.] [104.593124]\n",
      "[118.] [113.9461]\n",
      "[91.] [95.186356]\n",
      "[161.] [169.73196]\n",
      "[120.] [117.31339]\n",
      "[63.] [83.34338]\n",
      "[159.] [121.92307]\n",
      "[96.] [88.45223]\n",
      "[122.] [131.35088]\n",
      "[106.] [106.944496]\n",
      "[133.] [130.29984]\n",
      "[122.] [111.07079]\n",
      "[137.] [130.35855]\n",
      "[106.] [118.89994]\n",
      "[106.] [107.63591]\n",
      "[127.] [132.00537]\n",
      "[106.] [97.76815]\n",
      "[100.] [94.198166]\n",
      "[131.] [120.69036]\n",
      "[56.] [60.650288]\n",
      "[155.] [155.47397]\n",
      "[133.] [133.26172]\n",
      "[164.] [151.7396]\n",
      "[87.] [101.71233]\n",
      "[102.] [95.20818]\n",
      "[124.] [121.29383]\n",
      "[111.] [107.17518]\n",
      "[86.] [92.76908]\n",
      "[106.] [102.9188]\n",
      "[58.] [85.95071]\n",
      "[140.] [118.87403]\n",
      "[115.] [120.42574]\n",
      "[101.] [111.76688]\n",
      "[107.] [102.373634]\n",
      "[119.] [127.91036]\n",
      "[99.] [110.53511]\n",
      "[84.] [92.7488]\n",
      "[84.] [85.48574]\n",
      "[89.] [90.25286]\n",
      "[93.] [107.41006]\n",
      "[109.] [108.35203]\n",
      "[156.] [136.18723]\n",
      "[94.] [91.40032]\n",
      "[81.] [88.71785]\n",
      "[138.] [127.10061]\n",
      "[96.] [99.587135]\n",
      "[89.] [106.1849]\n",
      "[162.] [143.65497]\n",
      "[101.] [103.1206]\n",
      "[96.] [104.33663]\n",
      "[151.] [133.3399]\n",
      "[57.] [66.22641]\n",
      "[154.] [149.66287]\n",
      "[133.] [139.38123]\n",
      "[57.] [63.714733]\n",
      "[126.] [130.83609]\n",
      "[125.] [114.609184]\n",
      "[127.] [125.751884]\n",
      "[88.] [96.87522]\n",
      "[107.] [97.81957]\n",
      "[184.] [184.47969]\n",
      "[145.] [126.0253]\n",
      "[109.] [95.2065]\n",
      "[91.] [105.01183]\n",
      "[126.] [121.78982]\n",
      "[66.] [69.84885]\n",
      "[100.] [97.809456]\n",
      "[96.] [97.32099]\n",
      "[112.] [121.18694]\n",
      "[83.] [87.58428]\n",
      "[115.] [126.238045]\n",
      "[91.] [93.5128]\n",
      "[98.] [102.329025]\n",
      "[60.] [75.62946]\n",
      "[107.] [94.674446]\n",
      "[41.] [61.547077]\n",
      "[118.] [140.90941]\n",
      "[153.] [142.46567]\n",
      "[107.] [107.53297]\n",
      "[83.] [108.324394]\n",
      "[87.] [90.241646]\n",
      "[109.] [105.34974]\n",
      "[114.] [113.77191]\n",
      "[119.] [123.787636]\n",
      "[53.] [77.50916]\n",
      "[106.] [112.407684]\n",
      "[113.] [111.235214]\n",
      "[86.] [87.15165]\n",
      "[100.] [92.72483]\n",
      "[95.] [112.92097]\n",
      "[193.] [156.81161]\n",
      "[127.] [112.89802]\n",
      "[129.] [140.435]\n",
      "[127.] [124.44767]\n",
      "[77.] [86.62782]\n",
      "[91.] [104.67494]\n"
     ]
    }
   ],
   "source": [
    "for t,p in zip(y_train,y_train_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79.] [133.89131]\n",
      "[113.] [94.8348]\n",
      "[110.] [107.61438]\n",
      "[118.] [114.38392]\n",
      "[124.] [128.42104]\n",
      "[96.] [95.431046]\n",
      "[103.] [120.154335]\n",
      "[98.] [124.73133]\n",
      "[121.] [94.38041]\n",
      "[124.] [101.78868]\n",
      "[160.] [118.023445]\n",
      "[117.] [101.64473]\n",
      "[122.] [112.35338]\n",
      "[130.] [99.283226]\n",
      "[124.] [123.25825]\n",
      "[67.] [115.70742]\n",
      "[98.] [101.25549]\n",
      "[106.] [128.91151]\n",
      "[112.] [88.63468]\n",
      "[101.] [87.66409]\n",
      "[112.] [117.46909]\n",
      "[105.] [90.92988]\n",
      "[112.] [106.32493]\n",
      "[157.] [80.74386]\n",
      "[118.] [130.3009]\n",
      "[100.] [99.63773]\n",
      "[119.] [103.44134]\n",
      "[161.] [109.313614]\n",
      "[120.] [100.061165]\n",
      "[97.] [95.85464]\n",
      "[131.] [94.278564]\n",
      "[105.] [108.23846]\n",
      "[137.] [107.93865]\n",
      "[88.] [100.20776]\n",
      "[121.] [120.1137]\n",
      "[109.] [103.318]\n",
      "[94.] [117.97704]\n",
      "[169.] [133.76216]\n",
      "[105.] [91.724495]\n",
      "[98.] [114.44772]\n",
      "[105.] [124.571175]\n",
      "[67.] [84.506935]\n",
      "[58.] [99.81093]\n",
      "[133.] [81.852135]\n",
      "[192.] [109.78486]\n",
      "[60.] [95.421524]\n",
      "[63.] [94.840996]\n",
      "[92.] [86.30397]\n",
      "[84.] [146.41809]\n",
      "[52.] [128.20917]\n",
      "[102.] [89.40586]\n",
      "[65.] [97.790474]\n",
      "[99.] [118.28232]\n",
      "[102.] [112.443474]\n",
      "[125.] [116.69215]\n",
      "[65.] [122.17305]\n",
      "[86.] [135.72305]\n",
      "[114.] [84.77472]\n",
      "[97.] [101.21836]\n",
      "[129.] [93.98775]\n",
      "[93.] [92.185585]\n",
      "[79.] [93.946556]\n",
      "[86.] [155.85869]\n",
      "[110.] [123.84606]\n",
      "[53.] [44.43691]\n",
      "[112.] [141.79477]\n",
      "[116.] [113.532616]\n",
      "[76.] [94.23546]\n",
      "[64.] [79.81995]\n",
      "[146.] [121.75938]\n",
      "[139.] [92.33465]\n"
     ]
    }
   ],
   "source": [
    "for t,p in zip(y_test,y_test_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#오차 범위 3 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set prediction accuracy: 26.69 %\n",
      "test set prediction accuracy: 33.80 %\n"
     ]
    }
   ],
   "source": [
    "#평균 성능 테스트\n",
    "scores = 0\n",
    "mean=np.mean(Y, axis=0)\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= mean <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"train set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= mean <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"test set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### <오차범위 3>\n",
      "- train set prediction accuracy(+-3): 20.28 % <br>\n",
      "- test set prediction accuracy(+-3): 11.27 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 5>\n",
      "- train set prediction accuracy(+-5): 36.65 % <br>\n",
      "- test set prediction accuracy(+-5): 18.31 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 10>\n",
      "- train set prediction accuracy(+-10): 63.35 % <br>\n",
      "- test set prediction accuracy(+-10): 28.17 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 20>\n",
      "- train set prediction accuracy(+-20): 89.68 % <br>\n",
      "- test set prediction accuracy(+-20): 56.34 % <br>\n"
     ]
    }
   ],
   "source": [
    "######입력용#######\n",
    "\n",
    "#오차 범위 3 설정\n",
    "print('### <오차범위 3>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "print('### <오차범위 5>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "print('### <오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "print('### <오차범위 20>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Y=LDL>\n",
    "## 1. 임의+선별\n",
    "### <오차범위 3>\n",
    "- train set prediction accuracy(+-3): 11.03 % <br>\n",
    "- test set prediction accuracy(+-3): 7.04 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 5>\n",
    "- train set prediction accuracy(+-5): 21.35 % <br>\n",
    "- test set prediction accuracy(+-5): 12.68 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 10>\n",
    "- train set prediction accuracy(+-10): 39.86 % <br>\n",
    "- test set prediction accuracy(+-10): 25.35 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 20>\n",
    "- train set prediction accuracy(+-20): 68.68 % <br>\n",
    "- test set prediction accuracy(+-20): 56.34 % <br>\n",
    "\n",
    "## 2. 임의+선별+PSQI\n",
    "### <오차범위 3>\n",
    "- train set prediction accuracy(+-3): 20.28 % <br>\n",
    "- test set prediction accuracy(+-3): 11.27 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 5>\n",
    "- train set prediction accuracy(+-5): 36.65 % <br>\n",
    "- test set prediction accuracy(+-5): 18.31 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 10>\n",
    "- train set prediction accuracy(+-10): 63.35 % <br>\n",
    "- test set prediction accuracy(+-10): 28.17 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 20>\n",
    "- train set prediction accuracy(+-20): 89.68 % <br>\n",
    "- test set prediction accuracy(+-20): 56.34 % <br>\n",
    "\n",
    "\n",
    "## 3. PSQI+AGE+SEX+BMI+Fat+Fat_percentage+Waist\n",
    "### <오차범위 3>\n",
    "- train set prediction accuracy(+-3): 26.69 % <br>\n",
    "- test set prediction accuracy(+-3): 9.86 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 5>\n",
    "- train set prediction accuracy(+-5): 40.93 % <br>\n",
    "- test set prediction accuracy(+-5): 15.49 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 10>\n",
    "- train set prediction accuracy(+-10): 67.26 % <br>\n",
    "- test set prediction accuracy(+-10): 35.21 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 20>\n",
    "- train set prediction accuracy(+-20): 90.04 % <br>\n",
    "- test set prediction accuracy(+-20): 66.20 % <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

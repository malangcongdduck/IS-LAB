{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sample_ID GROUP  COHORT SEX  AGE     Trait FitbitOX      Fitbit_ID  HTN  \\\n",
      "0         S0001   SMI       2   M   60  fitbit_O        O  sevrance00001  NaN   \n",
      "1         S0002   SMI       2   M   61  fitbit_O        O  sevrance00002  NaN   \n",
      "2         S0003   SMI       2   F   52  fitbit_O        O  sevrance00003  NaN   \n",
      "3         S0004   SMI       2   F   41  fitbit_O        O  sevrance00004  NaN   \n",
      "4         S0005   SMI       2   F   41  fitbit_O        O  sevrance00005  NaN   \n",
      "..          ...   ...     ...  ..  ...       ...      ...            ...  ...   \n",
      "383  MetS_S0280  MetS       1   F   24  fitbit_O        O   gnfmmets+139  NaN   \n",
      "384  MetS_S0281  MetS       1   F   44  fitbit_O        O   gnfmmets+140  NaN   \n",
      "385  MetS_S0282  MetS       1   F   37  fitbit_O        O   gnfmmets+141  1.0   \n",
      "386  MetS_S0283  MetS       1   M   51  fitbit_X        X              X  NaN   \n",
      "387  MetS_S0284  MetS       1   F   42  fitbit_X        X              X  NaN   \n",
      "\n",
      "      DM  ...  BDI_Q13_2 BDI_Q14_2  BDI_Q15_2  BDI_Q16_2 BDI_Q17_2 BDI_Q18_2  \\\n",
      "0    NaN  ...        1.0       1.0        1.0        2.0       1.0       1.0   \n",
      "1    1.0  ...        1.0       1.0        1.0        1.0       2.0       1.0   \n",
      "2    NaN  ...        1.0       1.0        1.0        1.0       1.0       1.0   \n",
      "3    NaN  ...        2.0       2.0        2.0        2.0       2.0       2.0   \n",
      "4    NaN  ...        2.0       1.0        2.0        2.0       2.0       1.0   \n",
      "..   ...  ...        ...       ...        ...        ...       ...       ...   \n",
      "383  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "384  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "385  1.0  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "386  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "387  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "\n",
      "     BDI_Q19_2  BDI_Q20_2  BDI_Q21_2  Diet_2  \n",
      "0          2.0        1.0        2.0     2.0  \n",
      "1          1.0        1.0        1.0     2.0  \n",
      "2          1.0        2.0        4.0     1.0  \n",
      "3          1.0        1.0        1.0     2.0  \n",
      "4          1.0        2.0        1.0     2.0  \n",
      "..         ...        ...        ...     ...  \n",
      "383        NaN        NaN        NaN     NaN  \n",
      "384        NaN        NaN        NaN     NaN  \n",
      "385        NaN        NaN        NaN     NaN  \n",
      "386        NaN        NaN        NaN     NaN  \n",
      "387        NaN        NaN        NaN     NaN  \n",
      "\n",
      "[388 rows x 3527 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('./최종 데이터 그래프그리기용.xlsx') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df=df[['Sample_ID','GROUP','COHORT','AGE','SEX','BMI_1','PSQI_TOTAL_1','Insulin _1','CRP_1','WBC_1','Neutrophil_1','Lym_1','GLU0_1',\n",
    "            'Creatinine_1','AST_1','ALT_1','TG_1','LDL_1','Muscle_1','Fat_1_x','FatPercentage _1','WHR_1','SBP_1',\n",
    "            'DBP_1','HR_1','Waist_1','Chol_1','BUN_1',\n",
    "            'BMI_2','PSQI_TOTAL_2','Insulin _2','CRP_2','WBC_2','Neutrophil_2','Lym_2','GLU0_2',\n",
    "            'Creatinine_2','AST_2','ALT_2','TG_2','LDL_2','Muscle_2','Fat_2_x','FatPercentage_2','WHR_2','SBP_2',\n",
    "            'DBP_2','HR_2','Waist_2','Chol_2','BUN_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Muscle_2</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>Chol_2</th>\n",
       "      <th>BUN_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>28.9</td>\n",
       "      <td>9.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.89</td>\n",
       "      <td>108.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.51</td>\n",
       "      <td>...</td>\n",
       "      <td>28.6</td>\n",
       "      <td>19.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>0.99</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>90.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.85</td>\n",
       "      <td>...</td>\n",
       "      <td>21.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>127.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.14</td>\n",
       "      <td>...</td>\n",
       "      <td>19.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.82</td>\n",
       "      <td>119.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.93</td>\n",
       "      <td>...</td>\n",
       "      <td>22.8</td>\n",
       "      <td>14.9</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>110.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>66.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.82</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.67</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.03</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT  AGE SEX      BMI_1  PSQI_TOTAL_1 Insulin _1  \\\n",
       "0         S0001   SMI       2   60   M  21.110190           8.0        7.7   \n",
       "1         S0002   SMI       2   61   M  27.782064           4.0        5.4   \n",
       "2         S0003   SMI       2   52   F  24.944742           3.0        5.1   \n",
       "3         S0004   SMI       2   41   F  22.620489           6.0        4.2   \n",
       "4         S0005   SMI       2   41   F  20.524157          10.0        3.2   \n",
       "..          ...   ...     ...  ...  ..        ...           ...        ...   \n",
       "383  MetS_S0280  MetS       1   24   F  34.803410           5.0       11.3   \n",
       "384  MetS_S0281  MetS       1   44   F  30.903615           3.0       10.6   \n",
       "385  MetS_S0282  MetS       1   37   F  28.676533           3.0       12.2   \n",
       "386  MetS_S0283  MetS       1   51   M  24.549738           5.0       10.4   \n",
       "387  MetS_S0284  MetS       1   42   F  24.605921           3.0       10.1   \n",
       "\n",
       "    CRP_1  WBC_1  ...  Muscle_2  Fat_2_x  FatPercentage_2  WHR_2  SBP_2  \\\n",
       "0     0.2   3.91  ...      28.9      9.7             15.9   0.89  108.0   \n",
       "1     0.2   5.51  ...      28.6     19.9             27.9   0.99  138.0   \n",
       "2     0.7   4.85  ...      21.5     22.6             36.7   0.89  127.0   \n",
       "3     0.6   6.14  ...      19.8     16.0             30.9   0.82  119.0   \n",
       "4     0.1   4.93  ...      22.8     14.9             26.8   0.80  110.0   \n",
       "..    ...    ...  ...       ...      ...              ...    ...    ...   \n",
       "383   0.4   5.32  ...       NaN      NaN              NaN    NaN    NaN   \n",
       "384   2.3   5.82  ...       NaN      NaN              NaN    NaN    NaN   \n",
       "385     1   6.18  ...       NaN      NaN              NaN    NaN    NaN   \n",
       "386   1.2   6.67  ...       NaN      NaN              NaN    NaN    NaN   \n",
       "387   0.8   7.03  ...       NaN      NaN              NaN    NaN    NaN   \n",
       "\n",
       "     DBP_2  HR_2  Waist_2  Chol_2  BUN_2  \n",
       "0     78.0  87.0     83.0     NaN   13.1  \n",
       "1     92.0  73.0     90.5     NaN   19.2  \n",
       "2     80.0  66.0     86.5     NaN   17.1  \n",
       "3     83.0  77.0     77.0     NaN   12.2  \n",
       "4     68.0  67.0     66.5     NaN   16.5  \n",
       "..     ...   ...      ...     ...    ...  \n",
       "383    NaN   NaN      NaN     NaN    NaN  \n",
       "384    NaN   NaN      NaN     NaN    NaN  \n",
       "385    NaN   NaN      NaN     NaN    NaN  \n",
       "386    NaN   NaN      NaN     NaN    NaN  \n",
       "387    NaN   NaN      NaN     NaN    NaN  \n",
       "\n",
       "[388 rows x 51 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Muscle_2</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>Chol_2</th>\n",
       "      <th>BUN_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>28.9</td>\n",
       "      <td>9.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.89</td>\n",
       "      <td>108.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.51</td>\n",
       "      <td>...</td>\n",
       "      <td>28.6</td>\n",
       "      <td>19.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>0.99</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>90.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.85</td>\n",
       "      <td>...</td>\n",
       "      <td>21.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>127.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.14</td>\n",
       "      <td>...</td>\n",
       "      <td>19.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.82</td>\n",
       "      <td>119.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.93</td>\n",
       "      <td>...</td>\n",
       "      <td>22.8</td>\n",
       "      <td>14.9</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>110.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>66.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.82</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.67</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.03</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT  AGE SEX      BMI_1  PSQI_TOTAL_1 Insulin _1  \\\n",
       "0         S0001   SMI       2   60   M  21.110190           8.0        7.7   \n",
       "1         S0002   SMI       2   61   M  27.782064           4.0        5.4   \n",
       "2         S0003   SMI       2   52   F  24.944742           3.0        5.1   \n",
       "3         S0004   SMI       2   41   F  22.620489           6.0        4.2   \n",
       "4         S0005   SMI       2   41   F  20.524157          10.0        3.2   \n",
       "..          ...   ...     ...  ...  ..        ...           ...        ...   \n",
       "383  MetS_S0280  MetS       1   24   F  34.803410           5.0       11.3   \n",
       "384  MetS_S0281  MetS       1   44   F  30.903615           3.0       10.6   \n",
       "385  MetS_S0282  MetS       1   37   F  28.676533           3.0       12.2   \n",
       "386  MetS_S0283  MetS       1   51   M  24.549738           5.0       10.4   \n",
       "387  MetS_S0284  MetS       1   42   F  24.605921           3.0       10.1   \n",
       "\n",
       "    CRP_1  WBC_1  ...  Muscle_2  Fat_2_x  FatPercentage_2  WHR_2  SBP_2  \\\n",
       "0     0.2   3.91  ...      28.9      9.7             15.9   0.89  108.0   \n",
       "1     0.2   5.51  ...      28.6     19.9             27.9   0.99  138.0   \n",
       "2     0.7   4.85  ...      21.5     22.6             36.7   0.89  127.0   \n",
       "3     0.6   6.14  ...      19.8     16.0             30.9   0.82  119.0   \n",
       "4     0.1   4.93  ...      22.8     14.9             26.8   0.80  110.0   \n",
       "..    ...    ...  ...       ...      ...              ...    ...    ...   \n",
       "383   0.4   5.32  ...       NaN      NaN              NaN    NaN    NaN   \n",
       "384   2.3   5.82  ...       NaN      NaN              NaN    NaN    NaN   \n",
       "385     1   6.18  ...       NaN      NaN              NaN    NaN    NaN   \n",
       "386   1.2   6.67  ...       NaN      NaN              NaN    NaN    NaN   \n",
       "387   0.8   7.03  ...       NaN      NaN              NaN    NaN    NaN   \n",
       "\n",
       "     DBP_2  HR_2  Waist_2  Chol_2  BUN_2  \n",
       "0     78.0  87.0     83.0     NaN   13.1  \n",
       "1     92.0  73.0     90.5     NaN   19.2  \n",
       "2     80.0  66.0     86.5     NaN   17.1  \n",
       "3     83.0  77.0     77.0     NaN   12.2  \n",
       "4     68.0  67.0     66.5     NaN   16.5  \n",
       "..     ...   ...      ...     ...    ...  \n",
       "383    NaN   NaN      NaN     NaN    NaN  \n",
       "384    NaN   NaN      NaN     NaN    NaN  \n",
       "385    NaN   NaN      NaN     NaN    NaN  \n",
       "386    NaN   NaN      NaN     NaN    NaN  \n",
       "387    NaN   NaN      NaN     NaN    NaN  \n",
       "\n",
       "[317 rows x 51 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#보조 호르몬 요법을 받고 있는 Cohort 3 제거 Filter 적용\n",
    "psqi_df = psqi_df[(psqi_df['COHORT'] != 3)]\n",
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Muscle_2</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>Chol_2</th>\n",
       "      <th>BUN_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>28.9</td>\n",
       "      <td>9.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.89</td>\n",
       "      <td>108.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.51</td>\n",
       "      <td>...</td>\n",
       "      <td>28.6</td>\n",
       "      <td>19.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>0.99</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>90.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.85</td>\n",
       "      <td>...</td>\n",
       "      <td>21.5</td>\n",
       "      <td>22.6</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>127.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.14</td>\n",
       "      <td>...</td>\n",
       "      <td>19.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.82</td>\n",
       "      <td>119.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.93</td>\n",
       "      <td>...</td>\n",
       "      <td>22.8</td>\n",
       "      <td>14.9</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>110.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>66.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.82</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.67</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.03</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT  AGE SEX      BMI_1  PSQI_TOTAL_1 Insulin _1  \\\n",
       "0         S0001   SMI       2   60   M  21.110190           8.0        7.7   \n",
       "1         S0002   SMI       2   61   M  27.782064           4.0        5.4   \n",
       "2         S0003   SMI       2   52   F  24.944742           3.0        5.1   \n",
       "3         S0004   SMI       2   41   F  22.620489           6.0        4.2   \n",
       "4         S0005   SMI       2   41   F  20.524157          10.0        3.2   \n",
       "..          ...   ...     ...  ...  ..        ...           ...        ...   \n",
       "383  MetS_S0280  MetS       1   24   F  34.803410           5.0       11.3   \n",
       "384  MetS_S0281  MetS       1   44   F  30.903615           3.0       10.6   \n",
       "385  MetS_S0282  MetS       1   37   F  28.676533           3.0       12.2   \n",
       "386  MetS_S0283  MetS       1   51   M  24.549738           5.0       10.4   \n",
       "387  MetS_S0284  MetS       1   42   F  24.605921           3.0       10.1   \n",
       "\n",
       "    CRP_1  WBC_1  ...  Muscle_2  Fat_2_x  FatPercentage_2  WHR_2  SBP_2  \\\n",
       "0     0.2   3.91  ...      28.9      9.7             15.9   0.89  108.0   \n",
       "1     0.2   5.51  ...      28.6     19.9             27.9   0.99  138.0   \n",
       "2     0.7   4.85  ...      21.5     22.6             36.7   0.89  127.0   \n",
       "3     0.6   6.14  ...      19.8     16.0             30.9   0.82  119.0   \n",
       "4     0.1   4.93  ...      22.8     14.9             26.8   0.80  110.0   \n",
       "..    ...    ...  ...       ...      ...              ...    ...    ...   \n",
       "383   0.4   5.32  ...       NaN      NaN              NaN    NaN    NaN   \n",
       "384   2.3   5.82  ...       NaN      NaN              NaN    NaN    NaN   \n",
       "385     1   6.18  ...       NaN      NaN              NaN    NaN    NaN   \n",
       "386   1.2   6.67  ...       NaN      NaN              NaN    NaN    NaN   \n",
       "387   0.8   7.03  ...       NaN      NaN              NaN    NaN    NaN   \n",
       "\n",
       "     DBP_2  HR_2  Waist_2  Chol_2  BUN_2  \n",
       "0     78.0  87.0     83.0     NaN   13.1  \n",
       "1     92.0  73.0     90.5     NaN   19.2  \n",
       "2     80.0  66.0     86.5     NaN   17.1  \n",
       "3     83.0  77.0     77.0     NaN   12.2  \n",
       "4     68.0  67.0     66.5     NaN   16.5  \n",
       "..     ...   ...      ...     ...    ...  \n",
       "383    NaN   NaN      NaN     NaN    NaN  \n",
       "384    NaN   NaN      NaN     NaN    NaN  \n",
       "385    NaN   NaN      NaN     NaN    NaN  \n",
       "386    NaN   NaN      NaN     NaN    NaN  \n",
       "387    NaN   NaN      NaN     NaN    NaN  \n",
       "\n",
       "[317 rows x 51 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df=psqi_df.dropna()\n",
    "psqi_df.reset_index(drop=True, inplace=True)\n",
    "psqi_df.isnull().sum()\n",
    "psqi_df=psqi_df.drop([\"Sample_ID\", \"GROUP\", \"COHORT\"],axis=1)\n",
    "#1분, 매일다름, 정해진간이없음 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"SEX\"] = psqi_df[\"SEX\"].apply(lambda x: 1. if x=='M' else 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>Neutrophil_1</th>\n",
       "      <th>Lym_1</th>\n",
       "      <th>GLU0_1</th>\n",
       "      <th>Creatinine_1</th>\n",
       "      <th>AST_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Muscle_2</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>Chol_2</th>\n",
       "      <th>BUN_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.00000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.366667</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>23.799644</td>\n",
       "      <td>5.105556</td>\n",
       "      <td>5.844867</td>\n",
       "      <td>56.086111</td>\n",
       "      <td>34.113333</td>\n",
       "      <td>98.90000</td>\n",
       "      <td>0.857778</td>\n",
       "      <td>22.854778</td>\n",
       "      <td>...</td>\n",
       "      <td>25.771667</td>\n",
       "      <td>19.053333</td>\n",
       "      <td>28.888333</td>\n",
       "      <td>0.862444</td>\n",
       "      <td>114.605556</td>\n",
       "      <td>72.477778</td>\n",
       "      <td>75.644444</td>\n",
       "      <td>81.328889</td>\n",
       "      <td>190.922222</td>\n",
       "      <td>12.984444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.589776</td>\n",
       "      <td>0.461927</td>\n",
       "      <td>4.936177</td>\n",
       "      <td>2.893833</td>\n",
       "      <td>1.412280</td>\n",
       "      <td>8.502880</td>\n",
       "      <td>7.708889</td>\n",
       "      <td>14.43773</td>\n",
       "      <td>1.631532</td>\n",
       "      <td>9.602253</td>\n",
       "      <td>...</td>\n",
       "      <td>5.719205</td>\n",
       "      <td>6.616151</td>\n",
       "      <td>7.098802</td>\n",
       "      <td>0.071696</td>\n",
       "      <td>13.213544</td>\n",
       "      <td>9.091991</td>\n",
       "      <td>10.306814</td>\n",
       "      <td>10.251265</td>\n",
       "      <td>32.017358</td>\n",
       "      <td>3.508550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.231576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.820000</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>63.00000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.900000</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.833309</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.857500</td>\n",
       "      <td>50.525000</td>\n",
       "      <td>28.975000</td>\n",
       "      <td>92.00000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>21.300000</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>24.275000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>73.875000</td>\n",
       "      <td>167.750000</td>\n",
       "      <td>10.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.422889</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.720000</td>\n",
       "      <td>55.950000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>95.50000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>23.750000</td>\n",
       "      <td>17.950000</td>\n",
       "      <td>28.450000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>80.500000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>12.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.502662</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.580000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>102.00000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30.225000</td>\n",
       "      <td>22.125000</td>\n",
       "      <td>33.450000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>77.250000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>14.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>10.550000</td>\n",
       "      <td>78.400000</td>\n",
       "      <td>55.400000</td>\n",
       "      <td>182.00000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>40.800000</td>\n",
       "      <td>46.100000</td>\n",
       "      <td>48.300000</td>\n",
       "      <td>1.070000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>36.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              AGE         SEX       BMI_1  PSQI_TOTAL_1       WBC_1  \\\n",
       "count  180.000000  180.000000  180.000000    180.000000  180.000000   \n",
       "mean    38.366667    0.305556   23.799644      5.105556    5.844867   \n",
       "std     11.589776    0.461927    4.936177      2.893833    1.412280   \n",
       "min     20.000000    0.000000   15.231576      0.000000    2.820000   \n",
       "25%     29.000000    0.000000   20.833309      3.000000    4.857500   \n",
       "50%     35.500000    0.000000   23.422889      5.000000    5.720000   \n",
       "75%     46.000000    1.000000   25.502662      7.000000    6.580000   \n",
       "max     63.000000    1.000000   67.500000     14.000000   10.550000   \n",
       "\n",
       "       Neutrophil_1       Lym_1     GLU0_1  Creatinine_1       AST_1  ...  \\\n",
       "count    180.000000  180.000000  180.00000    180.000000  180.000000  ...   \n",
       "mean      56.086111   34.113333   98.90000      0.857778   22.854778  ...   \n",
       "std        8.502880    7.708889   14.43773      1.631532    9.602253  ...   \n",
       "min       34.500000   15.100000   63.00000      0.380000    0.860000  ...   \n",
       "25%       50.525000   28.975000   92.00000      0.620000   18.000000  ...   \n",
       "50%       55.950000   34.000000   95.50000      0.720000   21.000000  ...   \n",
       "75%       62.000000   39.000000  102.00000      0.810000   25.000000  ...   \n",
       "max       78.400000   55.400000  182.00000     22.500000   91.000000  ...   \n",
       "\n",
       "         Muscle_2     Fat_2_x  FatPercentage_2       WHR_2       SBP_2  \\\n",
       "count  180.000000  180.000000       180.000000  180.000000  180.000000   \n",
       "mean    25.771667   19.053333        28.888333    0.862444  114.605556   \n",
       "std      5.719205    6.616151         7.098802    0.071696   13.213544   \n",
       "min     16.900000    7.700000        11.500000    0.700000   91.000000   \n",
       "25%     21.300000   14.200000        24.275000    0.820000  104.000000   \n",
       "50%     23.750000   17.950000        28.450000    0.850000  114.000000   \n",
       "75%     30.225000   22.125000        33.450000    0.900000  123.000000   \n",
       "max     40.800000   46.100000        48.300000    1.070000  158.000000   \n",
       "\n",
       "            DBP_2        HR_2     Waist_2      Chol_2       BUN_2  \n",
       "count  180.000000  180.000000  180.000000  180.000000  180.000000  \n",
       "mean    72.477778   75.644444   81.328889  190.922222   12.984444  \n",
       "std      9.091991   10.306814   10.251265   32.017358    3.508550  \n",
       "min     57.000000   54.000000   61.000000  109.000000    6.000000  \n",
       "25%     67.000000   68.000000   73.875000  167.750000   10.675000  \n",
       "50%     71.000000   75.000000   80.500000  188.000000   12.700000  \n",
       "75%     77.250000   82.000000   89.000000  211.000000   14.600000  \n",
       "max    107.000000  112.000000  118.000000  296.000000   36.400000  \n",
       "\n",
       "[8 rows x 45 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    125\n",
       "1.0     55\n",
       "Name: SEX, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df[\"SEX\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>GLU0_1</th>\n",
       "      <th>ALT_1</th>\n",
       "      <th>TG_1</th>\n",
       "      <th>LDL_1</th>\n",
       "      <th>Muscle_1</th>\n",
       "      <th>...</th>\n",
       "      <th>PSQI_Q5e_2</th>\n",
       "      <th>PSQI_Q5f_2</th>\n",
       "      <th>PSQI_Q5g_2</th>\n",
       "      <th>PSQI_Q5h_2</th>\n",
       "      <th>PSQI_Q5i_2</th>\n",
       "      <th>PSQI_Q5j_2</th>\n",
       "      <th>PSQI_Q6_2</th>\n",
       "      <th>PSQI_Q7_2</th>\n",
       "      <th>PSQI_Q8_2</th>\n",
       "      <th>PSQI_Q9_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24.097789</td>\n",
       "      <td>5.82</td>\n",
       "      <td>89</td>\n",
       "      <td>24</td>\n",
       "      <td>93</td>\n",
       "      <td>89</td>\n",
       "      <td>32.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>46</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23.472213</td>\n",
       "      <td>5.46</td>\n",
       "      <td>90</td>\n",
       "      <td>33</td>\n",
       "      <td>111</td>\n",
       "      <td>160</td>\n",
       "      <td>36.1</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.744827</td>\n",
       "      <td>3.99</td>\n",
       "      <td>96</td>\n",
       "      <td>35</td>\n",
       "      <td>65</td>\n",
       "      <td>145</td>\n",
       "      <td>29.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.616175</td>\n",
       "      <td>5.84</td>\n",
       "      <td>81</td>\n",
       "      <td>14</td>\n",
       "      <td>56</td>\n",
       "      <td>99</td>\n",
       "      <td>24.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>28</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.437500</td>\n",
       "      <td>4.22</td>\n",
       "      <td>63</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>91</td>\n",
       "      <td>19.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.0</td>\n",
       "      <td>63</td>\n",
       "      <td>3.0</td>\n",
       "      <td>26.259585</td>\n",
       "      <td>4.78</td>\n",
       "      <td>96</td>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>65</td>\n",
       "      <td>24.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.0</td>\n",
       "      <td>57</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.630719</td>\n",
       "      <td>4.60</td>\n",
       "      <td>94</td>\n",
       "      <td>48</td>\n",
       "      <td>62</td>\n",
       "      <td>57</td>\n",
       "      <td>34.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.641274</td>\n",
       "      <td>6.34</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>88</td>\n",
       "      <td>94</td>\n",
       "      <td>23.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.0</td>\n",
       "      <td>61</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.421366</td>\n",
       "      <td>4.88</td>\n",
       "      <td>93</td>\n",
       "      <td>14</td>\n",
       "      <td>65</td>\n",
       "      <td>52</td>\n",
       "      <td>21.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1.0</td>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.271653</td>\n",
       "      <td>6.28</td>\n",
       "      <td>125</td>\n",
       "      <td>15</td>\n",
       "      <td>167</td>\n",
       "      <td>84</td>\n",
       "      <td>33.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SEX  AGE  PSQI_TOTAL_1      BMI_1  WBC_1  GLU0_1  ALT_1  TG_1  LDL_1  \\\n",
       "0    1.0   35           5.0  24.097789   5.82      89     24    93     89   \n",
       "1    1.0   46           5.0  23.472213   5.46      90     33   111    160   \n",
       "2    1.0   32           2.0  23.744827   3.99      96     35    65    145   \n",
       "3    0.0   33           4.0  20.616175   5.84      81     14    56     99   \n",
       "4    0.0   28           3.0  18.437500   4.22      63     17    40     91   \n",
       "..   ...  ...           ...        ...    ...     ...    ...   ...    ...   \n",
       "171  0.0   63           3.0  26.259585   4.78      96     24    64     65   \n",
       "172  1.0   57           4.0  28.630719   4.60      94     48    62     57   \n",
       "173  0.0   35           1.0  21.641274   6.34      87     10    88     94   \n",
       "174  0.0   61           8.0  20.421366   4.88      93     14    65     52   \n",
       "175  1.0   56           1.0  22.271653   6.28     125     15   167     84   \n",
       "\n",
       "     Muscle_1  ...  PSQI_Q5e_2  PSQI_Q5f_2  PSQI_Q5g_2  PSQI_Q5h_2  \\\n",
       "0        32.2  ...         2.0         0.0         0.0         1.0   \n",
       "1        36.1  ...         2.0         2.0         0.0         0.0   \n",
       "2        29.4  ...         0.0         0.0         0.0         0.0   \n",
       "3        24.1  ...         0.0         0.0         0.0         0.0   \n",
       "4        19.7  ...         0.0         0.0         0.0         0.0   \n",
       "..        ...  ...         ...         ...         ...         ...   \n",
       "171      24.6  ...         0.0         0.0         0.0         0.0   \n",
       "172      34.8  ...         0.0         0.0         0.0         0.0   \n",
       "173      23.2  ...         0.0         0.0         0.0         0.0   \n",
       "174      21.5  ...         0.0         0.0         0.0         0.0   \n",
       "175      33.5  ...         0.0         0.0         0.0         0.0   \n",
       "\n",
       "     PSQI_Q5i_2  PSQI_Q5j_2  PSQI_Q6_2  PSQI_Q7_2  PSQI_Q8_2  PSQI_Q9_2  \n",
       "0           0.0         1.0        1.0        0.0        1.0        0.0  \n",
       "1           0.0         0.0        2.0        0.0        2.0        0.0  \n",
       "2           0.0         0.0        1.0        0.0        0.0        0.0  \n",
       "3           0.0         0.0        1.0        0.0        1.0        1.0  \n",
       "4           1.0         1.0        1.0        0.0        0.0        1.0  \n",
       "..          ...         ...        ...        ...        ...        ...  \n",
       "171         0.0         0.0        1.0        0.0        0.0        0.0  \n",
       "172         1.0         0.0        1.0        0.0        0.0        0.0  \n",
       "173         0.0         0.0        0.0        0.0        0.0        0.0  \n",
       "174         0.0         0.0        2.0        0.0        0.0        0.0  \n",
       "175         0.0         0.0        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[176 rows x 80 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (선별)\n",
    "X1=psqi_df[['SEX','AGE','PSQI_TOTAL_1','BMI_1','WBC_1','GLU0_1','ALT_1','TG_1','LDL_1',\n",
    "            'Muscle_1','Fat_1_x','SBP_1','DBP_1','HR_1','Waist_1','PSQI_TOTAL_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1']].values\n",
    "X2=psqi_df[['SEX','AGE','PSQI_TOTAL_2','BMI_2','WBC_2','GLU0_2','ALT_2','TG_2','LDL_2',\n",
    "            'Muscle_2','Fat_2_x','SBP_2','DBP_2','HR_2','Waist_2','PSQI_TOTAL_2','PSQI_C1_2','PSQI_C2_2','PSQI_C3_2','PSQI_C4_2','PSQI_C5_2','PSQI_C6_2','PSQI_C7_2','PSQI_Q1_2','PSQI_Q2_2','PSQI_Q3_2','PSQI_Q4_2',\n",
    "            'PSQI_Q5a_2','PSQI_Q5b_2','PSQI_Q5c_2','PSQI_Q5d_2','PSQI_Q5e_2','PSQI_Q5f_2','PSQI_Q5g_2','PSQI_Q5h_2','PSQI_Q5i_2','PSQI_Q5j_2','PSQI_Q6_2','PSQI_Q7_2','PSQI_Q8_2','PSQI_Q9_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (선별)\n",
    "X1=psqi_df[['SEX','AGE','PSQI_TOTAL_1','BMI_1','WBC_1','GLU0_1','ALT_1','TG_1','LDL_1',\n",
    "            'Muscle_1','Fat_1_x','SBP_1','DBP_1','HR_1','Waist_1','PSQI_TOTAL_1']].values\n",
    "X2=psqi_df[['SEX','AGE','PSQI_TOTAL_2','BMI_2','WBC_2','GLU0_2','ALT_2','TG_2','LDL_2',\n",
    "            'Muscle_2','Fat_2_x','SBP_2','DBP_2','HR_2','Waist_2','PSQI_TOTAL_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 352)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((352, 41), (352, 1))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(281, 71)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((352, 41), (352, 1))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "71/71 [==============================] - 0s 635us/step - loss: 3547.0985 - mse: 3547.0985\n",
      "Epoch 2/150\n",
      "71/71 [==============================] - 0s 692us/step - loss: 3185.6142 - mse: 3185.6142\n",
      "Epoch 3/150\n",
      "71/71 [==============================] - 0s 613us/step - loss: 2176.8721 - mse: 2176.8721\n",
      "Epoch 4/150\n",
      "71/71 [==============================] - 0s 597us/step - loss: 988.8387 - mse: 988.8387\n",
      "Epoch 5/150\n",
      "71/71 [==============================] - 0s 638us/step - loss: 396.8599 - mse: 396.8599\n",
      "Epoch 6/150\n",
      "71/71 [==============================] - 0s 712us/step - loss: 247.3433 - mse: 247.3433\n",
      "Epoch 7/150\n",
      "71/71 [==============================] - 0s 710us/step - loss: 248.1778 - mse: 248.1778\n",
      "Epoch 8/150\n",
      "71/71 [==============================] - 0s 697us/step - loss: 210.7761 - mse: 210.7761\n",
      "Epoch 9/150\n",
      "71/71 [==============================] - 0s 681us/step - loss: 189.3519 - mse: 189.3519\n",
      "Epoch 10/150\n",
      "71/71 [==============================] - 0s 609us/step - loss: 148.0150 - mse: 148.0150\n",
      "Epoch 11/150\n",
      "71/71 [==============================] - 0s 715us/step - loss: 151.4285 - mse: 151.4285\n",
      "Epoch 12/150\n",
      "71/71 [==============================] - 0s 747us/step - loss: 139.3126 - mse: 139.3126\n",
      "Epoch 13/150\n",
      "71/71 [==============================] - 0s 672us/step - loss: 123.7351 - mse: 123.7351\n",
      "Epoch 14/150\n",
      "71/71 [==============================] - 0s 628us/step - loss: 129.9896 - mse: 129.9896\n",
      "Epoch 15/150\n",
      "71/71 [==============================] - 0s 742us/step - loss: 108.8184 - mse: 108.8184\n",
      "Epoch 16/150\n",
      "71/71 [==============================] - 0s 785us/step - loss: 98.2202 - mse: 98.2202\n",
      "Epoch 17/150\n",
      "71/71 [==============================] - 0s 681us/step - loss: 85.3572 - mse: 85.3572\n",
      "Epoch 18/150\n",
      "71/71 [==============================] - 0s 730us/step - loss: 88.2700 - mse: 88.2700\n",
      "Epoch 19/150\n",
      "71/71 [==============================] - 0s 696us/step - loss: 100.3784 - mse: 100.3784\n",
      "Epoch 20/150\n",
      "71/71 [==============================] - 0s 743us/step - loss: 71.1861 - mse: 71.1861\n",
      "Epoch 21/150\n",
      "71/71 [==============================] - 0s 612us/step - loss: 75.8247 - mse: 75.8247\n",
      "Epoch 22/150\n",
      "71/71 [==============================] - 0s 702us/step - loss: 73.1876 - mse: 73.1876\n",
      "Epoch 23/150\n",
      "71/71 [==============================] - 0s 682us/step - loss: 84.4890 - mse: 84.4890\n",
      "Epoch 24/150\n",
      "71/71 [==============================] - 0s 647us/step - loss: 72.5513 - mse: 72.5513\n",
      "Epoch 25/150\n",
      "71/71 [==============================] - 0s 629us/step - loss: 82.1775 - mse: 82.1775\n",
      "Epoch 26/150\n",
      "71/71 [==============================] - 0s 663us/step - loss: 74.6696 - mse: 74.6696\n",
      "Epoch 27/150\n",
      "71/71 [==============================] - 0s 662us/step - loss: 64.2480 - mse: 64.2480\n",
      "Epoch 28/150\n",
      "71/71 [==============================] - 0s 610us/step - loss: 55.9383 - mse: 55.9383\n",
      "Epoch 29/150\n",
      "71/71 [==============================] - 0s 646us/step - loss: 60.1076 - mse: 60.1076\n",
      "Epoch 30/150\n",
      "71/71 [==============================] - 0s 678us/step - loss: 69.7469 - mse: 69.7469\n",
      "Epoch 31/150\n",
      "71/71 [==============================] - 0s 787us/step - loss: 49.9535 - mse: 49.9535\n",
      "Epoch 32/150\n",
      "71/71 [==============================] - 0s 708us/step - loss: 55.4845 - mse: 55.4845\n",
      "Epoch 33/150\n",
      "71/71 [==============================] - 0s 744us/step - loss: 49.5268 - mse: 49.5268\n",
      "Epoch 34/150\n",
      "71/71 [==============================] - 0s 685us/step - loss: 56.3117 - mse: 56.3117\n",
      "Epoch 35/150\n",
      "71/71 [==============================] - 0s 775us/step - loss: 52.8364 - mse: 52.8364\n",
      "Epoch 36/150\n",
      "71/71 [==============================] - 0s 736us/step - loss: 53.5646 - mse: 53.5646\n",
      "Epoch 37/150\n",
      "71/71 [==============================] - 0s 765us/step - loss: 49.5054 - mse: 49.5054\n",
      "Epoch 38/150\n",
      "71/71 [==============================] - 0s 704us/step - loss: 32.3318 - mse: 32.3318\n",
      "Epoch 39/150\n",
      "71/71 [==============================] - 0s 673us/step - loss: 42.5107 - mse: 42.5107\n",
      "Epoch 40/150\n",
      "71/71 [==============================] - 0s 706us/step - loss: 49.2099 - mse: 49.2099\n",
      "Epoch 41/150\n",
      "71/71 [==============================] - 0s 648us/step - loss: 41.9302 - mse: 41.9302\n",
      "Epoch 42/150\n",
      "71/71 [==============================] - 0s 716us/step - loss: 36.4391 - mse: 36.4391\n",
      "Epoch 43/150\n",
      "71/71 [==============================] - 0s 684us/step - loss: 40.4673 - mse: 40.4673\n",
      "Epoch 44/150\n",
      "71/71 [==============================] - 0s 794us/step - loss: 43.3761 - mse: 43.3761\n",
      "Epoch 45/150\n",
      "71/71 [==============================] - 0s 777us/step - loss: 37.8388 - mse: 37.8388\n",
      "Epoch 46/150\n",
      "71/71 [==============================] - 0s 782us/step - loss: 46.5579 - mse: 46.5579\n",
      "Epoch 47/150\n",
      "71/71 [==============================] - 0s 759us/step - loss: 45.5037 - mse: 45.5037\n",
      "Epoch 48/150\n",
      "71/71 [==============================] - 0s 737us/step - loss: 36.2087 - mse: 36.2087\n",
      "Epoch 49/150\n",
      "71/71 [==============================] - 0s 674us/step - loss: 40.8808 - mse: 40.8808\n",
      "Epoch 50/150\n",
      "71/71 [==============================] - 0s 612us/step - loss: 39.4876 - mse: 39.4876\n",
      "Epoch 51/150\n",
      "71/71 [==============================] - 0s 684us/step - loss: 40.0311 - mse: 40.0311\n",
      "Epoch 52/150\n",
      "71/71 [==============================] - 0s 785us/step - loss: 31.6627 - mse: 31.6627\n",
      "Epoch 53/150\n",
      "71/71 [==============================] - 0s 743us/step - loss: 33.0848 - mse: 33.0848\n",
      "Epoch 54/150\n",
      "71/71 [==============================] - 0s 680us/step - loss: 27.7990 - mse: 27.7990\n",
      "Epoch 55/150\n",
      "71/71 [==============================] - 0s 726us/step - loss: 34.1720 - mse: 34.1720\n",
      "Epoch 56/150\n",
      "71/71 [==============================] - 0s 612us/step - loss: 30.5569 - mse: 30.5569\n",
      "Epoch 57/150\n",
      "71/71 [==============================] - 0s 653us/step - loss: 26.5324 - mse: 26.5324\n",
      "Epoch 58/150\n",
      "71/71 [==============================] - 0s 825us/step - loss: 28.7427 - mse: 28.7427\n",
      "Epoch 59/150\n",
      "71/71 [==============================] - 0s 776us/step - loss: 28.8508 - mse: 28.8508\n",
      "Epoch 60/150\n",
      "71/71 [==============================] - 0s 766us/step - loss: 26.8733 - mse: 26.8733\n",
      "Epoch 61/150\n",
      "71/71 [==============================] - 0s 680us/step - loss: 27.8577 - mse: 27.8577\n",
      "Epoch 62/150\n",
      "71/71 [==============================] - 0s 609us/step - loss: 28.7664 - mse: 28.7664\n",
      "Epoch 63/150\n",
      "71/71 [==============================] - 0s 631us/step - loss: 24.9638 - mse: 24.9638\n",
      "Epoch 64/150\n",
      "71/71 [==============================] - 0s 653us/step - loss: 26.0028 - mse: 26.0028\n",
      "Epoch 65/150\n",
      "71/71 [==============================] - 0s 633us/step - loss: 22.4705 - mse: 22.4705\n",
      "Epoch 66/150\n",
      "71/71 [==============================] - 0s 654us/step - loss: 19.7636 - mse: 19.7636\n",
      "Epoch 67/150\n",
      "71/71 [==============================] - 0s 651us/step - loss: 19.4784 - mse: 19.4784\n",
      "Epoch 68/150\n",
      "71/71 [==============================] - 0s 547us/step - loss: 22.3520 - mse: 22.3520\n",
      "Epoch 69/150\n",
      "71/71 [==============================] - 0s 561us/step - loss: 21.1383 - mse: 21.1383\n",
      "Epoch 70/150\n",
      "71/71 [==============================] - 0s 644us/step - loss: 18.7472 - mse: 18.7472\n",
      "Epoch 71/150\n",
      "71/71 [==============================] - 0s 626us/step - loss: 21.6475 - mse: 21.6475\n",
      "Epoch 72/150\n",
      "71/71 [==============================] - 0s 621us/step - loss: 18.5351 - mse: 18.5351\n",
      "Epoch 73/150\n",
      "71/71 [==============================] - 0s 654us/step - loss: 17.7789 - mse: 17.7789\n",
      "Epoch 74/150\n",
      "71/71 [==============================] - 0s 676us/step - loss: 18.6619 - mse: 18.6619\n",
      "Epoch 75/150\n",
      "71/71 [==============================] - 0s 670us/step - loss: 16.6737 - mse: 16.6737\n",
      "Epoch 76/150\n",
      "71/71 [==============================] - 0s 670us/step - loss: 17.3004 - mse: 17.3004\n",
      "Epoch 77/150\n",
      "71/71 [==============================] - 0s 760us/step - loss: 16.2860 - mse: 16.2860\n",
      "Epoch 78/150\n",
      "71/71 [==============================] - 0s 678us/step - loss: 18.3366 - mse: 18.3366\n",
      "Epoch 79/150\n",
      "71/71 [==============================] - 0s 690us/step - loss: 16.7474 - mse: 16.7474\n",
      "Epoch 80/150\n",
      "71/71 [==============================] - 0s 691us/step - loss: 16.3244 - mse: 16.3244\n",
      "Epoch 81/150\n",
      "71/71 [==============================] - 0s 648us/step - loss: 14.1260 - mse: 14.1260\n",
      "Epoch 82/150\n",
      "71/71 [==============================] - 0s 622us/step - loss: 18.6228 - mse: 18.6228\n",
      "Epoch 83/150\n",
      "71/71 [==============================] - 0s 944us/step - loss: 12.5824 - mse: 12.5824\n",
      "Epoch 84/150\n",
      "71/71 [==============================] - 0s 732us/step - loss: 13.5154 - mse: 13.5154\n",
      "Epoch 85/150\n",
      "71/71 [==============================] - 0s 770us/step - loss: 16.5627 - mse: 16.5627\n",
      "Epoch 86/150\n",
      "71/71 [==============================] - 0s 645us/step - loss: 13.9566 - mse: 13.9566\n",
      "Epoch 87/150\n",
      "71/71 [==============================] - 0s 673us/step - loss: 11.3949 - mse: 11.3949\n",
      "Epoch 88/150\n",
      "71/71 [==============================] - 0s 766us/step - loss: 11.0183 - mse: 11.0183\n",
      "Epoch 89/150\n",
      "71/71 [==============================] - 0s 675us/step - loss: 10.8056 - mse: 10.8056\n",
      "Epoch 90/150\n",
      "71/71 [==============================] - 0s 663us/step - loss: 10.1831 - mse: 10.1831\n",
      "Epoch 91/150\n",
      "71/71 [==============================] - 0s 656us/step - loss: 10.3530 - mse: 10.3530\n",
      "Epoch 92/150\n",
      "71/71 [==============================] - 0s 661us/step - loss: 8.9297 - mse: 8.9297\n",
      "Epoch 93/150\n",
      "71/71 [==============================] - 0s 675us/step - loss: 8.2450 - mse: 8.2450\n",
      "Epoch 94/150\n",
      "71/71 [==============================] - 0s 684us/step - loss: 11.7437 - mse: 11.7437\n",
      "Epoch 95/150\n",
      "71/71 [==============================] - 0s 608us/step - loss: 12.7076 - mse: 12.7076\n",
      "Epoch 96/150\n",
      "71/71 [==============================] - 0s 611us/step - loss: 8.7561 - mse: 8.7561\n",
      "Epoch 97/150\n",
      "71/71 [==============================] - 0s 653us/step - loss: 9.0403 - mse: 9.0403\n",
      "Epoch 98/150\n",
      "71/71 [==============================] - 0s 879us/step - loss: 8.8738 - mse: 8.8738\n",
      "Epoch 99/150\n",
      "71/71 [==============================] - 0s 656us/step - loss: 7.2932 - mse: 7.2932\n",
      "Epoch 100/150\n",
      "71/71 [==============================] - 0s 622us/step - loss: 6.3081 - mse: 6.3081\n",
      "Epoch 101/150\n",
      "71/71 [==============================] - 0s 642us/step - loss: 6.8182 - mse: 6.8182\n",
      "Epoch 102/150\n",
      "71/71 [==============================] - 0s 652us/step - loss: 6.7973 - mse: 6.7973\n",
      "Epoch 103/150\n",
      "71/71 [==============================] - 0s 660us/step - loss: 7.2223 - mse: 7.2223\n",
      "Epoch 104/150\n",
      "71/71 [==============================] - 0s 633us/step - loss: 6.3376 - mse: 6.3376\n",
      "Epoch 105/150\n",
      "71/71 [==============================] - 0s 625us/step - loss: 5.5725 - mse: 5.5725\n",
      "Epoch 106/150\n",
      "71/71 [==============================] - 0s 626us/step - loss: 5.9929 - mse: 5.9929\n",
      "Epoch 107/150\n",
      "71/71 [==============================] - 0s 647us/step - loss: 4.4479 - mse: 4.4479\n",
      "Epoch 108/150\n",
      "71/71 [==============================] - 0s 711us/step - loss: 5.3428 - mse: 5.3428\n",
      "Epoch 109/150\n",
      "71/71 [==============================] - 0s 749us/step - loss: 6.5607 - mse: 6.5607\n",
      "Epoch 110/150\n",
      "71/71 [==============================] - 0s 738us/step - loss: 6.5738 - mse: 6.5738\n",
      "Epoch 111/150\n",
      "71/71 [==============================] - 0s 710us/step - loss: 5.9700 - mse: 5.9700\n",
      "Epoch 112/150\n",
      "71/71 [==============================] - 0s 700us/step - loss: 5.6163 - mse: 5.6163\n",
      "Epoch 113/150\n",
      "71/71 [==============================] - 0s 695us/step - loss: 4.8466 - mse: 4.8466\n",
      "Epoch 114/150\n",
      "71/71 [==============================] - 0s 658us/step - loss: 6.2834 - mse: 6.2834\n",
      "Epoch 115/150\n",
      "71/71 [==============================] - 0s 639us/step - loss: 4.3456 - mse: 4.3456\n",
      "Epoch 116/150\n",
      "71/71 [==============================] - 0s 682us/step - loss: 3.4893 - mse: 3.4893\n",
      "Epoch 117/150\n",
      "71/71 [==============================] - 0s 703us/step - loss: 3.9646 - mse: 3.9646\n",
      "Epoch 118/150\n",
      "71/71 [==============================] - 0s 696us/step - loss: 4.0579 - mse: 4.0579\n",
      "Epoch 119/150\n",
      "71/71 [==============================] - 0s 712us/step - loss: 3.4262 - mse: 3.4262\n",
      "Epoch 120/150\n",
      "71/71 [==============================] - 0s 756us/step - loss: 3.9010 - mse: 3.9010\n",
      "Epoch 121/150\n",
      "71/71 [==============================] - 0s 712us/step - loss: 3.7451 - mse: 3.7451\n",
      "Epoch 122/150\n",
      "71/71 [==============================] - 0s 703us/step - loss: 2.7568 - mse: 2.7568\n",
      "Epoch 123/150\n",
      "71/71 [==============================] - 0s 629us/step - loss: 3.9855 - mse: 3.9855\n",
      "Epoch 124/150\n",
      "71/71 [==============================] - 0s 648us/step - loss: 3.5115 - mse: 3.5115\n",
      "Epoch 125/150\n",
      "71/71 [==============================] - 0s 598us/step - loss: 3.3809 - mse: 3.3809\n",
      "Epoch 126/150\n",
      "71/71 [==============================] - 0s 607us/step - loss: 2.5908 - mse: 2.5908\n",
      "Epoch 127/150\n",
      "71/71 [==============================] - 0s 808us/step - loss: 3.8813 - mse: 3.8813\n",
      "Epoch 128/150\n",
      "71/71 [==============================] - 0s 768us/step - loss: 3.4871 - mse: 3.4871\n",
      "Epoch 129/150\n",
      "71/71 [==============================] - 0s 787us/step - loss: 3.8307 - mse: 3.8307\n",
      "Epoch 130/150\n",
      "71/71 [==============================] - 0s 699us/step - loss: 2.5508 - mse: 2.5508\n",
      "Epoch 131/150\n",
      "71/71 [==============================] - 0s 682us/step - loss: 1.9504 - mse: 1.9504\n",
      "Epoch 132/150\n",
      "71/71 [==============================] - 0s 747us/step - loss: 2.3867 - mse: 2.3867\n",
      "Epoch 133/150\n",
      "71/71 [==============================] - 0s 670us/step - loss: 2.7278 - mse: 2.7278\n",
      "Epoch 134/150\n",
      "71/71 [==============================] - 0s 628us/step - loss: 2.1662 - mse: 2.1662\n",
      "Epoch 135/150\n",
      "71/71 [==============================] - 0s 694us/step - loss: 2.0229 - mse: 2.0229\n",
      "Epoch 136/150\n",
      "71/71 [==============================] - 0s 743us/step - loss: 2.3200 - mse: 2.3200\n",
      "Epoch 137/150\n",
      "71/71 [==============================] - 0s 707us/step - loss: 2.1289 - mse: 2.1289\n",
      "Epoch 138/150\n",
      "71/71 [==============================] - 0s 683us/step - loss: 1.6958 - mse: 1.6958\n",
      "Epoch 139/150\n",
      "71/71 [==============================] - 0s 664us/step - loss: 1.5407 - mse: 1.5407\n",
      "Epoch 140/150\n",
      "71/71 [==============================] - 0s 685us/step - loss: 1.9215 - mse: 1.9215\n",
      "Epoch 141/150\n",
      "71/71 [==============================] - 0s 745us/step - loss: 2.4950 - mse: 2.4950\n",
      "Epoch 142/150\n",
      "71/71 [==============================] - 0s 672us/step - loss: 1.4258 - mse: 1.4258\n",
      "Epoch 143/150\n",
      "71/71 [==============================] - 0s 698us/step - loss: 2.3394 - mse: 2.3394\n",
      "Epoch 144/150\n",
      "71/71 [==============================] - 0s 651us/step - loss: 1.4751 - mse: 1.4751\n",
      "Epoch 145/150\n",
      "71/71 [==============================] - 0s 673us/step - loss: 2.1425 - mse: 2.1425\n",
      "Epoch 146/150\n",
      "71/71 [==============================] - 0s 602us/step - loss: 1.9264 - mse: 1.9264\n",
      "Epoch 147/150\n",
      "71/71 [==============================] - 0s 652us/step - loss: 1.9433 - mse: 1.9433\n",
      "Epoch 148/150\n",
      "71/71 [==============================] - 0s 655us/step - loss: 1.8198 - mse: 1.8198\n",
      "Epoch 149/150\n",
      "71/71 [==============================] - 0s 686us/step - loss: 2.4050 - mse: 2.4050\n",
      "Epoch 150/150\n",
      "71/71 [==============================] - 0s 698us/step - loss: 1.5227 - mse: 1.5227\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fae868728b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 169.2167 - mse: 169.2167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[169.21673583984375, 169.21673583984375]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=150, batch_size=4)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 32)                1344      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,433\n",
      "Trainable params: 2,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for t,p in zip(y_train,y_train_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for t,p in zip(y_test,y_test_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#오차 범위 3 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set prediction accuracy: 50.89 %\n",
      "test set prediction accuracy: 56.34 %\n"
     ]
    }
   ],
   "source": [
    "#평균 성능 테스트\n",
    "scores = 0\n",
    "mean=np.mean(Y, axis=0)\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= mean <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"train set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= mean <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"test set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### <오차범위 3>\n",
      "- train set prediction accuracy(+-3): 94.31 % <br>\n",
      "- test set prediction accuracy(+-3): 22.54 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 5>\n",
      "- train set prediction accuracy(+-5): 98.58 % <br>\n",
      "- test set prediction accuracy(+-5): 28.17 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 10>\n",
      "- train set prediction accuracy(+-10): 100.00 % <br>\n",
      "- test set prediction accuracy(+-10): 50.70 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 20>\n",
      "- train set prediction accuracy(+-20): 100.00 % <br>\n",
      "- test set prediction accuracy(+-20): 83.10 % <br>\n"
     ]
    }
   ],
   "source": [
    "######입력용#######\n",
    "\n",
    "#오차 범위 3 설정\n",
    "print('### <오차범위 3>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "print('### <오차범위 5>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "print('### <오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "print('### <오차범위 20>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## psqi 각 항목 안넣은거 /(462)\n",
    "### <오차범위 3>\n",
    "- train set prediction accuracy(+-3): 36.57 % <br>\n",
    "- test set prediction accuracy(+-3): 30.77 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 5>\n",
    "- train set prediction accuracy(+-5): 57.62 % <br>\n",
    "- test set prediction accuracy(+-5): 47.25 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 10>\"\n",
    "- train set prediction accuracy(+-10): 85.04 % <br>\n",
    "- test set prediction accuracy(+-10): 67.03 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 20>\n",
    "- train set prediction accuracy(+-20): 99.45 % <br>\n",
    "- test set prediction accuracy(+-20): 89.01 % <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## psqi 각 항목 넣은거 /(352)\n",
    "\n",
    "### <오차범위 3>\n",
    "- train set prediction accuracy(+-3): 94.31 % <br>\n",
    "- test set prediction accuracy(+-3): 22.54 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 5>\n",
    "- train set prediction accuracy(+-5): 98.58 % <br>\n",
    "- test set prediction accuracy(+-5): 28.17 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 10>\n",
    "- train set prediction accuracy(+-10): 100.00 % <br>\n",
    "- test set prediction accuracy(+-10): 50.70 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 20>\n",
    "- train set prediction accuracy(+-20): 100.00 % <br>\n",
    "- test set prediction accuracy(+-20): 83.10 % <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

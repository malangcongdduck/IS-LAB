{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FONT 깨질때 폰트깨질때\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname = \"C:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font',family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sample_ID GROUP  COHORT SEX  AGE     Trait FitbitOX      Fitbit_ID  HTN  \\\n",
      "0         S0001   SMI       2   M   60  fitbit_O        O  sevrance00001  NaN   \n",
      "1         S0002   SMI       2   M   61  fitbit_O        O  sevrance00002  NaN   \n",
      "2         S0003   SMI       2   F   52  fitbit_O        O  sevrance00003  NaN   \n",
      "3         S0004   SMI       2   F   41  fitbit_O        O  sevrance00004  NaN   \n",
      "4         S0005   SMI       2   F   41  fitbit_O        O  sevrance00005  NaN   \n",
      "..          ...   ...     ...  ..  ...       ...      ...            ...  ...   \n",
      "383  MetS_S0280  MetS       1   F   24  fitbit_O        O   gnfmmets+139  NaN   \n",
      "384  MetS_S0281  MetS       1   F   44  fitbit_O        O   gnfmmets+140  NaN   \n",
      "385  MetS_S0282  MetS       1   F   37  fitbit_O        O   gnfmmets+141  1.0   \n",
      "386  MetS_S0283  MetS       1   M   51  fitbit_X        X              X  NaN   \n",
      "387  MetS_S0284  MetS       1   F   42  fitbit_X        X              X  NaN   \n",
      "\n",
      "      DM  ...  BDI_Q13_2 BDI_Q14_2  BDI_Q15_2  BDI_Q16_2 BDI_Q17_2 BDI_Q18_2  \\\n",
      "0    NaN  ...        1.0       1.0        1.0        2.0       1.0       1.0   \n",
      "1    1.0  ...        1.0       1.0        1.0        1.0       2.0       1.0   \n",
      "2    NaN  ...        1.0       1.0        1.0        1.0       1.0       1.0   \n",
      "3    NaN  ...        2.0       2.0        2.0        2.0       2.0       2.0   \n",
      "4    NaN  ...        2.0       1.0        2.0        2.0       2.0       1.0   \n",
      "..   ...  ...        ...       ...        ...        ...       ...       ...   \n",
      "383  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "384  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "385  1.0  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "386  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "387  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "\n",
      "     BDI_Q19_2  BDI_Q20_2  BDI_Q21_2  Diet_2  \n",
      "0          2.0        1.0        2.0     2.0  \n",
      "1          1.0        1.0        1.0     2.0  \n",
      "2          1.0        2.0        4.0     1.0  \n",
      "3          1.0        1.0        1.0     2.0  \n",
      "4          1.0        2.0        1.0     2.0  \n",
      "..         ...        ...        ...     ...  \n",
      "383        NaN        NaN        NaN     NaN  \n",
      "384        NaN        NaN        NaN     NaN  \n",
      "385        NaN        NaN        NaN     NaN  \n",
      "386        NaN        NaN        NaN     NaN  \n",
      "387        NaN        NaN        NaN     NaN  \n",
      "\n",
      "[388 rows x 3527 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('./최종 데이터 그래프그리기용.xlsx') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df=df[['Sample_ID','GROUP','COHORT','SEX','AGE','Insulin _1','FatPercentage _1','TG_1','BMI_1','AST_1','BUN_1','HDL_1','DBP_1','Waist_1','SBP_1','Fat_1_x','LDL_1',\n",
    "            'PSQI_TOTAL_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1',\n",
    "              'Insulin _2','FatPercentage_2','TG_2','BMI_2','AST_2','BUN_2','HDL_2','DBP_2','Waist_2','SBP_2','Fat_2_x','LDL_2',\n",
    "            'PSQI_TOTAL_2','PSQI_C1_2','PSQI_C2_2','PSQI_C3_2','PSQI_C4_2','PSQI_C5_2','PSQI_C6_2','PSQI_C7_2','PSQI_Q1_2','PSQI_Q2_2','PSQI_Q3_2','PSQI_Q4_2',\n",
    "            'PSQI_Q5a_2','PSQI_Q5b_2','PSQI_Q5c_2','PSQI_Q5d_2','PSQI_Q5e_2','PSQI_Q5f_2','PSQI_Q5g_2','PSQI_Q5h_2','PSQI_Q5i_2','PSQI_Q5j_2','PSQI_Q6_2','PSQI_Q7_2','PSQI_Q8_2','PSQI_Q9_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>FatPercentage _1</th>\n",
       "      <th>TG_1</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>AST_1</th>\n",
       "      <th>...</th>\n",
       "      <th>PSQI_Q5e_2</th>\n",
       "      <th>PSQI_Q5f_2</th>\n",
       "      <th>PSQI_Q5g_2</th>\n",
       "      <th>PSQI_Q5h_2</th>\n",
       "      <th>PSQI_Q5i_2</th>\n",
       "      <th>PSQI_Q5j_2</th>\n",
       "      <th>PSQI_Q6_2</th>\n",
       "      <th>PSQI_Q7_2</th>\n",
       "      <th>PSQI_Q8_2</th>\n",
       "      <th>PSQI_Q9_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>60</td>\n",
       "      <td>7.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>81</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>61</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.5</td>\n",
       "      <td>106</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>5.1</td>\n",
       "      <td>39.1</td>\n",
       "      <td>231</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>4.2</td>\n",
       "      <td>29.1</td>\n",
       "      <td>94</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>3.2</td>\n",
       "      <td>24.6</td>\n",
       "      <td>70</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>24</td>\n",
       "      <td>11.3</td>\n",
       "      <td>34.4</td>\n",
       "      <td>51</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>44</td>\n",
       "      <td>10.6</td>\n",
       "      <td>43.8</td>\n",
       "      <td>104</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>12.2</td>\n",
       "      <td>35.8</td>\n",
       "      <td>128</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>10.4</td>\n",
       "      <td>26.8</td>\n",
       "      <td>163</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>42</td>\n",
       "      <td>10.1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>90</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT SEX  AGE Insulin _1  FatPercentage _1  TG_1  \\\n",
       "0         S0001   SMI       2   M   60        7.7              15.0    81   \n",
       "1         S0002   SMI       2   M   61        5.4              29.5   106   \n",
       "2         S0003   SMI       2   F   52        5.1              39.1   231   \n",
       "3         S0004   SMI       2   F   41        4.2              29.1    94   \n",
       "4         S0005   SMI       2   F   41        3.2              24.6    70   \n",
       "..          ...   ...     ...  ..  ...        ...               ...   ...   \n",
       "383  MetS_S0280  MetS       1   F   24       11.3              34.4    51   \n",
       "384  MetS_S0281  MetS       1   F   44       10.6              43.8   104   \n",
       "385  MetS_S0282  MetS       1   F   37       12.2              35.8   128   \n",
       "386  MetS_S0283  MetS       1   M   51       10.4              26.8   163   \n",
       "387  MetS_S0284  MetS       1   F   42       10.1              32.6    90   \n",
       "\n",
       "         BMI_1  AST_1  ...  PSQI_Q5e_2  PSQI_Q5f_2  PSQI_Q5g_2  PSQI_Q5h_2  \\\n",
       "0    21.110190   21.0  ...         0.0         0.0         0.0         1.0   \n",
       "1    27.782064   29.0  ...         3.0         0.0         2.0         0.0   \n",
       "2    24.944742   16.0  ...         3.0         0.0         3.0         0.0   \n",
       "3    22.620489   16.0  ...         1.0         0.0         0.0         0.0   \n",
       "4    20.524157   26.0  ...         0.0         0.0         0.0         1.0   \n",
       "..         ...    ...  ...         ...         ...         ...         ...   \n",
       "383  34.803410   14.0  ...         NaN         NaN         NaN         NaN   \n",
       "384  30.903615   27.0  ...         NaN         NaN         NaN         NaN   \n",
       "385  28.676533   61.0  ...         NaN         NaN         NaN         NaN   \n",
       "386  24.549738   81.0  ...         NaN         NaN         NaN         NaN   \n",
       "387  24.605921   32.0  ...         NaN         NaN         NaN         NaN   \n",
       "\n",
       "     PSQI_Q5i_2  PSQI_Q5j_2  PSQI_Q6_2  PSQI_Q7_2  PSQI_Q8_2  PSQI_Q9_2  \n",
       "0           0.0         0.0        1.0        0.0        1.0        0.0  \n",
       "1           0.0         0.0        1.0        0.0        2.0        1.0  \n",
       "2           0.0         0.0        1.0        0.0        2.0        0.0  \n",
       "3           0.0         0.0        1.0        0.0        2.0        1.0  \n",
       "4           1.0         1.0        3.0        0.0        2.0        1.0  \n",
       "..          ...         ...        ...        ...        ...        ...  \n",
       "383         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "384         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "385         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "386         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "387         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "\n",
       "[388 rows x 81 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>FatPercentage _1</th>\n",
       "      <th>TG_1</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>AST_1</th>\n",
       "      <th>...</th>\n",
       "      <th>PSQI_Q5e_2</th>\n",
       "      <th>PSQI_Q5f_2</th>\n",
       "      <th>PSQI_Q5g_2</th>\n",
       "      <th>PSQI_Q5h_2</th>\n",
       "      <th>PSQI_Q5i_2</th>\n",
       "      <th>PSQI_Q5j_2</th>\n",
       "      <th>PSQI_Q6_2</th>\n",
       "      <th>PSQI_Q7_2</th>\n",
       "      <th>PSQI_Q8_2</th>\n",
       "      <th>PSQI_Q9_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>60</td>\n",
       "      <td>7.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>81</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>61</td>\n",
       "      <td>5.4</td>\n",
       "      <td>29.5</td>\n",
       "      <td>106</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>52</td>\n",
       "      <td>5.1</td>\n",
       "      <td>39.1</td>\n",
       "      <td>231</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>4.2</td>\n",
       "      <td>29.1</td>\n",
       "      <td>94</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>3.2</td>\n",
       "      <td>24.6</td>\n",
       "      <td>70</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>24</td>\n",
       "      <td>11.3</td>\n",
       "      <td>34.4</td>\n",
       "      <td>51</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>44</td>\n",
       "      <td>10.6</td>\n",
       "      <td>43.8</td>\n",
       "      <td>104</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>12.2</td>\n",
       "      <td>35.8</td>\n",
       "      <td>128</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>61.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>51</td>\n",
       "      <td>10.4</td>\n",
       "      <td>26.8</td>\n",
       "      <td>163</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>81.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>42</td>\n",
       "      <td>10.1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>90</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>32.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT SEX  AGE Insulin _1  FatPercentage _1  TG_1  \\\n",
       "0         S0001   SMI       2   M   60        7.7              15.0    81   \n",
       "1         S0002   SMI       2   M   61        5.4              29.5   106   \n",
       "2         S0003   SMI       2   F   52        5.1              39.1   231   \n",
       "3         S0004   SMI       2   F   41        4.2              29.1    94   \n",
       "4         S0005   SMI       2   F   41        3.2              24.6    70   \n",
       "..          ...   ...     ...  ..  ...        ...               ...   ...   \n",
       "383  MetS_S0280  MetS       1   F   24       11.3              34.4    51   \n",
       "384  MetS_S0281  MetS       1   F   44       10.6              43.8   104   \n",
       "385  MetS_S0282  MetS       1   F   37       12.2              35.8   128   \n",
       "386  MetS_S0283  MetS       1   M   51       10.4              26.8   163   \n",
       "387  MetS_S0284  MetS       1   F   42       10.1              32.6    90   \n",
       "\n",
       "         BMI_1  AST_1  ...  PSQI_Q5e_2  PSQI_Q5f_2  PSQI_Q5g_2  PSQI_Q5h_2  \\\n",
       "0    21.110190   21.0  ...         0.0         0.0         0.0         1.0   \n",
       "1    27.782064   29.0  ...         3.0         0.0         2.0         0.0   \n",
       "2    24.944742   16.0  ...         3.0         0.0         3.0         0.0   \n",
       "3    22.620489   16.0  ...         1.0         0.0         0.0         0.0   \n",
       "4    20.524157   26.0  ...         0.0         0.0         0.0         1.0   \n",
       "..         ...    ...  ...         ...         ...         ...         ...   \n",
       "383  34.803410   14.0  ...         NaN         NaN         NaN         NaN   \n",
       "384  30.903615   27.0  ...         NaN         NaN         NaN         NaN   \n",
       "385  28.676533   61.0  ...         NaN         NaN         NaN         NaN   \n",
       "386  24.549738   81.0  ...         NaN         NaN         NaN         NaN   \n",
       "387  24.605921   32.0  ...         NaN         NaN         NaN         NaN   \n",
       "\n",
       "     PSQI_Q5i_2  PSQI_Q5j_2  PSQI_Q6_2  PSQI_Q7_2  PSQI_Q8_2  PSQI_Q9_2  \n",
       "0           0.0         0.0        1.0        0.0        1.0        0.0  \n",
       "1           0.0         0.0        1.0        0.0        2.0        1.0  \n",
       "2           0.0         0.0        1.0        0.0        2.0        0.0  \n",
       "3           0.0         0.0        1.0        0.0        2.0        1.0  \n",
       "4           1.0         1.0        3.0        0.0        2.0        1.0  \n",
       "..          ...         ...        ...        ...        ...        ...  \n",
       "383         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "384         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "385         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "386         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "387         NaN         NaN        NaN        NaN        NaN        NaN  \n",
       "\n",
       "[317 rows x 81 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#보조 호르몬 요법을 받고 있는 Cohort 3 제거 Filter 적용\n",
    "psqi_df = psqi_df[(psqi_df['COHORT'] != 3)]\n",
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df=psqi_df.dropna()\n",
    "psqi_df.reset_index(drop=True, inplace=True)\n",
    "psqi_df.isnull().sum()\n",
    "psqi_df=psqi_df.drop([\"Sample_ID\", \"GROUP\", \"COHORT\"],axis=1)\n",
    "#1분, 매일다름, 정해진간이없음 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"SEX\"] = psqi_df[\"SEX\"].apply(lambda x: 1. if x=='M' else 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"Insulin _1\"] = psqi_df[\"Insulin _1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)\n",
    "psqi_df[\"Insulin _2\"] = psqi_df[\"Insulin _1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (x=임의+선별)\n",
    "#선별: 'AGE','HDL_1','DBP_1','Waist_1','SBP_1','Fat_1_x','Insulin _1','FatPercentage _1','LDL_1','AST_1','BUN_1'\n",
    "X1=psqi_df[['AGE','HDL_1','DBP_1','Waist_1','SBP_1','Fat_1_x','Insulin _1','FatPercentage _1','AST_1','BUN_1','BMI_1','LDL_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','HDL_2','DBP_2','Waist_2','SBP_2','Fat_2_x','Insulin _2','FatPercentage_2','AST_2','BUN_2','BMI_2','LDL_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=TG)\n",
    "Y1= psqi_df[['TG_1']].values\n",
    "Y2= psqi_df[['TG_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (x=임의+선별+PSQI)\n",
    "X1=psqi_df[['AGE','HDL_1','DBP_1','Waist_1','Insulin _1','SBP_1','Fat_1_x','LDL_1','FatPercentage _1','AST_1','BUN_1','BMI_1',\n",
    "            'PSQI_TOTAL_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','HDL_2','DBP_2','Waist_2','Insulin _2','SBP_2','Fat_2_x','LDL_2','FatPercentage_2','AST_2','BUN_2','BMI_2',\n",
    "            'PSQI_TOTAL_2','PSQI_C1_2','PSQI_C2_2','PSQI_C3_2','PSQI_C4_2','PSQI_C5_2','PSQI_C6_2','PSQI_C7_2','PSQI_Q1_2','PSQI_Q2_2','PSQI_Q3_2','PSQI_Q4_2',\n",
    "            'PSQI_Q5a_2','PSQI_Q5b_2','PSQI_Q5c_2','PSQI_Q5d_2','PSQI_Q5e_2','PSQI_Q5f_2','PSQI_Q5g_2','PSQI_Q5h_2','PSQI_Q5i_2','PSQI_Q5j_2','PSQI_Q6_2','PSQI_Q7_2','PSQI_Q8_2','PSQI_Q9_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=TG)\n",
    "Y1= psqi_df[['TG_1']].values\n",
    "Y2= psqi_df[['TG_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (x=AGE, SEX, PSQI, BMI, Waist, Fat, FatPercentage)\n",
    "X1=psqi_df[['AGE','SEX','BMI_1','Waist_1','Fat_1_x','FatPercentage _1',\n",
    "           'PSQI_TOTAL_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','SEX','BMI_2','Waist_2','Fat_2_x','FatPercentage_2',\n",
    "           'PSQI_TOTAL_1','PSQI_C1_1','PSQI_C2_1','PSQI_C3_1','PSQI_C4_1','PSQI_C5_1','PSQI_C6_1','PSQI_C7_1','PSQI_Q1_1','PSQI_Q2_1','PSQI_Q3_1','PSQI_Q4_1',\n",
    "            'PSQI_Q5a_1','PSQI_Q5b_1','PSQI_Q5c_1','PSQI_Q5d_1','PSQI_Q5e_1','PSQI_Q5f_1','PSQI_Q5g_1','PSQI_Q5h_1','PSQI_Q5i_1','PSQI_Q5j_1','PSQI_Q6_1','PSQI_Q7_1','PSQI_Q8_1','PSQI_Q9_1']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=TG)\n",
    "Y1= psqi_df[['TG_1']].values\n",
    "Y2= psqi_df[['TG_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(352, 352)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((352, 38), (352, 1))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((352, 38), (352, 1))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "71/71 [==============================] - 0s 732us/step - loss: 17149.2891 - mse: 17149.2891\n",
      "Epoch 2/100\n",
      "71/71 [==============================] - 0s 741us/step - loss: 15956.4199 - mse: 15956.4199\n",
      "Epoch 3/100\n",
      "71/71 [==============================] - 0s 749us/step - loss: 14073.7637 - mse: 14073.7637\n",
      "Epoch 4/100\n",
      "71/71 [==============================] - 0s 684us/step - loss: 11633.6152 - mse: 11633.6152\n",
      "Epoch 5/100\n",
      "71/71 [==============================] - 0s 841us/step - loss: 8834.2646 - mse: 8834.2646\n",
      "Epoch 6/100\n",
      "71/71 [==============================] - 0s 784us/step - loss: 6843.4976 - mse: 6843.4976\n",
      "Epoch 7/100\n",
      "71/71 [==============================] - 0s 698us/step - loss: 6024.6709 - mse: 6024.6709\n",
      "Epoch 8/100\n",
      "71/71 [==============================] - 0s 684us/step - loss: 5601.7817 - mse: 5601.7817\n",
      "Epoch 9/100\n",
      "71/71 [==============================] - 0s 657us/step - loss: 5377.3384 - mse: 5377.3384\n",
      "Epoch 10/100\n",
      "71/71 [==============================] - 0s 615us/step - loss: 5213.4131 - mse: 5213.4131\n",
      "Epoch 11/100\n",
      "71/71 [==============================] - 0s 641us/step - loss: 5022.5327 - mse: 5022.5327\n",
      "Epoch 12/100\n",
      "71/71 [==============================] - 0s 773us/step - loss: 4961.9722 - mse: 4961.9722\n",
      "Epoch 13/100\n",
      "71/71 [==============================] - 0s 741us/step - loss: 4829.8643 - mse: 4829.8643\n",
      "Epoch 14/100\n",
      "71/71 [==============================] - 0s 712us/step - loss: 4717.3613 - mse: 4717.3613\n",
      "Epoch 15/100\n",
      "71/71 [==============================] - 0s 698us/step - loss: 4674.4492 - mse: 4674.4492\n",
      "Epoch 16/100\n",
      "71/71 [==============================] - 0s 812us/step - loss: 4600.1206 - mse: 4600.1206\n",
      "Epoch 17/100\n",
      "71/71 [==============================] - 0s 784us/step - loss: 4567.8374 - mse: 4567.8374\n",
      "Epoch 18/100\n",
      "71/71 [==============================] - 0s 790us/step - loss: 4527.4287 - mse: 4527.4287\n",
      "Epoch 19/100\n",
      "71/71 [==============================] - 0s 741us/step - loss: 4511.0083 - mse: 4511.0083\n",
      "Epoch 20/100\n",
      "71/71 [==============================] - 0s 684us/step - loss: 4450.7769 - mse: 4450.7769\n",
      "Epoch 21/100\n",
      "71/71 [==============================] - 0s 826us/step - loss: 4399.6909 - mse: 4399.6909\n",
      "Epoch 22/100\n",
      "71/71 [==============================] - 0s 826us/step - loss: 4351.2461 - mse: 4351.2461\n",
      "Epoch 23/100\n",
      "71/71 [==============================] - 0s 798us/step - loss: 4340.7539 - mse: 4340.7539\n",
      "Epoch 24/100\n",
      "71/71 [==============================] - 0s 698us/step - loss: 4323.8281 - mse: 4323.8281\n",
      "Epoch 25/100\n",
      "71/71 [==============================] - 0s 741us/step - loss: 4283.9922 - mse: 4283.9922\n",
      "Epoch 26/100\n",
      "71/71 [==============================] - 0s 793us/step - loss: 4262.8740 - mse: 4262.8740\n",
      "Epoch 27/100\n",
      "71/71 [==============================] - 0s 955us/step - loss: 4211.8145 - mse: 4211.8145\n",
      "Epoch 28/100\n",
      "71/71 [==============================] - 0s 826us/step - loss: 4173.1626 - mse: 4173.1626\n",
      "Epoch 29/100\n",
      "71/71 [==============================] - 0s 882us/step - loss: 4150.1299 - mse: 4150.1299\n",
      "Epoch 30/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 4143.3926 - mse: 4143.3926\n",
      "Epoch 31/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 4086.5103 - mse: 4086.5103\n",
      "Epoch 32/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 4145.1885 - mse: 4145.1885\n",
      "Epoch 33/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 4084.9128 - mse: 4084.9128\n",
      "Epoch 34/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 4050.7939 - mse: 4050.7939 0s - loss: 5839.9746 - mse: 5839.974\n",
      "Epoch 35/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 4058.0881 - mse: 4058.0881\n",
      "Epoch 36/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 4041.4373 - mse: 4041.4373\n",
      "Epoch 37/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 4000.8616 - mse: 4000.8616\n",
      "Epoch 38/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 4025.9551 - mse: 4025.9551\n",
      "Epoch 39/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3995.5840 - mse: 3995.5840\n",
      "Epoch 40/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3911.6487 - mse: 3911.6487\n",
      "Epoch 41/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3949.1943 - mse: 3949.1943\n",
      "Epoch 42/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3916.2661 - mse: 3916.2661\n",
      "Epoch 43/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3887.3831 - mse: 3887.3831\n",
      "Epoch 44/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3861.2385 - mse: 3861.2385\n",
      "Epoch 45/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3848.8533 - mse: 3848.8533\n",
      "Epoch 46/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3890.4155 - mse: 3890.4155\n",
      "Epoch 47/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3843.2869 - mse: 3843.2869\n",
      "Epoch 48/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3804.3257 - mse: 3804.3257\n",
      "Epoch 49/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3821.5107 - mse: 3821.5107\n",
      "Epoch 50/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3776.0432 - mse: 3776.0432\n",
      "Epoch 51/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3734.7012 - mse: 3734.7012\n",
      "Epoch 52/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3766.7236 - mse: 3766.7236\n",
      "Epoch 53/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3728.1309 - mse: 3728.1309\n",
      "Epoch 54/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3741.0662 - mse: 3741.0662\n",
      "Epoch 55/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3708.5786 - mse: 3708.5786\n",
      "Epoch 56/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3660.5049 - mse: 3660.5049\n",
      "Epoch 57/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3680.4446 - mse: 3680.4446\n",
      "Epoch 58/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3662.6326 - mse: 3662.6326\n",
      "Epoch 59/100\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 3640.2727 - mse: 3640.2727\n",
      "Epoch 60/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3584.3938 - mse: 3584.3938\n",
      "Epoch 61/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3621.5652 - mse: 3621.5652\n",
      "Epoch 62/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3517.6487 - mse: 3517.6487\n",
      "Epoch 63/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3601.2849 - mse: 3601.2849\n",
      "Epoch 64/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3566.7759 - mse: 3566.7759\n",
      "Epoch 65/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3568.9719 - mse: 3568.9719\n",
      "Epoch 66/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3577.6138 - mse: 3577.6138\n",
      "Epoch 67/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3547.0776 - mse: 3547.0776\n",
      "Epoch 68/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3538.0295 - mse: 3538.0295\n",
      "Epoch 69/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3486.9299 - mse: 3486.9299\n",
      "Epoch 70/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3509.4446 - mse: 3509.4446\n",
      "Epoch 71/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3456.6111 - mse: 3456.6111\n",
      "Epoch 72/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3465.6670 - mse: 3465.6670\n",
      "Epoch 73/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3470.3962 - mse: 3470.3962\n",
      "Epoch 74/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3437.1313 - mse: 3437.1313\n",
      "Epoch 75/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3396.7910 - mse: 3396.7910\n",
      "Epoch 76/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3474.9329 - mse: 3474.9329\n",
      "Epoch 77/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3384.1594 - mse: 3384.1594\n",
      "Epoch 78/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3360.0881 - mse: 3360.0881\n",
      "Epoch 79/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3349.8809 - mse: 3349.8809\n",
      "Epoch 80/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3297.1790 - mse: 3297.1790\n",
      "Epoch 81/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3322.5488 - mse: 3322.5488\n",
      "Epoch 82/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3299.2793 - mse: 3299.2793\n",
      "Epoch 83/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3280.2185 - mse: 3280.2185\n",
      "Epoch 84/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3274.5862 - mse: 3274.5862\n",
      "Epoch 85/100\n",
      "71/71 [==============================] - 0s 976us/step - loss: 3282.5442 - mse: 3282.5442\n",
      "Epoch 86/100\n",
      "71/71 [==============================] - 0s 969us/step - loss: 3263.1213 - mse: 3263.1213\n",
      "Epoch 87/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3228.4438 - mse: 3228.4438\n",
      "Epoch 88/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3220.0376 - mse: 3220.0376\n",
      "Epoch 89/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3208.0588 - mse: 3208.0588\n",
      "Epoch 90/100\n",
      "71/71 [==============================] - 0s 942us/step - loss: 3207.1924 - mse: 3207.1924\n",
      "Epoch 91/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3206.9014 - mse: 3206.9014\n",
      "Epoch 92/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3193.5088 - mse: 3193.5088\n",
      "Epoch 93/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3169.6897 - mse: 3169.6897\n",
      "Epoch 94/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3172.5579 - mse: 3172.5579\n",
      "Epoch 95/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3140.0972 - mse: 3140.0972\n",
      "Epoch 96/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3149.4639 - mse: 3149.4639\n",
      "Epoch 97/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3124.4338 - mse: 3124.4338\n",
      "Epoch 98/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3146.9705 - mse: 3146.9705\n",
      "Epoch 99/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3067.9041 - mse: 3067.9041\n",
      "Epoch 100/100\n",
      "71/71 [==============================] - 0s 1ms/step - loss: 3114.9277 - mse: 3114.9277\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2361.6438 - mse: 2361.6438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2361.643798828125, 2361.643798828125]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=100, batch_size=4)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 32)                1248      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,337\n",
      "Trainable params: 2,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56.] [60.987896]\n",
      "[63.] [52.725574]\n",
      "[77.] [139.17744]\n",
      "[113.] [122.825264]\n",
      "[210.] [188.61406]\n",
      "[241.] [239.01125]\n",
      "[72.] [114.87356]\n",
      "[114.] [89.96656]\n",
      "[46.] [102.20816]\n",
      "[62.] [79.70579]\n",
      "[56.] [56.84406]\n",
      "[81.] [87.66238]\n",
      "[42.] [55.052357]\n",
      "[56.] [67.17216]\n",
      "[214.] [183.75125]\n",
      "[46.] [70.98127]\n",
      "[68.] [111.919014]\n",
      "[98.] [96.212074]\n",
      "[49.] [52.518547]\n",
      "[47.] [66.48894]\n",
      "[141.] [140.96758]\n",
      "[86.] [71.6379]\n",
      "[124.] [167.24738]\n",
      "[252.] [172.59749]\n",
      "[109.] [116.09988]\n",
      "[50.] [50.715504]\n",
      "[86.] [85.808174]\n",
      "[45.] [70.58448]\n",
      "[234.] [190.19778]\n",
      "[62.] [169.30132]\n",
      "[98.] [96.26879]\n",
      "[134.] [121.55467]\n",
      "[85.] [92.73955]\n",
      "[125.] [89.5149]\n",
      "[203.] [142.27347]\n",
      "[51.] [41.662205]\n",
      "[148.] [191.50667]\n",
      "[599.] [238.23505]\n",
      "[56.] [47.976074]\n",
      "[53.] [54.641163]\n",
      "[104.] [106.246376]\n",
      "[125.] [114.062515]\n",
      "[47.] [71.78571]\n",
      "[64.] [88.76356]\n",
      "[281.] [185.47752]\n",
      "[147.] [146.89534]\n",
      "[56.] [67.11622]\n",
      "[91.] [85.50733]\n",
      "[90.] [98.47013]\n",
      "[51.] [48.771957]\n",
      "[61.] [75.93119]\n",
      "[176.] [179.4952]\n",
      "[215.] [163.85866]\n",
      "[92.] [95.48374]\n",
      "[60.] [75.732086]\n",
      "[96.] [63.189346]\n",
      "[87.] [99.86259]\n",
      "[127.] [112.75679]\n",
      "[72.] [88.810295]\n",
      "[54.] [64.624146]\n",
      "[177.] [159.11272]\n",
      "[76.] [96.09586]\n",
      "[61.] [59.267612]\n",
      "[134.] [103.789406]\n",
      "[72.] [92.20939]\n",
      "[47.] [77.497925]\n",
      "[76.] [94.5507]\n",
      "[65.] [78.11341]\n",
      "[69.] [127.090775]\n",
      "[44.] [74.341]\n",
      "[61.] [70.56125]\n",
      "[88.] [96.245964]\n",
      "[158.] [122.6029]\n",
      "[71.] [130.96408]\n",
      "[120.] [106.62199]\n",
      "[56.] [92.89201]\n",
      "[111.] [108.5994]\n",
      "[137.] [133.32512]\n",
      "[74.] [72.01834]\n",
      "[61.] [69.65425]\n",
      "[46.] [29.024426]\n",
      "[75.] [49.732006]\n",
      "[185.] [180.48286]\n",
      "[62.] [63.996655]\n",
      "[87.] [72.45787]\n",
      "[139.] [135.02388]\n",
      "[84.] [103.31667]\n",
      "[56.] [43.39567]\n",
      "[78.] [179.39111]\n",
      "[186.] [144.77635]\n",
      "[97.] [102.11141]\n",
      "[104.] [90.503395]\n",
      "[197.] [101.08048]\n",
      "[72.] [68.98167]\n",
      "[57.] [63.024593]\n",
      "[105.] [144.36377]\n",
      "[61.] [70.44018]\n",
      "[57.] [78.880226]\n",
      "[61.] [124.55101]\n",
      "[57.] [67.30268]\n",
      "[204.] [179.34631]\n",
      "[88.] [121.556816]\n",
      "[82.] [104.21836]\n",
      "[80.] [74.57685]\n",
      "[44.] [59.835438]\n",
      "[48.] [73.177]\n",
      "[88.] [89.9204]\n",
      "[145.] [141.59007]\n",
      "[214.] [165.95863]\n",
      "[74.] [106.98202]\n",
      "[137.] [154.14024]\n",
      "[56.] [74.81866]\n",
      "[180.] [164.24693]\n",
      "[121.] [180.58012]\n",
      "[208.] [211.8629]\n",
      "[62.] [50.05672]\n",
      "[120.] [177.39915]\n",
      "[113.] [113.67661]\n",
      "[72.] [117.03779]\n",
      "[62.] [65.63699]\n",
      "[114.] [128.9034]\n",
      "[90.] [82.505585]\n",
      "[46.] [44.342075]\n",
      "[97.] [112.30384]\n",
      "[196.] [189.63353]\n",
      "[147.] [142.66449]\n",
      "[114.] [108.39123]\n",
      "[106.] [134.63777]\n",
      "[72.] [67.86329]\n",
      "[208.] [209.49443]\n",
      "[168.] [178.36821]\n",
      "[54.] [45.873272]\n",
      "[84.] [96.93084]\n",
      "[76.] [112.09643]\n",
      "[136.] [128.10109]\n",
      "[178.] [163.72687]\n",
      "[68.] [46.02348]\n",
      "[42.] [47.69994]\n",
      "[280.] [166.15794]\n",
      "[58.] [110.042114]\n",
      "[62.] [69.73731]\n",
      "[193.] [187.8329]\n",
      "[57.] [61.03886]\n",
      "[114.] [155.2635]\n",
      "[95.] [101.13108]\n",
      "[308.] [162.85585]\n",
      "[69.] [78.97492]\n",
      "[87.] [82.43293]\n",
      "[110.] [104.5994]\n",
      "[53.] [65.24677]\n",
      "[126.] [106.96404]\n",
      "[52.] [47.606205]\n",
      "[178.] [196.3303]\n",
      "[114.] [110.1447]\n",
      "[217.] [191.5448]\n",
      "[109.] [117.58175]\n",
      "[85.] [83.61285]\n",
      "[936.] [299.66962]\n",
      "[57.] [58.488316]\n",
      "[96.] [116.20753]\n",
      "[104.] [142.17387]\n",
      "[53.] [68.990845]\n",
      "[90.] [89.569145]\n",
      "[27.] [36.753803]\n",
      "[81.] [77.813774]\n",
      "[44.] [58.8027]\n",
      "[88.] [85.61352]\n",
      "[113.] [134.75214]\n",
      "[52.] [83.36738]\n",
      "[88.] [139.57985]\n",
      "[234.] [151.32292]\n",
      "[41.] [69.66613]\n",
      "[85.] [55.931637]\n",
      "[88.] [83.85057]\n",
      "[127.] [143.92567]\n",
      "[173.] [170.38638]\n",
      "[87.] [81.35778]\n",
      "[74.] [82.696175]\n",
      "[130.] [138.45221]\n",
      "[151.] [126.321045]\n",
      "[67.] [51.710064]\n",
      "[121.] [99.728065]\n",
      "[53.] [78.30963]\n",
      "[67.] [75.08703]\n",
      "[72.] [57.81953]\n",
      "[187.] [153.35661]\n",
      "[83.] [83.28301]\n",
      "[88.] [101.401115]\n",
      "[64.] [144.58897]\n",
      "[69.] [65.33242]\n",
      "[129.] [100.89686]\n",
      "[123.] [99.00405]\n",
      "[38.] [54.8852]\n",
      "[171.] [151.57864]\n",
      "[58.] [65.22829]\n",
      "[100.] [104.85824]\n",
      "[114.] [143.66354]\n",
      "[53.] [73.16769]\n",
      "[64.] [75.02387]\n",
      "[200.] [185.00377]\n",
      "[400.] [168.52672]\n",
      "[97.] [127.07122]\n",
      "[77.] [110.546104]\n",
      "[94.] [171.78433]\n",
      "[228.] [220.14226]\n",
      "[81.] [80.873604]\n",
      "[86.] [137.93619]\n",
      "[232.] [211.29689]\n",
      "[49.] [87.19965]\n",
      "[82.] [71.28252]\n",
      "[46.] [70.473595]\n",
      "[74.] [69.38133]\n",
      "[44.] [27.760393]\n",
      "[56.] [68.867]\n",
      "[58.] [68.420105]\n",
      "[142.] [145.32028]\n",
      "[136.] [134.1187]\n",
      "[70.] [71.11929]\n",
      "[76.] [83.50179]\n",
      "[95.] [107.143364]\n",
      "[105.] [110.57101]\n",
      "[44.] [41.8008]\n",
      "[60.] [139.79689]\n",
      "[93.] [65.417816]\n",
      "[49.] [63.735878]\n",
      "[51.] [57.053688]\n",
      "[87.] [100.369316]\n",
      "[63.] [75.66708]\n",
      "[80.] [82.01107]\n",
      "[52.] [53.13831]\n",
      "[138.] [133.19049]\n",
      "[46.] [58.372845]\n",
      "[53.] [72.67062]\n",
      "[68.] [73.944756]\n",
      "[53.] [54.372234]\n",
      "[143.] [156.82231]\n",
      "[62.] [91.93151]\n",
      "[138.] [112.16599]\n",
      "[92.] [91.676]\n",
      "[61.] [42.144703]\n",
      "[210.] [221.37123]\n",
      "[99.] [94.35444]\n",
      "[114.] [145.60574]\n",
      "[76.] [86.17458]\n",
      "[56.] [76.76852]\n",
      "[170.] [168.78221]\n",
      "[65.] [152.102]\n",
      "[87.] [56.883923]\n",
      "[49.] [67.880135]\n",
      "[222.] [158.87726]\n",
      "[134.] [99.371124]\n",
      "[56.] [76.82024]\n",
      "[61.] [84.75065]\n",
      "[208.] [188.5204]\n",
      "[91.] [108.09941]\n",
      "[75.] [105.60463]\n",
      "[40.] [72.139885]\n",
      "[71.] [103.02952]\n",
      "[95.] [71.88818]\n",
      "[56.] [70.798546]\n",
      "[126.] [88.88658]\n",
      "[184.] [163.62697]\n",
      "[144.] [105.96467]\n",
      "[151.] [147.84032]\n",
      "[117.] [130.77428]\n",
      "[93.] [83.47106]\n",
      "[74.] [47.046535]\n",
      "[74.] [74.967155]\n",
      "[146.] [133.56746]\n",
      "[62.] [98.57014]\n",
      "[84.] [94.579]\n",
      "[81.] [138.35274]\n",
      "[45.] [52.560978]\n",
      "[70.] [107.28796]\n",
      "[69.] [75.51835]\n",
      "[129.] [120.19282]\n",
      "[103.] [107.015526]\n",
      "[82.] [77.30132]\n",
      "[116.] [127.23804]\n",
      "[64.] [56.39413]\n",
      "[59.] [68.481186]\n"
     ]
    }
   ],
   "source": [
    "for t,p in zip(y_train,y_train_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[147.] [138.47673]\n",
      "[75.] [154.58615]\n",
      "[58.] [55.61067]\n",
      "[115.] [86.976204]\n",
      "[89.] [98.19588]\n",
      "[43.] [104.63014]\n",
      "[90.] [217.8203]\n",
      "[88.] [111.52886]\n",
      "[66.] [91.48281]\n",
      "[63.] [88.34547]\n",
      "[111.] [162.52165]\n",
      "[79.] [79.02687]\n",
      "[137.] [91.011925]\n",
      "[72.] [67.23845]\n",
      "[432.] [202.2482]\n",
      "[95.] [75.874565]\n",
      "[127.] [144.52094]\n",
      "[78.] [87.32252]\n",
      "[68.] [29.986605]\n",
      "[60.] [70.65178]\n",
      "[67.] [101.71166]\n",
      "[66.] [43.590702]\n",
      "[67.] [66.91717]\n",
      "[112.] [95.02262]\n",
      "[94.] [65.47787]\n",
      "[124.] [175.90343]\n",
      "[79.] [71.98815]\n",
      "[123.] [198.14265]\n",
      "[71.] [116.62699]\n",
      "[127.] [57.954082]\n",
      "[112.] [121.71819]\n",
      "[101.] [74.69652]\n",
      "[103.] [86.47701]\n",
      "[69.] [71.25587]\n",
      "[152.] [97.662346]\n",
      "[51.] [66.85438]\n",
      "[106.] [97.03651]\n",
      "[46.] [87.88613]\n",
      "[60.] [49.19794]\n",
      "[74.] [115.75929]\n",
      "[124.] [146.13245]\n",
      "[59.] [44.2195]\n",
      "[45.] [66.61707]\n",
      "[73.] [60.189945]\n",
      "[74.] [142.4871]\n",
      "[163.] [89.443245]\n",
      "[51.] [73.350105]\n",
      "[48.] [90.52885]\n",
      "[167.] [136.94762]\n",
      "[65.] [129.75188]\n",
      "[55.] [77.31422]\n",
      "[120.] [101.79783]\n",
      "[56.] [56.45666]\n",
      "[78.] [141.32086]\n",
      "[110.] [134.76181]\n",
      "[64.] [134.3721]\n",
      "[152.] [141.7314]\n",
      "[88.] [109.718254]\n",
      "[91.] [100.94018]\n",
      "[114.] [156.53271]\n",
      "[145.] [107.26396]\n",
      "[56.] [76.18855]\n",
      "[66.] [157.58003]\n",
      "[57.] [73.96035]\n",
      "[149.] [111.44611]\n",
      "[123.] [198.8311]\n",
      "[172.] [122.71679]\n",
      "[62.] [53.203262]\n",
      "[48.] [44.25963]\n",
      "[124.] [110.043526]\n",
      "[112.] [131.73416]\n"
     ]
    }
   ],
   "source": [
    "for t,p in zip(y_test,y_test_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#오차 범위 3 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set prediction accuracy: 9.61 %\n",
      "test set prediction accuracy: 14.08 %\n"
     ]
    }
   ],
   "source": [
    "#평균 성능 테스트\n",
    "scores = 0\n",
    "mean=np.mean(Y, axis=0)\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= mean <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"train set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= mean <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"test set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### <오차범위 3>\n",
      "- train set prediction accuracy(+-3): 12.46 % <br>\n",
      "- test set prediction accuracy(+-3): 7.04 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 5>\n",
      "- train set prediction accuracy(+-5): 22.42 % <br>\n",
      "- test set prediction accuracy(+-5): 9.86 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 10>\n",
      "- train set prediction accuracy(+-10): 38.08 % <br>\n",
      "- test set prediction accuracy(+-10): 21.13 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 20>\n",
      "- train set prediction accuracy(+-20): 62.99 % <br>\n",
      "- test set prediction accuracy(+-20): 40.85 % <br>\n"
     ]
    }
   ],
   "source": [
    "######입력용#######\n",
    "\n",
    "#오차 범위 3 설정\n",
    "print('### <오차범위 3>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "print('### <오차범위 5>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "print('### <오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "print('### <오차범위 20>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <Y=TG>\n",
    "## 1. 임의+선별\n",
    "### <오차범위 3>\n",
    "- train set prediction accuracy(+-3): 8.90 % <br>\n",
    "- test set prediction accuracy(+-3): 8.45 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 5>\n",
    "- train set prediction accuracy(+-5): 14.23 % <br>\n",
    "- test set prediction accuracy(+-5): 14.08 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 10>\n",
    "- train set prediction accuracy(+-10): 26.69 % <br>\n",
    "- test set prediction accuracy(+-10): 28.17 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 20>\n",
    "- train set prediction accuracy(+-20): 49.82 % <br>\n",
    "- test set prediction accuracy(+-20): 53.52 % <br>\n",
    "\n",
    "## 2. 임의+선별+PSQI\n",
    "### <오차범위 3>\n",
    "- train set prediction accuracy(+-3): 12.46 % <br>\n",
    "- test set prediction accuracy(+-3): 7.04 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 5>\n",
    "- train set prediction accuracy(+-5): 22.42 % <br>\n",
    "- test set prediction accuracy(+-5): 9.86 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 10>\n",
    "- train set prediction accuracy(+-10): 38.08 % <br>\n",
    "- test set prediction accuracy(+-10): 21.13 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 20>\n",
    "- train set prediction accuracy(+-20): 62.99 % <br>\n",
    "- test set prediction accuracy(+-20): 40.85 % <br>\n",
    "\n",
    "\n",
    "## 3. PSQI+AGE+SEX+BMI+Fat+Fat_percentage+Waist\n",
    "### <오차범위 3>\n",
    "- train set prediction accuracy(+-3): 7.83 % <br>\n",
    "- test set prediction accuracy(+-3): 2.82 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 5>\n",
    "- train set prediction accuracy(+-5): 14.59 % <br>\n",
    "- test set prediction accuracy(+-5): 9.86 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 10>\n",
    "- train set prediction accuracy(+-10): 36.30 % <br>\n",
    "- test set prediction accuracy(+-10): 19.72 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 20>\n",
    "- train set prediction accuracy(+-20): 61.57 % <br>\n",
    "- test set prediction accuracy(+-20): 43.66 % <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sample_ID GROUP  COHORT SEX  AGE     Trait FitbitOX      Fitbit_ID  HTN  \\\n",
      "0         S0001   SMI       2   M   60  fitbit_O        O  sevrance00001  NaN   \n",
      "1         S0002   SMI       2   M   61  fitbit_O        O  sevrance00002  NaN   \n",
      "2         S0003   SMI       2   F   52  fitbit_O        O  sevrance00003  NaN   \n",
      "3         S0004   SMI       2   F   41  fitbit_O        O  sevrance00004  NaN   \n",
      "4         S0005   SMI       2   F   41  fitbit_O        O  sevrance00005  NaN   \n",
      "..          ...   ...     ...  ..  ...       ...      ...            ...  ...   \n",
      "383  MetS_S0280  MetS       1   F   24  fitbit_O        O   gnfmmets+139  NaN   \n",
      "384  MetS_S0281  MetS       1   F   44  fitbit_O        O   gnfmmets+140  NaN   \n",
      "385  MetS_S0282  MetS       1   F   37  fitbit_O        O   gnfmmets+141  1.0   \n",
      "386  MetS_S0283  MetS       1   M   51  fitbit_X        X              X  NaN   \n",
      "387  MetS_S0284  MetS       1   F   42  fitbit_X        X              X  NaN   \n",
      "\n",
      "      DM  ...  BDI_Q13_2 BDI_Q14_2  BDI_Q15_2  BDI_Q16_2 BDI_Q17_2 BDI_Q18_2  \\\n",
      "0    NaN  ...        1.0       1.0        1.0        2.0       1.0       1.0   \n",
      "1    1.0  ...        1.0       1.0        1.0        1.0       2.0       1.0   \n",
      "2    NaN  ...        1.0       1.0        1.0        1.0       1.0       1.0   \n",
      "3    NaN  ...        2.0       2.0        2.0        2.0       2.0       2.0   \n",
      "4    NaN  ...        2.0       1.0        2.0        2.0       2.0       1.0   \n",
      "..   ...  ...        ...       ...        ...        ...       ...       ...   \n",
      "383  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "384  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "385  1.0  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "386  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "387  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "\n",
      "     BDI_Q19_2  BDI_Q20_2  BDI_Q21_2  Diet_2  \n",
      "0          2.0        1.0        2.0     2.0  \n",
      "1          1.0        1.0        1.0     2.0  \n",
      "2          1.0        2.0        4.0     1.0  \n",
      "3          1.0        1.0        1.0     2.0  \n",
      "4          1.0        2.0        1.0     2.0  \n",
      "..         ...        ...        ...     ...  \n",
      "383        NaN        NaN        NaN     NaN  \n",
      "384        NaN        NaN        NaN     NaN  \n",
      "385        NaN        NaN        NaN     NaN  \n",
      "386        NaN        NaN        NaN     NaN  \n",
      "387        NaN        NaN        NaN     NaN  \n",
      "\n",
      "[388 rows x 3527 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('./최종 데이터 그래프그리기용.xlsx') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#빈데이터 많은 Chol, BUN 제거\n",
    "psqi_df=df[['Sample_ID','GROUP','COHORT','AGE','SEX','BMI_1','PSQI_TOTAL_1','Insulin _1','CRP_1','WBC_1','Neutrophil_1','Lym_1','GLU0_1','Creatinine_1','AST_1','ALT_1','TG_1','LDL_1','Muscle_1','Fat_1_x','FatPercentage _1','WHR_1','SBP_1',\n",
    "            'DBP_1','HR_1','Waist_1','HDL_1',''\n",
    "          'BMI_2','PSQI_TOTAL_2','Insulin _2','CRP_2','WBC_2','Neutrophil_2','Lym_2','GLU0_2',\n",
    "            'Creatinine_2','AST_2','ALT_2','TG_2','LDL_2','Muscle_2','Fat_2_x','FatPercentage_2','WHR_2','SBP_2',\n",
    "            'DBP_2','HR_2','Waist_2','HDL_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#빈데이터 많은 Chol, BUN 추가\n",
    "psqi_df=df[['Sample_ID','GROUP','COHORT','AGE','SEX','BMI_1','PSQI_TOTAL_1','Insulin _1','CRP_1','WBC_1','Neutrophil_1','Lym_1','GLU0_1','Creatinine_1','AST_1','ALT_1','TG_1','LDL_1','Muscle_1','Fat_1_x','FatPercentage _1','WHR_1','SBP_1',\n",
    "            'DBP_1','HR_1','Waist_1','HDL_1','BUN_1','Chol_1',\n",
    "          'BMI_2','PSQI_TOTAL_2','Insulin _2','CRP_2','WBC_2','Neutrophil_2','Lym_2','GLU0_2',\n",
    "            'Creatinine_2','AST_2','ALT_2','TG_2','LDL_2','Muscle_2','Fat_2_x','FatPercentage_2','WHR_2','SBP_2',\n",
    "            'DBP_2','HR_2','Waist_2','HDL_2','BUN_2','Chol_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>HDL_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>Chol_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.89</td>\n",
       "      <td>108.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.51</td>\n",
       "      <td>...</td>\n",
       "      <td>19.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>0.99</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>90.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.85</td>\n",
       "      <td>...</td>\n",
       "      <td>22.6</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>127.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.14</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.82</td>\n",
       "      <td>119.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.93</td>\n",
       "      <td>...</td>\n",
       "      <td>14.9</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>110.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>66.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.82</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.67</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.03</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT  AGE SEX      BMI_1  PSQI_TOTAL_1 Insulin _1  \\\n",
       "0         S0001   SMI       2   60   M  21.110190           8.0        7.7   \n",
       "1         S0002   SMI       2   61   M  27.782064           4.0        5.4   \n",
       "2         S0003   SMI       2   52   F  24.944742           3.0        5.1   \n",
       "3         S0004   SMI       2   41   F  22.620489           6.0        4.2   \n",
       "4         S0005   SMI       2   41   F  20.524157          10.0        3.2   \n",
       "..          ...   ...     ...  ...  ..        ...           ...        ...   \n",
       "383  MetS_S0280  MetS       1   24   F  34.803410           5.0       11.3   \n",
       "384  MetS_S0281  MetS       1   44   F  30.903615           3.0       10.6   \n",
       "385  MetS_S0282  MetS       1   37   F  28.676533           3.0       12.2   \n",
       "386  MetS_S0283  MetS       1   51   M  24.549738           5.0       10.4   \n",
       "387  MetS_S0284  MetS       1   42   F  24.605921           3.0       10.1   \n",
       "\n",
       "    CRP_1  WBC_1  ...  Fat_2_x  FatPercentage_2  WHR_2  SBP_2  DBP_2  HR_2  \\\n",
       "0     0.2   3.91  ...      9.7             15.9   0.89  108.0   78.0  87.0   \n",
       "1     0.2   5.51  ...     19.9             27.9   0.99  138.0   92.0  73.0   \n",
       "2     0.7   4.85  ...     22.6             36.7   0.89  127.0   80.0  66.0   \n",
       "3     0.6   6.14  ...     16.0             30.9   0.82  119.0   83.0  77.0   \n",
       "4     0.1   4.93  ...     14.9             26.8   0.80  110.0   68.0  67.0   \n",
       "..    ...    ...  ...      ...              ...    ...    ...    ...   ...   \n",
       "383   0.4   5.32  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "384   2.3   5.82  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "385     1   6.18  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "386   1.2   6.67  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "387   0.8   7.03  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "\n",
       "     Waist_2  HDL_2  BUN_2  Chol_2  \n",
       "0       83.0   77.0   13.1     NaN  \n",
       "1       90.5   59.0   19.2     NaN  \n",
       "2       86.5   40.0   17.1     NaN  \n",
       "3       77.0   54.0   12.2     NaN  \n",
       "4       66.5   72.0   16.5     NaN  \n",
       "..       ...    ...    ...     ...  \n",
       "383      NaN    NaN    NaN     NaN  \n",
       "384      NaN    NaN    NaN     NaN  \n",
       "385      NaN    NaN    NaN     NaN  \n",
       "386      NaN    NaN    NaN     NaN  \n",
       "387      NaN    NaN    NaN     NaN  \n",
       "\n",
       "[388 rows x 53 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>HDL_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>Chol_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.89</td>\n",
       "      <td>108.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.51</td>\n",
       "      <td>...</td>\n",
       "      <td>19.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>0.99</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>90.5</td>\n",
       "      <td>59.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.85</td>\n",
       "      <td>...</td>\n",
       "      <td>22.6</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>127.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>40.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.14</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.82</td>\n",
       "      <td>119.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.93</td>\n",
       "      <td>...</td>\n",
       "      <td>14.9</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>110.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>66.5</td>\n",
       "      <td>72.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.82</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.67</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.03</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT  AGE SEX      BMI_1  PSQI_TOTAL_1 Insulin _1  \\\n",
       "0         S0001   SMI       2   60   M  21.110190           8.0        7.7   \n",
       "1         S0002   SMI       2   61   M  27.782064           4.0        5.4   \n",
       "2         S0003   SMI       2   52   F  24.944742           3.0        5.1   \n",
       "3         S0004   SMI       2   41   F  22.620489           6.0        4.2   \n",
       "4         S0005   SMI       2   41   F  20.524157          10.0        3.2   \n",
       "..          ...   ...     ...  ...  ..        ...           ...        ...   \n",
       "383  MetS_S0280  MetS       1   24   F  34.803410           5.0       11.3   \n",
       "384  MetS_S0281  MetS       1   44   F  30.903615           3.0       10.6   \n",
       "385  MetS_S0282  MetS       1   37   F  28.676533           3.0       12.2   \n",
       "386  MetS_S0283  MetS       1   51   M  24.549738           5.0       10.4   \n",
       "387  MetS_S0284  MetS       1   42   F  24.605921           3.0       10.1   \n",
       "\n",
       "    CRP_1  WBC_1  ...  Fat_2_x  FatPercentage_2  WHR_2  SBP_2  DBP_2  HR_2  \\\n",
       "0     0.2   3.91  ...      9.7             15.9   0.89  108.0   78.0  87.0   \n",
       "1     0.2   5.51  ...     19.9             27.9   0.99  138.0   92.0  73.0   \n",
       "2     0.7   4.85  ...     22.6             36.7   0.89  127.0   80.0  66.0   \n",
       "3     0.6   6.14  ...     16.0             30.9   0.82  119.0   83.0  77.0   \n",
       "4     0.1   4.93  ...     14.9             26.8   0.80  110.0   68.0  67.0   \n",
       "..    ...    ...  ...      ...              ...    ...    ...    ...   ...   \n",
       "383   0.4   5.32  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "384   2.3   5.82  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "385     1   6.18  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "386   1.2   6.67  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "387   0.8   7.03  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "\n",
       "     Waist_2  HDL_2  BUN_2  Chol_2  \n",
       "0       83.0   77.0   13.1     NaN  \n",
       "1       90.5   59.0   19.2     NaN  \n",
       "2       86.5   40.0   17.1     NaN  \n",
       "3       77.0   54.0   12.2     NaN  \n",
       "4       66.5   72.0   16.5     NaN  \n",
       "..       ...    ...    ...     ...  \n",
       "383      NaN    NaN    NaN     NaN  \n",
       "384      NaN    NaN    NaN     NaN  \n",
       "385      NaN    NaN    NaN     NaN  \n",
       "386      NaN    NaN    NaN     NaN  \n",
       "387      NaN    NaN    NaN     NaN  \n",
       "\n",
       "[317 rows x 53 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#보조 호르몬 요법을 받고 있는 Cohort 3 제거 Filter 적용\n",
    "psqi_df = psqi_df[(psqi_df['COHORT'] != 3)]\n",
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df=psqi_df.dropna()\n",
    "psqi_df.reset_index(drop=True, inplace=True)\n",
    "psqi_df=psqi_df.drop([\"Sample_ID\", \"GROUP\", \"COHORT\"],axis=1)\n",
    "#1분, 매일다름, 정해진간이없음 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"SEX\"] = psqi_df[\"SEX\"].apply(lambda x: 1. if x=='M' else 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"Insulin _1\"] = psqi_df[\"Insulin _1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)\n",
    "psqi_df[\"Insulin _2\"] = psqi_df[\"Insulin _2\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"CRP_1\"] = psqi_df[\"CRP_1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)\n",
    "psqi_df[\"CRP_2\"] = psqi_df[\"CRP_2\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>Neutrophil_1</th>\n",
       "      <th>Lym_1</th>\n",
       "      <th>GLU0_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>HDL_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>Chol_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.00000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.366667</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>23.799644</td>\n",
       "      <td>5.105556</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.748889</td>\n",
       "      <td>5.844867</td>\n",
       "      <td>56.086111</td>\n",
       "      <td>34.113333</td>\n",
       "      <td>98.90000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.053333</td>\n",
       "      <td>28.888333</td>\n",
       "      <td>0.862444</td>\n",
       "      <td>114.605556</td>\n",
       "      <td>72.477778</td>\n",
       "      <td>75.644444</td>\n",
       "      <td>81.328889</td>\n",
       "      <td>59.20000</td>\n",
       "      <td>12.984444</td>\n",
       "      <td>190.922222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.589776</td>\n",
       "      <td>0.461927</td>\n",
       "      <td>4.936177</td>\n",
       "      <td>2.893833</td>\n",
       "      <td>4.105985</td>\n",
       "      <td>1.344157</td>\n",
       "      <td>1.412280</td>\n",
       "      <td>8.502880</td>\n",
       "      <td>7.708889</td>\n",
       "      <td>14.43773</td>\n",
       "      <td>...</td>\n",
       "      <td>6.616151</td>\n",
       "      <td>7.098802</td>\n",
       "      <td>0.071696</td>\n",
       "      <td>13.213544</td>\n",
       "      <td>9.091991</td>\n",
       "      <td>10.306814</td>\n",
       "      <td>10.251265</td>\n",
       "      <td>14.01372</td>\n",
       "      <td>3.508550</td>\n",
       "      <td>32.017358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.231576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.820000</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>63.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>29.00000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>109.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.833309</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.857500</td>\n",
       "      <td>50.525000</td>\n",
       "      <td>28.975000</td>\n",
       "      <td>92.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>24.275000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>73.875000</td>\n",
       "      <td>49.00000</td>\n",
       "      <td>10.675000</td>\n",
       "      <td>167.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.422889</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>5.720000</td>\n",
       "      <td>55.950000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>95.50000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.950000</td>\n",
       "      <td>28.450000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>80.500000</td>\n",
       "      <td>57.00000</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>188.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.502662</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.505000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>6.580000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>102.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.125000</td>\n",
       "      <td>33.450000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>77.250000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>69.00000</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>211.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>10.550000</td>\n",
       "      <td>78.400000</td>\n",
       "      <td>55.400000</td>\n",
       "      <td>182.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>46.100000</td>\n",
       "      <td>48.300000</td>\n",
       "      <td>1.070000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>116.00000</td>\n",
       "      <td>36.400000</td>\n",
       "      <td>296.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              AGE         SEX       BMI_1  PSQI_TOTAL_1  Insulin _1  \\\n",
       "count  180.000000  180.000000  180.000000    180.000000  180.000000   \n",
       "mean    38.366667    0.305556   23.799644      5.105556    7.700000   \n",
       "std     11.589776    0.461927    4.936177      2.893833    4.105985   \n",
       "min     20.000000    0.000000   15.231576      0.000000    0.100000   \n",
       "25%     29.000000    0.000000   20.833309      3.000000    5.000000   \n",
       "50%     35.500000    0.000000   23.422889      5.000000    6.500000   \n",
       "75%     46.000000    1.000000   25.502662      7.000000    9.505000   \n",
       "max     63.000000    1.000000   67.500000     14.000000   24.700000   \n",
       "\n",
       "            CRP_1       WBC_1  Neutrophil_1       Lym_1     GLU0_1  ...  \\\n",
       "count  180.000000  180.000000    180.000000  180.000000  180.00000  ...   \n",
       "mean     0.748889    5.844867     56.086111   34.113333   98.90000  ...   \n",
       "std      1.344157    1.412280      8.502880    7.708889   14.43773  ...   \n",
       "min      0.000000    2.820000     34.500000   15.100000   63.00000  ...   \n",
       "25%      0.200000    4.857500     50.525000   28.975000   92.00000  ...   \n",
       "50%      0.300000    5.720000     55.950000   34.000000   95.50000  ...   \n",
       "75%      0.700000    6.580000     62.000000   39.000000  102.00000  ...   \n",
       "max     11.100000   10.550000     78.400000   55.400000  182.00000  ...   \n",
       "\n",
       "          Fat_2_x  FatPercentage_2       WHR_2       SBP_2       DBP_2  \\\n",
       "count  180.000000       180.000000  180.000000  180.000000  180.000000   \n",
       "mean    19.053333        28.888333    0.862444  114.605556   72.477778   \n",
       "std      6.616151         7.098802    0.071696   13.213544    9.091991   \n",
       "min      7.700000        11.500000    0.700000   91.000000   57.000000   \n",
       "25%     14.200000        24.275000    0.820000  104.000000   67.000000   \n",
       "50%     17.950000        28.450000    0.850000  114.000000   71.000000   \n",
       "75%     22.125000        33.450000    0.900000  123.000000   77.250000   \n",
       "max     46.100000        48.300000    1.070000  158.000000  107.000000   \n",
       "\n",
       "             HR_2     Waist_2      HDL_2       BUN_2      Chol_2  \n",
       "count  180.000000  180.000000  180.00000  180.000000  180.000000  \n",
       "mean    75.644444   81.328889   59.20000   12.984444  190.922222  \n",
       "std     10.306814   10.251265   14.01372    3.508550   32.017358  \n",
       "min     54.000000   61.000000   29.00000    6.000000  109.000000  \n",
       "25%     68.000000   73.875000   49.00000   10.675000  167.750000  \n",
       "50%     75.000000   80.500000   57.00000   12.700000  188.000000  \n",
       "75%     82.000000   89.000000   69.00000   14.600000  211.000000  \n",
       "max    112.000000  118.000000  116.00000   36.400000  296.000000  \n",
       "\n",
       "[8 rows x 50 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    125\n",
       "1.0     55\n",
       "Name: SEX, dtype: int64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df[\"SEX\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>Neutrophil_1</th>\n",
       "      <th>Lym_1</th>\n",
       "      <th>GLU0_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>HDL_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>Chol_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.097789</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.82</td>\n",
       "      <td>54.6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>20.4</td>\n",
       "      <td>26.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>131.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>88.5</td>\n",
       "      <td>53.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.472213</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.46</td>\n",
       "      <td>44.3</td>\n",
       "      <td>43.7</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>126.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>203.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.744827</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.26</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.99</td>\n",
       "      <td>51.0</td>\n",
       "      <td>37.8</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>17.8</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.89</td>\n",
       "      <td>131.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>196.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.616175</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.84</td>\n",
       "      <td>39.1</td>\n",
       "      <td>42.1</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>12.8</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.78</td>\n",
       "      <td>102.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.437500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.22</td>\n",
       "      <td>49.3</td>\n",
       "      <td>39.3</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>12.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>106.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>168.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.259585</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.78</td>\n",
       "      <td>42.3</td>\n",
       "      <td>47.3</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>27.3</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.94</td>\n",
       "      <td>134.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.630719</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.80</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.60</td>\n",
       "      <td>51.7</td>\n",
       "      <td>34.6</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>22.1</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.95</td>\n",
       "      <td>113.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>51.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.641274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.34</td>\n",
       "      <td>55.9</td>\n",
       "      <td>34.9</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>17.5</td>\n",
       "      <td>29.9</td>\n",
       "      <td>0.84</td>\n",
       "      <td>107.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>80.5</td>\n",
       "      <td>49.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.421366</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.88</td>\n",
       "      <td>40.9</td>\n",
       "      <td>48.0</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>15.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>106.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.271653</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.28</td>\n",
       "      <td>75.7</td>\n",
       "      <td>15.1</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>9.3</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>104.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>148.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGE  SEX      BMI_1  PSQI_TOTAL_1  Insulin _1  CRP_1  WBC_1  \\\n",
       "0     35  1.0  24.097789           5.0        5.57    0.0   5.82   \n",
       "1     46  1.0  23.472213           5.0        7.35    0.7   5.46   \n",
       "2     32  1.0  23.744827           2.0        9.26    0.4   3.99   \n",
       "3     33  0.0  20.616175           4.0        3.52    0.0   5.84   \n",
       "4     28  0.0  18.437500           3.0        2.86    0.0   4.22   \n",
       "..   ...  ...        ...           ...         ...    ...    ...   \n",
       "175   63  0.0  26.259585           3.0        4.20    0.2   4.78   \n",
       "176   57  1.0  28.630719           4.0        8.80    3.0   4.60   \n",
       "177   35  0.0  21.641274           1.0        6.30    0.4   6.34   \n",
       "178   61  0.0  20.421366           8.0        4.80    0.2   4.88   \n",
       "179   56  1.0  22.271653           1.0        9.00    0.2   6.28   \n",
       "\n",
       "     Neutrophil_1  Lym_1  GLU0_1  ...  Fat_2_x  FatPercentage_2  WHR_2  SBP_2  \\\n",
       "0            54.6   35.0      89  ...     20.4             26.8   1.00  131.0   \n",
       "1            44.3   43.7      90  ...     14.5             18.6   0.84  126.0   \n",
       "2            51.0   37.8      96  ...     17.8             25.6   0.89  131.0   \n",
       "3            39.1   42.1      81  ...     12.8             21.9   0.78  102.0   \n",
       "4            49.3   39.3      63  ...     12.3             25.6   0.80  106.0   \n",
       "..            ...    ...     ...  ...      ...              ...    ...    ...   \n",
       "175          42.3   47.3      96  ...     27.3             39.3   0.94  134.0   \n",
       "176          51.7   34.6      94  ...     22.1             25.7   0.95  113.0   \n",
       "177          55.9   34.9      87  ...     17.5             29.9   0.84  107.0   \n",
       "178          40.9   48.0      93  ...     15.3             29.0   0.81  106.0   \n",
       "179          75.7   15.1     125  ...      9.3             13.1   0.85  104.0   \n",
       "\n",
       "     DBP_2   HR_2  Waist_2  HDL_2  BUN_2  Chol_2  \n",
       "0     74.0   66.0     88.5   53.0   17.5   180.0  \n",
       "1     87.0  108.0     85.0   64.0   14.4   203.0  \n",
       "2     77.0   87.0     81.0   49.0   14.1   196.0  \n",
       "3     62.0   70.0     69.0   98.0   10.5   224.0  \n",
       "4     72.0   69.0     61.0   71.0   11.3   168.0  \n",
       "..     ...    ...      ...    ...    ...     ...  \n",
       "175   89.0   81.0     98.0   66.0   17.1   141.0  \n",
       "176   76.0   66.0     97.5   51.0   14.6   134.0  \n",
       "177   72.0   64.0     80.5   49.0    9.7   147.0  \n",
       "178   76.0   92.0     79.0   60.0   10.2   134.0  \n",
       "179   73.0   79.0     91.0   31.0   36.4   148.0  \n",
       "\n",
       "[180 rows x 50 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (x=쓸 수 있는 모든 특징)\n",
    "X1=psqi_df[['AGE','SEX','BMI_1','PSQI_TOTAL_1','Insulin _1','CRP_1','WBC_1','Neutrophil_1','Lym_1','GLU0_1',\n",
    "            'Creatinine_1','AST_1','ALT_1','TG_1','LDL_1','Muscle_1','Fat_1_x','FatPercentage _1','WHR_1','SBP_1',\n",
    "            'DBP_1','HR_1','Waist_1','BUN_1','Chol_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','SEX','BMI_2','PSQI_TOTAL_2','Insulin _2','CRP_2','WBC_2','Neutrophil_2','Lym_2','GLU0_2',\n",
    "            'Creatinine_2','AST_2','ALT_2','TG_2','LDL_2','Muscle_2','Fat_2_x','FatPercentage_2','WHR_2','SBP_2',\n",
    "            'DBP_2','HR_2','Waist_2','BUN_2','Chol_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 360)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 25), (360, 1))"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 72)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 25), (360, 1))"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "72/72 - 1s - loss: 3335.7236 - mse: 3335.7236\n",
      "Epoch 2/150\n",
      "72/72 - 0s - loss: 2461.4658 - mse: 2461.4658\n",
      "Epoch 3/150\n",
      "72/72 - 0s - loss: 1273.6605 - mse: 1273.6605\n",
      "Epoch 4/150\n",
      "72/72 - 0s - loss: 487.5621 - mse: 487.5621\n",
      "Epoch 5/150\n",
      "72/72 - 0s - loss: 309.1628 - mse: 309.1628\n",
      "Epoch 6/150\n",
      "72/72 - 0s - loss: 262.7277 - mse: 262.7277\n",
      "Epoch 7/150\n",
      "72/72 - 0s - loss: 226.1837 - mse: 226.1837\n",
      "Epoch 8/150\n",
      "72/72 - 0s - loss: 199.0319 - mse: 199.0319\n",
      "Epoch 9/150\n",
      "72/72 - 0s - loss: 180.5496 - mse: 180.5496\n",
      "Epoch 10/150\n",
      "72/72 - 0s - loss: 162.4221 - mse: 162.4221\n",
      "Epoch 11/150\n",
      "72/72 - 0s - loss: 152.8056 - mse: 152.8056\n",
      "Epoch 12/150\n",
      "72/72 - 0s - loss: 139.2540 - mse: 139.2540\n",
      "Epoch 13/150\n",
      "72/72 - 0s - loss: 132.3037 - mse: 132.3037\n",
      "Epoch 14/150\n",
      "72/72 - 0s - loss: 122.5193 - mse: 122.5193\n",
      "Epoch 15/150\n",
      "72/72 - 0s - loss: 114.6557 - mse: 114.6557\n",
      "Epoch 16/150\n",
      "72/72 - 0s - loss: 107.6579 - mse: 107.6579\n",
      "Epoch 17/150\n",
      "72/72 - 0s - loss: 99.9061 - mse: 99.9061\n",
      "Epoch 18/150\n",
      "72/72 - 0s - loss: 94.5527 - mse: 94.5527\n",
      "Epoch 19/150\n",
      "72/72 - 0s - loss: 89.1822 - mse: 89.1822\n",
      "Epoch 20/150\n",
      "72/72 - 0s - loss: 83.7938 - mse: 83.7938\n",
      "Epoch 21/150\n",
      "72/72 - 0s - loss: 80.4090 - mse: 80.4090\n",
      "Epoch 22/150\n",
      "72/72 - 0s - loss: 76.5270 - mse: 76.5270\n",
      "Epoch 23/150\n",
      "72/72 - 0s - loss: 72.8701 - mse: 72.8701\n",
      "Epoch 24/150\n",
      "72/72 - 0s - loss: 68.2740 - mse: 68.2740\n",
      "Epoch 25/150\n",
      "72/72 - 0s - loss: 65.4104 - mse: 65.4104\n",
      "Epoch 26/150\n",
      "72/72 - 0s - loss: 61.6835 - mse: 61.6835\n",
      "Epoch 27/150\n",
      "72/72 - 0s - loss: 59.5372 - mse: 59.5372\n",
      "Epoch 28/150\n",
      "72/72 - 0s - loss: 56.6524 - mse: 56.6524\n",
      "Epoch 29/150\n",
      "72/72 - 0s - loss: 54.8592 - mse: 54.8592\n",
      "Epoch 30/150\n",
      "72/72 - 0s - loss: 51.3454 - mse: 51.3454\n",
      "Epoch 31/150\n",
      "72/72 - 0s - loss: 47.8501 - mse: 47.8501\n",
      "Epoch 32/150\n",
      "72/72 - 0s - loss: 47.8290 - mse: 47.8290\n",
      "Epoch 33/150\n",
      "72/72 - 0s - loss: 45.5503 - mse: 45.5503\n",
      "Epoch 34/150\n",
      "72/72 - 0s - loss: 43.8469 - mse: 43.8469\n",
      "Epoch 35/150\n",
      "72/72 - 0s - loss: 42.2165 - mse: 42.2165\n",
      "Epoch 36/150\n",
      "72/72 - 0s - loss: 40.4076 - mse: 40.4076\n",
      "Epoch 37/150\n",
      "72/72 - 0s - loss: 38.5602 - mse: 38.5602\n",
      "Epoch 38/150\n",
      "72/72 - 0s - loss: 38.2869 - mse: 38.2869\n",
      "Epoch 39/150\n",
      "72/72 - 0s - loss: 36.5297 - mse: 36.5297\n",
      "Epoch 40/150\n",
      "72/72 - 0s - loss: 35.7557 - mse: 35.7557\n",
      "Epoch 41/150\n",
      "72/72 - 0s - loss: 33.5580 - mse: 33.5580\n",
      "Epoch 42/150\n",
      "72/72 - 0s - loss: 32.9096 - mse: 32.9096\n",
      "Epoch 43/150\n",
      "72/72 - 0s - loss: 31.8156 - mse: 31.8156\n",
      "Epoch 44/150\n",
      "72/72 - 0s - loss: 31.1843 - mse: 31.1843\n",
      "Epoch 45/150\n",
      "72/72 - 0s - loss: 30.3591 - mse: 30.3591\n",
      "Epoch 46/150\n",
      "72/72 - 0s - loss: 29.2035 - mse: 29.2035\n",
      "Epoch 47/150\n",
      "72/72 - 0s - loss: 28.8134 - mse: 28.8134\n",
      "Epoch 48/150\n",
      "72/72 - 0s - loss: 28.1772 - mse: 28.1772\n",
      "Epoch 49/150\n",
      "72/72 - 0s - loss: 28.1812 - mse: 28.1812\n",
      "Epoch 50/150\n",
      "72/72 - 0s - loss: 27.0533 - mse: 27.0533\n",
      "Epoch 51/150\n",
      "72/72 - 0s - loss: 26.6095 - mse: 26.6095\n",
      "Epoch 52/150\n",
      "72/72 - 0s - loss: 25.8540 - mse: 25.8540\n",
      "Epoch 53/150\n",
      "72/72 - 0s - loss: 25.2521 - mse: 25.2521\n",
      "Epoch 54/150\n",
      "72/72 - 0s - loss: 25.5914 - mse: 25.5914\n",
      "Epoch 55/150\n",
      "72/72 - 0s - loss: 24.7667 - mse: 24.7667\n",
      "Epoch 56/150\n",
      "72/72 - 0s - loss: 24.4768 - mse: 24.4768\n",
      "Epoch 57/150\n",
      "72/72 - 0s - loss: 24.0114 - mse: 24.0114\n",
      "Epoch 58/150\n",
      "72/72 - 0s - loss: 23.8281 - mse: 23.8281\n",
      "Epoch 59/150\n",
      "72/72 - 0s - loss: 23.3982 - mse: 23.3982\n",
      "Epoch 60/150\n",
      "72/72 - 0s - loss: 23.2374 - mse: 23.2374\n",
      "Epoch 61/150\n",
      "72/72 - 0s - loss: 22.4885 - mse: 22.4885\n",
      "Epoch 62/150\n",
      "72/72 - 0s - loss: 21.7790 - mse: 21.7790\n",
      "Epoch 63/150\n",
      "72/72 - 0s - loss: 21.9541 - mse: 21.9541\n",
      "Epoch 64/150\n",
      "72/72 - 0s - loss: 21.6870 - mse: 21.6870\n",
      "Epoch 65/150\n",
      "72/72 - 0s - loss: 21.2935 - mse: 21.2935\n",
      "Epoch 66/150\n",
      "72/72 - 0s - loss: 20.7305 - mse: 20.7305\n",
      "Epoch 67/150\n",
      "72/72 - 0s - loss: 21.3840 - mse: 21.3840\n",
      "Epoch 68/150\n",
      "72/72 - 0s - loss: 21.3769 - mse: 21.3769\n",
      "Epoch 69/150\n",
      "72/72 - 0s - loss: 20.5900 - mse: 20.5900\n",
      "Epoch 70/150\n",
      "72/72 - 0s - loss: 20.0897 - mse: 20.0897\n",
      "Epoch 71/150\n",
      "72/72 - 0s - loss: 19.9710 - mse: 19.9710\n",
      "Epoch 72/150\n",
      "72/72 - 0s - loss: 19.6706 - mse: 19.6706\n",
      "Epoch 73/150\n",
      "72/72 - 0s - loss: 19.2743 - mse: 19.2743\n",
      "Epoch 74/150\n",
      "72/72 - 0s - loss: 18.9153 - mse: 18.9153\n",
      "Epoch 75/150\n",
      "72/72 - 0s - loss: 19.1812 - mse: 19.1812\n",
      "Epoch 76/150\n",
      "72/72 - 0s - loss: 18.8550 - mse: 18.8550\n",
      "Epoch 77/150\n",
      "72/72 - 0s - loss: 18.5292 - mse: 18.5292\n",
      "Epoch 78/150\n",
      "72/72 - 0s - loss: 18.3868 - mse: 18.3868\n",
      "Epoch 79/150\n",
      "72/72 - 0s - loss: 18.5126 - mse: 18.5126\n",
      "Epoch 80/150\n",
      "72/72 - 0s - loss: 18.1484 - mse: 18.1484\n",
      "Epoch 81/150\n",
      "72/72 - 0s - loss: 18.0103 - mse: 18.0103\n",
      "Epoch 82/150\n",
      "72/72 - 0s - loss: 17.6610 - mse: 17.6610\n",
      "Epoch 83/150\n",
      "72/72 - 0s - loss: 17.4483 - mse: 17.4483\n",
      "Epoch 84/150\n",
      "72/72 - 0s - loss: 17.8500 - mse: 17.8500\n",
      "Epoch 85/150\n",
      "72/72 - 0s - loss: 17.2786 - mse: 17.2786\n",
      "Epoch 86/150\n",
      "72/72 - 0s - loss: 16.9240 - mse: 16.9240\n",
      "Epoch 87/150\n",
      "72/72 - 0s - loss: 16.3147 - mse: 16.3147\n",
      "Epoch 88/150\n",
      "72/72 - 0s - loss: 16.7813 - mse: 16.7813\n",
      "Epoch 89/150\n",
      "72/72 - 0s - loss: 16.3648 - mse: 16.3648\n",
      "Epoch 90/150\n",
      "72/72 - 0s - loss: 16.2543 - mse: 16.2543\n",
      "Epoch 91/150\n",
      "72/72 - 0s - loss: 16.5368 - mse: 16.5368\n",
      "Epoch 92/150\n",
      "72/72 - 0s - loss: 16.1650 - mse: 16.1650\n",
      "Epoch 93/150\n",
      "72/72 - 0s - loss: 16.2687 - mse: 16.2687\n",
      "Epoch 94/150\n",
      "72/72 - 0s - loss: 15.7605 - mse: 15.7605\n",
      "Epoch 95/150\n",
      "72/72 - 0s - loss: 15.8900 - mse: 15.8900\n",
      "Epoch 96/150\n",
      "72/72 - 0s - loss: 15.8722 - mse: 15.8722\n",
      "Epoch 97/150\n",
      "72/72 - 0s - loss: 15.2133 - mse: 15.2133\n",
      "Epoch 98/150\n",
      "72/72 - 0s - loss: 15.5131 - mse: 15.5131\n",
      "Epoch 99/150\n",
      "72/72 - 0s - loss: 15.6261 - mse: 15.6261\n",
      "Epoch 100/150\n",
      "72/72 - 0s - loss: 15.1767 - mse: 15.1767\n",
      "Epoch 101/150\n",
      "72/72 - 0s - loss: 14.8080 - mse: 14.8080\n",
      "Epoch 102/150\n",
      "72/72 - 0s - loss: 14.6669 - mse: 14.6669\n",
      "Epoch 103/150\n",
      "72/72 - 0s - loss: 14.4538 - mse: 14.4538\n",
      "Epoch 104/150\n",
      "72/72 - 0s - loss: 14.8717 - mse: 14.8717\n",
      "Epoch 105/150\n",
      "72/72 - 0s - loss: 14.8693 - mse: 14.8693\n",
      "Epoch 106/150\n",
      "72/72 - 0s - loss: 14.3664 - mse: 14.3664\n",
      "Epoch 107/150\n",
      "72/72 - 0s - loss: 14.0941 - mse: 14.0941\n",
      "Epoch 108/150\n",
      "72/72 - 0s - loss: 14.1140 - mse: 14.1140\n",
      "Epoch 109/150\n",
      "72/72 - 0s - loss: 13.7087 - mse: 13.7087\n",
      "Epoch 110/150\n",
      "72/72 - 0s - loss: 13.9009 - mse: 13.9009\n",
      "Epoch 111/150\n",
      "72/72 - 0s - loss: 13.1430 - mse: 13.1430\n",
      "Epoch 112/150\n",
      "72/72 - 0s - loss: 13.4794 - mse: 13.4794\n",
      "Epoch 113/150\n",
      "72/72 - 0s - loss: 13.9141 - mse: 13.9141\n",
      "Epoch 114/150\n",
      "72/72 - 0s - loss: 13.4132 - mse: 13.4132\n",
      "Epoch 115/150\n",
      "72/72 - 0s - loss: 12.9976 - mse: 12.9976\n",
      "Epoch 116/150\n",
      "72/72 - 0s - loss: 12.8957 - mse: 12.8957\n",
      "Epoch 117/150\n",
      "72/72 - 0s - loss: 12.5466 - mse: 12.5466\n",
      "Epoch 118/150\n",
      "72/72 - 0s - loss: 12.8457 - mse: 12.8457\n",
      "Epoch 119/150\n",
      "72/72 - 0s - loss: 12.8767 - mse: 12.8767\n",
      "Epoch 120/150\n",
      "72/72 - 0s - loss: 12.4274 - mse: 12.4274\n",
      "Epoch 121/150\n",
      "72/72 - 0s - loss: 11.4217 - mse: 11.4217\n",
      "Epoch 122/150\n",
      "72/72 - 0s - loss: 12.5826 - mse: 12.5826\n",
      "Epoch 123/150\n",
      "72/72 - 0s - loss: 12.0250 - mse: 12.0250\n",
      "Epoch 124/150\n",
      "72/72 - 0s - loss: 12.2574 - mse: 12.2574\n",
      "Epoch 125/150\n",
      "72/72 - 0s - loss: 11.9895 - mse: 11.9895\n",
      "Epoch 126/150\n",
      "72/72 - 0s - loss: 11.7824 - mse: 11.7824\n",
      "Epoch 127/150\n",
      "72/72 - 0s - loss: 11.0250 - mse: 11.0250\n",
      "Epoch 128/150\n",
      "72/72 - 0s - loss: 11.7244 - mse: 11.7244\n",
      "Epoch 129/150\n",
      "72/72 - 0s - loss: 11.3752 - mse: 11.3752\n",
      "Epoch 130/150\n",
      "72/72 - 0s - loss: 11.7173 - mse: 11.7173\n",
      "Epoch 131/150\n",
      "72/72 - 0s - loss: 11.4340 - mse: 11.4340\n",
      "Epoch 132/150\n",
      "72/72 - 0s - loss: 11.0993 - mse: 11.0993\n",
      "Epoch 133/150\n",
      "72/72 - 0s - loss: 11.3097 - mse: 11.3097\n",
      "Epoch 134/150\n",
      "72/72 - 0s - loss: 11.0284 - mse: 11.0284\n",
      "Epoch 135/150\n",
      "72/72 - 0s - loss: 10.7378 - mse: 10.7378\n",
      "Epoch 136/150\n",
      "72/72 - 0s - loss: 10.8024 - mse: 10.8024\n",
      "Epoch 137/150\n",
      "72/72 - 0s - loss: 10.2925 - mse: 10.2925\n",
      "Epoch 138/150\n",
      "72/72 - 0s - loss: 10.3667 - mse: 10.3667\n",
      "Epoch 139/150\n",
      "72/72 - 0s - loss: 10.4839 - mse: 10.4839\n",
      "Epoch 140/150\n",
      "72/72 - 0s - loss: 10.6239 - mse: 10.6239\n",
      "Epoch 141/150\n",
      "72/72 - 0s - loss: 10.2303 - mse: 10.2303\n",
      "Epoch 142/150\n",
      "72/72 - 0s - loss: 10.0915 - mse: 10.0915\n",
      "Epoch 143/150\n",
      "72/72 - 0s - loss: 10.2374 - mse: 10.2374\n",
      "Epoch 144/150\n",
      "72/72 - 0s - loss: 9.6071 - mse: 9.6071\n",
      "Epoch 145/150\n",
      "72/72 - 0s - loss: 10.0774 - mse: 10.0774\n",
      "Epoch 146/150\n",
      "72/72 - 0s - loss: 9.6584 - mse: 9.6584\n",
      "Epoch 147/150\n",
      "72/72 - 0s - loss: 9.6800 - mse: 9.6800\n",
      "Epoch 148/150\n",
      "72/72 - 0s - loss: 9.4606 - mse: 9.4606\n",
      "Epoch 149/150\n",
      "72/72 - 0s - loss: 9.4664 - mse: 9.4664\n",
      "Epoch 150/150\n",
      "72/72 - 0s - loss: 9.1657 - mse: 9.1657\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 99.2700 - mse: 99.2700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[99.26998901367188, 99.26998901367188]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=150, batch_size=4, verbose=2)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_33 (Dense)             (None, 32)                832       \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,921\n",
      "Trainable params: 1,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set prediction accuracy: 50.35 %\n",
      "test set prediction accuracy: 56.94 %\n"
     ]
    }
   ],
   "source": [
    "#평균 성능 테스트\n",
    "scores = 0\n",
    "mean=np.mean(Y, axis=0)\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= mean <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"train set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= mean <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"test set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### <오차범위 3>\n",
      "- train set prediction accuracy(+-3): 71.88 % <br>\n",
      "- test set prediction accuracy(+-3): 34.72 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 5>\n",
      "- train set prediction accuracy(+-5): 91.32 % <br>\n",
      "- test set prediction accuracy(+-5): 50.00 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 10>\n",
      "- train set prediction accuracy(+-10): 99.65 % <br>\n",
      "- test set prediction accuracy(+-10): 81.94 % <br>\n",
      "<br>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######입력용#######\n",
    "\n",
    "#오차 범위 3 설정\n",
    "print('### <오차범위 3>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "print('### <오차범위 5>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "print('### <오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (시본으로 선별한 특징)\n",
    "X1=psqi_df[['SEX','AGE','PSQI_TOTAL_1','BMI_1','WBC_1','GLU0_1','ALT_1','TG_1','LDL_1',\n",
    "            'Muscle_1','Fat_1_x','SBP_1','DBP_1','HR_1','Waist_1']].values\n",
    "\n",
    "X2=psqi_df[['SEX','AGE','PSQI_TOTAL_2','BMI_2','WBC_2','GLU0_2','ALT_2','TG_2','LDL_2',\n",
    "            'Muscle_2','Fat_2_x','SBP_2','DBP_2','HR_2','Waist_2']].values\n",
    "\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 72)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 15), (360, 1))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "72/72 - 1s - loss: 3503.1187 - mse: 3503.1187\n",
      "Epoch 2/150\n",
      "72/72 - 0s - loss: 2953.7666 - mse: 2953.7666\n",
      "Epoch 3/150\n",
      "72/72 - 0s - loss: 2167.2681 - mse: 2167.2681\n",
      "Epoch 4/150\n",
      "72/72 - 0s - loss: 1311.2179 - mse: 1311.2179\n",
      "Epoch 5/150\n",
      "72/72 - 0s - loss: 650.9197 - mse: 650.9197\n",
      "Epoch 6/150\n",
      "72/72 - 0s - loss: 360.5430 - mse: 360.5430\n",
      "Epoch 7/150\n",
      "72/72 - 0s - loss: 301.5302 - mse: 301.5302\n",
      "Epoch 8/150\n",
      "72/72 - 0s - loss: 261.2922 - mse: 261.2922\n",
      "Epoch 9/150\n",
      "72/72 - 0s - loss: 232.2170 - mse: 232.2170\n",
      "Epoch 10/150\n",
      "72/72 - 0s - loss: 206.3615 - mse: 206.3615\n",
      "Epoch 11/150\n",
      "72/72 - 0s - loss: 189.1823 - mse: 189.1823\n",
      "Epoch 12/150\n",
      "72/72 - 0s - loss: 179.0465 - mse: 179.0465\n",
      "Epoch 13/150\n",
      "72/72 - 0s - loss: 168.6813 - mse: 168.6813\n",
      "Epoch 14/150\n",
      "72/72 - 0s - loss: 162.5022 - mse: 162.5022\n",
      "Epoch 15/150\n",
      "72/72 - 0s - loss: 157.0538 - mse: 157.0538\n",
      "Epoch 16/150\n",
      "72/72 - 0s - loss: 151.7481 - mse: 151.7481\n",
      "Epoch 17/150\n",
      "72/72 - 0s - loss: 147.5046 - mse: 147.5046\n",
      "Epoch 18/150\n",
      "72/72 - 0s - loss: 143.9452 - mse: 143.9452\n",
      "Epoch 19/150\n",
      "72/72 - 0s - loss: 140.9381 - mse: 140.9381\n",
      "Epoch 20/150\n",
      "72/72 - 0s - loss: 137.8011 - mse: 137.8011\n",
      "Epoch 21/150\n",
      "72/72 - 0s - loss: 135.8322 - mse: 135.8322\n",
      "Epoch 22/150\n",
      "72/72 - 0s - loss: 134.0024 - mse: 134.0024\n",
      "Epoch 23/150\n",
      "72/72 - 0s - loss: 131.3719 - mse: 131.3719\n",
      "Epoch 24/150\n",
      "72/72 - 0s - loss: 127.4916 - mse: 127.4916\n",
      "Epoch 25/150\n",
      "72/72 - 0s - loss: 126.4482 - mse: 126.4482\n",
      "Epoch 26/150\n",
      "72/72 - 0s - loss: 125.2097 - mse: 125.2097\n",
      "Epoch 27/150\n",
      "72/72 - 0s - loss: 122.7385 - mse: 122.7385\n",
      "Epoch 28/150\n",
      "72/72 - 0s - loss: 123.1319 - mse: 123.1319\n",
      "Epoch 29/150\n",
      "72/72 - 0s - loss: 120.9742 - mse: 120.9742\n",
      "Epoch 30/150\n",
      "72/72 - 0s - loss: 120.8934 - mse: 120.8934\n",
      "Epoch 31/150\n",
      "72/72 - 0s - loss: 118.5009 - mse: 118.5009\n",
      "Epoch 32/150\n",
      "72/72 - 0s - loss: 117.6352 - mse: 117.6352\n",
      "Epoch 33/150\n",
      "72/72 - 0s - loss: 115.6732 - mse: 115.6732\n",
      "Epoch 34/150\n",
      "72/72 - 0s - loss: 116.3505 - mse: 116.3505\n",
      "Epoch 35/150\n",
      "72/72 - 0s - loss: 115.2400 - mse: 115.2400\n",
      "Epoch 36/150\n",
      "72/72 - 0s - loss: 114.9430 - mse: 114.9430\n",
      "Epoch 37/150\n",
      "72/72 - 0s - loss: 113.4360 - mse: 113.4360\n",
      "Epoch 38/150\n",
      "72/72 - 0s - loss: 112.3083 - mse: 112.3083\n",
      "Epoch 39/150\n",
      "72/72 - 0s - loss: 111.2333 - mse: 111.2333\n",
      "Epoch 40/150\n",
      "72/72 - 0s - loss: 111.2814 - mse: 111.2814\n",
      "Epoch 41/150\n",
      "72/72 - 0s - loss: 110.5623 - mse: 110.5623\n",
      "Epoch 42/150\n",
      "72/72 - 0s - loss: 108.8143 - mse: 108.8143\n",
      "Epoch 43/150\n",
      "72/72 - 0s - loss: 107.5485 - mse: 107.5485\n",
      "Epoch 44/150\n",
      "72/72 - 0s - loss: 109.3485 - mse: 109.3485\n",
      "Epoch 45/150\n",
      "72/72 - 0s - loss: 108.0948 - mse: 108.0948\n",
      "Epoch 46/150\n",
      "72/72 - 0s - loss: 106.7995 - mse: 106.7995\n",
      "Epoch 47/150\n",
      "72/72 - 0s - loss: 106.9318 - mse: 106.9318\n",
      "Epoch 48/150\n",
      "72/72 - 0s - loss: 105.0019 - mse: 105.0019\n",
      "Epoch 49/150\n",
      "72/72 - 0s - loss: 104.5560 - mse: 104.5560\n",
      "Epoch 50/150\n",
      "72/72 - 0s - loss: 104.1661 - mse: 104.1661\n",
      "Epoch 51/150\n",
      "72/72 - 0s - loss: 103.7831 - mse: 103.7831\n",
      "Epoch 52/150\n",
      "72/72 - 0s - loss: 102.0902 - mse: 102.0902\n",
      "Epoch 53/150\n",
      "72/72 - 0s - loss: 102.3737 - mse: 102.3737\n",
      "Epoch 54/150\n",
      "72/72 - 0s - loss: 102.1970 - mse: 102.1970\n",
      "Epoch 55/150\n",
      "72/72 - 0s - loss: 101.1650 - mse: 101.1650\n",
      "Epoch 56/150\n",
      "72/72 - 0s - loss: 100.5707 - mse: 100.5707\n",
      "Epoch 57/150\n",
      "72/72 - 0s - loss: 100.2188 - mse: 100.2188\n",
      "Epoch 58/150\n",
      "72/72 - 0s - loss: 99.6875 - mse: 99.6875\n",
      "Epoch 59/150\n",
      "72/72 - 0s - loss: 99.6967 - mse: 99.6967\n",
      "Epoch 60/150\n",
      "72/72 - 0s - loss: 97.5223 - mse: 97.5223\n",
      "Epoch 61/150\n",
      "72/72 - 0s - loss: 98.7588 - mse: 98.7588\n",
      "Epoch 62/150\n",
      "72/72 - 0s - loss: 97.2759 - mse: 97.2759\n",
      "Epoch 63/150\n",
      "72/72 - 0s - loss: 97.1115 - mse: 97.1115\n",
      "Epoch 64/150\n",
      "72/72 - 0s - loss: 96.9146 - mse: 96.9146\n",
      "Epoch 65/150\n",
      "72/72 - 0s - loss: 96.2417 - mse: 96.2417\n",
      "Epoch 66/150\n",
      "72/72 - 0s - loss: 95.2797 - mse: 95.2797\n",
      "Epoch 67/150\n",
      "72/72 - 0s - loss: 95.3373 - mse: 95.3373\n",
      "Epoch 68/150\n",
      "72/72 - 0s - loss: 94.5503 - mse: 94.5503\n",
      "Epoch 69/150\n",
      "72/72 - 0s - loss: 95.0660 - mse: 95.0660\n",
      "Epoch 70/150\n",
      "72/72 - 0s - loss: 94.0369 - mse: 94.0369\n",
      "Epoch 71/150\n",
      "72/72 - 0s - loss: 93.0645 - mse: 93.0645\n",
      "Epoch 72/150\n",
      "72/72 - 0s - loss: 93.3095 - mse: 93.3095\n",
      "Epoch 73/150\n",
      "72/72 - 0s - loss: 91.7854 - mse: 91.7854\n",
      "Epoch 74/150\n",
      "72/72 - 0s - loss: 91.8150 - mse: 91.8150\n",
      "Epoch 75/150\n",
      "72/72 - 0s - loss: 91.5438 - mse: 91.5438\n",
      "Epoch 76/150\n",
      "72/72 - 0s - loss: 90.6003 - mse: 90.6003\n",
      "Epoch 77/150\n",
      "72/72 - 0s - loss: 89.5742 - mse: 89.5742\n",
      "Epoch 78/150\n",
      "72/72 - 0s - loss: 89.7129 - mse: 89.7129\n",
      "Epoch 79/150\n",
      "72/72 - 0s - loss: 88.6745 - mse: 88.6745\n",
      "Epoch 80/150\n",
      "72/72 - 0s - loss: 88.4425 - mse: 88.4425\n",
      "Epoch 81/150\n",
      "72/72 - 0s - loss: 88.1272 - mse: 88.1272\n",
      "Epoch 82/150\n",
      "72/72 - 0s - loss: 86.9426 - mse: 86.9426\n",
      "Epoch 83/150\n",
      "72/72 - 0s - loss: 86.9784 - mse: 86.9784\n",
      "Epoch 84/150\n",
      "72/72 - 0s - loss: 86.0691 - mse: 86.0691\n",
      "Epoch 85/150\n",
      "72/72 - 0s - loss: 85.6612 - mse: 85.6612\n",
      "Epoch 86/150\n",
      "72/72 - 0s - loss: 84.0568 - mse: 84.0568\n",
      "Epoch 87/150\n",
      "72/72 - 0s - loss: 84.9233 - mse: 84.9233\n",
      "Epoch 88/150\n",
      "72/72 - 0s - loss: 83.9178 - mse: 83.9178\n",
      "Epoch 89/150\n",
      "72/72 - 0s - loss: 83.8213 - mse: 83.8213\n",
      "Epoch 90/150\n",
      "72/72 - 0s - loss: 84.1521 - mse: 84.1521\n",
      "Epoch 91/150\n",
      "72/72 - 0s - loss: 82.3193 - mse: 82.3193\n",
      "Epoch 92/150\n",
      "72/72 - 0s - loss: 82.5259 - mse: 82.5259\n",
      "Epoch 93/150\n",
      "72/72 - 0s - loss: 81.1388 - mse: 81.1388\n",
      "Epoch 94/150\n",
      "72/72 - 0s - loss: 81.6455 - mse: 81.6455\n",
      "Epoch 95/150\n",
      "72/72 - 0s - loss: 80.7332 - mse: 80.7332\n",
      "Epoch 96/150\n",
      "72/72 - 0s - loss: 79.5998 - mse: 79.5998\n",
      "Epoch 97/150\n",
      "72/72 - 0s - loss: 79.8944 - mse: 79.8944\n",
      "Epoch 98/150\n",
      "72/72 - 0s - loss: 78.6460 - mse: 78.6460\n",
      "Epoch 99/150\n",
      "72/72 - 0s - loss: 78.9857 - mse: 78.9857\n",
      "Epoch 100/150\n",
      "72/72 - 0s - loss: 78.0628 - mse: 78.0628\n",
      "Epoch 101/150\n",
      "72/72 - 0s - loss: 77.5796 - mse: 77.5796\n",
      "Epoch 102/150\n",
      "72/72 - 0s - loss: 76.4172 - mse: 76.4172\n",
      "Epoch 103/150\n",
      "72/72 - 0s - loss: 74.7580 - mse: 74.7580\n",
      "Epoch 104/150\n",
      "72/72 - 0s - loss: 76.6217 - mse: 76.6217\n",
      "Epoch 105/150\n",
      "72/72 - 0s - loss: 74.7285 - mse: 74.7285\n",
      "Epoch 106/150\n",
      "72/72 - 0s - loss: 74.3392 - mse: 74.3392\n",
      "Epoch 107/150\n",
      "72/72 - 0s - loss: 71.7531 - mse: 71.7531\n",
      "Epoch 108/150\n",
      "72/72 - 0s - loss: 74.3704 - mse: 74.3704\n",
      "Epoch 109/150\n",
      "72/72 - 0s - loss: 73.1297 - mse: 73.1297\n",
      "Epoch 110/150\n",
      "72/72 - 0s - loss: 72.5903 - mse: 72.5903\n",
      "Epoch 111/150\n",
      "72/72 - 0s - loss: 71.8825 - mse: 71.8825\n",
      "Epoch 112/150\n",
      "72/72 - 0s - loss: 70.8745 - mse: 70.8745\n",
      "Epoch 113/150\n",
      "72/72 - 0s - loss: 71.0352 - mse: 71.0352\n",
      "Epoch 114/150\n",
      "72/72 - 0s - loss: 69.6178 - mse: 69.6178\n",
      "Epoch 115/150\n",
      "72/72 - 0s - loss: 70.3426 - mse: 70.3426\n",
      "Epoch 116/150\n",
      "72/72 - 0s - loss: 67.4917 - mse: 67.4917\n",
      "Epoch 117/150\n",
      "72/72 - 0s - loss: 68.4964 - mse: 68.4964\n",
      "Epoch 118/150\n",
      "72/72 - 0s - loss: 68.5206 - mse: 68.5206\n",
      "Epoch 119/150\n",
      "72/72 - 0s - loss: 66.8484 - mse: 66.8484\n",
      "Epoch 120/150\n",
      "72/72 - 0s - loss: 66.7922 - mse: 66.7922\n",
      "Epoch 121/150\n",
      "72/72 - 0s - loss: 65.4441 - mse: 65.4441\n",
      "Epoch 122/150\n",
      "72/72 - 0s - loss: 65.9949 - mse: 65.9949\n",
      "Epoch 123/150\n",
      "72/72 - 0s - loss: 65.0908 - mse: 65.0908\n",
      "Epoch 124/150\n",
      "72/72 - 0s - loss: 64.0693 - mse: 64.0693\n",
      "Epoch 125/150\n",
      "72/72 - 0s - loss: 64.6521 - mse: 64.6521\n",
      "Epoch 126/150\n",
      "72/72 - 0s - loss: 64.3088 - mse: 64.3088\n",
      "Epoch 127/150\n",
      "72/72 - 0s - loss: 62.7801 - mse: 62.7801\n",
      "Epoch 128/150\n",
      "72/72 - 0s - loss: 62.7130 - mse: 62.7130\n",
      "Epoch 129/150\n",
      "72/72 - 0s - loss: 62.6226 - mse: 62.6226\n",
      "Epoch 130/150\n",
      "72/72 - 0s - loss: 61.6787 - mse: 61.6787\n",
      "Epoch 131/150\n",
      "72/72 - 0s - loss: 60.5447 - mse: 60.5447\n",
      "Epoch 132/150\n",
      "72/72 - 0s - loss: 60.6733 - mse: 60.6733\n",
      "Epoch 133/150\n",
      "72/72 - 0s - loss: 59.9925 - mse: 59.9925\n",
      "Epoch 134/150\n",
      "72/72 - 0s - loss: 59.3757 - mse: 59.3757\n",
      "Epoch 135/150\n",
      "72/72 - 0s - loss: 59.3960 - mse: 59.3960\n",
      "Epoch 136/150\n",
      "72/72 - 0s - loss: 58.9949 - mse: 58.9949\n",
      "Epoch 137/150\n",
      "72/72 - 0s - loss: 57.4366 - mse: 57.4366\n",
      "Epoch 138/150\n",
      "72/72 - 0s - loss: 57.2858 - mse: 57.2858\n",
      "Epoch 139/150\n",
      "72/72 - 0s - loss: 56.6922 - mse: 56.6922\n",
      "Epoch 140/150\n",
      "72/72 - 0s - loss: 56.4848 - mse: 56.4848\n",
      "Epoch 141/150\n",
      "72/72 - 0s - loss: 55.4053 - mse: 55.4053\n",
      "Epoch 142/150\n",
      "72/72 - 0s - loss: 55.6407 - mse: 55.6407\n",
      "Epoch 143/150\n",
      "72/72 - 0s - loss: 55.3321 - mse: 55.3321\n",
      "Epoch 144/150\n",
      "72/72 - 0s - loss: 54.5641 - mse: 54.5641\n",
      "Epoch 145/150\n",
      "72/72 - 0s - loss: 54.2672 - mse: 54.2672\n",
      "Epoch 146/150\n",
      "72/72 - 0s - loss: 53.3601 - mse: 53.3601\n",
      "Epoch 147/150\n",
      "72/72 - 0s - loss: 52.4477 - mse: 52.4477\n",
      "Epoch 148/150\n",
      "72/72 - 0s - loss: 52.1875 - mse: 52.1875\n",
      "Epoch 149/150\n",
      "72/72 - 0s - loss: 50.8606 - mse: 50.8606\n",
      "Epoch 150/150\n",
      "72/72 - 0s - loss: 50.5965 - mse: 50.5965\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 121.8063 - mse: 121.8063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[121.80634307861328, 121.80634307861328]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=150, batch_size=4, verbose=2)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 32)                512       \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,601\n",
      "Trainable params: 1,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAEvCAYAAABolJlEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAArZUlEQVR4nO3dfbQc9X3f8fd3Zp/33qsnxJOusARVYkCyhREElx7ihDRgOzU4OTkRpTaO7eD6kJQ0aVqwT+r4tCRpcILjFrshsQsksQlpnFj1gZaHOiH0EIRwhXmQKTJgc4UMQiDpPu3TzLd/zFyxSHt1H3R1Z/fu53XOnp357czu96eH+5n5/ebumLsjIiIi3S/IugARERGZHYW2iIhIj1Boi4iI9AiFtoiISI9QaIuIiPQIhbaIiEiPyGVdwExOOukkX7duXdZliIiILIrHH3/8NXdf3em1rg/tdevWsWPHjqzLEBERWRRm9v3pXtPwuIiISI9QaIuIiPQIhbaIiEiP6Po5bRER6U/NZpORkRFqtVrWpZwQpVKJ4eFh8vn8rPdRaIuISFcaGRlhcHCQdevWYWZZl7Og3J39+/czMjLC+vXrZ72fhsdFRKQr1Wo1Vq1ateQCG8DMWLVq1ZxHERTaIiLStZZiYE+ZT99mDG0zK5nZdjN7wsyeNrPPpu2/ZWZ7zGxn+nhf2z43mtluM3vWzC5raz/fzJ5MX/uCLeW/DRER6XkDAwNZl/AWs5nTrgM/6e5jZpYHHjaze9PXbnH3z7VvbGbnAFuBc4HTgQfM7EfcPQK+BFwL/ANwD3A5cC8iIiIyoxnPtD0xlq7m04cfY5crgLvcve7uLwC7gQvN7DRgyN0fcXcH7gSuPK7q52jnA19j5wNfW8yPFBGRJcDd+Y3f+A02btzIpk2b+Iu/+AsA9u7dyyWXXMLmzZvZuHEjf//3f08URXzkIx85vO0tt9yyYHXM6upxMwuBx4F/BNzq7o+a2XuBXzazDwM7gF939zeANSRn0lNG0rZmunxk+6IpbL81Odr4qasW82NFRKTHff3rX2fnzp088cQTvPbaa1xwwQVccsklfPWrX+Wyyy7j05/+NFEUMTExwc6dO9mzZw9PPfUUAAcOHFiwOmYV2unQ9mYzWw78tZltJBnq/g8kZ93/Afh94KNAp3lqP0b7UczsWpJhdM4444zZlDgr9dwQy2t7Fuz9RERkcXz2fzzNMy8fWtD3POf0IT7zz86d1bYPP/wwV111FWEYcsopp/DjP/7jPPbYY1xwwQV89KMfpdlscuWVV7J582bOPPNMnn/+eX7lV36F97///fz0T//0gtU8p6vH3f0A8LfA5e7+irtH7h4DfwxcmG42Aqxt220YeDltH+7Q3ulzbnP3Le6+ZfXqjjc6mZdmYRnVeGH/0kVEZOlLZnWPdskll/DQQw+xZs0aPvShD3HnnXeyYsUKnnjiCd7znvdw66238vGPf3zB6pjxTNvMVgNNdz9gZmXgp4D/ZGanufvedLMPAk+ly9uAr5rZH5BciLYB2O7ukZmNmtlFwKPAh4H/vGA9mYW4uIzBw9PzIiLSK2Z7RnyiXHLJJfzRH/0R11xzDa+//joPPfQQN998M9///vdZs2YNv/RLv8T4+Djf/va3ed/73kehUODnfu7nOOuss/jIRz6yYHXMZnj8NOCOdF47AO5292+a2Z+a2WaSIe4XgU8AuPvTZnY38AzQAq5Lh9cBPgncDpRJrhpf3CvHyyspW4Pa5DilcnVRP1pERHrXBz/4QR555BHe+c53Ymb83u/9Hqeeeip33HEHN998M/l8noGBAe6880727NnDL/7iLxLHMQC/8zu/s2B12HSn/N1iy5YtvlD303707pv5sWf+I69d+x1OOv1tC/KeIiJyYuzatYuzzz476zJOqE59NLPH3X1Lp+376hvRcgMrARg7uC/jSkREROaur0K7kIb2xMHXMq5ERERk7voqtEtDJwHQGH0940pERETmrq9Cu7os+fWxxtj+jCsRERGZu74K7YEVSWjHEzrTFhGR3tNfoT24nMgNn3gj61JERETmrK9COwhDDtkAQf1g1qWIiIjMWV+FNsCYDZKrH8i6DBERkTnru9CeDAfIN3WmLSIiM3vxxRd5+9vfzsc//nE2btzI1VdfzQMPPMDFF1/Mhg0b2L59O3/3d3/H5s2b2bx5M+eddx6jo6MA3HzzzVxwwQW84x3v4DOf+cyC1DOru3wtJbXcMsqtA1mXISIiPWL37t385V/+JbfddhsXXHABX/3qV3n44YfZtm0bv/3bv00URdx6661cfPHFjI2NUSqVuO+++3juuefYvn077s4HPvABHnroIS655JLjqqXvQrtRWMbK+ktZlyEiInNx7w3wwycX9j1P3QTv/d0ZN1u/fj2bNm0C4Nxzz+XSSy/FzNi0aRMvvvgiW7du5dd+7de4+uqr+dmf/VmGh4e57777uO+++zjvvPMAGBsb47nnnlNoz1VUWMagj2ZdhoiI9IhisXh4OQiCw+tBENBqtbjhhht4//vfzz333MNFF13EAw88gLtz44038olPfGJBa+m70PbScgZ9gqjVIsz1XfdFRHrTLM6Is/K9732PTZs2sWnTJh555BG++93vctlll/Gbv/mbXH311QwMDLBnzx7y+Twnn3zycX1W/6VWZQWBOQcP7mfZqlOyrkZERHrc5z//eb71rW8RhiHnnHMO733veykWi+zatYt3v/vdAAwMDPBnf/ZnCu25CitTd/p6TaEtIiLHtG7dOp566qnD67fffvu0rx3p+uuv5/rrr1/QevruV77yg6sAGD+gO32JiEhv6bvQLqW356wdUmiLiEhv6bvQLi9Lb8+pO32JiEiP6bvQri5P7vQVjeumISIi3c7dsy7hhJlP3/outId0e04RkZ5QKpXYv3//kgxud2f//v2USqU57dd3V48XiiUmvIjVDmRdioiIHMPw8DAjIyPs27cv61JOiFKpxPDw8Jz26bvQBjhkg4S6PaeISFfL5/OsX78+6zK6St8NjwOMh4PkGgptERHpLX0Z2rVwkJJuzykiIj2mL0O7nl9GOTqUdRkiIiJz0peh3SosoxqPZV2GiIjInPRlaMfFZQz5GB7HWZciIiIyazOGtpmVzGy7mT1hZk+b2WfT9pVmdr+ZPZc+r2jb50Yz221mz5rZZW3t55vZk+lrXzAzOzHdOjYvr6BoTWqT41l8vIiIyLzM5ky7Dvyku78T2AxcbmYXATcAD7r7BuDBdB0zOwfYCpwLXA580czC9L2+BFwLbEgfly9cV2YvSO/0deiNV7P4eBERkXmZMbQ9MTUBnE8fDlwB3JG23wFcmS5fAdzl7nV3fwHYDVxoZqcBQ+7+iCdfb3Nn2z6LKp/eNGTioG4aIiIivWNWc9pmFprZTuBV4H53fxQ4xd33AqTPU3f2XgO81Lb7SNq2Jl0+sr3T511rZjvMbMeJ+CacwuHQ1k1DRESkd8wqtN09cvfNwDDJWfPGY2zeaZ7aj9He6fNuc/ct7r5l9erVsylxTkpDyZ2+6qMKbRER6R1zunrc3Q8Af0syF/1KOuRN+jw1QTwCrG3bbRh4OW0f7tC+6KrLk9Bu6facIiLSQ2Zz9fhqM1ueLpeBnwK+C2wDrkk3uwb4Rrq8DdhqZkUzW09ywdn2dAh91MwuSq8a/3DbPotqIL09Zzyp23OKiEjvmM0NQ04D7kivAA+Au939m2b2CHC3mX0M+AHw8wDu/rSZ3Q08A7SA69w9St/rk8DtQBm4N30suurAsmShNprFx4uIiMzLjKHt7t8BzuvQvh+4dJp9bgJu6tC+AzjWfPiiCMKQCS9CU7+nLSIivaMvvxENYMLKBAptERHpIX0b2jUrEyq0RUSkh/RvaAcVwtZE1mWIiIjMWt+GdiMok48U2iIi0jv6NrSbYZmCQltERHpI34Z2K1el6JNZlyEiIjJrfRvaUa5CKVZoi4hI7+jb0I7zVco60xYRkR7St6HthQEq1PA4zroUERGRWenb0KZQJTSnNqnf1RYRkd7Qt6EdlAYBmBg7mHElIiIis9O/oV0cAKA2rpuGiIhIb+jb0A5LU6GtM20REekNfRva+fIQAM2JQxlXIiIiMjt9HNrJnHZDoS0iIj2ib0O7WE3OtFs1zWmLiEhv6N/QriwDoFUby7gSERGR2enb0C5Vk+HxWGfaIiLSI/o2tCuDywHwhs60RUSkN/RtaBeLZVoeQF2hLSIivaFvQ9uCgAkrEzT1NaYiItIb+ja0ASYpYc2JrMsQERGZlb4O7VpQJtfS8LiIiPSGvg7telAh19I9tUVEpDf0dWg3gzL5SMPjIiLSG/o7tHMVCrFCW0REesOMoW1ma83sW2a2y8yeNrPr0/bfMrM9ZrYzfbyvbZ8bzWy3mT1rZpe1tZ9vZk+mr33BzOzEdGt2WrkqxVjD4yIi0htys9imBfy6u3/bzAaBx83s/vS1W9z9c+0bm9k5wFbgXOB04AEz+xF3j4AvAdcC/wDcA1wO3LswXZm7KFeh7AptERHpDTOeabv7Xnf/dro8CuwC1hxjlyuAu9y97u4vALuBC83sNGDI3R9xdwfuBK483g4cD89XKXstyxJERERmbU5z2ma2DjgPeDRt+mUz+46ZfcXMVqRta4CX2nYbSdvWpMtHtmfGCwNUrE7UamVZhoiIyKzMOrTNbAD4K+BX3f0QyVD3WcBmYC/w+1Obdtjdj9He6bOuNbMdZrZj3759sy1xzqxYBWBiXPfUFhGR7jer0DazPElg/7m7fx3A3V9x98jdY+CPgQvTzUeAtW27DwMvp+3DHdqP4u63ufsWd9+yevXqufRnTqyY3OmrptAWEZEeMJurxw34MrDL3f+grf20ts0+CDyVLm8DtppZ0czWAxuA7e6+Fxg1s4vS9/ww8I0F6se8hMUBAGrjB7MsQ0REZFZmc/X4xcCHgCfNbGfa9ingKjPbTDLE/SLwCQB3f9rM7gaeIbny/Lr0ynGATwK3A2WSq8Yzu3IcIFceAnSmLSIivWHG0Hb3h+k8H33PMfa5CbipQ/sOYONcCjyRcuXkTLsxMZpxJSIiIjPr629EK1SSM+3mpM60RUSk+/V1aBfT0G7VdKYtIiLdr79Du5qEdlzT7TlFRKT79XVol6vLAIh1pi0iIj2gr0O7MpCcaXtjPONKREREZtbXoZ0vFKl7HhoaHhcRke7X16ENMGFlAoW2iIj0gL4P7UkrEbQmsi5DRERkRn0f2nUrk2tqTltERLqfQjuokIt0pi0iIt2v70O7GZYpRJNZlyEiIjIjhXauSjHWmbaIiHS/vg/tKFehGOtMW0REul/fh3acr1JGoS0iIt1PoZ0foOK1rMsQERGZUd+HNoUKBWvRqCu4RUSku/V9aFtxAIDJsYMZVyIiInJsfR/aQXEQgMnxQxlXIiIicmx9H9phKTnTro3rTFtERLpb34d2rpyEdmNSNw0REZHuptBOh8cbExoeFxGR7tb3oV2oJKHdqummISIi0t0U2unweKuu4XEREelufR/axeoQAHFNoS0iIt2t70O7nA6Px3UNj4uISHfr+9AuVZPQ9obOtEVEpLv1fWgXCiWaHkJDt+cUEZHuNmNom9laM/uWme0ys6fN7Pq0faWZ3W9mz6XPK9r2udHMdpvZs2Z2WVv7+Wb2ZPraF8zMTky3Zs+CgEkrYk2FtoiIdLfZnGm3gF9397OBi4DrzOwc4AbgQXffADyYrpO+thU4F7gc+KKZhel7fQm4FtiQPi5fwL7MW40SQVNz2iIi0t1mDG133+vu306XR4FdwBrgCuCOdLM7gCvT5SuAu9y97u4vALuBC83sNGDI3R9xdwfubNsnU3UrEUa6p7aIiHS3Oc1pm9k64DzgUeAUd98LSbADJ6ebrQFeatttJG1bky4f2Z65elAmbCm0RUSku806tM1sAPgr4Ffd/Vjf+dlpntqP0d7ps641sx1mtmPfvn2zLXHeGkGZfKQ5bRER6W6zCm0zy5ME9p+7+9fT5lfSIW/S51fT9hFgbdvuw8DLaftwh/ajuPtt7r7F3besXr16tn2Zt1ZYJh/XTvjniIiIHI/ZXD1uwJeBXe7+B20vbQOuSZevAb7R1r7VzIpmtp7kgrPt6RD6qJldlL7nh9v2yVQrLFOMNTwuIiLdLTeLbS4GPgQ8aWY707ZPAb8L3G1mHwN+APw8gLs/bWZ3A8+QXHl+nbtH6X6fBG4HysC96SNzUa5CUWfaIiLS5WYMbXd/mM7z0QCXTrPPTcBNHdp3ABvnUuBiiPMViii0RUSku/X9N6JBEtoVV2iLiEh3U2gD5KsUrUmr2ci6EhERkWkptAErVACYGB/NuBIREZHpKbQBKw4AUJ9QaIuISPdSaANhsQpATaEtIiJdTKENhKXkntr18WN90ZuIiEi2FNpArpScaTdrYxlXIiIiMj2FNpAvJXPazUmFtoiIdC+FNlCoDAHQqmlOW0REupdCGyhWkjPtqDaecSUiIiLTU2gDxfRMO65reFxERLqXQhsoV5Orx72hM20REeleCm2gXJkK7YmMKxEREZmeQhsIwpAJL2INDY+LiEj3UminalbEWpNZlyEiIjIthXaqZmWClobHRUSkeym0U3UrkVNoi4hIF1NopxpBiTDS8LiIiHQvhXaqGZYpKLRFRKSLKbRTzbBCPlZoi4hI91Jop6KwTDGuZV2GiIjItBTaqThfoeQ60xYRke6l0E7FuQolr2ddhoiIyLQU2ikvVClTw+M461JEREQ6UmhPyVcIzanX9LvaIiLSnRTaKStUAZgcH824EhERkc4U2qmgNADA5PihjCsRERHpbMbQNrOvmNmrZvZUW9tvmdkeM9uZPt7X9tqNZrbbzJ41s8va2s83syfT175gZrbw3Zm/sJicaTcmdaYtIiLdaTZn2rcDl3dov8XdN6ePewDM7BxgK3Buus8XzSxMt/8ScC2wIX10es/M5ErJPbUbk7o9p4iIdKcZQ9vdHwJen+X7XQHc5e51d38B2A1caGanAUPu/oi7O3AncOU8az4hcunweGNCw+MiItKdjmdO+5fN7Dvp8PmKtG0N8FLbNiNp25p0+cj2rlEoJ6Hdqo1nXImIiEhn8w3tLwFnAZuBvcDvp+2d5qn9GO0dmdm1ZrbDzHbs27dvniXOTaEyBECrruFxERHpTvMKbXd/xd0jd4+BPwYuTF8aAda2bToMvJy2D3don+79b3P3Le6+ZfXq1fMpcc6KleRMO64ptEVEpDvNK7TTOeopHwSmrizfBmw1s6KZrSe54Gy7u+8FRs3sovSq8Q8D3ziOuhdcuboMgLiu4XEREelOuZk2MLOvAe8BTjKzEeAzwHvMbDPJEPeLwCcA3P1pM7sbeAZoAde5e5S+1SdJrkQvA/emj65RriZXj3tDZ9oiItKdZgxtd7+qQ/OXj7H9TcBNHdp3ABvnVN0iKhRLND2Ehr7GVEREupO+Ea3NpJWwpkJbRES6k0K7TY0iQVNz2iIi0p0U2m1qQZkwmsy6DBERkY4U2m0aViJsKbRFRKQ7KbTbNIIy+Uhz2iIi0p0U2m2aYZl8XMu6DBERkY4U2m2iXJlirOFxERHpTgrtNlGuSlFn2iIi0qUU2m3iXIUymtMWEZHupNBuExcHqfokHsdZlyIiInIUhXYbKw6Rs5jJidGsSxERETmKQruNlZM7fY0feiPjSkRERI6m0G4TVpLQnjj0esaViIiIHE2h3SafnmnXxg5kW4iIiEgHCu02xepyABrjBzKtQ0REpBOFdpvi4AoAGuMHM65ERETkaArtNuU0tKPJA9kWIiIi0oFCu00lDe24dijjSkRERI6m0G4zMLic2A1XaIuISBdSaLcJwpBxSlhdoS0iIt1HoX2EcasSNvSNaCIi0n0U2keoBRXC5ljWZYiIiBxFoX2EWjhAoaUzbRER6T4K7SPUwyrFaDzrMkRERI6i0D5CKz9ASaEtIiJdSKF9hFZ+kLJPZF2GiIjIURTaR/DCIAOuM20REek+M4a2mX3FzF41s6fa2laa2f1m9lz6vKLttRvNbLeZPWtml7W1n29mT6avfcHMbOG7c/y8NETJmjTqtaxLEREReYvZnGnfDlx+RNsNwIPuvgF4MF3HzM4BtgLnpvt80czCdJ8vAdcCG9LHke/ZFaw4BMDYwf0ZVyIiIvJWM4a2uz8EvH5E8xXAHenyHcCVbe13uXvd3V8AdgMXmtlpwJC7P+LuDtzZtk9XCdN7ak/qntoiItJl5junfYq77wVIn09O29cAL7VtN5K2rUmXj2zvyMyuNbMdZrZj37598yxxfnKVNLRH31jUzxUREZnJQl+I1mme2o/R3pG73+buW9x9y+rVqxesuNkoVJPp+dqYQltERLrLfEP7lXTIm/T51bR9BFjbtt0w8HLaPtyhvesUB5Iz7eb4wYwrEREReav5hvY24Jp0+RrgG23tW82saGbrSS44254OoY+a2UXpVeMfbtunq5TTe2q3JhTaIiLSXXIzbWBmXwPeA5xkZiPAZ4DfBe42s48BPwB+HsDdnzazu4FngBZwnbtH6Vt9kuRK9DJwb/roOpXBlQBEkwptERHpLjOGtrtfNc1Ll06z/U3ATR3adwAb51RdBqpDyZm21xTaIiLSXfSNaEcoFEvUPI/VdacvERHpLgrtDsasStA4lHUZIiIib6HQ7mDSKoTNsazLEBEReQuFdgeT4QB5hbaIiHQZhXYHjbBCoaXQFhGR7qLQ7qCRG6QUK7RFRKS7KLQ7aOUHKccTWZchIiLyFgrtDuLCIFVXaIuISHdRaHfgxUEGbJKo1cq6FBERkcMU2h1YaQiAsdED2RYiIiLSRqHdQVDSPbVFRKT7KLQ7CMtTof16xpWIiIi8SaHdQaGahHZt7EC2hYiIiLRRaHdQqC4HoDGu4XEREekeCu0OSuk9tZsTummIiIh0D4V2B5XB5QBEE7qntoiIdA+FdgfVoRUAxDWdaYuISPdQaHdQrgzS8gBqOtMWEZHuodDuwIKAMasQNEazLkVEROQwhfY0xq1Krn4g6zJEREQOU2hP40D+VKqTe7MuQ0RE5DCF9jTGq8Oc1FJoi4hI91BoTyNadgYncYDJcc1ri4hId1BoTyN/0pkAvPKDZzOuREREJKHQnsbgqf8IgAN7nsu4EhERkYRCexonrf0RAGr7ns+4EhERkcRxhbaZvWhmT5rZTjPbkbatNLP7zey59HlF2/Y3mtluM3vWzC473uJPpJWrT2fCi/DGi1mXIiIiAizMmfZPuPtmd9+Srt8APOjuG4AH03XM7BxgK3AucDnwRTMLF+DzTwgLAl4JT6U4NpJ1KSIiIsCJGR6/ArgjXb4DuLKt/S53r7v7C8Bu4MIT8PkL5kBpDctre7IuQ0REBDj+0HbgPjN73MyuTdtOcfe9AOnzyWn7GuCltn1H0rauVR9YyynRD/E4zroUERERcse5/8Xu/rKZnQzcb2bfPca21qHNO26YHABcC3DGGWccZ4nHYcXbqLxaZ/++l1l1ynB2dYiIiHCcZ9ru/nL6/Crw1yTD3a+Y2WkA6fOr6eYjwNq23YeBl6d539vcfYu7b1m9evXxlHhcSiefBcBrL/2/zGoQERGZMu/QNrOqmQ1OLQM/DTwFbAOuSTe7BvhGurwN2GpmRTNbD2wAts/38xfD8tOT39Ue/eHujCsRERE5vuHxU4C/NrOp9/mqu/9PM3sMuNvMPgb8APh5AHd/2szuBp4BWsB17h4dV/Un2Cln/CgAzdf0u9oiIpK9eYe2uz8PvLND+37g0mn2uQm4ab6fudjK1UFeYznhwR9kXYqIiIi+EW0mr+VOozqu39UWEZHsKbRnMFZZw4qmbtEpIiLZU2jPoDl0BqfE+2g26lmXIiIifU6hPYNw1XpCc14d0cVoIiKSLYX2DKrp72q/PqLf1RYRkWwptGdw2obNNDxH47H/lnUpIiLS5xTaM1h58hoeX/dxzh/9Fjsf+FrW5YiISB9TaM/C+f/8s7wQvI3TH/4Uhw7sz7ocERHpUwrtWSgUSzR/5gus8jfY9ae/lnU5IiLSpxTas/Qj73oPj536C/zY/r/hsa//YdbliIhIH1Joz8F5v3gL3ylt4V1PfIbH7/ly1uWIiEifUWjPQbFUYcOv/A3PFs7lHY/+BjsfvCvrkkREpI8otOeoXB1k+LptvJhbz6aH/iWP3PEp4qirb1YmIiJLhEJ7HoaWr+L0X32QnUM/wbtfuJUnP3c5B177YdZliYjIEqfQnqfq4HLe9a//ikfP/hRnTzxO67/8GE/8bw2Xi4jIiaPQPg4WBPzYL/w7Xvq5bzIaLOedD32C7Z+/in0vv5h1aSIisgQptBfAWe/4x5z+bx/hkTUf4fw37mXZH72Lx275BZ7b+fd4HGddnoiILBHm7lnXcExbtmzxHTt2ZF3GrO15fhcj936OTa/+DypW5zWW8+LQFvzMn+BtF7yfk9esz7pEERHpYmb2uLtv6fiaQvvEOLj/FZ596G6CF/6W9YceYxUHAfh+sJZ9Az9Kc/lZFE79UZavPZfTzzyXcnUw44pFRKQbKLQzFkcRLzzzGPueuJfyyP/hlNqLnMq+t2zzCqt4PX8qY5U1RINrCVe+jfLJ6xlctYahk05n2cqTCcIwox6IiMhiOVZo5xa7mH4UhCFnbbqIszZddLhtcnyUl59/mgMvPU3jh8+SO/gC1cm9rD34f1l94H7CkbceTEVu7LchDgXLGc+voF5YQau0Ci8ug9IQQWmIsLKMfHkZhYHllAaWUx5cwbKVp1CqDCx2l0VE5ARQaGekXB1MQrwtyKc06jV+uOcF3ti7m9qBH9I6tA8f30cw8RqF+uuUGq9z8tizLBs9wIBPEtixR0sOUuWNYCWNoEzLCkRBgSgsEgcFolyFqDCEl5ZDEIA7uGPFKkFpGUGpimEAWK5IvlQlXxogXx6gUBmkVBmkPLCMSnXo8EhAHEWYGRboOkcRkYWk0O5ChWKJNWeezZozz55x2ziKGB07yMToG0yOvkFt7ACNsQM0Jw8STRwkHnsNG9tLfnIfuWiSMG5QiCbItQ6Q8yaleIIBH6dqteOqOXajQUhIRJgeRDQ8R4M8TcvTJEfT8rSsQMvytCxPZHmiIJ8cPAQF4qAAFuAWJM9Y8hwW8FwZz1ewfBkrViHI480JvD4GcQvCPJYrQljAckUsVyDIFQmmnvNFgnyBXL5EmC+SKxQJwjxBGBKEucOPMMhhYUgul8fCHGEYEubyhGGOMMxpikJEMqXQ7nFBGDK4bCWDy1Ye1/u0mg3iOCYMk38S42MHmTj0OvWJ0WQDd1rNOs3JMZq1MZq1ceL6GFFtDK+PQn0Mj5oQ5iDIgcfQamBRPX00COKpR5MgbhDGTfJRjVzrEDlvkvMmRozhBO4YMQExeZqUvE7Jmsf7x3XcYjciAmICovQRW0BMeLg9JiRK26ZeawZFGmGFZm4APCaM64Rxk9hC4iBPbDk8yBMHedxC3MLkgCUIYWo5fX5Le5CDIHm29M/e0jYLchAm6xakBxue/ApiWKwQFqoEhSJBkCMIQggCgjDZ1ixID2SSg5YgLBDmcskBTC5PmEvWc1PrOqARWRQKbQEgly+8ZX1o+SqGlq/KqJrO4iiiNjnG5PgorWadUmWIcnWQfL5Ao1Gj2ajTatRpHl6eJGrWaTUbRI0aUbNB1KwRtxrEzRoeR3jUSp49gnQZj5LnuAVxdLiNOMKmto1jLG6Cx5in26bL5jH2lvWIMKpRjMapTr5EbGEyTWE58nGTMBojjJvJKIU3Cf3N+H/zMCAm8Le25YhnnBpZTLEbrcMHNMmBS5RUfvg5tnTdQnyqJxYST62nBydT64eX2w5aYssdPohxC/Aglx7MhIeXpw5qLMily0HbgUweC/MQ5AjCfLqeLFuYxyyAIMAsfQQBNnWgkk9GaHKFIvlimWI6RdRq1JkcP0hjcpxcoUyxMkC5Oki5MjjtwYzHsaaQZM4U2tIzgjCkMrCMysCyo14rlioUS5UMqsqWxzFR1KLVahK1mrRaLeJWkyhqEkcRUatBHLWIWs3kOgMLcZxmbYLG5ChRo47HLdxjPIpwb+GxJwcycevNA5uohUdNPG5BnKwTN5PRlThKzuDTg5ypAxbiVnJA48nBTvty4Ecc5HhE4FEy0uIRYdwg8DgZbUlfC5haT8c1fGq8Iz58aJC8NrUek7fFu5nP8mnaJ71AzUrUKNIIShTjGoM+StVqND2kSY6WhbTIJQ/L07IcEemz5YktxHDAcQtpBUWioAhw+M+ymR8iKi4nLgwc/nM+/Iwn00z5CuTLmIXpCM3UwU06WpO22dQjzL05vRSEeHrNC8k7Jp8fFgimRlzyyZRUmEunnIIcQS6ZhsqFeSwMk1GZXD6ZegqT0ZtcLq8DmFlSaIv0MAsCckHhqJESeVMcRURRK3m0mrSaTaJWI12uE0ctWs0mcatO1GoBjscx7jFxHEEUEbWaxFGDuFUnbrWS50aNuDGON8YhLBAWB7BihbhRwxvjeH0cb05izQmsOU7QmiSMJonCMlFxORQGcI+wqAlRA4ubhx/BkQ9v4RhuRuARpdYh8nEdsHTUwijXX2JodJSKTyYjHW+ZvgkoeJMy9a4anWkXuRER0pqq3cK0H+FbppwiSw/LbOqRO2K0JhlxmZpmSkZmDLCjr5dJ1w+P0kyNzKTLyYFN/s2DmjCXrKdTRpbLY2GBFWvfzvpzLliUP6dFD20zuxz4QyAE/sTdf3exaxCR/pFcbBiSp5h1KYtmuh/sHsfU6pPJ6EsUEUdRupyMqkRRizhKRlniqEXcatFs1Gg1azD1lcxmaQgm4lYzmXJKnz1KRnfap58Oj84cnnpK29qmnkhHcSxdTkZskpEba3/21uGRmyBdDzwijJvpiEwyehOmy6EnB2JBOlIxdb2MvTlBk4zWeHJ4kJs6VJjDwc0/fO8XlmZom1kI3Ar8U2AEeMzMtrn7M4tZh4hIP7IgoFSuZl1GTzg8QtNqptNPLVrNejpCk1wfE7WaRM0G61acvGh1LfaZ9oXAbnd/HsDM7gKuABTaIiLSNQ6P0BS6a4RmsWf+1wAvta2PpG0iIiIyg8UObevQdtTEgZlda2Y7zGzHvn37OuwiIiLSfxY7tEeAtW3rw8DLR27k7re5+xZ337J69epFK05ERKSbLXZoPwZsMLP1ZlYAtgLbFrkGERGRnrSoF6K5e8vMfhn4XyS/8vUVd396MWsQERHpVYv+e9rufg9wz2J/roiISK/T98aJiIj0CIW2iIhIj1Boi4iI9AiFtoiISI8w9+6848sUM9sHfH8B3/Ik4LUFfL9usVT7BUu3b0u1X7B0+7ZU+wVLt2+92K+3uXvHLynp+tBeaGa2w923ZF3HQluq/YKl27el2i9Yun1bqv2Cpdu3pdYvDY+LiIj0CIW2iIhIj+jH0L4t6wJOkKXaL1i6fVuq/YKl27el2i9Yun1bUv3quzltERGRXtWPZ9oiIiI9qW9C28wuN7NnzWy3md2QdT3Hw8zWmtm3zGyXmT1tZten7SvN7H4zey59XpF1rfNhZqGZ/V8z+2a6vlT6tdzM/ruZfTf9u3v3Uuibmf3r9N/hU2b2NTMr9Wq/zOwrZvaqmT3V1jZtX8zsxvRnyrNmdlk2Vc9smn7dnP5b/I6Z/bWZLW97rSf6BZ371vbavzEzN7OT2tp6pm+d9EVom1kI3Aq8FzgHuMrMzsm2quPSAn7d3c8GLgKuS/tzA/Cgu28AHkzXe9H1wK629aXSrz8E/qe7vx14J0kfe7pvZrYG+FfAFnffSHL3vq30br9uBy4/oq1jX9L/c1uBc9N9vpj+rOlGt3N0v+4HNrr7O4D/B9wIPdcv6Nw3zGwt8E+BH7S19VrfjtIXoQ1cCOx29+fdvQHcBVyRcU3z5u573f3b6fIoyQ//NSR9uiPd7A7gykwKPA5mNgy8H/iTtual0K8h4BLgywDu3nD3AyyBvpHcLbBsZjmgArxMj/bL3R8CXj+iebq+XAHc5e51d38B2E3ys6brdOqXu9/n7q109R+A4XS5Z/oF0/6dAdwC/Fug/cKtnupbJ/0S2muAl9rWR9K2nmdm64DzgEeBU9x9LyTBDpycYWnz9XmS/2hxW9tS6NeZwD7gv6VD/39iZlV6vG/uvgf4HMnZzF7goLvfR4/36wjT9WUp/Vz5KHBvutzz/TKzDwB73P2JI17q+b71S2hbh7aev2zezAaAvwJ+1d0PZV3P8TKznwFedffHs67lBMgB7wK+5O7nAeP0zpDxtNL53SuA9cDpQNXM/kW2VS2aJfFzxcw+TTLl9udTTR0265l+mVkF+DTw7zu93KGtZ/oG/RPaI8DatvVhkiG8nmVmeZLA/nN3/3ra/IqZnZa+fhrwalb1zdPFwAfM7EWSKYyfNLM/o/f7Bcm/wRF3fzRd/+8kId7rffsp4AV33+fuTeDrwD+m9/vVbrq+9PzPFTO7BvgZ4Gp/8/d/e71fZ5EcRD6R/iwZBr5tZqfS+33rm9B+DNhgZuvNrEByIcK2jGuaNzMzkrnRXe7+B20vbQOuSZevAb6x2LUdD3e/0d2H3X0dyd/R/3b3f0GP9wvA3X8IvGRmP5o2XQo8Q+/37QfARWZWSf9dXkpyjUWv96vddH3ZBmw1s6KZrQc2ANszqG9ezOxy4N8BH3D3ibaXerpf7v6ku5/s7uvSnyUjwLvS/4M93TcA3L0vHsD7SK6Q/B7w6azrOc6+/BOSIZ3vADvTx/uAVSRXtz6XPq/Mutbj6ON7gG+my0uiX8BmYEf69/Y3wIql0Dfgs8B3gaeAPwWKvdov4Gskc/NNkh/2HztWX0iGYb8HPAu8N+v659iv3STzu1M/Q/5rr/Vrur4d8fqLwEm92LdOD30jmoiISI/ol+FxERGRnqfQFhER6REKbRERkR6h0BYREekRCm0REZEeodAWERHpEQptERGRHqHQFhER6RH/HwJm8IDo9SRhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set prediction accuracy: 50.35 %\n",
      "test set prediction accuracy: 56.94 %\n"
     ]
    }
   ],
   "source": [
    "#평균 성능 테스트\n",
    "scores = 0\n",
    "mean=np.mean(Y, axis=0)\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= mean <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"train set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= mean <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"test set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### <오차범위 3>\n",
      "- train set prediction accuracy(+-3): 46.88 % <br>\n",
      "- test set prediction accuracy(+-3): 19.44 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 5>\n",
      "- train set prediction accuracy(+-5): 63.54 % <br>\n",
      "- test set prediction accuracy(+-5): 33.33 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 10>\n",
      "- train set prediction accuracy(+-10): 86.81 % <br>\n",
      "- test set prediction accuracy(+-10): 70.83 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 20>\n",
      "- train set prediction accuracy(+-20): 97.92 % <br>\n",
      "- test set prediction accuracy(+-20): 90.28 % <br>\n"
     ]
    }
   ],
   "source": [
    "######입력용#######\n",
    "\n",
    "#오차 범위 3 설정\n",
    "print('### <오차범위 3>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "print('### <오차범위 5>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "print('### <오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "print('### <오차범위 20>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (피검사 안하고 할 수 있는 수치)\n",
    "X1=psqi_df[['AGE','SEX','BMI_1','PSQI_TOTAL_1','Muscle_1','Fat_1_x','FatPercentage _1','WHR_1','SBP_1',\n",
    "            'DBP_1','HR_1','Waist_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','SEX','BMI_2','PSQI_TOTAL_2','Muscle_2','Fat_2_x','FatPercentage_2','WHR_2','SBP_2',\n",
    "            'DBP_2','HR_2','Waist_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 72)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 12), (360, 1))"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "72/72 - 1s - loss: 3495.9221 - mse: 3495.9221\n",
      "Epoch 2/150\n",
      "72/72 - 0s - loss: 2932.5312 - mse: 2932.5312\n",
      "Epoch 3/150\n",
      "72/72 - 0s - loss: 2048.9573 - mse: 2048.9573\n",
      "Epoch 4/150\n",
      "72/72 - 0s - loss: 1039.6245 - mse: 1039.6245\n",
      "Epoch 5/150\n",
      "72/72 - 0s - loss: 466.4681 - mse: 466.4681\n",
      "Epoch 6/150\n",
      "72/72 - 0s - loss: 331.8402 - mse: 331.8402\n",
      "Epoch 7/150\n",
      "72/72 - 0s - loss: 280.3280 - mse: 280.3280\n",
      "Epoch 8/150\n",
      "72/72 - 0s - loss: 244.6665 - mse: 244.6665\n",
      "Epoch 9/150\n",
      "72/72 - 0s - loss: 219.6311 - mse: 219.6311\n",
      "Epoch 10/150\n",
      "72/72 - 0s - loss: 200.4189 - mse: 200.4189\n",
      "Epoch 11/150\n",
      "72/72 - 0s - loss: 187.2165 - mse: 187.2165\n",
      "Epoch 12/150\n",
      "72/72 - 0s - loss: 177.5354 - mse: 177.5354\n",
      "Epoch 13/150\n",
      "72/72 - 0s - loss: 170.4562 - mse: 170.4562\n",
      "Epoch 14/150\n",
      "72/72 - 0s - loss: 164.3528 - mse: 164.3528\n",
      "Epoch 15/150\n",
      "72/72 - 0s - loss: 158.3164 - mse: 158.3164\n",
      "Epoch 16/150\n",
      "72/72 - 0s - loss: 153.3413 - mse: 153.3413\n",
      "Epoch 17/150\n",
      "72/72 - 0s - loss: 151.3214 - mse: 151.3214\n",
      "Epoch 18/150\n",
      "72/72 - 0s - loss: 147.8335 - mse: 147.8335\n",
      "Epoch 19/150\n",
      "72/72 - 0s - loss: 145.9645 - mse: 145.9645\n",
      "Epoch 20/150\n",
      "72/72 - 0s - loss: 143.2320 - mse: 143.2320\n",
      "Epoch 21/150\n",
      "72/72 - 0s - loss: 142.1853 - mse: 142.1853\n",
      "Epoch 22/150\n",
      "72/72 - 0s - loss: 140.3692 - mse: 140.3692\n",
      "Epoch 23/150\n",
      "72/72 - 0s - loss: 137.4566 - mse: 137.4566\n",
      "Epoch 24/150\n",
      "72/72 - 0s - loss: 137.2160 - mse: 137.2160\n",
      "Epoch 25/150\n",
      "72/72 - 0s - loss: 134.6055 - mse: 134.6055\n",
      "Epoch 26/150\n",
      "72/72 - 0s - loss: 135.3781 - mse: 135.3781\n",
      "Epoch 27/150\n",
      "72/72 - 0s - loss: 134.9228 - mse: 134.9228\n",
      "Epoch 28/150\n",
      "72/72 - 0s - loss: 132.2396 - mse: 132.2396\n",
      "Epoch 29/150\n",
      "72/72 - 0s - loss: 132.3408 - mse: 132.3408\n",
      "Epoch 30/150\n",
      "72/72 - 0s - loss: 132.8452 - mse: 132.8452\n",
      "Epoch 31/150\n",
      "72/72 - 0s - loss: 130.7397 - mse: 130.7397\n",
      "Epoch 32/150\n",
      "72/72 - 0s - loss: 128.3648 - mse: 128.3648\n",
      "Epoch 33/150\n",
      "72/72 - 0s - loss: 128.7144 - mse: 128.7144\n",
      "Epoch 34/150\n",
      "72/72 - 0s - loss: 129.1026 - mse: 129.1026\n",
      "Epoch 35/150\n",
      "72/72 - 0s - loss: 128.5136 - mse: 128.5136\n",
      "Epoch 36/150\n",
      "72/72 - 0s - loss: 128.3720 - mse: 128.3720\n",
      "Epoch 37/150\n",
      "72/72 - 0s - loss: 126.4618 - mse: 126.4618\n",
      "Epoch 38/150\n",
      "72/72 - 0s - loss: 127.1150 - mse: 127.1150\n",
      "Epoch 39/150\n",
      "72/72 - 0s - loss: 126.0448 - mse: 126.0448\n",
      "Epoch 40/150\n",
      "72/72 - 0s - loss: 124.6115 - mse: 124.6115\n",
      "Epoch 41/150\n",
      "72/72 - 0s - loss: 125.5820 - mse: 125.5820\n",
      "Epoch 42/150\n",
      "72/72 - 0s - loss: 124.9267 - mse: 124.9267\n",
      "Epoch 43/150\n",
      "72/72 - 0s - loss: 124.0082 - mse: 124.0082\n",
      "Epoch 44/150\n",
      "72/72 - 0s - loss: 124.5927 - mse: 124.5927\n",
      "Epoch 45/150\n",
      "72/72 - 0s - loss: 121.2152 - mse: 121.2152\n",
      "Epoch 46/150\n",
      "72/72 - 0s - loss: 122.7550 - mse: 122.7550\n",
      "Epoch 47/150\n",
      "72/72 - 0s - loss: 121.7154 - mse: 121.7154\n",
      "Epoch 48/150\n",
      "72/72 - 0s - loss: 122.9479 - mse: 122.9479\n",
      "Epoch 49/150\n",
      "72/72 - 0s - loss: 122.2096 - mse: 122.2096\n",
      "Epoch 50/150\n",
      "72/72 - 0s - loss: 120.3918 - mse: 120.3918\n",
      "Epoch 51/150\n",
      "72/72 - 0s - loss: 121.3592 - mse: 121.3592\n",
      "Epoch 52/150\n",
      "72/72 - 0s - loss: 121.7171 - mse: 121.7171\n",
      "Epoch 53/150\n",
      "72/72 - 0s - loss: 119.1045 - mse: 119.1045\n",
      "Epoch 54/150\n",
      "72/72 - 0s - loss: 119.0983 - mse: 119.0983\n",
      "Epoch 55/150\n",
      "72/72 - 0s - loss: 120.1072 - mse: 120.1072\n",
      "Epoch 56/150\n",
      "72/72 - 0s - loss: 119.3733 - mse: 119.3733\n",
      "Epoch 57/150\n",
      "72/72 - 0s - loss: 118.7713 - mse: 118.7713\n",
      "Epoch 58/150\n",
      "72/72 - 0s - loss: 118.9870 - mse: 118.9870\n",
      "Epoch 59/150\n",
      "72/72 - 0s - loss: 118.4519 - mse: 118.4519\n",
      "Epoch 60/150\n",
      "72/72 - 0s - loss: 118.5458 - mse: 118.5458\n",
      "Epoch 61/150\n",
      "72/72 - 0s - loss: 117.6046 - mse: 117.6046\n",
      "Epoch 62/150\n",
      "72/72 - 0s - loss: 118.6415 - mse: 118.6415\n",
      "Epoch 63/150\n",
      "72/72 - 0s - loss: 117.8667 - mse: 117.8667\n",
      "Epoch 64/150\n",
      "72/72 - 0s - loss: 117.3459 - mse: 117.3459\n",
      "Epoch 65/150\n",
      "72/72 - 0s - loss: 116.7737 - mse: 116.7737\n",
      "Epoch 66/150\n",
      "72/72 - 0s - loss: 117.4786 - mse: 117.4786\n",
      "Epoch 67/150\n",
      "72/72 - 0s - loss: 116.7138 - mse: 116.7138\n",
      "Epoch 68/150\n",
      "72/72 - 0s - loss: 115.2818 - mse: 115.2818\n",
      "Epoch 69/150\n",
      "72/72 - 0s - loss: 115.3210 - mse: 115.3210\n",
      "Epoch 70/150\n",
      "72/72 - 0s - loss: 114.3662 - mse: 114.3662\n",
      "Epoch 71/150\n",
      "72/72 - 0s - loss: 116.5672 - mse: 116.5672\n",
      "Epoch 72/150\n",
      "72/72 - 0s - loss: 114.8099 - mse: 114.8099\n",
      "Epoch 73/150\n",
      "72/72 - 0s - loss: 114.8773 - mse: 114.8773\n",
      "Epoch 74/150\n",
      "72/72 - 0s - loss: 115.7575 - mse: 115.7575\n",
      "Epoch 75/150\n",
      "72/72 - 0s - loss: 114.0363 - mse: 114.0363\n",
      "Epoch 76/150\n",
      "72/72 - 0s - loss: 114.9162 - mse: 114.9162\n",
      "Epoch 77/150\n",
      "72/72 - 0s - loss: 114.6319 - mse: 114.6319\n",
      "Epoch 78/150\n",
      "72/72 - 0s - loss: 113.1139 - mse: 113.1139\n",
      "Epoch 79/150\n",
      "72/72 - 0s - loss: 113.7212 - mse: 113.7212\n",
      "Epoch 80/150\n",
      "72/72 - 0s - loss: 112.5687 - mse: 112.5687\n",
      "Epoch 81/150\n",
      "72/72 - 0s - loss: 114.2847 - mse: 114.2847\n",
      "Epoch 82/150\n",
      "72/72 - 0s - loss: 112.8678 - mse: 112.8678\n",
      "Epoch 83/150\n",
      "72/72 - 0s - loss: 112.8421 - mse: 112.8421\n",
      "Epoch 84/150\n",
      "72/72 - 0s - loss: 111.4812 - mse: 111.4812\n",
      "Epoch 85/150\n",
      "72/72 - 0s - loss: 113.2284 - mse: 113.2284\n",
      "Epoch 86/150\n",
      "72/72 - 0s - loss: 112.9332 - mse: 112.9332\n",
      "Epoch 87/150\n",
      "72/72 - 0s - loss: 112.1225 - mse: 112.1225\n",
      "Epoch 88/150\n",
      "72/72 - 0s - loss: 110.2693 - mse: 110.2693\n",
      "Epoch 89/150\n",
      "72/72 - 0s - loss: 111.9124 - mse: 111.9124\n",
      "Epoch 90/150\n",
      "72/72 - 0s - loss: 110.1183 - mse: 110.1183\n",
      "Epoch 91/150\n",
      "72/72 - 0s - loss: 111.5239 - mse: 111.5239\n",
      "Epoch 92/150\n",
      "72/72 - 0s - loss: 110.4194 - mse: 110.4194\n",
      "Epoch 93/150\n",
      "72/72 - 0s - loss: 107.2950 - mse: 107.2950\n",
      "Epoch 94/150\n",
      "72/72 - 0s - loss: 109.6275 - mse: 109.6275\n",
      "Epoch 95/150\n",
      "72/72 - 0s - loss: 109.3006 - mse: 109.3006\n",
      "Epoch 96/150\n",
      "72/72 - 0s - loss: 110.1218 - mse: 110.1218\n",
      "Epoch 97/150\n",
      "72/72 - 0s - loss: 107.2868 - mse: 107.2868\n",
      "Epoch 98/150\n",
      "72/72 - 0s - loss: 109.3575 - mse: 109.3575\n",
      "Epoch 99/150\n",
      "72/72 - 0s - loss: 108.8477 - mse: 108.8477\n",
      "Epoch 100/150\n",
      "72/72 - 0s - loss: 107.6751 - mse: 107.6751\n",
      "Epoch 101/150\n",
      "72/72 - 0s - loss: 108.2039 - mse: 108.2039\n",
      "Epoch 102/150\n",
      "72/72 - 0s - loss: 106.4931 - mse: 106.4931\n",
      "Epoch 103/150\n",
      "72/72 - 0s - loss: 107.8622 - mse: 107.8622\n",
      "Epoch 104/150\n",
      "72/72 - 0s - loss: 107.1970 - mse: 107.1970\n",
      "Epoch 105/150\n",
      "72/72 - 0s - loss: 106.7889 - mse: 106.7889\n",
      "Epoch 106/150\n",
      "72/72 - 0s - loss: 107.8367 - mse: 107.8367\n",
      "Epoch 107/150\n",
      "72/72 - 0s - loss: 104.9392 - mse: 104.9392\n",
      "Epoch 108/150\n",
      "72/72 - 0s - loss: 106.3840 - mse: 106.3840\n",
      "Epoch 109/150\n",
      "72/72 - 0s - loss: 106.1662 - mse: 106.1662\n",
      "Epoch 110/150\n",
      "72/72 - 0s - loss: 105.5047 - mse: 105.5047\n",
      "Epoch 111/150\n",
      "72/72 - 0s - loss: 105.6437 - mse: 105.6437\n",
      "Epoch 112/150\n",
      "72/72 - 0s - loss: 106.0975 - mse: 106.0975\n",
      "Epoch 113/150\n",
      "72/72 - 0s - loss: 105.8167 - mse: 105.8167\n",
      "Epoch 114/150\n",
      "72/72 - 0s - loss: 104.6631 - mse: 104.6631\n",
      "Epoch 115/150\n",
      "72/72 - 0s - loss: 103.6512 - mse: 103.6512\n",
      "Epoch 116/150\n",
      "72/72 - 0s - loss: 105.0961 - mse: 105.0961\n",
      "Epoch 117/150\n",
      "72/72 - 0s - loss: 103.5816 - mse: 103.5816\n",
      "Epoch 118/150\n",
      "72/72 - 0s - loss: 104.3318 - mse: 104.3318\n",
      "Epoch 119/150\n",
      "72/72 - 0s - loss: 103.7807 - mse: 103.7807\n",
      "Epoch 120/150\n",
      "72/72 - 0s - loss: 104.3695 - mse: 104.3695\n",
      "Epoch 121/150\n",
      "72/72 - 0s - loss: 103.3148 - mse: 103.3148\n",
      "Epoch 122/150\n",
      "72/72 - 0s - loss: 103.8515 - mse: 103.8515\n",
      "Epoch 123/150\n",
      "72/72 - 0s - loss: 102.5613 - mse: 102.5613\n",
      "Epoch 124/150\n",
      "72/72 - 0s - loss: 103.3199 - mse: 103.3199\n",
      "Epoch 125/150\n",
      "72/72 - 0s - loss: 103.1022 - mse: 103.1022\n",
      "Epoch 126/150\n",
      "72/72 - 0s - loss: 102.6952 - mse: 102.6952\n",
      "Epoch 127/150\n",
      "72/72 - 0s - loss: 102.6986 - mse: 102.6986\n",
      "Epoch 128/150\n",
      "72/72 - 0s - loss: 101.2591 - mse: 101.2591\n",
      "Epoch 129/150\n",
      "72/72 - 0s - loss: 101.4765 - mse: 101.4765\n",
      "Epoch 130/150\n",
      "72/72 - 0s - loss: 100.7273 - mse: 100.7273\n",
      "Epoch 131/150\n",
      "72/72 - 0s - loss: 101.5167 - mse: 101.5167\n",
      "Epoch 132/150\n",
      "72/72 - 0s - loss: 100.3209 - mse: 100.3209\n",
      "Epoch 133/150\n",
      "72/72 - 0s - loss: 100.4695 - mse: 100.4695\n",
      "Epoch 134/150\n",
      "72/72 - 0s - loss: 100.6543 - mse: 100.6543\n",
      "Epoch 135/150\n",
      "72/72 - 0s - loss: 100.6290 - mse: 100.6290\n",
      "Epoch 136/150\n",
      "72/72 - 0s - loss: 99.2618 - mse: 99.2618\n",
      "Epoch 137/150\n",
      "72/72 - 0s - loss: 98.7779 - mse: 98.7779\n",
      "Epoch 138/150\n",
      "72/72 - 0s - loss: 99.7754 - mse: 99.7754\n",
      "Epoch 139/150\n",
      "72/72 - 0s - loss: 98.9247 - mse: 98.9247\n",
      "Epoch 140/150\n",
      "72/72 - 0s - loss: 99.0153 - mse: 99.0153\n",
      "Epoch 141/150\n",
      "72/72 - 0s - loss: 98.2933 - mse: 98.2933\n",
      "Epoch 142/150\n",
      "72/72 - 0s - loss: 98.3659 - mse: 98.3659\n",
      "Epoch 143/150\n",
      "72/72 - 0s - loss: 97.8665 - mse: 97.8665\n",
      "Epoch 144/150\n",
      "72/72 - 0s - loss: 98.8946 - mse: 98.8946\n",
      "Epoch 145/150\n",
      "72/72 - 0s - loss: 97.9680 - mse: 97.9680\n",
      "Epoch 146/150\n",
      "72/72 - 0s - loss: 97.0267 - mse: 97.0267\n",
      "Epoch 147/150\n",
      "72/72 - 0s - loss: 97.6222 - mse: 97.6222\n",
      "Epoch 148/150\n",
      "72/72 - 0s - loss: 95.9729 - mse: 95.9729\n",
      "Epoch 149/150\n",
      "72/72 - 0s - loss: 95.6931 - mse: 95.6931\n",
      "Epoch 150/150\n",
      "72/72 - 0s - loss: 94.9548 - mse: 94.9548\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 284.7257 - mse: 284.7257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[284.7256774902344, 284.7256774902344]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=150, batch_size=4, verbose=2)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_39 (Dense)             (None, 32)                416       \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,505\n",
      "Trainable params: 1,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set prediction accuracy: 50.35 %\n",
      "test set prediction accuracy: 56.94 %\n"
     ]
    }
   ],
   "source": [
    "#평균 성능 테스트\n",
    "scores = 0\n",
    "mean=np.mean(Y, axis=0)\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= mean <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"train set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= mean <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"test set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### <오차범위 3>\n",
      "- train set prediction accuracy(+-3): 31.94 % <br>\n",
      "- test set prediction accuracy(+-3): 12.50 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 5>\n",
      "- train set prediction accuracy(+-5): 46.18 % <br>\n",
      "- test set prediction accuracy(+-5): 29.17 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 10>\n",
      "- train set prediction accuracy(+-10): 74.31 % <br>\n",
      "- test set prediction accuracy(+-10): 69.44 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 20>\n",
      "- train set prediction accuracy(+-20): 94.44 % <br>\n",
      "- test set prediction accuracy(+-20): 91.67 % <br>\n"
     ]
    }
   ],
   "source": [
    "######입력용#######\n",
    "\n",
    "#오차 범위 3 설정\n",
    "print('### <오차범위 3>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "print('### <오차범위 5>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "print('### <오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "print('### <오차범위 20>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (피검사 안하고 할 수 있는 수치 중 선별한 것만)\n",
    "X1=psqi_df[['AGE','SEX','BMI_1','PSQI_TOTAL_1','Muscle_1','Fat_1_x','SBP_1','DBP_1','HR_1','Waist_1']].values\n",
    "\n",
    "X2=psqi_df[['AGE','SEX','BMI_2','PSQI_TOTAL_2','Muscle_2','Fat_2_x','SBP_2','DBP_2','HR_2','Waist_2']].values\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 72)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 10), (360, 1))"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "72/72 - 1s - loss: 3537.1548 - mse: 3537.1548\n",
      "Epoch 2/150\n",
      "72/72 - 0s - loss: 3055.6523 - mse: 3055.6523\n",
      "Epoch 3/150\n",
      "72/72 - 0s - loss: 2217.0525 - mse: 2217.0525\n",
      "Epoch 4/150\n",
      "72/72 - 0s - loss: 1146.5502 - mse: 1146.5502\n",
      "Epoch 5/150\n",
      "72/72 - 0s - loss: 472.3297 - mse: 472.3297\n",
      "Epoch 6/150\n",
      "72/72 - 0s - loss: 334.9715 - mse: 334.9715\n",
      "Epoch 7/150\n",
      "72/72 - 0s - loss: 296.1100 - mse: 296.1100\n",
      "Epoch 8/150\n",
      "72/72 - 0s - loss: 264.9335 - mse: 264.9335\n",
      "Epoch 9/150\n",
      "72/72 - 0s - loss: 241.6303 - mse: 241.6303\n",
      "Epoch 10/150\n",
      "72/72 - 0s - loss: 218.6454 - mse: 218.6454\n",
      "Epoch 11/150\n",
      "72/72 - 0s - loss: 205.2290 - mse: 205.2290\n",
      "Epoch 12/150\n",
      "72/72 - 0s - loss: 192.9594 - mse: 192.9594\n",
      "Epoch 13/150\n",
      "72/72 - 0s - loss: 184.5636 - mse: 184.5636\n",
      "Epoch 14/150\n",
      "72/72 - 0s - loss: 177.1030 - mse: 177.1030\n",
      "Epoch 15/150\n",
      "72/72 - 0s - loss: 170.9918 - mse: 170.9918\n",
      "Epoch 16/150\n",
      "72/72 - 0s - loss: 166.0890 - mse: 166.0890\n",
      "Epoch 17/150\n",
      "72/72 - 0s - loss: 161.0064 - mse: 161.0064\n",
      "Epoch 18/150\n",
      "72/72 - 0s - loss: 158.7499 - mse: 158.7499\n",
      "Epoch 19/150\n",
      "72/72 - 0s - loss: 153.3664 - mse: 153.3664\n",
      "Epoch 20/150\n",
      "72/72 - 0s - loss: 151.6311 - mse: 151.6311\n",
      "Epoch 21/150\n",
      "72/72 - 0s - loss: 149.2215 - mse: 149.2215\n",
      "Epoch 22/150\n",
      "72/72 - 0s - loss: 148.3323 - mse: 148.3323\n",
      "Epoch 23/150\n",
      "72/72 - 0s - loss: 146.3124 - mse: 146.3124\n",
      "Epoch 24/150\n",
      "72/72 - 0s - loss: 144.6775 - mse: 144.6775\n",
      "Epoch 25/150\n",
      "72/72 - 0s - loss: 142.3333 - mse: 142.3333\n",
      "Epoch 26/150\n",
      "72/72 - 0s - loss: 141.6058 - mse: 141.6058\n",
      "Epoch 27/150\n",
      "72/72 - 0s - loss: 139.5526 - mse: 139.5526\n",
      "Epoch 28/150\n",
      "72/72 - 0s - loss: 137.9803 - mse: 137.9803\n",
      "Epoch 29/150\n",
      "72/72 - 0s - loss: 137.7595 - mse: 137.7595\n",
      "Epoch 30/150\n",
      "72/72 - 0s - loss: 137.9427 - mse: 137.9427\n",
      "Epoch 31/150\n",
      "72/72 - 0s - loss: 136.7840 - mse: 136.7840\n",
      "Epoch 32/150\n",
      "72/72 - 0s - loss: 135.5283 - mse: 135.5283\n",
      "Epoch 33/150\n",
      "72/72 - 0s - loss: 134.9895 - mse: 134.9895\n",
      "Epoch 34/150\n",
      "72/72 - 0s - loss: 133.2042 - mse: 133.2042\n",
      "Epoch 35/150\n",
      "72/72 - 0s - loss: 132.6682 - mse: 132.6682\n",
      "Epoch 36/150\n",
      "72/72 - 0s - loss: 131.9415 - mse: 131.9415\n",
      "Epoch 37/150\n",
      "72/72 - 0s - loss: 131.8796 - mse: 131.8796\n",
      "Epoch 38/150\n",
      "72/72 - 0s - loss: 129.8466 - mse: 129.8466\n",
      "Epoch 39/150\n",
      "72/72 - 0s - loss: 129.3112 - mse: 129.3112\n",
      "Epoch 40/150\n",
      "72/72 - 0s - loss: 128.4857 - mse: 128.4857\n",
      "Epoch 41/150\n",
      "72/72 - 0s - loss: 128.9647 - mse: 128.9647\n",
      "Epoch 42/150\n",
      "72/72 - 0s - loss: 129.3008 - mse: 129.3008\n",
      "Epoch 43/150\n",
      "72/72 - 0s - loss: 126.9024 - mse: 126.9024\n",
      "Epoch 44/150\n",
      "72/72 - 0s - loss: 126.0754 - mse: 126.0754\n",
      "Epoch 45/150\n",
      "72/72 - 0s - loss: 126.7795 - mse: 126.7795\n",
      "Epoch 46/150\n",
      "72/72 - 0s - loss: 125.3572 - mse: 125.3572\n",
      "Epoch 47/150\n",
      "72/72 - 0s - loss: 125.1444 - mse: 125.1444\n",
      "Epoch 48/150\n",
      "72/72 - 0s - loss: 124.1706 - mse: 124.1706\n",
      "Epoch 49/150\n",
      "72/72 - 0s - loss: 124.3153 - mse: 124.3153\n",
      "Epoch 50/150\n",
      "72/72 - 0s - loss: 124.4951 - mse: 124.4951\n",
      "Epoch 51/150\n",
      "72/72 - 0s - loss: 124.1621 - mse: 124.1621\n",
      "Epoch 52/150\n",
      "72/72 - 0s - loss: 123.8761 - mse: 123.8761\n",
      "Epoch 53/150\n",
      "72/72 - 0s - loss: 123.3223 - mse: 123.3223\n",
      "Epoch 54/150\n",
      "72/72 - 0s - loss: 122.6138 - mse: 122.6138\n",
      "Epoch 55/150\n",
      "72/72 - 0s - loss: 123.2872 - mse: 123.2872\n",
      "Epoch 56/150\n",
      "72/72 - 0s - loss: 121.9437 - mse: 121.9437\n",
      "Epoch 57/150\n",
      "72/72 - 0s - loss: 122.2967 - mse: 122.2967\n",
      "Epoch 58/150\n",
      "72/72 - 0s - loss: 122.1083 - mse: 122.1083\n",
      "Epoch 59/150\n",
      "72/72 - 0s - loss: 121.1899 - mse: 121.1899\n",
      "Epoch 60/150\n",
      "72/72 - 0s - loss: 120.7094 - mse: 120.7094\n",
      "Epoch 61/150\n",
      "72/72 - 0s - loss: 121.1653 - mse: 121.1653\n",
      "Epoch 62/150\n",
      "72/72 - 0s - loss: 119.4272 - mse: 119.4272\n",
      "Epoch 63/150\n",
      "72/72 - 0s - loss: 120.1180 - mse: 120.1180\n",
      "Epoch 64/150\n",
      "72/72 - 0s - loss: 119.3894 - mse: 119.3894\n",
      "Epoch 65/150\n",
      "72/72 - 0s - loss: 119.8542 - mse: 119.8542\n",
      "Epoch 66/150\n",
      "72/72 - 0s - loss: 120.2778 - mse: 120.2778\n",
      "Epoch 67/150\n",
      "72/72 - 0s - loss: 118.4162 - mse: 118.4162\n",
      "Epoch 68/150\n",
      "72/72 - 0s - loss: 118.9931 - mse: 118.9931\n",
      "Epoch 69/150\n",
      "72/72 - 0s - loss: 119.2508 - mse: 119.2508\n",
      "Epoch 70/150\n",
      "72/72 - 0s - loss: 118.5016 - mse: 118.5016\n",
      "Epoch 71/150\n",
      "72/72 - 0s - loss: 117.9278 - mse: 117.9278\n",
      "Epoch 72/150\n",
      "72/72 - 0s - loss: 117.8634 - mse: 117.8634\n",
      "Epoch 73/150\n",
      "72/72 - 0s - loss: 116.9734 - mse: 116.9734\n",
      "Epoch 74/150\n",
      "72/72 - 0s - loss: 117.5600 - mse: 117.5600\n",
      "Epoch 75/150\n",
      "72/72 - 0s - loss: 113.4633 - mse: 113.4633\n",
      "Epoch 76/150\n",
      "72/72 - 0s - loss: 114.9520 - mse: 114.9520\n",
      "Epoch 77/150\n",
      "72/72 - 0s - loss: 116.1534 - mse: 116.1534\n",
      "Epoch 78/150\n",
      "72/72 - 0s - loss: 117.1890 - mse: 117.1890\n",
      "Epoch 79/150\n",
      "72/72 - 0s - loss: 116.3547 - mse: 116.3547\n",
      "Epoch 80/150\n",
      "72/72 - 0s - loss: 116.5111 - mse: 116.5111\n",
      "Epoch 81/150\n",
      "72/72 - 0s - loss: 115.3471 - mse: 115.3471\n",
      "Epoch 82/150\n",
      "72/72 - 0s - loss: 114.4675 - mse: 114.4675\n",
      "Epoch 83/150\n",
      "72/72 - 0s - loss: 114.6447 - mse: 114.6447\n",
      "Epoch 84/150\n",
      "72/72 - 0s - loss: 114.9150 - mse: 114.9150\n",
      "Epoch 85/150\n",
      "72/72 - 0s - loss: 114.6794 - mse: 114.6794\n",
      "Epoch 86/150\n",
      "72/72 - 0s - loss: 113.2400 - mse: 113.2400\n",
      "Epoch 87/150\n",
      "72/72 - 0s - loss: 110.8161 - mse: 110.8161\n",
      "Epoch 88/150\n",
      "72/72 - 0s - loss: 115.0717 - mse: 115.0717\n",
      "Epoch 89/150\n",
      "72/72 - 0s - loss: 114.2019 - mse: 114.2019\n",
      "Epoch 90/150\n",
      "72/72 - 0s - loss: 113.1726 - mse: 113.1726\n",
      "Epoch 91/150\n",
      "72/72 - 0s - loss: 112.7676 - mse: 112.7676\n",
      "Epoch 92/150\n",
      "72/72 - 0s - loss: 113.5199 - mse: 113.5199\n",
      "Epoch 93/150\n",
      "72/72 - 0s - loss: 111.6101 - mse: 111.6101\n",
      "Epoch 94/150\n",
      "72/72 - 0s - loss: 113.2106 - mse: 113.2106\n",
      "Epoch 95/150\n",
      "72/72 - 0s - loss: 113.0329 - mse: 113.0329\n",
      "Epoch 96/150\n",
      "72/72 - 0s - loss: 112.0006 - mse: 112.0006\n",
      "Epoch 97/150\n",
      "72/72 - 0s - loss: 111.8835 - mse: 111.8835\n",
      "Epoch 98/150\n",
      "72/72 - 0s - loss: 111.6936 - mse: 111.6936\n",
      "Epoch 99/150\n",
      "72/72 - 0s - loss: 111.2193 - mse: 111.2193\n",
      "Epoch 100/150\n",
      "72/72 - 0s - loss: 111.5387 - mse: 111.5387\n",
      "Epoch 101/150\n",
      "72/72 - 0s - loss: 110.7112 - mse: 110.7112\n",
      "Epoch 102/150\n",
      "72/72 - 0s - loss: 110.9363 - mse: 110.9363\n",
      "Epoch 103/150\n",
      "72/72 - 0s - loss: 111.1474 - mse: 111.1474\n",
      "Epoch 104/150\n",
      "72/72 - 0s - loss: 110.4384 - mse: 110.4384\n",
      "Epoch 105/150\n",
      "72/72 - 0s - loss: 109.8027 - mse: 109.8027\n",
      "Epoch 106/150\n",
      "72/72 - 0s - loss: 110.1760 - mse: 110.1760\n",
      "Epoch 107/150\n",
      "72/72 - 0s - loss: 110.2481 - mse: 110.2481\n",
      "Epoch 108/150\n",
      "72/72 - 0s - loss: 109.8729 - mse: 109.8729\n",
      "Epoch 109/150\n",
      "72/72 - 0s - loss: 109.3924 - mse: 109.3924\n",
      "Epoch 110/150\n",
      "72/72 - 0s - loss: 109.8489 - mse: 109.8489\n",
      "Epoch 111/150\n",
      "72/72 - 0s - loss: 109.2871 - mse: 109.2871\n",
      "Epoch 112/150\n",
      "72/72 - 0s - loss: 109.1144 - mse: 109.1144\n",
      "Epoch 113/150\n",
      "72/72 - 0s - loss: 108.9440 - mse: 108.9440\n",
      "Epoch 114/150\n",
      "72/72 - 0s - loss: 108.0723 - mse: 108.0723\n",
      "Epoch 115/150\n",
      "72/72 - 0s - loss: 107.7525 - mse: 107.7525\n",
      "Epoch 116/150\n",
      "72/72 - 0s - loss: 108.3608 - mse: 108.3608\n",
      "Epoch 117/150\n",
      "72/72 - 0s - loss: 108.2495 - mse: 108.2495\n",
      "Epoch 118/150\n",
      "72/72 - 0s - loss: 107.8149 - mse: 107.8149\n",
      "Epoch 119/150\n",
      "72/72 - 0s - loss: 106.8822 - mse: 106.8822\n",
      "Epoch 120/150\n",
      "72/72 - 0s - loss: 107.2498 - mse: 107.2498\n",
      "Epoch 121/150\n",
      "72/72 - 0s - loss: 106.7806 - mse: 106.7806\n",
      "Epoch 122/150\n",
      "72/72 - 0s - loss: 106.3481 - mse: 106.3481\n",
      "Epoch 123/150\n",
      "72/72 - 0s - loss: 107.1396 - mse: 107.1396\n",
      "Epoch 124/150\n",
      "72/72 - 0s - loss: 105.6669 - mse: 105.6669\n",
      "Epoch 125/150\n",
      "72/72 - 0s - loss: 106.3312 - mse: 106.3312\n",
      "Epoch 126/150\n",
      "72/72 - 0s - loss: 105.6381 - mse: 105.6381\n",
      "Epoch 127/150\n",
      "72/72 - 0s - loss: 105.7167 - mse: 105.7167\n",
      "Epoch 128/150\n",
      "72/72 - 0s - loss: 105.2981 - mse: 105.2981\n",
      "Epoch 129/150\n",
      "72/72 - 0s - loss: 105.4899 - mse: 105.4899\n",
      "Epoch 130/150\n",
      "72/72 - 0s - loss: 105.1725 - mse: 105.1725\n",
      "Epoch 131/150\n",
      "72/72 - 0s - loss: 105.0032 - mse: 105.0032\n",
      "Epoch 132/150\n",
      "72/72 - 0s - loss: 104.1606 - mse: 104.1606\n",
      "Epoch 133/150\n",
      "72/72 - 0s - loss: 104.1976 - mse: 104.1976\n",
      "Epoch 134/150\n",
      "72/72 - 0s - loss: 103.6440 - mse: 103.6440\n",
      "Epoch 135/150\n",
      "72/72 - 0s - loss: 103.8315 - mse: 103.8315\n",
      "Epoch 136/150\n",
      "72/72 - 0s - loss: 103.4582 - mse: 103.4582\n",
      "Epoch 137/150\n",
      "72/72 - 0s - loss: 102.6074 - mse: 102.6074\n",
      "Epoch 138/150\n",
      "72/72 - 0s - loss: 103.2911 - mse: 103.2911\n",
      "Epoch 139/150\n",
      "72/72 - 0s - loss: 102.6921 - mse: 102.6921\n",
      "Epoch 140/150\n",
      "72/72 - 0s - loss: 102.5113 - mse: 102.5113\n",
      "Epoch 141/150\n",
      "72/72 - 0s - loss: 102.7582 - mse: 102.7582\n",
      "Epoch 142/150\n",
      "72/72 - 0s - loss: 101.3637 - mse: 101.3637\n",
      "Epoch 143/150\n",
      "72/72 - 0s - loss: 102.4515 - mse: 102.4515\n",
      "Epoch 144/150\n",
      "72/72 - 0s - loss: 101.8986 - mse: 101.8986\n",
      "Epoch 145/150\n",
      "72/72 - 0s - loss: 99.3018 - mse: 99.3018\n",
      "Epoch 146/150\n",
      "72/72 - 0s - loss: 101.6889 - mse: 101.6889\n",
      "Epoch 147/150\n",
      "72/72 - 0s - loss: 100.0740 - mse: 100.0740\n",
      "Epoch 148/150\n",
      "72/72 - 0s - loss: 100.7899 - mse: 100.7899\n",
      "Epoch 149/150\n",
      "72/72 - 0s - loss: 99.0307 - mse: 99.0307\n",
      "Epoch 150/150\n",
      "72/72 - 0s - loss: 100.7114 - mse: 100.7114\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 105.4252 - mse: 105.4252\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[105.42523956298828, 105.42523956298828]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=150, batch_size=4, verbose=2)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 1,441\n",
      "Trainable params: 1,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set prediction accuracy: 50.35 %\n",
      "test set prediction accuracy: 56.94 %\n"
     ]
    }
   ],
   "source": [
    "#평균 성능 테스트\n",
    "scores = 0\n",
    "mean=np.mean(Y, axis=0)\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= mean <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"train set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= mean <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"test set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### <오차범위 3>\n",
      "- train set prediction accuracy(+-3): 29.17 % <br>\n",
      "- test set prediction accuracy(+-3): 22.22 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 5>\n",
      "- train set prediction accuracy(+-5): 41.67 % <br>\n",
      "- test set prediction accuracy(+-5): 33.33 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 10>\n",
      "- train set prediction accuracy(+-10): 70.83 % <br>\n",
      "- test set prediction accuracy(+-10): 68.06 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 20>\n",
      "- train set prediction accuracy(+-20): 95.14 % <br>\n",
      "- test set prediction accuracy(+-20): 94.44 % <br>\n"
     ]
    }
   ],
   "source": [
    "######입력용#######\n",
    "\n",
    "#오차 범위 3 설정\n",
    "print('### <오차범위 3>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "print('### <오차범위 5>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "print('### <오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "print('### <오차범위 20>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FONT 깨질때 폰트깨질때\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname = \"C:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font',family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Sample_ID GROUP  COHORT SEX  AGE     Trait FitbitOX      Fitbit_ID  HTN  \\\n",
      "0         S0001   SMI       2   M   60  fitbit_O        O  sevrance00001  NaN   \n",
      "1         S0002   SMI       2   M   61  fitbit_O        O  sevrance00002  NaN   \n",
      "2         S0003   SMI       2   F   52  fitbit_O        O  sevrance00003  NaN   \n",
      "3         S0004   SMI       2   F   41  fitbit_O        O  sevrance00004  NaN   \n",
      "4         S0005   SMI       2   F   41  fitbit_O        O  sevrance00005  NaN   \n",
      "..          ...   ...     ...  ..  ...       ...      ...            ...  ...   \n",
      "383  MetS_S0280  MetS       1   F   24  fitbit_O        O   gnfmmets+139  NaN   \n",
      "384  MetS_S0281  MetS       1   F   44  fitbit_O        O   gnfmmets+140  NaN   \n",
      "385  MetS_S0282  MetS       1   F   37  fitbit_O        O   gnfmmets+141  1.0   \n",
      "386  MetS_S0283  MetS       1   M   51  fitbit_X        X              X  NaN   \n",
      "387  MetS_S0284  MetS       1   F   42  fitbit_X        X              X  NaN   \n",
      "\n",
      "      DM  ...  BDI_Q13_2 BDI_Q14_2  BDI_Q15_2  BDI_Q16_2 BDI_Q17_2 BDI_Q18_2  \\\n",
      "0    NaN  ...        1.0       1.0        1.0        2.0       1.0       1.0   \n",
      "1    1.0  ...        1.0       1.0        1.0        1.0       2.0       1.0   \n",
      "2    NaN  ...        1.0       1.0        1.0        1.0       1.0       1.0   \n",
      "3    NaN  ...        2.0       2.0        2.0        2.0       2.0       2.0   \n",
      "4    NaN  ...        2.0       1.0        2.0        2.0       2.0       1.0   \n",
      "..   ...  ...        ...       ...        ...        ...       ...       ...   \n",
      "383  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "384  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "385  1.0  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "386  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "387  NaN  ...        NaN       NaN        NaN        NaN       NaN       NaN   \n",
      "\n",
      "     BDI_Q19_2  BDI_Q20_2  BDI_Q21_2  Diet_2  \n",
      "0          2.0        1.0        2.0     2.0  \n",
      "1          1.0        1.0        1.0     2.0  \n",
      "2          1.0        2.0        4.0     1.0  \n",
      "3          1.0        1.0        1.0     2.0  \n",
      "4          1.0        2.0        1.0     2.0  \n",
      "..         ...        ...        ...     ...  \n",
      "383        NaN        NaN        NaN     NaN  \n",
      "384        NaN        NaN        NaN     NaN  \n",
      "385        NaN        NaN        NaN     NaN  \n",
      "386        NaN        NaN        NaN     NaN  \n",
      "387        NaN        NaN        NaN     NaN  \n",
      "\n",
      "[388 rows x 3527 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('./최종 데이터 그래프그리기용.xlsx') \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df=df[['Sample_ID','GROUP','COHORT','AGE','SEX','BMI_1','PSQI_TOTAL_1','Insulin _1','CRP_1','WBC_1','Neutrophil_1','Lym_1','GLU0_1','Creatinine_1','AST_1','ALT_1','TG_1','LDL_1','Muscle_1','Fat_1_x','FatPercentage _1','WHR_1','SBP_1',\n",
    "            'DBP_1','HR_1','Waist_1','Chol_1','BUN_1','HDL_1',\n",
    "          'BMI_2','PSQI_TOTAL_2','Insulin _2','CRP_2','WBC_2','Neutrophil_2','Lym_2','GLU0_2',\n",
    "            'Creatinine_2','AST_2','ALT_2','TG_2','LDL_2','Muscle_2','Fat_2_x','FatPercentage_2','WHR_2','SBP_2',\n",
    "            'DBP_2','HR_2','Waist_2','Chol_2','BUN_2','HDL_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>Chol_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>HDL_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.89</td>\n",
       "      <td>108.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.1</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.51</td>\n",
       "      <td>...</td>\n",
       "      <td>19.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>0.99</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>90.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.2</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.85</td>\n",
       "      <td>...</td>\n",
       "      <td>22.6</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>127.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.1</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.14</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.82</td>\n",
       "      <td>119.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.2</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.93</td>\n",
       "      <td>...</td>\n",
       "      <td>14.9</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>110.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>66.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.5</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.82</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.67</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.03</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>388 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT  AGE SEX      BMI_1  PSQI_TOTAL_1 Insulin _1  \\\n",
       "0         S0001   SMI       2   60   M  21.110190           8.0        7.7   \n",
       "1         S0002   SMI       2   61   M  27.782064           4.0        5.4   \n",
       "2         S0003   SMI       2   52   F  24.944742           3.0        5.1   \n",
       "3         S0004   SMI       2   41   F  22.620489           6.0        4.2   \n",
       "4         S0005   SMI       2   41   F  20.524157          10.0        3.2   \n",
       "..          ...   ...     ...  ...  ..        ...           ...        ...   \n",
       "383  MetS_S0280  MetS       1   24   F  34.803410           5.0       11.3   \n",
       "384  MetS_S0281  MetS       1   44   F  30.903615           3.0       10.6   \n",
       "385  MetS_S0282  MetS       1   37   F  28.676533           3.0       12.2   \n",
       "386  MetS_S0283  MetS       1   51   M  24.549738           5.0       10.4   \n",
       "387  MetS_S0284  MetS       1   42   F  24.605921           3.0       10.1   \n",
       "\n",
       "    CRP_1  WBC_1  ...  Fat_2_x  FatPercentage_2  WHR_2  SBP_2  DBP_2  HR_2  \\\n",
       "0     0.2   3.91  ...      9.7             15.9   0.89  108.0   78.0  87.0   \n",
       "1     0.2   5.51  ...     19.9             27.9   0.99  138.0   92.0  73.0   \n",
       "2     0.7   4.85  ...     22.6             36.7   0.89  127.0   80.0  66.0   \n",
       "3     0.6   6.14  ...     16.0             30.9   0.82  119.0   83.0  77.0   \n",
       "4     0.1   4.93  ...     14.9             26.8   0.80  110.0   68.0  67.0   \n",
       "..    ...    ...  ...      ...              ...    ...    ...    ...   ...   \n",
       "383   0.4   5.32  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "384   2.3   5.82  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "385     1   6.18  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "386   1.2   6.67  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "387   0.8   7.03  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "\n",
       "     Waist_2  Chol_2  BUN_2  HDL_2  \n",
       "0       83.0     NaN   13.1   77.0  \n",
       "1       90.5     NaN   19.2   59.0  \n",
       "2       86.5     NaN   17.1   40.0  \n",
       "3       77.0     NaN   12.2   54.0  \n",
       "4       66.5     NaN   16.5   72.0  \n",
       "..       ...     ...    ...    ...  \n",
       "383      NaN     NaN    NaN    NaN  \n",
       "384      NaN     NaN    NaN    NaN  \n",
       "385      NaN     NaN    NaN    NaN  \n",
       "386      NaN     NaN    NaN    NaN  \n",
       "387      NaN     NaN    NaN    NaN  \n",
       "\n",
       "[388 rows x 53 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample_ID</th>\n",
       "      <th>GROUP</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>Chol_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>HDL_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S0001</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>21.110190</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>9.7</td>\n",
       "      <td>15.9</td>\n",
       "      <td>0.89</td>\n",
       "      <td>108.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.1</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0002</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>27.782064</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5.51</td>\n",
       "      <td>...</td>\n",
       "      <td>19.9</td>\n",
       "      <td>27.9</td>\n",
       "      <td>0.99</td>\n",
       "      <td>138.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>90.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.2</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S0003</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>F</td>\n",
       "      <td>24.944742</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.85</td>\n",
       "      <td>...</td>\n",
       "      <td>22.6</td>\n",
       "      <td>36.7</td>\n",
       "      <td>0.89</td>\n",
       "      <td>127.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>86.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.1</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S0004</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>22.620489</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>6.14</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>30.9</td>\n",
       "      <td>0.82</td>\n",
       "      <td>119.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.2</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S0005</td>\n",
       "      <td>SMI</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>20.524157</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.93</td>\n",
       "      <td>...</td>\n",
       "      <td>14.9</td>\n",
       "      <td>26.8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>110.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>66.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.5</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>MetS_S0280</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>34.803410</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>MetS_S0281</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>F</td>\n",
       "      <td>30.903615</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.82</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>MetS_S0282</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>28.676533</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1</td>\n",
       "      <td>6.18</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>MetS_S0283</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>M</td>\n",
       "      <td>24.549738</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.67</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>MetS_S0284</td>\n",
       "      <td>MetS</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>F</td>\n",
       "      <td>24.605921</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.03</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>317 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sample_ID GROUP  COHORT  AGE SEX      BMI_1  PSQI_TOTAL_1 Insulin _1  \\\n",
       "0         S0001   SMI       2   60   M  21.110190           8.0        7.7   \n",
       "1         S0002   SMI       2   61   M  27.782064           4.0        5.4   \n",
       "2         S0003   SMI       2   52   F  24.944742           3.0        5.1   \n",
       "3         S0004   SMI       2   41   F  22.620489           6.0        4.2   \n",
       "4         S0005   SMI       2   41   F  20.524157          10.0        3.2   \n",
       "..          ...   ...     ...  ...  ..        ...           ...        ...   \n",
       "383  MetS_S0280  MetS       1   24   F  34.803410           5.0       11.3   \n",
       "384  MetS_S0281  MetS       1   44   F  30.903615           3.0       10.6   \n",
       "385  MetS_S0282  MetS       1   37   F  28.676533           3.0       12.2   \n",
       "386  MetS_S0283  MetS       1   51   M  24.549738           5.0       10.4   \n",
       "387  MetS_S0284  MetS       1   42   F  24.605921           3.0       10.1   \n",
       "\n",
       "    CRP_1  WBC_1  ...  Fat_2_x  FatPercentage_2  WHR_2  SBP_2  DBP_2  HR_2  \\\n",
       "0     0.2   3.91  ...      9.7             15.9   0.89  108.0   78.0  87.0   \n",
       "1     0.2   5.51  ...     19.9             27.9   0.99  138.0   92.0  73.0   \n",
       "2     0.7   4.85  ...     22.6             36.7   0.89  127.0   80.0  66.0   \n",
       "3     0.6   6.14  ...     16.0             30.9   0.82  119.0   83.0  77.0   \n",
       "4     0.1   4.93  ...     14.9             26.8   0.80  110.0   68.0  67.0   \n",
       "..    ...    ...  ...      ...              ...    ...    ...    ...   ...   \n",
       "383   0.4   5.32  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "384   2.3   5.82  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "385     1   6.18  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "386   1.2   6.67  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "387   0.8   7.03  ...      NaN              NaN    NaN    NaN    NaN   NaN   \n",
       "\n",
       "     Waist_2  Chol_2  BUN_2  HDL_2  \n",
       "0       83.0     NaN   13.1   77.0  \n",
       "1       90.5     NaN   19.2   59.0  \n",
       "2       86.5     NaN   17.1   40.0  \n",
       "3       77.0     NaN   12.2   54.0  \n",
       "4       66.5     NaN   16.5   72.0  \n",
       "..       ...     ...    ...    ...  \n",
       "383      NaN     NaN    NaN    NaN  \n",
       "384      NaN     NaN    NaN    NaN  \n",
       "385      NaN     NaN    NaN    NaN  \n",
       "386      NaN     NaN    NaN    NaN  \n",
       "387      NaN     NaN    NaN    NaN  \n",
       "\n",
       "[317 rows x 53 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#보조 호르몬 요법을 받고 있는 Cohort 3 제거 Filter 적용\n",
    "psqi_df = psqi_df[(psqi_df['COHORT'] != 3)]\n",
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df=psqi_df.dropna()\n",
    "psqi_df.reset_index(drop=True, inplace=True)\n",
    "psqi_df.isnull().sum()\n",
    "#psqi_df=psqi_df.drop([\"Sample_ID\", \"GROUP\", \"COHORT\"],axis=1)\n",
    "#1분, 매일다름, 정해진간이없음 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"SEX\"] = psqi_df[\"SEX\"].apply(lambda x: 1. if x=='M' else 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "psqi_df[\"Insulin _1\"] = psqi_df[\"Insulin _1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)\n",
    "psqi_df[\"Insulin _2\"] = psqi_df[\"Insulin _1\"].apply(lambda x: 0.1 if x=='<0.2' else 0. if x=='<0.1' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>Neutrophil_1</th>\n",
       "      <th>Lym_1</th>\n",
       "      <th>GLU0_1</th>\n",
       "      <th>Creatinine_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>Chol_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>HDL_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.00000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>180.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.366667</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>23.799644</td>\n",
       "      <td>5.105556</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>5.844867</td>\n",
       "      <td>56.086111</td>\n",
       "      <td>34.113333</td>\n",
       "      <td>98.90000</td>\n",
       "      <td>0.857778</td>\n",
       "      <td>...</td>\n",
       "      <td>19.053333</td>\n",
       "      <td>28.888333</td>\n",
       "      <td>0.862444</td>\n",
       "      <td>114.605556</td>\n",
       "      <td>72.477778</td>\n",
       "      <td>75.644444</td>\n",
       "      <td>81.328889</td>\n",
       "      <td>190.922222</td>\n",
       "      <td>12.984444</td>\n",
       "      <td>59.20000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>11.589776</td>\n",
       "      <td>0.461927</td>\n",
       "      <td>4.936177</td>\n",
       "      <td>2.893833</td>\n",
       "      <td>4.105985</td>\n",
       "      <td>1.412280</td>\n",
       "      <td>8.502880</td>\n",
       "      <td>7.708889</td>\n",
       "      <td>14.43773</td>\n",
       "      <td>1.631532</td>\n",
       "      <td>...</td>\n",
       "      <td>6.616151</td>\n",
       "      <td>7.098802</td>\n",
       "      <td>0.071696</td>\n",
       "      <td>13.213544</td>\n",
       "      <td>9.091991</td>\n",
       "      <td>10.306814</td>\n",
       "      <td>10.251265</td>\n",
       "      <td>32.017358</td>\n",
       "      <td>3.508550</td>\n",
       "      <td>14.01372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.231576</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>2.820000</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>63.00000</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>29.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.833309</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.857500</td>\n",
       "      <td>50.525000</td>\n",
       "      <td>28.975000</td>\n",
       "      <td>92.00000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>24.275000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>73.875000</td>\n",
       "      <td>167.750000</td>\n",
       "      <td>10.675000</td>\n",
       "      <td>49.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>35.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.422889</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>5.720000</td>\n",
       "      <td>55.950000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>95.50000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>...</td>\n",
       "      <td>17.950000</td>\n",
       "      <td>28.450000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>80.500000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>12.700000</td>\n",
       "      <td>57.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.502662</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.505000</td>\n",
       "      <td>6.580000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>102.00000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.125000</td>\n",
       "      <td>33.450000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>77.250000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>69.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>63.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>24.700000</td>\n",
       "      <td>10.550000</td>\n",
       "      <td>78.400000</td>\n",
       "      <td>55.400000</td>\n",
       "      <td>182.00000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>46.100000</td>\n",
       "      <td>48.300000</td>\n",
       "      <td>1.070000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>36.400000</td>\n",
       "      <td>116.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              AGE         SEX       BMI_1  PSQI_TOTAL_1  Insulin _1  \\\n",
       "count  180.000000  180.000000  180.000000    180.000000  180.000000   \n",
       "mean    38.366667    0.305556   23.799644      5.105556    7.700000   \n",
       "std     11.589776    0.461927    4.936177      2.893833    4.105985   \n",
       "min     20.000000    0.000000   15.231576      0.000000    0.100000   \n",
       "25%     29.000000    0.000000   20.833309      3.000000    5.000000   \n",
       "50%     35.500000    0.000000   23.422889      5.000000    6.500000   \n",
       "75%     46.000000    1.000000   25.502662      7.000000    9.505000   \n",
       "max     63.000000    1.000000   67.500000     14.000000   24.700000   \n",
       "\n",
       "            WBC_1  Neutrophil_1       Lym_1     GLU0_1  Creatinine_1  ...  \\\n",
       "count  180.000000    180.000000  180.000000  180.00000    180.000000  ...   \n",
       "mean     5.844867     56.086111   34.113333   98.90000      0.857778  ...   \n",
       "std      1.412280      8.502880    7.708889   14.43773      1.631532  ...   \n",
       "min      2.820000     34.500000   15.100000   63.00000      0.380000  ...   \n",
       "25%      4.857500     50.525000   28.975000   92.00000      0.620000  ...   \n",
       "50%      5.720000     55.950000   34.000000   95.50000      0.720000  ...   \n",
       "75%      6.580000     62.000000   39.000000  102.00000      0.810000  ...   \n",
       "max     10.550000     78.400000   55.400000  182.00000     22.500000  ...   \n",
       "\n",
       "          Fat_2_x  FatPercentage_2       WHR_2       SBP_2       DBP_2  \\\n",
       "count  180.000000       180.000000  180.000000  180.000000  180.000000   \n",
       "mean    19.053333        28.888333    0.862444  114.605556   72.477778   \n",
       "std      6.616151         7.098802    0.071696   13.213544    9.091991   \n",
       "min      7.700000        11.500000    0.700000   91.000000   57.000000   \n",
       "25%     14.200000        24.275000    0.820000  104.000000   67.000000   \n",
       "50%     17.950000        28.450000    0.850000  114.000000   71.000000   \n",
       "75%     22.125000        33.450000    0.900000  123.000000   77.250000   \n",
       "max     46.100000        48.300000    1.070000  158.000000  107.000000   \n",
       "\n",
       "             HR_2     Waist_2      Chol_2       BUN_2      HDL_2  \n",
       "count  180.000000  180.000000  180.000000  180.000000  180.00000  \n",
       "mean    75.644444   81.328889  190.922222   12.984444   59.20000  \n",
       "std     10.306814   10.251265   32.017358    3.508550   14.01372  \n",
       "min     54.000000   61.000000  109.000000    6.000000   29.00000  \n",
       "25%     68.000000   73.875000  167.750000   10.675000   49.00000  \n",
       "50%     75.000000   80.500000  188.000000   12.700000   57.00000  \n",
       "75%     82.000000   89.000000  211.000000   14.600000   69.00000  \n",
       "max    112.000000  118.000000  296.000000   36.400000  116.00000  \n",
       "\n",
       "[8 rows x 48 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    125\n",
       "1.0     55\n",
       "Name: SEX, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df[\"SEX\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI_1</th>\n",
       "      <th>PSQI_TOTAL_1</th>\n",
       "      <th>Insulin _1</th>\n",
       "      <th>CRP_1</th>\n",
       "      <th>WBC_1</th>\n",
       "      <th>Neutrophil_1</th>\n",
       "      <th>Lym_1</th>\n",
       "      <th>GLU0_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Fat_2_x</th>\n",
       "      <th>FatPercentage_2</th>\n",
       "      <th>WHR_2</th>\n",
       "      <th>SBP_2</th>\n",
       "      <th>DBP_2</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>Waist_2</th>\n",
       "      <th>Chol_2</th>\n",
       "      <th>BUN_2</th>\n",
       "      <th>HDL_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.097789</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.57</td>\n",
       "      <td>&lt;0.1</td>\n",
       "      <td>5.82</td>\n",
       "      <td>54.6</td>\n",
       "      <td>35.0</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>20.4</td>\n",
       "      <td>26.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>131.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>88.5</td>\n",
       "      <td>180.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.472213</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.35</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5.46</td>\n",
       "      <td>44.3</td>\n",
       "      <td>43.7</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>18.6</td>\n",
       "      <td>0.84</td>\n",
       "      <td>126.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.744827</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.26</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3.99</td>\n",
       "      <td>51.0</td>\n",
       "      <td>37.8</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>17.8</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.89</td>\n",
       "      <td>131.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.616175</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.52</td>\n",
       "      <td>&lt;0.1</td>\n",
       "      <td>5.84</td>\n",
       "      <td>39.1</td>\n",
       "      <td>42.1</td>\n",
       "      <td>81</td>\n",
       "      <td>...</td>\n",
       "      <td>12.8</td>\n",
       "      <td>21.9</td>\n",
       "      <td>0.78</td>\n",
       "      <td>102.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.437500</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.86</td>\n",
       "      <td>&lt;0.1</td>\n",
       "      <td>4.22</td>\n",
       "      <td>49.3</td>\n",
       "      <td>39.3</td>\n",
       "      <td>63</td>\n",
       "      <td>...</td>\n",
       "      <td>12.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>106.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>11.3</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.259585</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.20</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.78</td>\n",
       "      <td>42.3</td>\n",
       "      <td>47.3</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>27.3</td>\n",
       "      <td>39.3</td>\n",
       "      <td>0.94</td>\n",
       "      <td>134.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.630719</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.80</td>\n",
       "      <td>3</td>\n",
       "      <td>4.60</td>\n",
       "      <td>51.7</td>\n",
       "      <td>34.6</td>\n",
       "      <td>94</td>\n",
       "      <td>...</td>\n",
       "      <td>22.1</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.95</td>\n",
       "      <td>113.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>134.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.641274</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6.34</td>\n",
       "      <td>55.9</td>\n",
       "      <td>34.9</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>17.5</td>\n",
       "      <td>29.9</td>\n",
       "      <td>0.84</td>\n",
       "      <td>107.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>80.5</td>\n",
       "      <td>147.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.421366</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.80</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.88</td>\n",
       "      <td>40.9</td>\n",
       "      <td>48.0</td>\n",
       "      <td>93</td>\n",
       "      <td>...</td>\n",
       "      <td>15.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>106.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.271653</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.28</td>\n",
       "      <td>75.7</td>\n",
       "      <td>15.1</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>9.3</td>\n",
       "      <td>13.1</td>\n",
       "      <td>0.85</td>\n",
       "      <td>104.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     AGE  SEX      BMI_1  PSQI_TOTAL_1  Insulin _1 CRP_1  WBC_1  Neutrophil_1  \\\n",
       "0     35  1.0  24.097789           5.0        5.57  <0.1   5.82          54.6   \n",
       "1     46  1.0  23.472213           5.0        7.35   0.7   5.46          44.3   \n",
       "2     32  1.0  23.744827           2.0        9.26   0.4   3.99          51.0   \n",
       "3     33  0.0  20.616175           4.0        3.52  <0.1   5.84          39.1   \n",
       "4     28  0.0  18.437500           3.0        2.86  <0.1   4.22          49.3   \n",
       "..   ...  ...        ...           ...         ...   ...    ...           ...   \n",
       "175   63  0.0  26.259585           3.0        4.20   0.2   4.78          42.3   \n",
       "176   57  1.0  28.630719           4.0        8.80     3   4.60          51.7   \n",
       "177   35  0.0  21.641274           1.0        6.30   0.4   6.34          55.9   \n",
       "178   61  0.0  20.421366           8.0        4.80   0.2   4.88          40.9   \n",
       "179   56  1.0  22.271653           1.0        9.00   0.2   6.28          75.7   \n",
       "\n",
       "     Lym_1  GLU0_1  ...  Fat_2_x  FatPercentage_2  WHR_2  SBP_2  DBP_2   HR_2  \\\n",
       "0     35.0      89  ...     20.4             26.8   1.00  131.0   74.0   66.0   \n",
       "1     43.7      90  ...     14.5             18.6   0.84  126.0   87.0  108.0   \n",
       "2     37.8      96  ...     17.8             25.6   0.89  131.0   77.0   87.0   \n",
       "3     42.1      81  ...     12.8             21.9   0.78  102.0   62.0   70.0   \n",
       "4     39.3      63  ...     12.3             25.6   0.80  106.0   72.0   69.0   \n",
       "..     ...     ...  ...      ...              ...    ...    ...    ...    ...   \n",
       "175   47.3      96  ...     27.3             39.3   0.94  134.0   89.0   81.0   \n",
       "176   34.6      94  ...     22.1             25.7   0.95  113.0   76.0   66.0   \n",
       "177   34.9      87  ...     17.5             29.9   0.84  107.0   72.0   64.0   \n",
       "178   48.0      93  ...     15.3             29.0   0.81  106.0   76.0   92.0   \n",
       "179   15.1     125  ...      9.3             13.1   0.85  104.0   73.0   79.0   \n",
       "\n",
       "     Waist_2  Chol_2  BUN_2  HDL_2  \n",
       "0       88.5   180.0   17.5   53.0  \n",
       "1       85.0   203.0   14.4   64.0  \n",
       "2       81.0   196.0   14.1   49.0  \n",
       "3       69.0   224.0   10.5   98.0  \n",
       "4       61.0   168.0   11.3   71.0  \n",
       "..       ...     ...    ...    ...  \n",
       "175     98.0   141.0   17.1   66.0  \n",
       "176     97.5   134.0   14.6   51.0  \n",
       "177     80.5   147.0    9.7   49.0  \n",
       "178     79.0   134.0   10.2   60.0  \n",
       "179     91.0   148.0   36.4   31.0  \n",
       "\n",
       "[180 rows x 50 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "psqi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x 배열 생성 (x=AGE, SEX, PSQI, BMI)\n",
    "X1=psqi_df[['AGE','SEX','BMI_1','PSQI_TOTAL_1','Insulin _1','CRP_1','WBC_1','Neutrophil_1','Lym_1','GLU0_1',\n",
    "            'Creatinine_1','AST_1','ALT_1','TG_1','LDL_1','Muscle_1','Fat_1_x','FatPercentage _1','WHR_1','SBP_1',\n",
    "            'DBP_1','HR_1','Waist_1','Chol_1','BUN_1']]\n",
    "\n",
    "X2=psqi_df[['AGE','SEX','BMI_2','PSQI_TOTAL_2','Insulin _2','CRP_2','WBC_2','Neutrophil_2','Lym_2','GLU0_2',\n",
    "            'Creatinine_2','AST_2','ALT_2','TG_2','LDL_2','Muscle_2','Fat_2_x','FatPercentage_2','WHR_2','SBP_2',\n",
    "            'DBP_2','HR_2','Waist_2','Chol_2','BUN_2']]\n",
    "X=np.concatenate((X1, X2), axis=0)\n",
    "\n",
    "#y 배열 생성 (y=HDL)\n",
    "Y1= psqi_df[['HDL_1']].values\n",
    "Y2= psqi_df[['HDL_2']].values\n",
    "Y=np.concatenate((Y1, Y2), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360, 360)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((360, 25), (360, 1))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#정규화 (변수간의 스케일 차이)\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "X=np.asarray(X).astype(np.float)\n",
    "Y=np.asarray(Y).astype(np.float)\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(291, 73)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((364, 29), (364, 1))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X.shape[1]\n",
    "dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "73/73 - 0s - loss: 3558.9670 - mse: 3558.9670\n",
      "Epoch 2/150\n",
      "73/73 - 0s - loss: 2851.5046 - mse: 2851.5046\n",
      "Epoch 3/150\n",
      "73/73 - 0s - loss: 1785.2904 - mse: 1785.2904\n",
      "Epoch 4/150\n",
      "73/73 - 0s - loss: 761.4655 - mse: 761.4655\n",
      "Epoch 5/150\n",
      "73/73 - 0s - loss: 394.1552 - mse: 394.1552\n",
      "Epoch 6/150\n",
      "73/73 - 0s - loss: 299.1922 - mse: 299.1922\n",
      "Epoch 7/150\n",
      "73/73 - 0s - loss: 249.3072 - mse: 249.3072\n",
      "Epoch 8/150\n",
      "73/73 - 0s - loss: 221.9204 - mse: 221.9204\n",
      "Epoch 9/150\n",
      "73/73 - 0s - loss: 199.9163 - mse: 199.9163\n",
      "Epoch 10/150\n",
      "73/73 - 0s - loss: 186.9595 - mse: 186.9595\n",
      "Epoch 11/150\n",
      "73/73 - 0s - loss: 173.9228 - mse: 173.9228\n",
      "Epoch 12/150\n",
      "73/73 - 0s - loss: 164.9903 - mse: 164.9903\n",
      "Epoch 13/150\n",
      "73/73 - 0s - loss: 156.7066 - mse: 156.7066\n",
      "Epoch 14/150\n",
      "73/73 - 0s - loss: 150.2861 - mse: 150.2861\n",
      "Epoch 15/150\n",
      "73/73 - 0s - loss: 144.9669 - mse: 144.9669\n",
      "Epoch 16/150\n",
      "73/73 - 0s - loss: 139.6684 - mse: 139.6684\n",
      "Epoch 17/150\n",
      "73/73 - 0s - loss: 134.2883 - mse: 134.2883\n",
      "Epoch 18/150\n",
      "73/73 - 0s - loss: 131.0194 - mse: 131.0194\n",
      "Epoch 19/150\n",
      "73/73 - 0s - loss: 126.1009 - mse: 126.1009\n",
      "Epoch 20/150\n",
      "73/73 - 0s - loss: 123.5575 - mse: 123.5575\n",
      "Epoch 21/150\n",
      "73/73 - 0s - loss: 120.4720 - mse: 120.4720\n",
      "Epoch 22/150\n",
      "73/73 - 0s - loss: 118.5722 - mse: 118.5722\n",
      "Epoch 23/150\n",
      "73/73 - 0s - loss: 115.7672 - mse: 115.7672\n",
      "Epoch 24/150\n",
      "73/73 - 0s - loss: 111.2371 - mse: 111.2371\n",
      "Epoch 25/150\n",
      "73/73 - 0s - loss: 111.1977 - mse: 111.1977\n",
      "Epoch 26/150\n",
      "73/73 - 0s - loss: 108.1810 - mse: 108.1810\n",
      "Epoch 27/150\n",
      "73/73 - 0s - loss: 105.8285 - mse: 105.8285\n",
      "Epoch 28/150\n",
      "73/73 - 0s - loss: 104.3222 - mse: 104.3222\n",
      "Epoch 29/150\n",
      "73/73 - 0s - loss: 102.0468 - mse: 102.0468\n",
      "Epoch 30/150\n",
      "73/73 - 0s - loss: 100.4745 - mse: 100.4745\n",
      "Epoch 31/150\n",
      "73/73 - 0s - loss: 98.8119 - mse: 98.8119\n",
      "Epoch 32/150\n",
      "73/73 - 0s - loss: 96.3817 - mse: 96.3817\n",
      "Epoch 33/150\n",
      "73/73 - 0s - loss: 94.9897 - mse: 94.9897\n",
      "Epoch 34/150\n",
      "73/73 - 0s - loss: 94.1698 - mse: 94.1698\n",
      "Epoch 35/150\n",
      "73/73 - 0s - loss: 92.5761 - mse: 92.5761\n",
      "Epoch 36/150\n",
      "73/73 - 0s - loss: 91.6432 - mse: 91.6432\n",
      "Epoch 37/150\n",
      "73/73 - 0s - loss: 90.4566 - mse: 90.4566\n",
      "Epoch 38/150\n",
      "73/73 - 0s - loss: 88.2992 - mse: 88.2992\n",
      "Epoch 39/150\n",
      "73/73 - 0s - loss: 88.2312 - mse: 88.2312\n",
      "Epoch 40/150\n",
      "73/73 - 0s - loss: 85.6698 - mse: 85.6698\n",
      "Epoch 41/150\n",
      "73/73 - 0s - loss: 85.3418 - mse: 85.3418\n",
      "Epoch 42/150\n",
      "73/73 - 0s - loss: 84.3577 - mse: 84.3577\n",
      "Epoch 43/150\n",
      "73/73 - 0s - loss: 83.2451 - mse: 83.2451\n",
      "Epoch 44/150\n",
      "73/73 - 0s - loss: 82.1232 - mse: 82.1232\n",
      "Epoch 45/150\n",
      "73/73 - 0s - loss: 81.1294 - mse: 81.1294\n",
      "Epoch 46/150\n",
      "73/73 - 0s - loss: 79.4298 - mse: 79.4298\n",
      "Epoch 47/150\n",
      "73/73 - 0s - loss: 80.0781 - mse: 80.0781\n",
      "Epoch 48/150\n",
      "73/73 - 0s - loss: 78.1594 - mse: 78.1594\n",
      "Epoch 49/150\n",
      "73/73 - 0s - loss: 77.4358 - mse: 77.4358\n",
      "Epoch 50/150\n",
      "73/73 - 0s - loss: 77.0333 - mse: 77.0333\n",
      "Epoch 51/150\n",
      "73/73 - 0s - loss: 75.7217 - mse: 75.7217\n",
      "Epoch 52/150\n",
      "73/73 - 0s - loss: 74.9008 - mse: 74.9008\n",
      "Epoch 53/150\n",
      "73/73 - 0s - loss: 74.5749 - mse: 74.5749\n",
      "Epoch 54/150\n",
      "73/73 - 0s - loss: 72.2310 - mse: 72.2310\n",
      "Epoch 55/150\n",
      "73/73 - 0s - loss: 73.1553 - mse: 73.1553\n",
      "Epoch 56/150\n",
      "73/73 - 0s - loss: 71.4287 - mse: 71.4287\n",
      "Epoch 57/150\n",
      "73/73 - 0s - loss: 71.4136 - mse: 71.4136\n",
      "Epoch 58/150\n",
      "73/73 - 0s - loss: 70.6267 - mse: 70.6267\n",
      "Epoch 59/150\n",
      "73/73 - 0s - loss: 70.0109 - mse: 70.0109\n",
      "Epoch 60/150\n",
      "73/73 - 0s - loss: 68.7969 - mse: 68.7969\n",
      "Epoch 61/150\n",
      "73/73 - 0s - loss: 67.6265 - mse: 67.6265\n",
      "Epoch 62/150\n",
      "73/73 - 0s - loss: 67.0651 - mse: 67.0651\n",
      "Epoch 63/150\n",
      "73/73 - 0s - loss: 66.5302 - mse: 66.5302\n",
      "Epoch 64/150\n",
      "73/73 - 0s - loss: 66.2922 - mse: 66.2922\n",
      "Epoch 65/150\n",
      "73/73 - 0s - loss: 65.2704 - mse: 65.2704\n",
      "Epoch 66/150\n",
      "73/73 - 0s - loss: 64.9653 - mse: 64.9653\n",
      "Epoch 67/150\n",
      "73/73 - 0s - loss: 63.5062 - mse: 63.5062\n",
      "Epoch 68/150\n",
      "73/73 - 0s - loss: 63.3665 - mse: 63.3665\n",
      "Epoch 69/150\n",
      "73/73 - 0s - loss: 62.9248 - mse: 62.9248\n",
      "Epoch 70/150\n",
      "73/73 - 0s - loss: 62.6999 - mse: 62.6999\n",
      "Epoch 71/150\n",
      "73/73 - 0s - loss: 60.0867 - mse: 60.0867\n",
      "Epoch 72/150\n",
      "73/73 - 0s - loss: 60.9365 - mse: 60.9365\n",
      "Epoch 73/150\n",
      "73/73 - 0s - loss: 59.7916 - mse: 59.7916\n",
      "Epoch 74/150\n",
      "73/73 - 0s - loss: 58.9314 - mse: 58.9314\n",
      "Epoch 75/150\n",
      "73/73 - 0s - loss: 59.2400 - mse: 59.2400\n",
      "Epoch 76/150\n",
      "73/73 - 0s - loss: 58.8861 - mse: 58.8861\n",
      "Epoch 77/150\n",
      "73/73 - 0s - loss: 57.7803 - mse: 57.7803\n",
      "Epoch 78/150\n",
      "73/73 - 0s - loss: 56.0385 - mse: 56.0385\n",
      "Epoch 79/150\n",
      "73/73 - 0s - loss: 56.5519 - mse: 56.5519\n",
      "Epoch 80/150\n",
      "73/73 - 0s - loss: 55.9753 - mse: 55.9753\n",
      "Epoch 81/150\n",
      "73/73 - 0s - loss: 55.4485 - mse: 55.4485\n",
      "Epoch 82/150\n",
      "73/73 - 0s - loss: 54.8231 - mse: 54.8231\n",
      "Epoch 83/150\n",
      "73/73 - 0s - loss: 54.3827 - mse: 54.3827\n",
      "Epoch 84/150\n",
      "73/73 - 0s - loss: 54.4213 - mse: 54.4213\n",
      "Epoch 85/150\n",
      "73/73 - 0s - loss: 52.8659 - mse: 52.8659\n",
      "Epoch 86/150\n",
      "73/73 - 0s - loss: 52.9284 - mse: 52.9284\n",
      "Epoch 87/150\n",
      "73/73 - 0s - loss: 51.9225 - mse: 51.9225\n",
      "Epoch 88/150\n",
      "73/73 - 0s - loss: 51.3200 - mse: 51.3200\n",
      "Epoch 89/150\n",
      "73/73 - 0s - loss: 50.7118 - mse: 50.7118\n",
      "Epoch 90/150\n",
      "73/73 - 0s - loss: 50.2002 - mse: 50.2002\n",
      "Epoch 91/150\n",
      "73/73 - 0s - loss: 48.9410 - mse: 48.9410\n",
      "Epoch 92/150\n",
      "73/73 - 0s - loss: 48.5156 - mse: 48.5156\n",
      "Epoch 93/150\n",
      "73/73 - 0s - loss: 48.7671 - mse: 48.7671\n",
      "Epoch 94/150\n",
      "73/73 - 0s - loss: 47.2807 - mse: 47.2807\n",
      "Epoch 95/150\n",
      "73/73 - 0s - loss: 47.2148 - mse: 47.2148\n",
      "Epoch 96/150\n",
      "73/73 - 0s - loss: 47.3173 - mse: 47.3173\n",
      "Epoch 97/150\n",
      "73/73 - 0s - loss: 46.1598 - mse: 46.1598\n",
      "Epoch 98/150\n",
      "73/73 - 0s - loss: 45.2180 - mse: 45.2180\n",
      "Epoch 99/150\n",
      "73/73 - 0s - loss: 45.4163 - mse: 45.4163\n",
      "Epoch 100/150\n",
      "73/73 - 0s - loss: 44.2155 - mse: 44.2155\n",
      "Epoch 101/150\n",
      "73/73 - 0s - loss: 43.9125 - mse: 43.9125\n",
      "Epoch 102/150\n",
      "73/73 - 0s - loss: 43.4825 - mse: 43.4825\n",
      "Epoch 103/150\n",
      "73/73 - 0s - loss: 43.1459 - mse: 43.1459\n",
      "Epoch 104/150\n",
      "73/73 - 0s - loss: 42.0004 - mse: 42.0004\n",
      "Epoch 105/150\n",
      "73/73 - 0s - loss: 42.3671 - mse: 42.3671\n",
      "Epoch 106/150\n",
      "73/73 - 0s - loss: 40.9704 - mse: 40.9704\n",
      "Epoch 107/150\n",
      "73/73 - 0s - loss: 41.2872 - mse: 41.2872\n",
      "Epoch 108/150\n",
      "73/73 - 0s - loss: 39.7985 - mse: 39.7985\n",
      "Epoch 109/150\n",
      "73/73 - 0s - loss: 40.1646 - mse: 40.1646\n",
      "Epoch 110/150\n",
      "73/73 - 0s - loss: 39.7843 - mse: 39.7843\n",
      "Epoch 111/150\n",
      "73/73 - 0s - loss: 40.0415 - mse: 40.0415\n",
      "Epoch 112/150\n",
      "73/73 - 0s - loss: 37.8942 - mse: 37.8942\n",
      "Epoch 113/150\n",
      "73/73 - 0s - loss: 37.5086 - mse: 37.5086\n",
      "Epoch 114/150\n",
      "73/73 - 0s - loss: 37.7149 - mse: 37.7149\n",
      "Epoch 115/150\n",
      "73/73 - 0s - loss: 37.2052 - mse: 37.2052\n",
      "Epoch 116/150\n",
      "73/73 - 0s - loss: 36.3398 - mse: 36.3398\n",
      "Epoch 117/150\n",
      "73/73 - 0s - loss: 35.8721 - mse: 35.8721\n",
      "Epoch 118/150\n",
      "73/73 - 0s - loss: 35.1215 - mse: 35.1215\n",
      "Epoch 119/150\n",
      "73/73 - 0s - loss: 35.3020 - mse: 35.3020\n",
      "Epoch 120/150\n",
      "73/73 - 0s - loss: 34.5115 - mse: 34.5115\n",
      "Epoch 121/150\n",
      "73/73 - 0s - loss: 33.4299 - mse: 33.4299\n",
      "Epoch 122/150\n",
      "73/73 - 0s - loss: 33.3263 - mse: 33.3263\n",
      "Epoch 123/150\n",
      "73/73 - 0s - loss: 33.4869 - mse: 33.4869\n",
      "Epoch 124/150\n",
      "73/73 - 0s - loss: 32.4967 - mse: 32.4967\n",
      "Epoch 125/150\n",
      "73/73 - 0s - loss: 32.2397 - mse: 32.2397\n",
      "Epoch 126/150\n",
      "73/73 - 0s - loss: 31.6306 - mse: 31.6306\n",
      "Epoch 127/150\n",
      "73/73 - 0s - loss: 30.7560 - mse: 30.7560\n",
      "Epoch 128/150\n",
      "73/73 - 0s - loss: 29.7329 - mse: 29.7329\n",
      "Epoch 129/150\n",
      "73/73 - 0s - loss: 30.4756 - mse: 30.4756\n",
      "Epoch 130/150\n",
      "73/73 - 0s - loss: 29.2165 - mse: 29.2165\n",
      "Epoch 131/150\n",
      "73/73 - 0s - loss: 28.9466 - mse: 28.9466\n",
      "Epoch 132/150\n",
      "73/73 - 0s - loss: 29.0463 - mse: 29.0463\n",
      "Epoch 133/150\n",
      "73/73 - 0s - loss: 28.5711 - mse: 28.5711\n",
      "Epoch 134/150\n",
      "73/73 - 0s - loss: 28.1976 - mse: 28.1976\n",
      "Epoch 135/150\n",
      "73/73 - 0s - loss: 27.2515 - mse: 27.2515\n",
      "Epoch 136/150\n",
      "73/73 - 0s - loss: 27.2460 - mse: 27.2460\n",
      "Epoch 137/150\n",
      "73/73 - 0s - loss: 27.0443 - mse: 27.0443\n",
      "Epoch 138/150\n",
      "73/73 - 0s - loss: 26.1221 - mse: 26.1221\n",
      "Epoch 139/150\n",
      "73/73 - 0s - loss: 25.5320 - mse: 25.5320\n",
      "Epoch 140/150\n",
      "73/73 - 0s - loss: 25.4825 - mse: 25.4825\n",
      "Epoch 141/150\n",
      "73/73 - 0s - loss: 25.4043 - mse: 25.4043\n",
      "Epoch 142/150\n",
      "73/73 - 0s - loss: 24.9217 - mse: 24.9217\n",
      "Epoch 143/150\n",
      "73/73 - 0s - loss: 24.5358 - mse: 24.5358\n",
      "Epoch 144/150\n",
      "73/73 - 0s - loss: 23.8122 - mse: 23.8122\n",
      "Epoch 145/150\n",
      "73/73 - 0s - loss: 23.2525 - mse: 23.2525\n",
      "Epoch 146/150\n",
      "73/73 - 0s - loss: 22.6753 - mse: 22.6753\n",
      "Epoch 147/150\n",
      "73/73 - 0s - loss: 22.9553 - mse: 22.9553\n",
      "Epoch 148/150\n",
      "73/73 - 0s - loss: 22.1936 - mse: 22.1936\n",
      "Epoch 149/150\n",
      "73/73 - 0s - loss: 21.7258 - mse: 21.7258\n",
      "Epoch 150/150\n",
      "73/73 - 0s - loss: 21.4881 - mse: 21.4881\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe29e9051f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x7fe29e9051f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 195.7815 - mse: 195.7815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[195.78152465820312, 195.78150939941406]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define model\n",
    "model=Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=dim))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "\n",
    "model.compile(loss='mse',optimizer='rmsprop',metrics=['mse'])\n",
    "\n",
    "#fit model\n",
    "history=model.fit(x_train, y_train, epochs=150, batch_size=4, verbose=2)\n",
    "model.evaluate(x_test, y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 32)                960       \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 2,049\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_p = model.predict(x_train)\n",
    "y_test_p = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for t,p in zip(y_train,y_train_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for t,p in zip(y_test,y_test_p):\n",
    "    print(t,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list=np.array(y_train).flatten().tolist() #y_train 리스트\n",
    "y_test_list=np.array(y_test).flatten().tolist() #y_test 리스트\n",
    "y_p_train_list=np.array(y_train_p).flatten().tolist() #y_train 예측 리스트\n",
    "y_p_test_list=np.array(y_test_p).flatten().tolist() #y_test 예측 리스트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#오차 범위 3 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set prediction accuracy: 47.77 %\n",
      "test set prediction accuracy: 53.42 %\n"
     ]
    }
   ],
   "source": [
    "#평균 성능 테스트\n",
    "scores = 0\n",
    "mean=np.mean(Y, axis=0)\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= mean <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"train set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "#======================================================================================\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= mean <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"test set prediction accuracy: {:.2f} %\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### <오차범위 3>\n",
      "- train set prediction accuracy(+-3): 67.01 % <br>\n",
      "- test set prediction accuracy(+-3): 21.92 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 5>\n",
      "- train set prediction accuracy(+-5): 83.16 % <br>\n",
      "- test set prediction accuracy(+-5): 39.73 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 10>\n",
      "- train set prediction accuracy(+-10): 95.19 % <br>\n",
      "- test set prediction accuracy(+-10): 56.16 % <br>\n",
      "<br>\n",
      "\n",
      "### <오차범위 20>\n",
      "- train set prediction accuracy(+-20): 100.00 % <br>\n",
      "- test set prediction accuracy(+-20): 83.56 % <br>\n"
     ]
    }
   ],
   "source": [
    "######입력용#######\n",
    "\n",
    "#오차 범위 3 설정\n",
    "print('### <오차범위 3>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-3 <= y_p_train_list[i] <= y_train_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-3 <= y_p_test_list[i] <= y_test_list[i]+3:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-3): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 5 설정\n",
    "print('### <오차범위 5>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-5 <= y_p_train_list[i] <= y_train_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-5 <= y_p_test_list[i] <= y_test_list[i]+5:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-5): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 10 설정\n",
    "print('### <오차범위 10>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-10 <= y_p_train_list[i] <= y_train_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-10 <= y_p_test_list[i] <= y_test_list[i]+10:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-10): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "print('<br>')\n",
    "print()\n",
    "#======================================================================================\n",
    "\n",
    "\n",
    "#오차 범위 20 설정\n",
    "print('### <오차범위 20>')\n",
    "scores = 0\n",
    "for i in range(len(y_train)):\n",
    "    if  y_train_list[i]-20 <= y_p_train_list[i] <= y_train_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_train)\n",
    "print(\"- train set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도\n",
    "\n",
    "\n",
    "scores = 0\n",
    "for i in range(len(y_test)):\n",
    "    if  y_test_list[i]-20 <= y_p_test_list[i] <= y_test_list[i]+20:\n",
    "        scores+=1\n",
    "\n",
    "accuracy=scores/len(y_test)\n",
    "print(\"- test set prediction accuracy(+-20): {:.2f} % <br>\".format(accuracy*100)) # 예측 정확도"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## age, sex, psqi, bmi (각 항목 넣은거)\n",
    "\n",
    "### <오차범위 3>\n",
    "- train set prediction accuracy(+-3): 67.01 % <br>\n",
    "- test set prediction accuracy(+-3): 21.92 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 5>\n",
    "- train set prediction accuracy(+-5): 83.16 % <br>\n",
    "- test set prediction accuracy(+-5): 39.73 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 10>\n",
    "- train set prediction accuracy(+-10): 95.19 % <br>\n",
    "- test set prediction accuracy(+-10): 56.16 % <br>\n",
    "<br>\n",
    "\n",
    "### <오차범위 20>\n",
    "- train set prediction accuracy(+-20): 100.00 % <br>\n",
    "- test set prediction accuracy(+-20): 83.56 % <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1642828349419,
     "user": {
      "displayName": "양수빈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZpClH7QNtKhKeJIcs3sa4-tZizTNC7lJVLbnyOw=s64",
      "userId": "18433039501969003379"
     },
     "user_tz": -540
    },
    "id": "5hYUMeCL51AQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate, cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tqdm import tqdm\n",
    "from warnings import filterwarnings\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot\n",
    "filterwarnings('ignore')\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yangb\\OneDrive\\바탕 화면\\SMU\\OneDrive - SangMyung University\\lab\\공공데이터_국민건강보험공단\\DNN_hyperlipidemia_4categorical_ALL2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<이상지질혈증 임상적 정상 범위>\n",
    "TC 200mg/dl 미만\n",
    "LDL 100mg/dl 미만\n",
    "TG 150mg/dl 미만\n",
    "HDL 40mg/dl 초과\n",
    "\n",
    "*tc 계산법 = HDL 콜레스테롤+LDL 콜레스테롤+중성지방/5\n",
    "\n",
    "TC ~99 낮음, 100~169 보통,  170~199 위험, 200~ 이상\n",
    "LDL ~49 낮음, 50~69 보통, 70~99 위험, 100~ 이상\n",
    "TG ~69 낮음,70~119 보통, 120~149 위험, 150~ 이상\n",
    "HDL 60~ 높음, 50~59 보통, 49~41 위험, ~40 이상 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv, model LOAD\n",
    "df_scaler=pd.read_csv(\"./hyperlipidemia_scaler_4categorical.csv\")\n",
    "df_scaler=df_scaler.drop([df_scaler.columns[0]], axis=1)\n",
    "\n",
    "model_1 = tf.keras.models.load_model('DNN_LDL_4categorical.h5')\n",
    "model_2= tf.keras.models.load_model('DNN_HDL_4categorical.h5')\n",
    "model_3= tf.keras.models.load_model('DNN_TG_4categorical.h5')\n",
    "model_4= tf.keras.models.load_model('DNN_TC_4categorical.h5')\n",
    "model_5= tf.keras.models.load_model('DNN_HDL_4categorical(model_5)_forprediction_LDL.h5')\n",
    "model_6= tf.keras.models.load_model('DNN_TG_4categorical(model_6)_forprediction_LDL.h5')\n",
    "model_7= tf.keras.models.load_model('DNN_TC_4categorical(model_7)_forprediction_LDL.h5')\n",
    "model_8= tf.keras.models.load_model('DNN_LDL_4categorical(model_8)_forprediction_LDL.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_1=\"LDL\"\n",
    "id_2=\"HDL\"\n",
    "id_3=\"TG\"\n",
    "id_4=\"TC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확도 배열\n",
    "accuracy_list=[0 for i in range(8)]\n",
    "\n",
    "# 클래스 개수 배열\n",
    "class_list=[[0]*4 for i in range(8)]\n",
    "\n",
    "#각 특징별 x,y 생성\n",
    "X_onlybody=df_scaler.drop(['LDL', 'HDL', 'TG', 'TC'], axis=1) #신체계측치로만 구성\n",
    "X_onlybody=np.array(X_onlybody)\n",
    "\n",
    "Y_model_1=np.array(df_scaler[id_1])\n",
    "Y_model_1=np.array(Y_model_1)\n",
    "\n",
    "Y_model_2=np.array(df_scaler[id_2])\n",
    "Y_model_2=np.array(Y_model_2)\n",
    "\n",
    "Y_model_3=np.array(df_scaler[id_3])\n",
    "Y_model_3=np.array(Y_model_3)\n",
    "\n",
    "Y_model_4=np.array(df_scaler[id_4])\n",
    "Y_model_4=np.array(Y_model_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <신체계측치를 이용해 예측한 model_1 특징 수치>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1642828358072,
     "user": {
      "displayName": "양수빈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZpClH7QNtKhKeJIcs3sa4-tZizTNC7lJVLbnyOw=s64",
      "userId": "18433039501969003379"
     },
     "user_tz": -540
    },
    "id": "fUC5ejGS51Aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 4ms/step - loss: 3.7703 - accuracy: 0.6703\n"
     ]
    }
   ],
   "source": [
    "#train-test 데이터 생성\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_onlybody, Y_model_1, train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "accuracy_list[0]=round((model_1.evaluate(x_test, y_test_encoded)[1]*100),2)\n",
    "\n",
    "predict_model_1=model_1.predict(X_onlybody)\n",
    "\n",
    "predict_model_1_list=[]\n",
    "for li in predict_model_1:\n",
    "    index=li.argmax()\n",
    "    predict_model_1_list.append(index)\n",
    "\n",
    "for i in range(4):\n",
    "    class_list[0][i]=predict_model_1_list.count(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <신체계측치를 이용해 예측한 model_2 특징 수치>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 1.8639 - accuracy: 0.5604\n"
     ]
    }
   ],
   "source": [
    "#train-test 데이터 생성\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_onlybody, Y_model_2, train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "accuracy_list[1]=round((model_2.evaluate(x_test, y_test_encoded)[1]*100),2)\n",
    "\n",
    "predict_model_2=model_2.predict(X_onlybody)\n",
    "\n",
    "predict_model_2_list=[]\n",
    "for li in predict_model_2:\n",
    "    index=li.argmax()\n",
    "    predict_model_2_list.append(index)\n",
    "\n",
    "for i in range(4):\n",
    "    class_list[1][i]=predict_model_2_list.count(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <신체계측치를 이용해 예측한 model_3 특징 수치>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1642828358072,
     "user": {
      "displayName": "양수빈",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgZpClH7QNtKhKeJIcs3sa4-tZizTNC7lJVLbnyOw=s64",
      "userId": "18433039501969003379"
     },
     "user_tz": -540
    },
    "id": "fUC5ejGS51Aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 0s/step - loss: 2.2007 - accuracy: 0.5385\n"
     ]
    }
   ],
   "source": [
    "#train-test 데이터 생성\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_onlybody, Y_model_3, train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "accuracy_list[2]=round((model_3.evaluate(x_test, y_test_encoded)[1]*100),2)\n",
    "\n",
    "predict_model_3=model_3.predict(X_onlybody)\n",
    "\n",
    "predict_model_3_list=[]\n",
    "for li in predict_model_3:\n",
    "    index=li.argmax()\n",
    "    predict_model_3_list.append(index)\n",
    "\n",
    "for i in range(4):\n",
    "    class_list[2][i]=predict_model_3_list.count(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <신체계측치를 이용해 예측한 model_4 특징 수치>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step - loss: 4.2557 - accuracy: 0.4945\n"
     ]
    }
   ],
   "source": [
    "#train-test 데이터 생성\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_onlybody, Y_model_4, train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "accuracy_list[3]=round((model_4.evaluate(x_test, y_test_encoded)[1]*100),2)\n",
    "\n",
    "predict_model_4=model_4.predict(X_onlybody)\n",
    "\n",
    "predict_model_4_list=[]\n",
    "for li in predict_model_4:\n",
    "    index=li.argmax()\n",
    "    predict_model_4_list.append(index)\n",
    "\n",
    "for i in range(4):\n",
    "    class_list[3][i]=predict_model_4_list.count(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====test-신체+일반 prediction===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model_2_list=np.array(predict_model_2_list, dtype='float64')\n",
    "predict_model_2_list=predict_model_2_list.reshape(-1,1)\n",
    "\n",
    "predict_model_3_list=np.array(predict_model_3_list, dtype='float64')\n",
    "predict_model_3_list=predict_model_3_list.reshape(-1,1)\n",
    "\n",
    "predict_model_4_list=np.array(predict_model_4_list, dtype='float64')\n",
    "predict_model_4_list=predict_model_4_list.reshape(-1,1)\n",
    "\n",
    "X_model_prediction=np.hstack([X_onlybody, predict_model_2_list, predict_model_3_list, predict_model_4_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test 데이터 생성\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_model_prediction,Y_model_1,train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step - loss: 6.3194 - accuracy: 0.6703\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.3194 - accuracy: 0.6703\n",
      "Accuracy: 0.6703\n"
     ]
    }
   ],
   "source": [
    "# DNN_prediction 모델 \n",
    "accuracy_pre=0\n",
    "while accuracy_pre<=0.67:\n",
    "    DNN_prediction = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=4, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    DNN_prediction.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    DNN_prediction.fit(x_train, y_train_encoded, epochs=150, batch_size=8, verbose=0)\n",
    "\n",
    "    accuracy_pre=round(DNN_prediction.evaluate(x_test, y_test_encoded)[1],4)\n",
    "    \n",
    "print(\"Accuracy: %.4f\" % (DNN_prediction.evaluate(x_test, y_test_encoded)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_prediction.save('DNN_normal_prediction.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ====정답 수치 넣어서 prediction===="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_real=df_scaler.drop(['LDL'], axis=1) #신체계측치+실제 HDL, TG, TC\n",
    "\n",
    "#train-test 데이터 생성\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_all_real,Y_model_1,train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step - loss: 2.4361 - accuracy: 0.7912\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.4361 - accuracy: 0.7912\n",
      "Accuracy: 0.7912\n"
     ]
    }
   ],
   "source": [
    "# DNN_prediction 모델 \n",
    "accuracy_real=0\n",
    "while accuracy_real<=0.78:\n",
    "    DNN_real = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(rate=0.2),\n",
    "        tf.keras.layers.Dense(units=32, activation='relu'),\n",
    "        tf.keras.layers.Dense(units=4, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    DNN_real.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    DNN_real.fit(x_train, y_train_encoded, epochs=150, batch_size=8, verbose=0)\n",
    "\n",
    "    accuracy_real=round(DNN_real.evaluate(x_test, y_test_encoded)[1],4)\n",
    "    \n",
    "print(\"Accuracy: %.4f\" % (DNN_real.evaluate(x_test, y_test_encoded)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_real.save('DNN_real_prediction.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <신체 + model_1 예측값 -> model_5(id_2 수치)로 예측>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F4427FC820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.1421 - accuracy: 0.5714\n"
     ]
    }
   ],
   "source": [
    "#예측값 붙여주기\n",
    "#X_model_5 = X_onlybody+model_1_prediction\n",
    "predict_model_1_list=np.array(predict_model_1_list, dtype='float64')\n",
    "predict_model_1_list=predict_model_1_list.reshape(-1,1)\n",
    "X_model_5=np.hstack([X_onlybody, predict_model_1_list])\n",
    "\n",
    "#train-test 데이터 생성\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_model_5,Y_model_2,train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "accuracy_list[4]=round((model_5.evaluate(x_test, y_test_encoded)[1]*100),2)\n",
    "\n",
    "predict_model_5=model_5.predict(X_model_5)\n",
    "\n",
    "predict_model_5_list=[]\n",
    "for li in predict_model_5:\n",
    "    index=li.argmax()\n",
    "    predict_model_5_list.append(index)\n",
    "\n",
    "for i in range(4):\n",
    "    class_list[4][i]=predict_model_5_list.count(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <신체 + model_1&5 예측값 -> model_6(id_3 수치)로 예측>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x000001F4406049D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2.3619 - accuracy: 0.5824\n"
     ]
    }
   ],
   "source": [
    "#예측값 붙여주기\n",
    "#X_model_6 = X_onlybody+model_1 & 5_prediction\n",
    "predict_model_5_list=np.array(predict_model_5_list, dtype='float64')\n",
    "predict_model_5_list=predict_model_5_list.reshape(-1,1)\n",
    "X_model_6=np.hstack([X_onlybody, predict_model_1_list, predict_model_5_list])\n",
    "\n",
    "\n",
    "#train-test 데이터 생성\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_model_6,Y_model_3,train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "accuracy_list[5]=round((model_6.evaluate(x_test, y_test_encoded)[1]*100),2)\n",
    "\n",
    "predict_model_6=model_6.predict(X_model_6)\n",
    "\n",
    "predict_model_6_list=[]\n",
    "for li in predict_model_6:\n",
    "    index=li.argmax()\n",
    "    predict_model_6_list.append(index)\n",
    "\n",
    "for i in range(4):\n",
    "    class_list[5][i]=predict_model_6_list.count(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <신체 + model_1&5&6 예측값 -> model_7(id_4 수치)로 예측>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step - loss: 6.0388 - accuracy: 0.5055\n"
     ]
    }
   ],
   "source": [
    "#예측값 붙여주기\n",
    "#X_model_7 = X_onlybody+model_1 & 5 & 6_prediction\n",
    "predict_model_6_list=np.array(predict_model_6_list, dtype='float64')\n",
    "predict_model_6_list=predict_model_6_list.reshape(-1,1)\n",
    "X_model_7=np.hstack([X_onlybody, predict_model_1_list, predict_model_5_list, predict_model_6_list])\n",
    "\n",
    "\n",
    "#train-test 데이터 생성\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_model_7,Y_model_4,train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "accuracy_list[6]=round((model_7.evaluate(x_test, y_test_encoded)[1]*100),2)\n",
    "\n",
    "predict_model_7=model_7.predict(X_model_7)\n",
    "\n",
    "predict_model_7_list=[]\n",
    "for li in predict_model_7:\n",
    "    index=li.argmax()\n",
    "    predict_model_7_list.append(index)\n",
    "\n",
    "for i in range(4):\n",
    "    class_list[6][i]=predict_model_7_list.count(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <신체 + model_5&6&7 예측값 -> model_8(id_1 수치)로 예측>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step - loss: 6.2369 - accuracy: 0.7143\n"
     ]
    }
   ],
   "source": [
    "#예측값 붙여주기\n",
    "#X_model_8 = X_onlybody+model_5 & 6 & 7_prediction\n",
    "predict_model_7_list=np.array(predict_model_7_list, dtype='float64')\n",
    "predict_model_7_list=predict_model_7_list.reshape(-1,1)\n",
    "X_model_8=np.hstack([X_onlybody, predict_model_5_list, predict_model_6_list, predict_model_7_list])\n",
    "\n",
    "\n",
    "#train-test 데이터 생성\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_model_8,Y_model_1,train_size=0.8, random_state=100)\n",
    "\n",
    "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
    "y_test_encoded = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "accuracy_list[7]=round((model_8.evaluate(x_test, y_test_encoded)[1]*100),2)\n",
    "\n",
    "predict_model_8=model_8.predict(X_model_8)\n",
    "\n",
    "predict_model_8_list=[]\n",
    "for li in predict_model_8:\n",
    "    index=li.argmax()\n",
    "    predict_model_8_list.append(index)\n",
    "\n",
    "for i in range(4):\n",
    "    class_list[7][i]=predict_model_8_list.count(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <결과 출력>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 accuracy: 67.03%\n",
      "model 2 accuracy: 56.04%\n",
      "model 3 accuracy: 53.85%\n",
      "model 4 accuracy: 49.45%\n",
      "model 5 accuracy: 57.14%\n",
      "model 6 accuracy: 58.24%\n",
      "model 7 accuracy: 50.55%\n",
      "model 8 accuracy: 71.43%\n"
     ]
    }
   ],
   "source": [
    "# 정확도 출력\n",
    "for i in range(8):\n",
    "    print(f\"model {i+1} accuracy: {accuracy_list[i]}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 class\n",
      "[1, 32, 121, 298]\n",
      "\n",
      "model 2 class\n",
      "[208, 102, 122, 20]\n",
      "\n",
      "model 3 class\n",
      "[145, 180, 53, 74]\n",
      "\n",
      "model 4 class\n",
      "[0, 125, 165, 162]\n",
      "\n",
      "model 5 class\n",
      "[213, 100, 119, 20]\n",
      "\n",
      "model 6 class\n",
      "[150, 170, 58, 74]\n",
      "\n",
      "model 7 class\n",
      "[0, 127, 150, 175]\n",
      "\n",
      "model 8 class\n",
      "[1, 30, 124, 297]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 클래스 출력\n",
    "for i in range(8):\n",
    "    print(f\"model {i+1} class\")\n",
    "    print(class_list[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "bagging_logi_ensemble.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
